== Status ==
Memory usage on this node: 1.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+-------+
| Trial name        | status   | loc   |
|-------------------+----------+-------|
| PPO_autovec_00000 | RUNNING  |       |
+-------------------+----------+-------+


[2m[36m(pid=21329)[0m /home/bdmanley/anaconda3/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.
[2m[36m(pid=21329)[0m   for external in metadata.entry_points().get(self.group, []):
[2m[36m(pid=21329)[0m 2021-12-04 11:24:02,853	INFO trainer.py:428 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
[2m[36m(pid=21329)[0m 2021-12-04 11:24:02,861	WARNING deprecation.py:30 -- DeprecationWarning: `sample_batch_size` has been deprecated. Use `rollout_fragment_length` instead. This will raise an error in the future!
[2m[36m(pid=21329)[0m 2021-12-04 11:24:02,861	INFO trainer.py:585 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=21329)[0m cp: cannot stat './training_data/*': No such file or directory
[2m[36m(pid=21329)[0m creating ./new_max8_garbage_21329 directory
[2m[36m(pid=21329)[0m running: cp -r ./training_data/* ./new_max8_garbage_21329
[2m[36m(pid=21329)[0m Checking if local obs_encodings.pkl file exists.
[2m[36m(pid=21329)[0m Checking if local O3_runtimes.pkl file exists to avoid waste of compilation.
[2m[36m(pid=21329)[0m Did not find O3_runtimes.pkl... Compiling to get -O3 runtimes.
[2m[36m(pid=21334)[0m /home/bdmanley/anaconda3/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.
[2m[36m(pid=21334)[0m   for external in metadata.entry_points().get(self.group, []):
[2m[36m(pid=21334)[0m creating ./new_max8_garbage_21334 directory
[2m[36m(pid=21334)[0m running: cp -r ./training_data/* ./new_max8_garbage_21334
[2m[36m(pid=21329)[0m 2021-12-04 11:24:06,948	INFO trainable.py:217 -- Getting current IP.
[2m[36m(pid=21329)[0m 2021-12-04 11:24:06,948	WARNING util.py:37 -- Install gputil for GPU system monitoring.
[2m[36m(pid=21334)[0m Checking if local obs_encodings.pkl file exists.
[2m[36m(pid=21334)[0m found local obs_encodings.pkl.
[2m[36m(pid=21334)[0m Checking if local O3_runtimes.pkl file exists to avoid waste of compilation.
[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_11-32-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8652037617554859
  episode_reward_mean: 0.2404279215042947
  episode_reward_min: -5.4006410256410255
  episodes_this_iter: 500
  episodes_total: 500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 2127.827
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 2.9824090003967285
        entropy_coeff: 0.0
        kl: 0.013629249297082424
        model: {}
        policy_loss: -0.07127166539430618
        total_loss: 0.22674259543418884
        vf_explained_var: 0.12080033123493195
        vf_loss: 0.29528844356536865
    load_time_ms: 54.629
    num_steps_sampled: 500
    num_steps_trained: 500
    sample_time_ms: 480108.892
    update_time_ms: 589.262
  iterations_since_restore: 1
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.271159420289854
    ram_util_percent: 15.10391304347826
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 948.2308695178308
    mean_inference_ms: 1.9156433151153747
    mean_processing_ms: 1.4796709110161026
  time_since_restore: 482.930136680603
  time_this_iter_s: 482.930136680603
  time_total_s: 482.930136680603
  timestamp: 1638635529
  timesteps_since_restore: 500
  timesteps_this_iter: 500
  timesteps_total: 500
  training_iteration: 1
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |      1 |           482.93 |  500 | 0.240428 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_11-39-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9374130737134909
  episode_reward_mean: 0.3458245286459268
  episode_reward_min: -5.39297124600639
  episodes_this_iter: 500
  episodes_total: 1000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1869.648
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 2.9455699920654297
        entropy_coeff: 0.0
        kl: 0.022302627563476562
        model: {}
        policy_loss: -0.0846170112490654
        total_loss: 0.08834882825613022
        vf_explained_var: 0.07938465476036072
        vf_loss: 0.16850531101226807
    load_time_ms: 28.44
    num_steps_sampled: 1000
    num_steps_trained: 1000
    sample_time_ms: 453603.426
    update_time_ms: 297.814
  iterations_since_restore: 2
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.281014729950899
    ram_util_percent: 15.344517184942717
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 899.5569121468435
    mean_inference_ms: 1.8422639334237543
    mean_processing_ms: 1.4475775765372323
  time_since_restore: 911.656968832016
  time_this_iter_s: 428.72683215141296
  time_total_s: 911.656968832016
  timestamp: 1638635958
  timesteps_since_restore: 1000
  timesteps_this_iter: 500
  timesteps_total: 1000
  training_iteration: 2
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |      2 |          911.657 | 1000 | 0.345825 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_11-46-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8937809576224546
  episode_reward_mean: 0.37302354455256975
  episode_reward_min: -2.195774647887324
  episodes_this_iter: 500
  episodes_total: 1500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1870.829
    learner:
      default_policy:
        cur_kl_coeff: 0.30000001192092896
        cur_lr: 4.999999873689376e-05
        entropy: 2.8835325241088867
        entropy_coeff: 0.0
        kl: 0.0243945624679327
        model: {}
        policy_loss: -0.09061235189437866
        total_loss: 0.0011229836381971836
        vf_explained_var: 0.14117033779621124
        vf_loss: 0.08441697061061859
    load_time_ms: 19.839
    num_steps_sampled: 1500
    num_steps_trained: 1500
    sample_time_ms: 446199.77
    update_time_ms: 199.958
  iterations_since_restore: 3
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.141262135922329
    ram_util_percent: 15.382524271844662
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 886.1720280834708
    mean_inference_ms: 1.8130895854789841
    mean_processing_ms: 1.4425623345422713
  time_since_restore: 1344.938402414322
  time_this_iter_s: 433.2814335823059
  time_total_s: 1344.938402414322
  timestamp: 1638636392
  timesteps_since_restore: 1500
  timesteps_this_iter: 500
  timesteps_total: 1500
  training_iteration: 3
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |      3 |          1344.94 | 1500 | 0.373024 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_11-53-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8650602409638555
  episode_reward_mean: 0.36776288638242544
  episode_reward_min: -4.914893617021277
  episodes_this_iter: 500
  episodes_total: 2000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1876.418
    learner:
      default_policy:
        cur_kl_coeff: 0.44999998807907104
        cur_lr: 4.999999873689376e-05
        entropy: 2.811089515686035
        entropy_coeff: 0.0
        kl: 0.016155768185853958
        model: {}
        policy_loss: -0.0855628028512001
        total_loss: 0.05403682217001915
        vf_explained_var: 0.10983364284038544
        vf_loss: 0.1323295384645462
    load_time_ms: 15.611
    num_steps_sampled: 2000
    num_steps_trained: 2000
    sample_time_ms: 443922.792
    update_time_ms: 150.99
  iterations_since_restore: 4
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.251355661881975
    ram_util_percent: 15.403349282296652
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 882.3217004016302
    mean_inference_ms: 1.8025459735647318
    mean_processing_ms: 1.4370085894018936
  time_since_restore: 1783.939359664917
  time_this_iter_s: 439.0009572505951
  time_total_s: 1783.939359664917
  timestamp: 1638636831
  timesteps_since_restore: 2000
  timesteps_this_iter: 500
  timesteps_total: 2000
  training_iteration: 4
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |      4 |          1783.94 | 2000 | 0.367763 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_12-00-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8533123028391167
  episode_reward_mean: 0.3523890111946723
  episode_reward_min: -2.157608695652174
  episodes_this_iter: 500
  episodes_total: 2500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1859.839
    learner:
      default_policy:
        cur_kl_coeff: 0.44999998807907104
        cur_lr: 4.999999873689376e-05
        entropy: 2.70845890045166
        entropy_coeff: 0.0
        kl: 0.02062552608549595
        model: {}
        policy_loss: -0.08166181296110153
        total_loss: 0.007579332683235407
        vf_explained_var: 0.07482419162988663
        vf_loss: 0.07995965331792831
    load_time_ms: 12.951
    num_steps_sampled: 2500
    num_steps_trained: 2500
    sample_time_ms: 438638.055
    update_time_ms: 121.798
  iterations_since_restore: 5
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.224247491638794
    ram_util_percent: 15.466387959866223
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 872.1817338623938
    mean_inference_ms: 1.795140422377191
    mean_processing_ms: 1.430718529848803
  time_since_restore: 2203.2479043006897
  time_this_iter_s: 419.3085446357727
  time_total_s: 2203.2479043006897
  timestamp: 1638637250
  timesteps_since_restore: 2500
  timesteps_this_iter: 500
  timesteps_total: 2500
  training_iteration: 5
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |      5 |          2203.25 | 2500 | 0.352389 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_12-07-42
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8576329331046312
  episode_reward_mean: 0.3583844329912695
  episode_reward_min: -1.6647058823529413
  episodes_this_iter: 500
  episodes_total: 3000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1818.315
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 2.6431467533111572
        entropy_coeff: 0.0
        kl: 0.018550166860222816
        model: {}
        policy_loss: -0.08596089482307434
        total_loss: -0.008096526376903057
        vf_explained_var: 0.26979464292526245
        vf_loss: 0.06534299999475479
    load_time_ms: 11.161
    num_steps_sampled: 3000
    num_steps_trained: 3000
    sample_time_ms: 433973.644
    update_time_ms: 102.451
  iterations_since_restore: 6
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.081122448979594
    ram_util_percent: 15.453911564625853
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 863.1345282710024
    mean_inference_ms: 1.790232993649944
    mean_processing_ms: 1.4313690188089159
  time_since_restore: 2615.5268728733063
  time_this_iter_s: 412.2789685726166
  time_total_s: 2615.5268728733063
  timestamp: 1638637662
  timesteps_since_restore: 3000
  timesteps_this_iter: 500
  timesteps_total: 3000
  training_iteration: 6
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |      6 |          2615.53 | 3000 | 0.358384 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_12-14-23
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8763888888888889
  episode_reward_mean: 0.39824170946393556
  episode_reward_min: -2.0416666666666665
  episodes_this_iter: 500
  episodes_total: 3500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1811.369
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 2.5259010791778564
        entropy_coeff: 0.0
        kl: 0.018413985148072243
        model: {}
        policy_loss: -0.09201756119728088
        total_loss: -0.02489190176129341
        vf_explained_var: 0.15799793601036072
        vf_loss: 0.054696224629879
    load_time_ms: 9.972
    num_steps_sampled: 3500
    num_steps_trained: 3500
    sample_time_ms: 429029.124
    update_time_ms: 88.505
  iterations_since_restore: 7
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.151134380453751
    ram_util_percent: 15.428097731239095
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 853.4465683286307
    mean_inference_ms: 1.7872067799877345
    mean_processing_ms: 1.431095024682018
  time_since_restore: 3016.6743643283844
  time_this_iter_s: 401.1474914550781
  time_total_s: 3016.6743643283844
  timestamp: 1638638063
  timesteps_since_restore: 3500
  timesteps_this_iter: 500
  timesteps_total: 3500
  training_iteration: 7
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |      7 |          3016.67 | 3500 | 0.398242 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_12-20-59
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.4210478246410077
  episode_reward_min: -2.0658602150537635
  episodes_this_iter: 500
  episodes_total: 4000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1798.535
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 2.404261589050293
        entropy_coeff: 0.0
        kl: 0.0193774551153183
        model: {}
        policy_loss: -0.09032811969518661
        total_loss: -0.026512816548347473
        vf_explained_var: 0.22193942964076996
        vf_loss: 0.050735536962747574
    load_time_ms: 9.02
    num_steps_sampled: 4000
    num_steps_trained: 4000
    sample_time_ms: 424620.086
    update_time_ms: 77.901
  iterations_since_restore: 8
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.17322695035461
    ram_util_percent: 15.448936170212768
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 844.7805089194966
    mean_inference_ms: 1.7830459691977023
    mean_processing_ms: 1.4315155022622823
  time_since_restore: 3412.1544032096863
  time_this_iter_s: 395.4800388813019
  time_total_s: 3412.1544032096863
  timestamp: 1638638459
  timesteps_since_restore: 4000
  timesteps_this_iter: 500
  timesteps_total: 4000
  training_iteration: 8
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |      8 |          3412.15 | 4000 | 0.421048 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_12-27-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8631578947368421
  episode_reward_mean: 0.41759417099413587
  episode_reward_min: -4.435616438356164
  episodes_this_iter: 500
  episodes_total: 4500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1798.905
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 2.2845637798309326
        entropy_coeff: 0.0
        kl: 0.012136337347328663
        model: {}
        policy_loss: -0.06707638502120972
        total_loss: 0.016542674973607063
        vf_explained_var: 0.2241358906030655
        vf_loss: 0.07542703300714493
    load_time_ms: 8.277
    num_steps_sampled: 4500
    num_steps_trained: 4500
    sample_time_ms: 422230.337
    update_time_ms: 69.722
  iterations_since_restore: 9
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.165224913494809
    ram_util_percent: 15.464186851211075
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 840.1170173662815
    mean_inference_ms: 1.7809829190687934
    mean_processing_ms: 1.4319180965529519
  time_since_restore: 3817.083582878113
  time_this_iter_s: 404.9291796684265
  time_total_s: 3817.083582878113
  timestamp: 1638638864
  timesteps_since_restore: 4500
  timesteps_this_iter: 500
  timesteps_total: 4500
  training_iteration: 9
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |      9 |          3817.08 | 4500 | 0.417594 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_12-34-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8735795454545454
  episode_reward_mean: 0.42633236409816017
  episode_reward_min: -2.8584615384615386
  episodes_this_iter: 500
  episodes_total: 5000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1782.161
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 2.195736885070801
        entropy_coeff: 0.0
        kl: 0.015504462644457817
        model: {}
        policy_loss: -0.07700559496879578
        total_loss: -0.00997187104076147
        vf_explained_var: 0.2636721730232239
        vf_loss: 0.056568216532468796
    load_time_ms: 7.662
    num_steps_sampled: 5000
    num_steps_trained: 5000
    sample_time_ms: 418207.995
    update_time_ms: 63.265
  iterations_since_restore: 10
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.004570383912249
    ram_util_percent: 15.512979890310787
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 832.1634336748831
    mean_inference_ms: 1.7809495046791424
    mean_processing_ms: 1.432953870575372
  time_since_restore: 4200.7377116680145
  time_this_iter_s: 383.65412878990173
  time_total_s: 4200.7377116680145
  timestamp: 1638639248
  timesteps_since_restore: 5000
  timesteps_this_iter: 500
  timesteps_total: 5000
  training_iteration: 10
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     10 |          4200.74 | 5000 | 0.426332 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_12-40-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.4406489880509442
  episode_reward_min: -1.2331288343558282
  episodes_this_iter: 500
  episodes_total: 5500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1752.311
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 2.1020729541778564
        entropy_coeff: 0.0
        kl: 0.018570268526673317
        model: {}
        policy_loss: -0.07091736048460007
        total_loss: -0.028823060914874077
        vf_explained_var: 0.41379180550575256
        vf_loss: 0.02955937385559082
    load_time_ms: 2.414
    num_steps_sampled: 5500
    num_steps_trained: 5500
    sample_time_ms: 409120.428
    update_time_ms: 4.821
  iterations_since_restore: 11
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.130645161290323
    ram_util_percent: 15.532795698924733
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 826.9711099002948
    mean_inference_ms: 1.7798059182998331
    mean_processing_ms: 1.4322688635469158
  time_since_restore: 4591.816123962402
  time_this_iter_s: 391.0784122943878
  time_total_s: 4591.816123962402
  timestamp: 1638639639
  timesteps_since_restore: 5500
  timesteps_this_iter: 500
  timesteps_total: 5500
  training_iteration: 11
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     11 |          4591.82 | 5500 | 0.440649 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_12-47-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.866877971473851
  episode_reward_mean: 0.4427755990376889
  episode_reward_min: -1.628
  episodes_this_iter: 500
  episodes_total: 6000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1756.801
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.9886865615844727
        entropy_coeff: 0.0
        kl: 0.01579408347606659
        model: {}
        policy_loss: -0.07975906133651733
        total_loss: -0.0370279997587204
        vf_explained_var: 0.4753245413303375
        vf_loss: 0.03207005560398102
    load_time_ms: 2.426
    num_steps_sampled: 6000
    num_steps_trained: 6000
    sample_time_ms: 404458.211
    update_time_ms: 4.701
  iterations_since_restore: 12
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.005871559633029
    ram_util_percent: 15.477614678899082
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 821.1868001587924
    mean_inference_ms: 1.778290045696424
    mean_processing_ms: 1.4309502108814995
  time_since_restore: 4973.964335680008
  time_this_iter_s: 382.1482117176056
  time_total_s: 4973.964335680008
  timestamp: 1638640021
  timesteps_since_restore: 6000
  timesteps_this_iter: 500
  timesteps_total: 6000
  training_iteration: 12
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     12 |          4973.96 | 6000 | 0.442776 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_12-53-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.4456604155250295
  episode_reward_min: -1.0650887573964498
  episodes_this_iter: 500
  episodes_total: 6500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1728.387
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.9344083070755005
        entropy_coeff: 0.0
        kl: 0.01904921419918537
        model: {}
        policy_loss: -0.06744370609521866
        total_loss: -0.02989497408270836
        vf_explained_var: 0.4415556788444519
        vf_loss: 0.02469050884246826
    load_time_ms: 2.349
    num_steps_sampled: 6500
    num_steps_trained: 6500
    sample_time_ms: 400139.125
    update_time_ms: 4.635
  iterations_since_restore: 13
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.989048473967683
    ram_util_percent: 15.511490125673252
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 817.4728541498166
    mean_inference_ms: 1.779625808582033
    mean_processing_ms: 1.4351411812709964
  time_since_restore: 5363.768370628357
  time_this_iter_s: 389.804034948349
  time_total_s: 5363.768370628357
  timestamp: 1638640411
  timesteps_since_restore: 6500
  timesteps_this_iter: 500
  timesteps_total: 6500
  training_iteration: 13
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     13 |          5363.77 | 6500 |  0.44566 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_13-00-00
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8646362098138748
  episode_reward_mean: 0.454395502922696
  episode_reward_min: -0.9886363636363636
  episodes_this_iter: 500
  episodes_total: 7000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1711.948
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.8072466850280762
        entropy_coeff: 0.0
        kl: 0.014021395705640316
        model: {}
        policy_loss: -0.07671879976987839
        total_loss: -0.039514679461717606
        vf_explained_var: 0.40719932317733765
        vf_loss: 0.02773967571556568
    load_time_ms: 2.278
    num_steps_sampled: 7000
    num_steps_trained: 7000
    sample_time_ms: 395189.671
    update_time_ms: 4.705
  iterations_since_restore: 14
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.061261261261262
    ram_util_percent: 15.544504504504506
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 814.2063704205829
    mean_inference_ms: 1.7805004133495015
    mean_processing_ms: 1.4356473670178114
  time_since_restore: 5753.111868619919
  time_this_iter_s: 389.3434979915619
  time_total_s: 5753.111868619919
  timestamp: 1638640800
  timesteps_since_restore: 7000
  timesteps_this_iter: 500
  timesteps_total: 7000
  training_iteration: 14
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     14 |          5753.11 | 7000 | 0.454396 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_13-06-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.874926943308007
  episode_reward_mean: 0.48337930574850463
  episode_reward_min: -1.0358744394618835
  episodes_this_iter: 500
  episodes_total: 7500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1699.898
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.6401351690292358
        entropy_coeff: 0.0
        kl: 0.01809944398701191
        model: {}
        policy_loss: -0.07113875448703766
        total_loss: -0.03195296600461006
        vf_explained_var: 0.5000106692314148
        vf_loss: 0.026968663558363914
    load_time_ms: 2.273
    num_steps_sampled: 7500
    num_steps_trained: 7500
    sample_time_ms: 389743.611
    update_time_ms: 4.608
  iterations_since_restore: 15
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.933653846153845
    ram_util_percent: 15.596923076923076
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 808.1027779670069
    mean_inference_ms: 1.7812047349883788
    mean_processing_ms: 1.4342637463198264
  time_since_restore: 6117.838885068893
  time_this_iter_s: 364.7270164489746
  time_total_s: 6117.838885068893
  timestamp: 1638641165
  timesteps_since_restore: 7500
  timesteps_this_iter: 500
  timesteps_total: 7500
  training_iteration: 15
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     15 |          6117.84 | 7500 | 0.483379 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_13-12-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.46587910892659123
  episode_reward_min: -1.183622828784119
  episodes_this_iter: 500
  episodes_total: 8000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1706.133
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.5811264514923096
        entropy_coeff: 0.0
        kl: 0.011859866790473461
        model: {}
        policy_loss: -0.060878995805978775
        total_loss: -0.023865938186645508
        vf_explained_var: 0.4348459243774414
        vf_loss: 0.02900763973593712
    load_time_ms: 2.295
    num_steps_sampled: 8000
    num_steps_trained: 8000
    sample_time_ms: 387189.752
    update_time_ms: 4.469
  iterations_since_restore: 16
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.166304347826086
    ram_util_percent: 15.593659420289853
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 805.5203581076834
    mean_inference_ms: 1.7807348089476787
    mean_processing_ms: 1.4349866577899844
  time_since_restore: 6504.63970041275
  time_this_iter_s: 386.8008153438568
  time_total_s: 6504.63970041275
  timestamp: 1638641552
  timesteps_since_restore: 8000
  timesteps_this_iter: 500
  timesteps_total: 8000
  training_iteration: 16
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     16 |          6504.64 | 8000 | 0.465879 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_13-18-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9531871043721478
  episode_reward_mean: 0.4602081295685004
  episode_reward_min: -1.2822085889570551
  episodes_this_iter: 500
  episodes_total: 8500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1694.703
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.4811582565307617
        entropy_coeff: 0.0
        kl: 0.011179916560649872
        model: {}
        policy_loss: -0.0575389638543129
        total_loss: -0.02459254488348961
        vf_explained_var: 0.5417512655258179
        vf_loss: 0.025399982929229736
    load_time_ms: 2.231
    num_steps_sampled: 8500
    num_steps_trained: 8500
    sample_time_ms: 385616.784
    update_time_ms: 4.484
  iterations_since_restore: 17
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.362727272727271
    ram_util_percent: 15.637090909090904
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 803.0595787271812
    mean_inference_ms: 1.7852608476887173
    mean_processing_ms: 1.4382008313712
  time_since_restore: 6889.943255901337
  time_this_iter_s: 385.3035554885864
  time_total_s: 6889.943255901337
  timestamp: 1638641937
  timesteps_since_restore: 8500
  timesteps_this_iter: 500
  timesteps_total: 8500
  training_iteration: 17
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     17 |          6889.94 | 8500 | 0.460208 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_13-25-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8817610062893082
  episode_reward_mean: 0.4814096828437717
  episode_reward_min: -1.3525641025641026
  episodes_this_iter: 500
  episodes_total: 9000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1696.069
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.5086475610733032
        entropy_coeff: 0.0
        kl: 0.009393446147441864
        model: {}
        policy_loss: -0.04781634360551834
        total_loss: -0.020038926973938942
        vf_explained_var: 0.48968303203582764
        vf_loss: 0.021436838433146477
    load_time_ms: 2.218
    num_steps_sampled: 9000
    num_steps_trained: 9000
    sample_time_ms: 382877.085
    update_time_ms: 4.638
  iterations_since_restore: 18
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.123238095238095
    ram_util_percent: 15.678857142857138
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 798.957965490805
    mean_inference_ms: 1.7858389920227362
    mean_processing_ms: 1.4397503336116133
  time_since_restore: 7258.041341781616
  time_this_iter_s: 368.09808588027954
  time_total_s: 7258.041341781616
  timestamp: 1638642305
  timesteps_since_restore: 9000
  timesteps_this_iter: 500
  timesteps_total: 9000
  training_iteration: 18
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     18 |          7258.04 | 9000 |  0.48141 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_13-31-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8778205833791964
  episode_reward_mean: 0.4996330986234851
  episode_reward_min: -0.18115942028985507
  episodes_this_iter: 500
  episodes_total: 9500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1682.366
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.4227633476257324
        entropy_coeff: 0.0
        kl: 0.01437643077224493
        model: {}
        policy_loss: -0.06829425692558289
        total_loss: -0.04424254596233368
        vf_explained_var: 0.5444333553314209
        vf_loss: 0.014347615651786327
    load_time_ms: 2.216
    num_steps_sampled: 9500
    num_steps_trained: 9500
    sample_time_ms: 378460.421
    update_time_ms: 4.808
  iterations_since_restore: 19
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.120970873786408
    ram_util_percent: 15.648349514563105
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 794.5130384541752
    mean_inference_ms: 1.7841154870805263
    mean_processing_ms: 1.4383126128260657
  time_since_restore: 7618.668403863907
  time_this_iter_s: 360.62706208229065
  time_total_s: 7618.668403863907
  timestamp: 1638642666
  timesteps_since_restore: 9500
  timesteps_this_iter: 500
  timesteps_total: 9500
  training_iteration: 19
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+----------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     19 |          7618.67 | 9500 | 0.499633 |
+-------------------+----------+----------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_13-36-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8945362134688691
  episode_reward_mean: 0.5010287763856803
  episode_reward_min: -1.6282722513089005
  episodes_this_iter: 500
  episodes_total: 10000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1676.367
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.3186084032058716
        entropy_coeff: 0.0
        kl: 0.007367461919784546
        model: {}
        policy_loss: -0.04935627058148384
        total_loss: -0.01995493844151497
        vf_explained_var: 0.5414053797721863
        vf_loss: 0.02442830614745617
    load_time_ms: 2.201
    num_steps_sampled: 10000
    num_steps_trained: 10000
    sample_time_ms: 374974.367
    update_time_ms: 4.706
  iterations_since_restore: 20
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.03420523138833
    ram_util_percent: 15.651509054325953
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 789.3350828577192
    mean_inference_ms: 1.7823082794488494
    mean_processing_ms: 1.435442264527514
  time_since_restore: 7967.400581121445
  time_this_iter_s: 348.73217725753784
  time_total_s: 7967.400581121445
  timestamp: 1638643015
  timesteps_since_restore: 10000
  timesteps_this_iter: 500
  timesteps_total: 10000
  training_iteration: 20
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     20 |           7967.4 | 10000 | 0.501029 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_13-43-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8564954682779456
  episode_reward_mean: 0.4130718693721454
  episode_reward_min: -0.9813333333333333
  episodes_this_iter: 500
  episodes_total: 10500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1694.832
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.3507914543151855
        entropy_coeff: 0.0
        kl: 0.009713146835565567
        model: {}
        policy_loss: -0.04694204032421112
        total_loss: -0.014505717903375626
        vf_explained_var: 0.48598918318748474
        vf_loss: 0.025879941880702972
    load_time_ms: 2.26
    num_steps_sampled: 10500
    num_steps_trained: 10500
    sample_time_ms: 374929.242
    update_time_ms: 4.732
  iterations_since_restore: 21
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.187275985663083
    ram_util_percent: 15.672222222222219
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 788.5940633448134
    mean_inference_ms: 1.7905890538617328
    mean_processing_ms: 1.4434154573343745
  time_since_restore: 8358.214908123016
  time_this_iter_s: 390.81432700157166
  time_total_s: 8358.214908123016
  timestamp: 1638643406
  timesteps_since_restore: 10500
  timesteps_this_iter: 500
  timesteps_total: 10500
  training_iteration: 21
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     21 |          8358.21 | 10500 | 0.413072 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_13-50-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8568935427574171
  episode_reward_mean: 0.3811186218590537
  episode_reward_min: -1.4987468671679198
  episodes_this_iter: 500
  episodes_total: 11000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1706.745
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.2990431785583496
        entropy_coeff: 0.0
        kl: 0.00935453176498413
        model: {}
        policy_loss: -0.05294978246092796
        total_loss: -0.015143483877182007
        vf_explained_var: 0.5160689353942871
        vf_loss: 0.03149197995662689
    load_time_ms: 2.258
    num_steps_sampled: 11000
    num_steps_trained: 11000
    sample_time_ms: 377577.805
    update_time_ms: 4.638
  iterations_since_restore: 22
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.084905660377359
    ram_util_percent: 15.647512864493997
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 789.5681810600088
    mean_inference_ms: 1.8003765598945907
    mean_processing_ms: 1.452632822044198
  time_since_restore: 8766.967658042908
  time_this_iter_s: 408.75274991989136
  time_total_s: 8766.967658042908
  timestamp: 1638643814
  timesteps_since_restore: 11000
  timesteps_this_iter: 500
  timesteps_total: 11000
  training_iteration: 22
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     22 |          8766.97 | 11000 | 0.381119 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_13-56-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.40935011738148613
  episode_reward_min: -0.20698924731182797
  episodes_this_iter: 500
  episodes_total: 11500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1729.651
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.1859288215637207
        entropy_coeff: 0.0
        kl: 0.010649967938661575
        model: {}
        policy_loss: -0.049031853675842285
        total_loss: -0.024524115025997162
        vf_explained_var: 0.5728476047515869
        vf_loss: 0.017319004982709885
    load_time_ms: 2.291
    num_steps_sampled: 11500
    num_steps_trained: 11500
    sample_time_ms: 378064.305
    update_time_ms: 4.993
  iterations_since_restore: 23
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.044148936170211
    ram_util_percent: 15.625531914893616
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 789.251439955512
    mean_inference_ms: 1.8080669572566674
    mean_processing_ms: 1.4604729845693614
  time_since_restore: 9161.875706911087
  time_this_iter_s: 394.9080488681793
  time_total_s: 9161.875706911087
  timestamp: 1638644209
  timesteps_since_restore: 11500
  timesteps_this_iter: 500
  timesteps_total: 11500
  training_iteration: 23
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     23 |          9161.88 | 11500 |  0.40935 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_14-03-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8347222222222223
  episode_reward_mean: 0.41137217534695586
  episode_reward_min: -1.1256830601092895
  episodes_this_iter: 500
  episodes_total: 12000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1732.497
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.1527115106582642
        entropy_coeff: 0.0
        kl: 0.007926581427454948
        model: {}
        policy_loss: -0.04168814793229103
        total_loss: -0.013192152604460716
        vf_explained_var: 0.5251724720001221
        vf_loss: 0.02314554899930954
    load_time_ms: 2.333
    num_steps_sampled: 12000
    num_steps_trained: 12000
    sample_time_ms: 378150.025
    update_time_ms: 5.062
  iterations_since_restore: 24
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.222122302158274
    ram_util_percent: 15.637050359712228
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 788.573973874789
    mean_inference_ms: 1.815892509515758
    mean_processing_ms: 1.469492326228979
  time_since_restore: 9552.10480928421
  time_this_iter_s: 390.22910237312317
  time_total_s: 9552.10480928421
  timestamp: 1638644600
  timesteps_since_restore: 12000
  timesteps_this_iter: 500
  timesteps_total: 12000
  training_iteration: 24
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     24 |           9552.1 | 12000 | 0.411372 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_14-09-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8662704309063893
  episode_reward_mean: 0.4274242608654402
  episode_reward_min: -0.42
  episodes_this_iter: 500
  episodes_total: 12500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1732.195
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.1069027185440063
        entropy_coeff: 0.0
        kl: 0.009806856513023376
        model: {}
        policy_loss: -0.0536547414958477
        total_loss: -0.02375558763742447
        vf_explained_var: 0.47328177094459534
        vf_loss: 0.023279523476958275
    load_time_ms: 2.338
    num_steps_sampled: 12500
    num_steps_trained: 12500
    sample_time_ms: 377043.47
    update_time_ms: 5.131
  iterations_since_restore: 25
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.234059405940595
    ram_util_percent: 15.646336633663363
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 785.0451061662868
    mean_inference_ms: 1.817827310173829
    mean_processing_ms: 1.47037225364256
  time_since_restore: 9905.76387143135
  time_this_iter_s: 353.6590621471405
  time_total_s: 9905.76387143135
  timestamp: 1638644954
  timesteps_since_restore: 12500
  timesteps_this_iter: 500
  timesteps_total: 12500
  training_iteration: 25
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     25 |          9905.76 | 12500 | 0.427424 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_14-14-40
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.45407303647656766
  episode_reward_min: -1.0382352941176471
  episodes_this_iter: 500
  episodes_total: 13000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1743.988
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.0279651880264282
        entropy_coeff: 0.0
        kl: 0.009896990843117237
        model: {}
        policy_loss: -0.05236333981156349
        total_loss: -0.024483337998390198
        vf_explained_var: 0.5448707342147827
        vf_loss: 0.021199526265263557
    load_time_ms: 2.319
    num_steps_sampled: 13000
    num_steps_trained: 13000
    sample_time_ms: 371028.567
    update_time_ms: 5.113
  iterations_since_restore: 26
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.206866952789701
    ram_util_percent: 15.699141630901284
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 779.71706972811
    mean_inference_ms: 1.8164975653610893
    mean_processing_ms: 1.4682629962818736
  time_since_restore: 10232.533635616302
  time_this_iter_s: 326.7697641849518
  time_total_s: 10232.533635616302
  timestamp: 1638645280
  timesteps_since_restore: 13000
  timesteps_this_iter: 500
  timesteps_total: 13000
  training_iteration: 26
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     26 |          10232.5 | 13000 | 0.454073 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_14-19-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8621236133122029
  episode_reward_mean: 0.4489042748421672
  episode_reward_min: -0.3812154696132597
  episodes_this_iter: 500
  episodes_total: 13500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1753.268
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 1.0460765361785889
        entropy_coeff: 0.0
        kl: 0.010163648054003716
        model: {}
        policy_loss: -0.05555616691708565
        total_loss: -0.03423203527927399
        vf_explained_var: 0.6123301386833191
        vf_loss: 0.01446367148309946
    load_time_ms: 2.33
    num_steps_sampled: 13500
    num_steps_trained: 13500
    sample_time_ms: 363380.063
    update_time_ms: 5.188
  iterations_since_restore: 27
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.019954648526078
    ram_util_percent: 15.643764172335597
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 773.467409461527
    mean_inference_ms: 1.8133809324388428
    mean_processing_ms: 1.4648287219123903
  time_since_restore: 10541.447480201721
  time_this_iter_s: 308.9138445854187
  time_total_s: 10541.447480201721
  timestamp: 1638645589
  timesteps_since_restore: 13500
  timesteps_this_iter: 500
  timesteps_total: 13500
  training_iteration: 27
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     27 |          10541.4 | 13500 | 0.448904 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_14-24-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.861764705882353
  episode_reward_mean: 0.47273517212618527
  episode_reward_min: -0.4318181818181818
  episodes_this_iter: 500
  episodes_total: 14000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1749.142
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 0.9865649938583374
        entropy_coeff: 0.0
        kl: 0.005693609826266766
        model: {}
        policy_loss: -0.03424884006381035
        total_loss: -0.01776355691254139
        vf_explained_var: 0.6122913360595703
        vf_loss: 0.01264209020882845
    load_time_ms: 2.343
    num_steps_sampled: 14000
    num_steps_trained: 14000
    sample_time_ms: 356985.17
    update_time_ms: 5.228
  iterations_since_restore: 28
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.14331797235023
    ram_util_percent: 15.666820276497694
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 767.3239769590607
    mean_inference_ms: 1.8109862493298825
    mean_processing_ms: 1.4629753629919988
  time_since_restore: 10845.555897712708
  time_this_iter_s: 304.1084175109863
  time_total_s: 10845.555897712708
  timestamp: 1638645893
  timesteps_since_restore: 14000
  timesteps_this_iter: 500
  timesteps_total: 14000
  training_iteration: 28
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     28 |          10845.6 | 14000 | 0.472735 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_14-29-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8313758389261745
  episode_reward_mean: 0.45987378955848524
  episode_reward_min: -0.4025157232704403
  episodes_this_iter: 500
  episodes_total: 14500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1753.907
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 0.9889401197433472
        entropy_coeff: 0.0
        kl: 0.007036943454295397
        model: {}
        policy_loss: -0.04039193317294121
        total_loss: -0.02196095883846283
        vf_explained_var: 0.6088653802871704
        vf_loss: 0.013681032694876194
    load_time_ms: 2.333
    num_steps_sampled: 14500
    num_steps_trained: 14500
    sample_time_ms: 348963.508
    update_time_ms: 5.081
  iterations_since_restore: 29
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.09075
    ram_util_percent: 15.655749999999998
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 759.9734397322858
    mean_inference_ms: 1.8084232219046013
    mean_processing_ms: 1.4590059557533883
  time_since_restore: 11126.012480974197
  time_this_iter_s: 280.45658326148987
  time_total_s: 11126.012480974197
  timestamp: 1638646174
  timesteps_since_restore: 14500
  timesteps_this_iter: 500
  timesteps_total: 14500
  training_iteration: 29
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     29 |            11126 | 14500 | 0.459874 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_14-33-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8646362098138748
  episode_reward_mean: 0.4666127753170453
  episode_reward_min: -1.5
  episodes_this_iter: 500
  episodes_total: 15000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1766.908
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 0.9272539019584656
        entropy_coeff: 0.0
        kl: 0.0061003039591014385
        model: {}
        policy_loss: -0.03977837413549423
        total_loss: -0.01579529605805874
        vf_explained_var: 0.5418026447296143
        vf_loss: 0.0198653731495142
    load_time_ms: 2.358
    num_steps_sampled: 15000
    num_steps_trained: 15000
    sample_time_ms: 339393.049
    update_time_ms: 5.116
  iterations_since_restore: 30
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.14376731301939
    ram_util_percent: 15.664542936288084
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 751.2988168297985
    mean_inference_ms: 1.8032302173660022
    mean_processing_ms: 1.4534475135688787
  time_since_restore: 11379.1713514328
  time_this_iter_s: 253.1588704586029
  time_total_s: 11379.1713514328
  timestamp: 1638646427
  timesteps_since_restore: 15000
  timesteps_this_iter: 500
  timesteps_total: 15000
  training_iteration: 30
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     30 |          11379.2 | 15000 | 0.466613 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_14-37-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.4917057379108347
  episode_reward_min: -0.4061302681992337
  episodes_this_iter: 500
  episodes_total: 15500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1734.168
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 0.8207182884216309
        entropy_coeff: 0.0
        kl: 0.008148754015564919
        model: {}
        policy_loss: -0.03887337073683739
        total_loss: -0.018854642286896706
        vf_explained_var: 0.5599969029426575
        vf_loss: 0.01451832614839077
    load_time_ms: 2.305
    num_steps_sampled: 15500
    num_steps_trained: 15500
    sample_time_ms: 324250.377
    update_time_ms: 5.147
  iterations_since_restore: 31
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.08533724340176
    ram_util_percent: 15.705865102639294
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 742.2775153875061
    mean_inference_ms: 1.7964922684283804
    mean_processing_ms: 1.4476735209981884
  time_since_restore: 11618.230115652084
  time_this_iter_s: 239.05876421928406
  time_total_s: 11618.230115652084
  timestamp: 1638646666
  timesteps_since_restore: 15500
  timesteps_this_iter: 500
  timesteps_total: 15500
  training_iteration: 31
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     31 |          11618.2 | 15500 | 0.491706 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_14-41-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8668341708542714
  episode_reward_mean: 0.4802300136343852
  episode_reward_min: -0.4107883817427386
  episodes_this_iter: 500
  episodes_total: 16000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1722.477
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 0.8435461521148682
        entropy_coeff: 0.0
        kl: 0.008563305251300335
        model: {}
        policy_loss: -0.04369062930345535
        total_loss: -0.02301587164402008
        vf_explained_var: 0.5434867143630981
        vf_loss: 0.014894516207277775
    load_time_ms: 2.298
    num_steps_sampled: 16000
    num_steps_trained: 16000
    sample_time_ms: 303770.822
    update_time_ms: 5.255
  iterations_since_restore: 32
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.118556701030927
    ram_util_percent: 15.697250859106529
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 731.623055018393
    mean_inference_ms: 1.789024118914931
    mean_processing_ms: 1.4413030704374081
  time_since_restore: 11822.07103562355
  time_this_iter_s: 203.84091997146606
  time_total_s: 11822.07103562355
  timestamp: 1638646870
  timesteps_since_restore: 16000
  timesteps_this_iter: 500
  timesteps_total: 16000
  training_iteration: 32
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     32 |          11822.1 | 16000 |  0.48023 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_14-44-40
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9531871043721478
  episode_reward_mean: 0.4822803732907839
  episode_reward_min: -0.1712962962962963
  episodes_this_iter: 500
  episodes_total: 16500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1703.672
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 0.8014606237411499
        entropy_coeff: 0.0
        kl: 0.006961079780012369
        model: {}
        policy_loss: -0.038429372012615204
        total_loss: -0.017949268221855164
        vf_explained_var: 0.5651645064353943
        vf_loss: 0.01578136719763279
    load_time_ms: 2.295
    num_steps_sampled: 16500
    num_steps_trained: 16500
    sample_time_ms: 285309.133
    update_time_ms: 5.101
  iterations_since_restore: 33
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.215666666666666
    ram_util_percent: 15.759666666666666
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 721.9963940221115
    mean_inference_ms: 1.7814651690615384
    mean_processing_ms: 1.434644275228585
  time_since_restore: 12032.16747379303
  time_this_iter_s: 210.09643816947937
  time_total_s: 12032.16747379303
  timestamp: 1638647080
  timesteps_since_restore: 16500
  timesteps_this_iter: 500
  timesteps_total: 16500
  training_iteration: 33
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     33 |          12032.2 | 16500 |  0.48228 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_14-47-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8926802421574023
  episode_reward_mean: 0.4986887673396828
  episode_reward_min: 0.028
  episodes_this_iter: 500
  episodes_total: 17000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1695.647
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 0.7754934430122375
        entropy_coeff: 0.0
        kl: 0.005618814844638109
        model: {}
        policy_loss: -0.02889714017510414
        total_loss: -0.012096354737877846
        vf_explained_var: 0.5587168335914612
        vf_loss: 0.013008088804781437
    load_time_ms: 2.315
    num_steps_sampled: 17000
    num_steps_trained: 17000
    sample_time_ms: 264694.359
    update_time_ms: 5.095
  iterations_since_restore: 34
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.09619771863118
    ram_util_percent: 15.699999999999998
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 711.4022000944831
    mean_inference_ms: 1.7723851775808914
    mean_processing_ms: 1.4265828760615036
  time_since_restore: 12216.167983293533
  time_this_iter_s: 184.00050950050354
  time_total_s: 12216.167983293533
  timestamp: 1638647264
  timesteps_since_restore: 17000
  timesteps_this_iter: 500
  timesteps_total: 17000
  training_iteration: 34
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     34 |          12216.2 | 17000 | 0.498689 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_14-50-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.878494623655914
  episode_reward_mean: 0.4963073885477248
  episode_reward_min: -0.068359375
  episodes_this_iter: 500
  episodes_total: 17500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1695.144
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 0.7243732213973999
        entropy_coeff: 0.0
        kl: 0.008610290475189686
        model: {}
        policy_loss: -0.04543140530586243
        total_loss: -0.027066631242632866
        vf_explained_var: 0.5989429354667664
        vf_loss: 0.012552833184599876
    load_time_ms: 2.307
    num_steps_sampled: 17500
    num_steps_trained: 17500
    sample_time_ms: 248101.514
    update_time_ms: 5.143
  iterations_since_restore: 35
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.124626865671642
    ram_util_percent: 15.706343283582086
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 701.622818478257
    mean_inference_ms: 1.7656787627969808
    mean_processing_ms: 1.4209336031846242
  time_since_restore: 12403.893142223358
  time_this_iter_s: 187.72515892982483
  time_total_s: 12403.893142223358
  timestamp: 1638647452
  timesteps_since_restore: 17500
  timesteps_this_iter: 500
  timesteps_total: 17500
  training_iteration: 35
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     35 |          12403.9 | 17500 | 0.496307 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_14-53-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8945362134688691
  episode_reward_mean: 0.48235139151990336
  episode_reward_min: -0.33163265306122447
  episodes_this_iter: 500
  episodes_total: 18000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1680.986
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 0.7330885529518127
        entropy_coeff: 0.0
        kl: 0.004169898573309183
        model: {}
        policy_loss: -0.02861981838941574
        total_loss: -0.012446213513612747
        vf_explained_var: 0.6025524139404297
        vf_loss: 0.013358915224671364
    load_time_ms: 2.312
    num_steps_sampled: 18000
    num_steps_trained: 18000
    sample_time_ms: 233297.087
    update_time_ms: 5.264
  iterations_since_restore: 36
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.278740157480316
    ram_util_percent: 15.73307086614173
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 691.8820897232633
    mean_inference_ms: 1.7581438463294876
    mean_processing_ms: 1.4146941150932084
  time_since_restore: 12582.479642152786
  time_this_iter_s: 178.5864999294281
  time_total_s: 12582.479642152786
  timestamp: 1638647631
  timesteps_since_restore: 18000
  timesteps_this_iter: 500
  timesteps_total: 18000
  training_iteration: 36
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     36 |          12582.5 | 18000 | 0.482351 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_14-56-58
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8533123028391167
  episode_reward_mean: 0.4340729652318795
  episode_reward_min: -0.3640661938534279
  episodes_this_iter: 500
  episodes_total: 18500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1681.214
    learner:
      default_policy:
        cur_kl_coeff: 0.3375000059604645
        cur_lr: 4.999999873689376e-05
        entropy: 0.7004345059394836
        entropy_coeff: 0.0
        kl: 0.007284505758434534
        model: {}
        policy_loss: -0.02396710403263569
        total_loss: -0.00494858855381608
        vf_explained_var: 0.5715745687484741
        vf_loss: 0.01655999757349491
    load_time_ms: 2.305
    num_steps_sampled: 18500
    num_steps_trained: 18500
    sample_time_ms: 221125.592
    update_time_ms: 5.202
  iterations_since_restore: 37
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.384701492537314
    ram_util_percent: 15.681343283582084
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 683.1276564074622
    mean_inference_ms: 1.7518898350671461
    mean_processing_ms: 1.4082796798771215
  time_since_restore: 12769.67884850502
  time_this_iter_s: 187.1992063522339
  time_total_s: 12769.67884850502
  timestamp: 1638647818
  timesteps_since_restore: 18500
  timesteps_this_iter: 500
  timesteps_total: 18500
  training_iteration: 37
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     37 |          12769.7 | 18500 | 0.434073 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-00-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8568935427574171
  episode_reward_mean: 0.4088318621075088
  episode_reward_min: -0.5502645502645502
  episodes_this_iter: 500
  episodes_total: 19000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1686.81
    learner:
      default_policy:
        cur_kl_coeff: 0.3375000059604645
        cur_lr: 4.999999873689376e-05
        entropy: 0.7298734784126282
        entropy_coeff: 0.0
        kl: 0.009128727950155735
        model: {}
        policy_loss: -0.045557901263237
        total_loss: -0.025900578126311302
        vf_explained_var: 0.6042407751083374
        vf_loss: 0.016576368361711502
    load_time_ms: 2.342
    num_steps_sampled: 19000
    num_steps_trained: 19000
    sample_time_ms: 209339.612
    update_time_ms: 5.177
  iterations_since_restore: 38
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.177819548872181
    ram_util_percent: 15.674436090225562
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 674.7808973887461
    mean_inference_ms: 1.7485194730480107
    mean_processing_ms: 1.4059731699430242
  time_since_restore: 12955.984316825867
  time_this_iter_s: 186.30546832084656
  time_total_s: 12955.984316825867
  timestamp: 1638648005
  timesteps_since_restore: 19000
  timesteps_this_iter: 500
  timesteps_total: 19000
  training_iteration: 38
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     38 |            12956 | 19000 | 0.408832 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-02-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.41380557915055666
  episode_reward_min: -1.1946902654867257
  episodes_this_iter: 500
  episodes_total: 19500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1688.887
    learner:
      default_policy:
        cur_kl_coeff: 0.3375000059604645
        cur_lr: 4.999999873689376e-05
        entropy: 0.6691243052482605
        entropy_coeff: 0.0
        kl: 0.005572134628891945
        model: {}
        policy_loss: -0.0362689271569252
        total_loss: -0.011653264984488487
        vf_explained_var: 0.5428949594497681
        vf_loss: 0.02273506671190262
    load_time_ms: 2.365
    num_steps_sampled: 19500
    num_steps_trained: 19500
    sample_time_ms: 197731.614
    update_time_ms: 5.199
  iterations_since_restore: 39
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.380769230769229
    ram_util_percent: 15.696153846153843
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 665.7387009462169
    mean_inference_ms: 1.7450585816922626
    mean_processing_ms: 1.4045047525271204
  time_since_restore: 13120.382972717285
  time_this_iter_s: 164.39865589141846
  time_total_s: 13120.382972717285
  timestamp: 1638648169
  timesteps_since_restore: 19500
  timesteps_this_iter: 500
  timesteps_total: 19500
  training_iteration: 39
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     39 |          13120.4 | 19500 | 0.413806 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-05-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8560250391236307
  episode_reward_mean: 0.42067614149525145
  episode_reward_min: -0.32151898734177214
  episodes_this_iter: 500
  episodes_total: 20000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1724.231
    learner:
      default_policy:
        cur_kl_coeff: 0.3375000059604645
        cur_lr: 4.999999873689376e-05
        entropy: 0.6355682611465454
        entropy_coeff: 0.0
        kl: 0.005945751443505287
        model: {}
        policy_loss: -0.02500557340681553
        total_loss: -0.005020924378186464
        vf_explained_var: 0.5272587537765503
        vf_loss: 0.01797795481979847
    load_time_ms: 2.373
    num_steps_sampled: 20000
    num_steps_trained: 20000
    sample_time_ms: 188619.276
    update_time_ms: 5.207
  iterations_since_restore: 40
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.230603448275861
    ram_util_percent: 15.694827586206896
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 657.0321243111238
    mean_inference_ms: 1.741651236835131
    mean_processing_ms: 1.4029350359912733
  time_since_restore: 13282.77410364151
  time_this_iter_s: 162.39113092422485
  time_total_s: 13282.77410364151
  timestamp: 1638648332
  timesteps_since_restore: 20000
  timesteps_this_iter: 500
  timesteps_total: 20000
  training_iteration: 40
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     40 |          13282.8 | 20000 | 0.420676 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-07-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647845468053492
  episode_reward_mean: 0.4659030279427866
  episode_reward_min: -0.1444043321299639
  episodes_this_iter: 500
  episodes_total: 20500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1724.623
    learner:
      default_policy:
        cur_kl_coeff: 0.3375000059604645
        cur_lr: 4.999999873689376e-05
        entropy: 0.6513521075248718
        entropy_coeff: 0.0
        kl: 0.008905936032533646
        model: {}
        policy_loss: -0.027816377580165863
        total_loss: -0.010612333193421364
        vf_explained_var: 0.554755449295044
        vf_loss: 0.014198286458849907
    load_time_ms: 2.39
    num_steps_sampled: 20500
    num_steps_trained: 20500
    sample_time_ms: 178632.714
    update_time_ms: 5.141
  iterations_since_restore: 41
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.20100502512563
    ram_util_percent: 15.713567839195976
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 647.646431364459
    mean_inference_ms: 1.7343217771487442
    mean_processing_ms: 1.3963175333974933
  time_since_restore: 13421.969757556915
  time_this_iter_s: 139.19565391540527
  time_total_s: 13421.969757556915
  timestamp: 1638648471
  timesteps_since_restore: 20500
  timesteps_this_iter: 500
  timesteps_total: 20500
  training_iteration: 41
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     41 |            13422 | 20500 | 0.465903 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-10-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.4691639562064778
  episode_reward_min: -0.9241573033707865
  episodes_this_iter: 500
  episodes_total: 21000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1739.788
    learner:
      default_policy:
        cur_kl_coeff: 0.3375000059604645
        cur_lr: 4.999999873689376e-05
        entropy: 0.6031486392021179
        entropy_coeff: 0.0
        kl: 0.005933638196438551
        model: {}
        policy_loss: -0.03690459579229355
        total_loss: -0.01730569452047348
        vf_explained_var: 0.5497219562530518
        vf_loss: 0.017596298828721046
    load_time_ms: 2.39
    num_steps_sampled: 21000
    num_steps_trained: 21000
    sample_time_ms: 171521.195
    update_time_ms: 5.141
  iterations_since_restore: 42
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.161904761904763
    ram_util_percent: 15.841269841269842
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 638.4057001206802
    mean_inference_ms: 1.724516208453051
    mean_processing_ms: 1.388347374246856
  time_since_restore: 13554.84697341919
  time_this_iter_s: 132.87721586227417
  time_total_s: 13554.84697341919
  timestamp: 1638648604
  timesteps_since_restore: 21000
  timesteps_this_iter: 500
  timesteps_total: 21000
  training_iteration: 42
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     42 |          13554.8 | 21000 | 0.469164 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-12-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8684627575277337
  episode_reward_mean: 0.4650617813407195
  episode_reward_min: -0.32
  episodes_this_iter: 500
  episodes_total: 21500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1757.95
    learner:
      default_policy:
        cur_kl_coeff: 0.3375000059604645
        cur_lr: 4.999999873689376e-05
        entropy: 0.5992013812065125
        entropy_coeff: 0.0
        kl: 0.007531642913818359
        model: {}
        policy_loss: -0.040012702345848083
        total_loss: -0.024253200739622116
        vf_explained_var: 0.6031076908111572
        vf_loss: 0.013217573054134846
    load_time_ms: 2.386
    num_steps_sampled: 21500
    num_steps_trained: 21500
    sample_time_ms: 162170.431
    update_time_ms: 5.182
  iterations_since_restore: 43
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.985628742514969
    ram_util_percent: 15.710778443113771
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 628.8463300141915
    mean_inference_ms: 1.7153905727747871
    mean_processing_ms: 1.3799022771076772
  time_since_restore: 13671.617095947266
  time_this_iter_s: 116.77012252807617
  time_total_s: 13671.617095947266
  timestamp: 1638648721
  timesteps_since_restore: 21500
  timesteps_this_iter: 500
  timesteps_total: 21500
  training_iteration: 43
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     43 |          13671.6 | 21500 | 0.465062 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-13-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.4789560307566851
  episode_reward_min: -0.1145374449339207
  episodes_this_iter: 500
  episodes_total: 22000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1755.031
    learner:
      default_policy:
        cur_kl_coeff: 0.3375000059604645
        cur_lr: 4.999999873689376e-05
        entropy: 0.580407977104187
        entropy_coeff: 0.0
        kl: 0.007417738903313875
        model: {}
        policy_loss: -0.03209129348397255
        total_loss: -0.01766170747578144
        vf_explained_var: 0.6070190668106079
        vf_loss: 0.011926094070076942
    load_time_ms: 2.322
    num_steps_sampled: 22000
    num_steps_trained: 22000
    sample_time_ms: 154870.794
    update_time_ms: 5.247
  iterations_since_restore: 44
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.167721518987342
    ram_util_percent: 15.710759493670885
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 619.4674788830005
    mean_inference_ms: 1.705363763310108
    mean_processing_ms: 1.371201610170729
  time_since_restore: 13782.591908693314
  time_this_iter_s: 110.97481274604797
  time_total_s: 13782.591908693314
  timestamp: 1638648832
  timesteps_since_restore: 22000
  timesteps_this_iter: 500
  timesteps_total: 22000
  training_iteration: 44
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     44 |          13782.6 | 22000 | 0.478956 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-15-48
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8646362098138748
  episode_reward_mean: 0.47174655711852165
  episode_reward_min: -1.3421052631578947
  episodes_this_iter: 500
  episodes_total: 22500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1763.167
    learner:
      default_policy:
        cur_kl_coeff: 0.3375000059604645
        cur_lr: 4.999999873689376e-05
        entropy: 0.5635585784912109
        entropy_coeff: 0.0
        kl: 0.007046467624604702
        model: {}
        policy_loss: -0.03355441987514496
        total_loss: -0.011089458130300045
        vf_explained_var: 0.5211783051490784
        vf_loss: 0.020086780190467834
    load_time_ms: 2.324
    num_steps_sampled: 22500
    num_steps_trained: 22500
    sample_time_ms: 147706.862
    update_time_ms: 5.329
  iterations_since_restore: 45
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.345783132530121
    ram_util_percent: 15.704216867469878
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 610.7308906765229
    mean_inference_ms: 1.6961297026359112
    mean_processing_ms: 1.3634634994887271
  time_since_restore: 13898.76036310196
  time_this_iter_s: 116.16845440864563
  time_total_s: 13898.76036310196
  timestamp: 1638648948
  timesteps_since_restore: 22500
  timesteps_this_iter: 500
  timesteps_total: 22500
  training_iteration: 45
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     45 |          13898.8 | 22500 | 0.471747 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-17-24
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.874926943308007
  episode_reward_mean: 0.4970382646788973
  episode_reward_min: 0.047619047619047616
  episodes_this_iter: 500
  episodes_total: 23000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1776.977
    learner:
      default_policy:
        cur_kl_coeff: 0.3375000059604645
        cur_lr: 4.999999873689376e-05
        entropy: 0.5176128149032593
        entropy_coeff: 0.0
        kl: 0.007717515807598829
        model: {}
        policy_loss: -0.03576536476612091
        total_loss: -0.022775763645768166
        vf_explained_var: 0.6468526721000671
        vf_loss: 0.010384938679635525
    load_time_ms: 2.315
    num_steps_sampled: 23000
    num_steps_trained: 23000
    sample_time_ms: 139435.353
    update_time_ms: 5.384
  iterations_since_restore: 46
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.327007299270074
    ram_util_percent: 15.750364963503651
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 601.4978314196513
    mean_inference_ms: 1.6864995677379633
    mean_processing_ms: 1.3550269251818
  time_since_restore: 13994.769365310669
  time_this_iter_s: 96.00900220870972
  time_total_s: 13994.769365310669
  timestamp: 1638649044
  timesteps_since_restore: 23000
  timesteps_this_iter: 500
  timesteps_total: 23000
  training_iteration: 46
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     46 |          13994.8 | 23000 | 0.497038 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-18-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.49496241558623727
  episode_reward_min: -0.09276018099547512
  episodes_this_iter: 500
  episodes_total: 23500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1773.903
    learner:
      default_policy:
        cur_kl_coeff: 0.3375000059604645
        cur_lr: 4.999999873689376e-05
        entropy: 0.49558091163635254
        entropy_coeff: 0.0
        kl: 0.010185591876506805
        model: {}
        policy_loss: -0.03525742143392563
        total_loss: -0.01653328910470009
        vf_explained_var: 0.5350251793861389
        vf_loss: 0.015286501497030258
    load_time_ms: 2.322
    num_steps_sampled: 23500
    num_steps_trained: 23500
    sample_time_ms: 129786.776
    update_time_ms: 5.367
  iterations_since_restore: 47
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.279230769230768
    ram_util_percent: 15.72846153846154
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 592.4339347086351
    mean_inference_ms: 1.6773542512361506
    mean_processing_ms: 1.3467892906137349
  time_since_restore: 14085.45137500763
  time_this_iter_s: 90.68200969696045
  time_total_s: 14085.45137500763
  timestamp: 1638649135
  timesteps_since_restore: 23500
  timesteps_this_iter: 500
  timesteps_total: 23500
  training_iteration: 47
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     47 |          14085.5 | 23500 | 0.494962 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-20-27
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8821316614420063
  episode_reward_mean: 0.4833123838653995
  episode_reward_min: -2.1211305518169583
  episodes_this_iter: 500
  episodes_total: 24000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1771.322
    learner:
      default_policy:
        cur_kl_coeff: 0.3375000059604645
        cur_lr: 4.999999873689376e-05
        entropy: 0.5021841526031494
        entropy_coeff: 0.0
        kl: 0.00437699630856514
        model: {}
        policy_loss: -0.02428966946899891
        total_loss: 0.0020409629214555025
        vf_explained_var: 0.581007719039917
        vf_loss: 0.024853400886058807
    load_time_ms: 2.304
    num_steps_sampled: 24000
    num_steps_trained: 24000
    sample_time_ms: 120342.674
    update_time_ms: 5.425
  iterations_since_restore: 48
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.312213740458017
    ram_util_percent: 15.739694656488554
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 583.7967608959534
    mean_inference_ms: 1.668096020799752
    mean_processing_ms: 1.3388783766534853
  time_since_restore: 14177.290449857712
  time_this_iter_s: 91.8390748500824
  time_total_s: 14177.290449857712
  timestamp: 1638649227
  timesteps_since_restore: 24000
  timesteps_this_iter: 500
  timesteps_total: 24000
  training_iteration: 48
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     48 |          14177.3 | 24000 | 0.483312 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-22-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9531871043721478
  episode_reward_mean: 0.48380027341753395
  episode_reward_min: -0.3316582914572864
  episodes_this_iter: 500
  episodes_total: 24500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1772.946
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.4664996266365051
        entropy_coeff: 0.0
        kl: 0.009412920102477074
        model: {}
        policy_loss: -0.036880239844322205
        total_loss: -0.016443632543087006
        vf_explained_var: 0.5092222094535828
        vf_loss: 0.018848175182938576
    load_time_ms: 2.304
    num_steps_sampled: 24500
    num_steps_trained: 24500
    sample_time_ms: 113279.551
    update_time_ms: 5.44
  iterations_since_restore: 49
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.60597014925373
    ram_util_percent: 15.758208955223884
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 575.5863122748169
    mean_inference_ms: 1.661033174183061
    mean_processing_ms: 1.3330650399652855
  time_since_restore: 14271.077559947968
  time_this_iter_s: 93.78711009025574
  time_total_s: 14271.077559947968
  timestamp: 1638649321
  timesteps_since_restore: 24500
  timesteps_this_iter: 500
  timesteps_total: 24500
  training_iteration: 49
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     49 |          14271.1 | 24500 |   0.4838 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-23-33
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8926802421574023
  episode_reward_mean: 0.4995930810028835
  episode_reward_min: -0.152
  episodes_this_iter: 500
  episodes_total: 25000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1735.634
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.4753490090370178
        entropy_coeff: 0.0
        kl: 0.006277749314904213
        model: {}
        policy_loss: -0.023936785757541656
        total_loss: -0.00998708140105009
        vf_explained_var: 0.5866848230361938
        vf_loss: 0.012890334241092205
    load_time_ms: 2.282
    num_steps_sampled: 25000
    num_steps_trained: 25000
    sample_time_ms: 106273.26
    update_time_ms: 5.529
  iterations_since_restore: 50
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.314503816793891
    ram_util_percent: 15.73969465648855
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 567.6318796476045
    mean_inference_ms: 1.6550572317775014
    mean_processing_ms: 1.328486680250197
  time_since_restore: 14363.031005859375
  time_this_iter_s: 91.95344591140747
  time_total_s: 14363.031005859375
  timestamp: 1638649413
  timesteps_since_restore: 25000
  timesteps_this_iter: 500
  timesteps_total: 25000
  training_iteration: 50
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     50 |            14363 | 25000 | 0.499593 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-24-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8945362134688691
  episode_reward_mean: 0.5047388044181287
  episode_reward_min: -0.32098765432098764
  episodes_this_iter: 500
  episodes_total: 25500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1739.871
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.4455143213272095
        entropy_coeff: 0.0
        kl: 0.007521962746977806
        model: {}
        policy_loss: -0.030438421294093132
        total_loss: -0.016233891248703003
        vf_explained_var: 0.5864380598068237
        vf_loss: 0.012935196049511433
    load_time_ms: 2.281
    num_steps_sampled: 25500
    num_steps_trained: 25500
    sample_time_ms: 100398.356
    update_time_ms: 5.631
  iterations_since_restore: 51
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.56608695652174
    ram_util_percent: 15.73391304347826
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 559.5396033623965
    mean_inference_ms: 1.6484569088673429
    mean_processing_ms: 1.3229783565538742
  time_since_restore: 14443.522039413452
  time_this_iter_s: 80.49103355407715
  time_total_s: 14443.522039413452
  timestamp: 1638649493
  timesteps_since_restore: 25500
  timesteps_this_iter: 500
  timesteps_total: 25500
  training_iteration: 51
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     51 |          14443.5 | 25500 | 0.504739 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-26-33
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8564954682779456
  episode_reward_mean: 0.4565694957270665
  episode_reward_min: -0.350253807106599
  episodes_this_iter: 500
  episodes_total: 26000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1740.23
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.44860801100730896
        entropy_coeff: 0.0
        kl: 0.00804522167891264
        model: {}
        policy_loss: -0.027031471952795982
        total_loss: -0.012151220813393593
        vf_explained_var: 0.5736591219902039
        vf_loss: 0.013522611930966377
    load_time_ms: 2.289
    num_steps_sampled: 26000
    num_steps_trained: 26000
    sample_time_ms: 97030.147
    update_time_ms: 5.623
  iterations_since_restore: 52
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.687323943661974
    ram_util_percent: 15.754929577464791
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 552.4744844258756
    mean_inference_ms: 1.6426195305524656
    mean_processing_ms: 1.3178103859848869
  time_since_restore: 14542.720637321472
  time_this_iter_s: 99.19859790802002
  time_total_s: 14542.720637321472
  timestamp: 1638649593
  timesteps_since_restore: 26000
  timesteps_this_iter: 500
  timesteps_total: 26000
  training_iteration: 52
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     52 |          14542.7 | 26000 | 0.456569 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-27-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8462837837837838
  episode_reward_mean: 0.42262117154184703
  episode_reward_min: -0.3640661938534279
  episodes_this_iter: 500
  episodes_total: 26500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1727.842
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.5125311017036438
        entropy_coeff: 0.0
        kl: 0.009895166382193565
        model: {}
        policy_loss: -0.03141487389802933
        total_loss: -0.012962737120687962
        vf_explained_var: 0.5544168949127197
        vf_loss: 0.01678232103586197
    load_time_ms: 2.311
    num_steps_sampled: 26500
    num_steps_trained: 26500
    sample_time_ms: 93572.592
    update_time_ms: 5.655
  iterations_since_restore: 53
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.56837606837607
    ram_util_percent: 15.77863247863248
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 545.0329384908673
    mean_inference_ms: 1.6377699752559456
    mean_processing_ms: 1.3136041690248763
  time_since_restore: 14624.791851758957
  time_this_iter_s: 82.07121443748474
  time_total_s: 14624.791851758957
  timestamp: 1638649675
  timesteps_since_restore: 26500
  timesteps_this_iter: 500
  timesteps_total: 26500
  training_iteration: 53
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     53 |          14624.8 | 26500 | 0.422621 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-29-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.4240205708923693
  episode_reward_min: -0.04918032786885246
  episodes_this_iter: 500
  episodes_total: 27000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1730.682
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.4680663049221039
        entropy_coeff: 0.0
        kl: 0.012585696764290333
        model: {}
        policy_loss: -0.03784547746181488
        total_loss: -0.021720945835113525
        vf_explained_var: 0.6232587695121765
        vf_loss: 0.01400068961083889
    load_time_ms: 2.31
    num_steps_sampled: 27000
    num_steps_trained: 27000
    sample_time_ms: 89768.668
    update_time_ms: 5.612
  iterations_since_restore: 54
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.45096153846154
    ram_util_percent: 15.74903846153846
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 537.5325503090937
    mean_inference_ms: 1.63161394786033
    mean_processing_ms: 1.3085337887118997
  time_since_restore: 14697.757128953934
  time_this_iter_s: 72.9652771949768
  time_total_s: 14697.757128953934
  timestamp: 1638649748
  timesteps_since_restore: 27000
  timesteps_this_iter: 500
  timesteps_total: 27000
  training_iteration: 54
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     54 |          14697.8 | 27000 | 0.424021 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-30-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8504273504273504
  episode_reward_mean: 0.4369188322666971
  episode_reward_min: -0.16791044776119404
  episodes_this_iter: 500
  episodes_total: 27500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1719.182
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.4822084903717041
        entropy_coeff: 0.0
        kl: 0.00841377954930067
        model: {}
        policy_loss: -0.028959356248378754
        total_loss: -0.010694045573472977
        vf_explained_var: 0.5570314526557922
        vf_loss: 0.016845492646098137
    load_time_ms: 2.312
    num_steps_sampled: 27500
    num_steps_trained: 27500
    sample_time_ms: 85212.97
    update_time_ms: 5.526
  iterations_since_restore: 55
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.474257425742575
    ram_util_percent: 15.74950495049505
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 530.2176901541736
    mean_inference_ms: 1.6252281128209334
    mean_processing_ms: 1.3033418342254925
  time_since_restore: 14768.25301861763
  time_this_iter_s: 70.49588966369629
  time_total_s: 14768.25301861763
  timestamp: 1638649818
  timesteps_since_restore: 27500
  timesteps_this_iter: 500
  timesteps_total: 27500
  training_iteration: 55
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     55 |          14768.3 | 27500 | 0.436919 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-31-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647845468053492
  episode_reward_mean: 0.4415492279093514
  episode_reward_min: -0.233201581027668
  episodes_this_iter: 500
  episodes_total: 28000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1712.48
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.4681275188922882
        entropy_coeff: 0.0
        kl: 0.008145836181938648
        model: {}
        policy_loss: -0.028895452618598938
        total_loss: -0.008873837999999523
        vf_explained_var: 0.4885258376598358
        vf_loss: 0.018646996468305588
    load_time_ms: 2.365
    num_steps_sampled: 28000
    num_steps_trained: 28000
    sample_time_ms: 83829.741
    update_time_ms: 5.567
  iterations_since_restore: 56
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.495726495726496
    ram_util_percent: 15.756410256410259
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 523.5751408227217
    mean_inference_ms: 1.6196024068351018
    mean_processing_ms: 1.2982628148886342
  time_since_restore: 14850.363550901413
  time_this_iter_s: 82.11053228378296
  time_total_s: 14850.363550901413
  timestamp: 1638649901
  timesteps_since_restore: 28000
  timesteps_this_iter: 500
  timesteps_total: 28000
  training_iteration: 56
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     56 |          14850.4 | 28000 | 0.441549 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-32-54
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8565340909090909
  episode_reward_mean: 0.4678181461831541
  episode_reward_min: -0.1444043321299639
  episodes_this_iter: 500
  episodes_total: 28500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1703.872
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.4737154245376587
        entropy_coeff: 0.0
        kl: 0.009539465419948101
        model: {}
        policy_loss: -0.033437784761190414
        total_loss: -0.019109327346086502
        vf_explained_var: 0.5739979147911072
        vf_loss: 0.012718677520751953
    load_time_ms: 2.404
    num_steps_sampled: 28500
    num_steps_trained: 28500
    sample_time_ms: 82139.627
    update_time_ms: 5.655
  iterations_since_restore: 57
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.731428571428573
    ram_util_percent: 15.811428571428571
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 516.873681676174
    mean_inference_ms: 1.6137963616845068
    mean_processing_ms: 1.293430068711139
  time_since_restore: 14924.059815883636
  time_this_iter_s: 73.69626498222351
  time_total_s: 14924.059815883636
  timestamp: 1638649974
  timesteps_since_restore: 28500
  timesteps_this_iter: 500
  timesteps_total: 28500
  training_iteration: 57
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     57 |          14924.1 | 28500 | 0.467818 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-34-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.45828550999533535
  episode_reward_min: -0.32
  episodes_this_iter: 500
  episodes_total: 29000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1696.411
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.5286208987236023
        entropy_coeff: 0.0
        kl: 0.00968920812010765
        model: {}
        policy_loss: -0.037182748317718506
        total_loss: -0.023627886548638344
        vf_explained_var: 0.6624244451522827
        vf_loss: 0.011919807642698288
    load_time_ms: 2.409
    num_steps_sampled: 29000
    num_steps_trained: 29000
    sample_time_ms: 81087.84
    update_time_ms: 5.577
  iterations_since_restore: 58
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.424999999999999
    ram_util_percent: 15.745689655172415
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 510.66315331535833
    mean_inference_ms: 1.6087091674862568
    mean_processing_ms: 1.2886656148241065
  time_since_restore: 15005.30499958992
  time_this_iter_s: 81.24518370628357
  time_total_s: 15005.30499958992
  timestamp: 1638650056
  timesteps_since_restore: 29000
  timesteps_this_iter: 500
  timesteps_total: 29000
  training_iteration: 58
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     58 |          15005.3 | 29000 | 0.458286 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-35-30
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647058823529412
  episode_reward_mean: 0.48136743955739464
  episode_reward_min: -0.44751381215469616
  episodes_this_iter: 500
  episodes_total: 29500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1692.635
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.4883388876914978
        entropy_coeff: 0.0
        kl: 0.008277880027890205
        model: {}
        policy_loss: -0.03424428403377533
        total_loss: -0.0206154752522707
        vf_explained_var: 0.6395430564880371
        vf_loss: 0.012231913395226002
    load_time_ms: 2.383
    num_steps_sampled: 29500
    num_steps_trained: 29500
    sample_time_ms: 79172.195
    update_time_ms: 5.621
  iterations_since_restore: 59
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.386915887850465
    ram_util_percent: 15.752336448598129
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 504.436758226356
    mean_inference_ms: 1.6025626971751477
    mean_processing_ms: 1.283615000195182
  time_since_restore: 15079.894987821579
  time_this_iter_s: 74.58998823165894
  time_total_s: 15079.894987821579
  timestamp: 1638650130
  timesteps_since_restore: 29500
  timesteps_this_iter: 500
  timesteps_total: 29500
  training_iteration: 59
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     59 |          15079.9 | 29500 | 0.481367 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-36-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.4687716502911174
  episode_reward_min: -0.40217391304347827
  episodes_this_iter: 500
  episodes_total: 30000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1693.878
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.45065784454345703
        entropy_coeff: 0.0
        kl: 0.007611952256411314
        model: {}
        policy_loss: -0.03515104576945305
        total_loss: -0.02007930353283882
        vf_explained_var: 0.5912591814994812
        vf_loss: 0.013787217438220978
    load_time_ms: 2.388
    num_steps_sampled: 30000
    num_steps_trained: 30000
    sample_time_ms: 76307.866
    update_time_ms: 5.674
  iterations_since_restore: 60
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.989010989010987
    ram_util_percent: 15.782417582417583
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 498.0427518073236
    mean_inference_ms: 1.5967789063759315
    mean_processing_ms: 1.2788198251795129
  time_since_restore: 15143.218025684357
  time_this_iter_s: 63.32303786277771
  time_total_s: 15143.218025684357
  timestamp: 1638650194
  timesteps_since_restore: 30000
  timesteps_this_iter: 500
  timesteps_total: 30000
  training_iteration: 60
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     60 |          15143.2 | 30000 | 0.468772 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-37-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8646362098138748
  episode_reward_mean: 0.4767376862345877
  episode_reward_min: -1.0146198830409356
  episodes_this_iter: 500
  episodes_total: 30500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1694.488
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.45014235377311707
        entropy_coeff: 0.0
        kl: 0.006357701029628515
        model: {}
        policy_loss: -0.029907558113336563
        total_loss: -0.01199992373585701
        vf_explained_var: 0.5166711807250977
        vf_loss: 0.016834763810038567
    load_time_ms: 2.389
    num_steps_sampled: 30500
    num_steps_trained: 30500
    sample_time_ms: 75873.805
    update_time_ms: 5.625
  iterations_since_restore: 61
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.318518518518522
    ram_util_percent: 15.732407407407406
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 492.27668651928377
    mean_inference_ms: 1.5917125285553124
    mean_processing_ms: 1.2745002868398208
  time_since_restore: 15219.375129461288
  time_this_iter_s: 76.15710377693176
  time_total_s: 15219.375129461288
  timestamp: 1638650270
  timesteps_since_restore: 30500
  timesteps_this_iter: 500
  timesteps_total: 30500
  training_iteration: 61
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     61 |          15219.4 | 30500 | 0.476738 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-38-48
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.874926943308007
  episode_reward_mean: 0.49961584898450173
  episode_reward_min: -0.3684210526315789
  episodes_this_iter: 500
  episodes_total: 31000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1678.213
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.3760417103767395
        entropy_coeff: 0.0
        kl: 0.005785924382507801
        model: {}
        policy_loss: -0.02622757852077484
        total_loss: -0.01169633399695158
        vf_explained_var: 0.599661648273468
        vf_loss: 0.013554861769080162
    load_time_ms: 2.412
    num_steps_sampled: 31000
    num_steps_trained: 31000
    sample_time_ms: 71766.686
    update_time_ms: 5.761
  iterations_since_restore: 62
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.783132530120483
    ram_util_percent: 15.74698795180723
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 486.11214519996764
    mean_inference_ms: 1.5869405337992895
    mean_processing_ms: 1.270718660813286
  time_since_restore: 15277.342304468155
  time_this_iter_s: 57.967175006866455
  time_total_s: 15277.342304468155
  timestamp: 1638650328
  timesteps_since_restore: 31000
  timesteps_this_iter: 500
  timesteps_total: 31000
  training_iteration: 62
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     62 |          15277.3 | 31000 | 0.499616 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-39-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.4814273078223535
  episode_reward_min: -0.37841726618705035
  episodes_this_iter: 500
  episodes_total: 31500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1670.605
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.3836721181869507
        entropy_coeff: 0.0
        kl: 0.005618085153400898
        model: {}
        policy_loss: -0.02420615404844284
        total_loss: -0.006696512922644615
        vf_explained_var: 0.5449499487876892
        vf_loss: 0.01656159572303295
    load_time_ms: 2.395
    num_steps_sampled: 31500
    num_steps_trained: 31500
    sample_time_ms: 69134.174
    update_time_ms: 5.668
  iterations_since_restore: 63
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.116249999999999
    ram_util_percent: 15.86375
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 480.0720301428574
    mean_inference_ms: 1.5819000670283276
    mean_processing_ms: 1.2671190089095012
  time_since_restore: 15333.011037826538
  time_this_iter_s: 55.66873335838318
  time_total_s: 15333.011037826538
  timestamp: 1638650384
  timesteps_since_restore: 31500
  timesteps_this_iter: 500
  timesteps_total: 31500
  training_iteration: 63
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     63 |            15333 | 31500 | 0.481427 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-40-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9531871043721478
  episode_reward_mean: 0.49664480439860836
  episode_reward_min: -0.3050847457627119
  episodes_this_iter: 500
  episodes_total: 32000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1684.79
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.3826017379760742
        entropy_coeff: 0.0
        kl: 0.008875081315636635
        model: {}
        policy_loss: -0.03268786147236824
        total_loss: -0.017466451972723007
        vf_explained_var: 0.5881116390228271
        vf_loss: 0.013723735697567463
    load_time_ms: 2.396
    num_steps_sampled: 32000
    num_steps_trained: 32000
    sample_time_ms: 66593.349
    update_time_ms: 5.731
  iterations_since_restore: 64
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.899999999999999
    ram_util_percent: 15.798529411764708
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 473.9673714992243
    mean_inference_ms: 1.5763931730971377
    mean_processing_ms: 1.2620654069931447
  time_since_restore: 15380.70927476883
  time_this_iter_s: 47.69823694229126
  time_total_s: 15380.70927476883
  timestamp: 1638650432
  timesteps_since_restore: 32000
  timesteps_this_iter: 500
  timesteps_total: 32000
  training_iteration: 64
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     64 |          15380.7 | 32000 | 0.496645 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-41-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8814285714285715
  episode_reward_mean: 0.4868959571235991
  episode_reward_min: -0.1111111111111111
  episodes_this_iter: 500
  episodes_total: 32500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1683.494
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.35170313715934753
        entropy_coeff: 0.0
        kl: 0.009089468978345394
        model: {}
        policy_loss: -0.023049786686897278
        total_loss: -0.006918209604918957
        vf_explained_var: 0.5499650835990906
        vf_loss: 0.014597722329199314
    load_time_ms: 2.385
    num_steps_sampled: 32500
    num_steps_trained: 32500
    sample_time_ms: 64338.675
    update_time_ms: 5.923
  iterations_since_restore: 65
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.18840579710145
    ram_util_percent: 15.743478260869567
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 468.06460383312435
    mean_inference_ms: 1.570778499584609
    mean_processing_ms: 1.2568878557516174
  time_since_restore: 15428.647739887238
  time_this_iter_s: 47.9384651184082
  time_total_s: 15428.647739887238
  timestamp: 1638650480
  timesteps_since_restore: 32500
  timesteps_this_iter: 500
  timesteps_total: 32500
  training_iteration: 65
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     65 |          15428.6 | 32500 | 0.486896 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-42-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8926802421574023
  episode_reward_mean: 0.4906146305556467
  episode_reward_min: -0.03731343283582089
  episodes_this_iter: 500
  episodes_total: 33000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1673.428
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.3678724765777588
        entropy_coeff: 0.0
        kl: 0.0069095296785235405
        model: {}
        policy_loss: -0.03187021613121033
        total_loss: -0.018244387581944466
        vf_explained_var: 0.5889586806297302
        vf_loss: 0.01245984435081482
    load_time_ms: 2.438
    num_steps_sampled: 33000
    num_steps_trained: 33000
    sample_time_ms: 61987.297
    update_time_ms: 5.882
  iterations_since_restore: 66
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.8
    ram_util_percent: 15.74698795180723
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 462.65982898819556
    mean_inference_ms: 1.5655483882653558
    mean_processing_ms: 1.2524766035684798
  time_since_restore: 15487.144459486008
  time_this_iter_s: 58.49671959877014
  time_total_s: 15487.144459486008
  timestamp: 1638650538
  timesteps_since_restore: 33000
  timesteps_this_iter: 500
  timesteps_total: 33000
  training_iteration: 66
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     66 |          15487.1 | 33000 | 0.490615 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-42-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8945362134688691
  episode_reward_mean: 0.5070669909996744
  episode_reward_min: -0.18465227817745802
  episodes_this_iter: 500
  episodes_total: 33500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1680.913
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.3511109948158264
        entropy_coeff: 0.0
        kl: 0.004108229652047157
        model: {}
        policy_loss: -0.02335755154490471
        total_loss: -0.00923584308475256
        vf_explained_var: 0.5761101841926575
        vf_loss: 0.013428433798253536
    load_time_ms: 2.476
    num_steps_sampled: 33500
    num_steps_trained: 33500
    sample_time_ms: 58473.993
    update_time_ms: 5.845
  iterations_since_restore: 67
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.04909090909091
    ram_util_percent: 15.718181818181822
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 456.82217118946545
    mean_inference_ms: 1.5598354238256948
    mean_processing_ms: 1.2476427021825394
  time_since_restore: 15525.782410383224
  time_this_iter_s: 38.6379508972168
  time_total_s: 15525.782410383224
  timestamp: 1638650577
  timesteps_since_restore: 33500
  timesteps_this_iter: 500
  timesteps_total: 33500
  training_iteration: 67
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     67 |          15525.8 | 33500 | 0.507067 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-43-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8564954682779456
  episode_reward_mean: 0.43645636825262785
  episode_reward_min: -0.3640661938534279
  episodes_this_iter: 500
  episodes_total: 34000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1688.679
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3723611533641815
        entropy_coeff: 0.0
        kl: 0.005688789300620556
        model: {}
        policy_loss: -0.020369118079543114
        total_loss: -0.003228929126635194
        vf_explained_var: 0.5397781133651733
        vf_loss: 0.01666019856929779
    load_time_ms: 2.51
    num_steps_sampled: 34000
    num_steps_trained: 34000
    sample_time_ms: 55488.69
    update_time_ms: 5.896
  iterations_since_restore: 68
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.935135135135132
    ram_util_percent: 15.733783783783787
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 451.5320767318811
    mean_inference_ms: 1.5551977930887702
    mean_processing_ms: 1.2433085314389771
  time_since_restore: 15577.253279924393
  time_this_iter_s: 51.47086954116821
  time_total_s: 15577.253279924393
  timestamp: 1638650629
  timesteps_since_restore: 34000
  timesteps_this_iter: 500
  timesteps_total: 34000
  training_iteration: 68
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     68 |          15577.3 | 34000 | 0.436456 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-44-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8568935427574171
  episode_reward_mean: 0.426624830234664
  episode_reward_min: -0.33157894736842103
  episodes_this_iter: 500
  episodes_total: 34500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1687.447
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.38366150856018066
        entropy_coeff: 0.0
        kl: 0.00874722097069025
        model: {}
        policy_loss: -0.029131606221199036
        total_loss: -0.012747147120535374
        vf_explained_var: 0.594033420085907
        vf_loss: 0.015646405518054962
    load_time_ms: 2.51
    num_steps_sampled: 34500
    num_steps_trained: 34500
    sample_time_ms: 51923.189
    update_time_ms: 5.913
  iterations_since_restore: 69
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.43392857142857
    ram_util_percent: 15.732142857142858
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 446.03298149994527
    mean_inference_ms: 1.5502435905837118
    mean_processing_ms: 1.2388622922132486
  time_since_restore: 15616.176174163818
  time_this_iter_s: 38.92289423942566
  time_total_s: 15616.176174163818
  timestamp: 1638650668
  timesteps_since_restore: 34500
  timesteps_this_iter: 500
  timesteps_total: 34500
  training_iteration: 69
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     69 |          15616.2 | 34500 | 0.426625 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-45-00
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.4307331541127231
  episode_reward_min: -0.07336683417085427
  episodes_this_iter: 500
  episodes_total: 35000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1682.894
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3438692092895508
        entropy_coeff: 0.0
        kl: 0.004421671386808157
        model: {}
        policy_loss: -0.01570405438542366
        total_loss: -0.00042660950566641986
        vf_explained_var: 0.5984978079795837
        vf_loss: 0.014904363080859184
    load_time_ms: 2.496
    num_steps_sampled: 35000
    num_steps_trained: 35000
    sample_time_ms: 48848.248
    update_time_ms: 5.829
  iterations_since_restore: 70
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.9
    ram_util_percent: 15.730434782608704
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 440.5104349158203
    mean_inference_ms: 1.5449978134256845
    mean_processing_ms: 1.2343236710091274
  time_since_restore: 15648.706147909164
  time_this_iter_s: 32.52997374534607
  time_total_s: 15648.706147909164
  timestamp: 1638650700
  timesteps_since_restore: 35000
  timesteps_this_iter: 500
  timesteps_total: 35000
  training_iteration: 70
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     70 |          15648.7 | 35000 | 0.430733 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-45-37
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8504273504273504
  episode_reward_mean: 0.432131560343566
  episode_reward_min: -0.16791044776119404
  episodes_this_iter: 500
  episodes_total: 35500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1675.924
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.39834973216056824
        entropy_coeff: 0.0
        kl: 0.009734044782817364
        model: {}
        policy_loss: -0.021391194313764572
        total_loss: -0.00457396637648344
        vf_explained_var: 0.4985750615596771
        vf_loss: 0.016406577080488205
    load_time_ms: 2.496
    num_steps_sampled: 35500
    num_steps_trained: 35500
    sample_time_ms: 44919.007
    update_time_ms: 5.831
  iterations_since_restore: 71
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.030188679245281
    ram_util_percent: 15.724528301886794
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 435.26318738072433
    mean_inference_ms: 1.539840264668388
    mean_processing_ms: 1.2297465235027627
  time_since_restore: 15685.499134778976
  time_this_iter_s: 36.79298686981201
  time_total_s: 15685.499134778976
  timestamp: 1638650737
  timesteps_since_restore: 35500
  timesteps_this_iter: 500
  timesteps_total: 35500
  training_iteration: 71
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     71 |          15685.5 | 35500 | 0.432132 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-46-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647845468053492
  episode_reward_mean: 0.45696332426152275
  episode_reward_min: -0.1444043321299639
  episodes_this_iter: 500
  episodes_total: 36000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1762.068
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.37743592262268066
        entropy_coeff: 0.0
        kl: 0.010351822711527348
        model: {}
        policy_loss: -0.019023509696125984
        total_loss: -0.0015312969917431474
        vf_explained_var: 0.5329478979110718
        vf_loss: 0.01705549657344818
    load_time_ms: 2.516
    num_steps_sampled: 36000
    num_steps_trained: 36000
    sample_time_ms: 43538.693
    update_time_ms: 5.824
  iterations_since_restore: 72
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.8109375
    ram_util_percent: 15.74375
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 430.3637071767219
    mean_inference_ms: 1.5361734153277307
    mean_processing_ms: 1.2269374122321879
  time_since_restore: 15730.527354478836
  time_this_iter_s: 45.02821969985962
  time_total_s: 15730.527354478836
  timestamp: 1638650782
  timesteps_since_restore: 36000
  timesteps_this_iter: 500
  timesteps_total: 36000
  training_iteration: 72
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     72 |          15730.5 | 36000 | 0.456963 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-47-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.4668764960640178
  episode_reward_min: -0.26542056074766357
  episodes_this_iter: 500
  episodes_total: 36500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1764.223
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.36693644523620605
        entropy_coeff: 0.0
        kl: 0.007458253297954798
        model: {}
        policy_loss: -0.02580946683883667
        total_loss: -0.012527110986411572
        vf_explained_var: 0.6433449387550354
        vf_loss: 0.012967702001333237
    load_time_ms: 2.505
    num_steps_sampled: 36500
    num_steps_trained: 36500
    sample_time_ms: 42094.693
    update_time_ms: 6.02
  iterations_since_restore: 73
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.906779661016952
    ram_util_percent: 15.735593220338984
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 425.51498709500714
    mean_inference_ms: 1.5349913870111591
    mean_processing_ms: 1.2259443689152292
  time_since_restore: 15771.780870437622
  time_this_iter_s: 41.25351595878601
  time_total_s: 15771.780870437622
  timestamp: 1638650824
  timesteps_since_restore: 36500
  timesteps_this_iter: 500
  timesteps_total: 36500
  training_iteration: 73
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     73 |          15771.8 | 36500 | 0.466876 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-47-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8684627575277337
  episode_reward_mean: 0.454247445963855
  episode_reward_min: -1.353846153846154
  episodes_this_iter: 500
  episodes_total: 37000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1776.751
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.4138854742050171
        entropy_coeff: 0.0
        kl: 0.0058657340705394745
        model: {}
        policy_loss: -0.02763347327709198
        total_loss: -0.0096615394577384
        vf_explained_var: 0.5999569892883301
        vf_loss: 0.017724476754665375
    load_time_ms: 2.564
    num_steps_sampled: 37000
    num_steps_trained: 37000
    sample_time_ms: 42207.56
    update_time_ms: 5.975
  iterations_since_restore: 74
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.248571428571427
    ram_util_percent: 15.727142857142862
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 421.000840505978
    mean_inference_ms: 1.5316828886002052
    mean_processing_ms: 1.223342431106747
  time_since_restore: 15820.732826471329
  time_this_iter_s: 48.951956033706665
  time_total_s: 15820.732826471329
  timestamp: 1638650873
  timesteps_since_restore: 37000
  timesteps_this_iter: 500
  timesteps_total: 37000
  training_iteration: 74
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     74 |          15820.7 | 37000 | 0.454247 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-48-37
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.4844546530212227
  episode_reward_min: 0.01904761904761905
  episodes_this_iter: 500
  episodes_total: 37500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1789.947
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.38103339076042175
        entropy_coeff: 0.0
        kl: 0.0099679846316576
        model: {}
        policy_loss: -0.02531360648572445
        total_loss: -0.012791890650987625
        vf_explained_var: 0.6116645336151123
        vf_loss: 0.012101191096007824
    load_time_ms: 2.581
    num_steps_sampled: 37500
    num_steps_trained: 37500
    sample_time_ms: 41813.357
    update_time_ms: 5.875
  iterations_since_restore: 75
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.784126984126983
    ram_util_percent: 15.742857142857146
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 416.48576740315644
    mean_inference_ms: 1.5276325902590187
    mean_processing_ms: 1.2196574362814354
  time_since_restore: 15864.86010837555
  time_this_iter_s: 44.12728190422058
  time_total_s: 15864.86010837555
  timestamp: 1638650917
  timesteps_since_restore: 37500
  timesteps_this_iter: 500
  timesteps_total: 37500
  training_iteration: 75
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     75 |          15864.9 | 37500 | 0.484455 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-49-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8646362098138748
  episode_reward_mean: 0.47400651880443445
  episode_reward_min: -0.40217391304347827
  episodes_this_iter: 500
  episodes_total: 38000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1792.317
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.3374432623386383
        entropy_coeff: 0.0
        kl: 0.009892160072922707
        model: {}
        policy_loss: -0.02580222673714161
        total_loss: -0.012866570614278316
        vf_explained_var: 0.6369569897651672
        vf_loss: 0.012518323957920074
    load_time_ms: 2.544
    num_steps_sampled: 38000
    num_steps_trained: 38000
    sample_time_ms: 38826.793
    update_time_ms: 5.857
  iterations_since_restore: 76
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.704878048780488
    ram_util_percent: 15.826829268292686
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 411.68597546920233
    mean_inference_ms: 1.5231968619278182
    mean_processing_ms: 1.2158173980977904
  time_since_restore: 15893.514122247696
  time_this_iter_s: 28.654013872146606
  time_total_s: 15893.514122247696
  timestamp: 1638650946
  timesteps_since_restore: 38000
  timesteps_this_iter: 500
  timesteps_total: 38000
  training_iteration: 76
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     76 |          15893.5 | 38000 | 0.474007 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-49-38
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.874926943308007
  episode_reward_mean: 0.4816775048990025
  episode_reward_min: -1.0116279069767442
  episodes_this_iter: 500
  episodes_total: 38500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1795.632
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.3585510551929474
        entropy_coeff: 0.0
        kl: 0.008391723036766052
        model: {}
        policy_loss: -0.027506094425916672
        total_loss: -0.011237435042858124
        vf_explained_var: 0.5557488203048706
        vf_loss: 0.015914639458060265
    load_time_ms: 2.499
    num_steps_sampled: 38500
    num_steps_trained: 38500
    sample_time_ms: 38164.268
    update_time_ms: 5.83
  iterations_since_restore: 77
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.56304347826087
    ram_util_percent: 15.819565217391311
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 407.0960151409502
    mean_inference_ms: 1.5190307117029278
    mean_processing_ms: 1.2122486440278544
  time_since_restore: 15925.55919623375
  time_this_iter_s: 32.04507398605347
  time_total_s: 15925.55919623375
  timestamp: 1638650978
  timesteps_since_restore: 38500
  timesteps_this_iter: 500
  timesteps_total: 38500
  training_iteration: 77
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     77 |          15925.6 | 38500 | 0.481678 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-50-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.499241247839636
  episode_reward_min: 0.028639618138424822
  episodes_this_iter: 500
  episodes_total: 39000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1797.751
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.305961012840271
        entropy_coeff: 0.0
        kl: 0.00808798335492611
        model: {}
        policy_loss: -0.023095890879631042
        total_loss: -0.008577869273722172
        vf_explained_var: 0.5582868456840515
        vf_loss: 0.014176798984408379
    load_time_ms: 2.519
    num_steps_sampled: 39000
    num_steps_trained: 39000
    sample_time_ms: 35982.438
    update_time_ms: 5.852
  iterations_since_restore: 78
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.606976744186044
    ram_util_percent: 15.753488372093026
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 402.5628684847812
    mean_inference_ms: 1.5147839297741148
    mean_processing_ms: 1.2091259623682775
  time_since_restore: 15955.23397231102
  time_this_iter_s: 29.674776077270508
  time_total_s: 15955.23397231102
  timestamp: 1638651008
  timesteps_since_restore: 39000
  timesteps_this_iter: 500
  timesteps_total: 39000
  training_iteration: 78
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     78 |          15955.2 | 39000 | 0.499241 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-50-36
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8821316614420063
  episode_reward_mean: 0.4872383035528263
  episode_reward_min: -0.0032258064516129032
  episodes_this_iter: 500
  episodes_total: 39500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1800.526
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.44220417737960815
        entropy_coeff: 0.0
        kl: 0.047018036246299744
        model: {}
        policy_loss: -0.03700322285294533
        total_loss: -0.021538682281970978
        vf_explained_var: 0.604362428188324
        vf_loss: 0.013480969704687595
    load_time_ms: 2.486
    num_steps_sampled: 39500
    num_steps_trained: 39500
    sample_time_ms: 34913.219
    update_time_ms: 5.855
  iterations_since_restore: 79
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.0825
    ram_util_percent: 15.752500000000001
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 398.1093088315019
    mean_inference_ms: 1.5107291954528992
    mean_processing_ms: 1.2056473004588906
  time_since_restore: 15983.490975618362
  time_this_iter_s: 28.25700330734253
  time_total_s: 15983.490975618362
  timestamp: 1638651036
  timesteps_since_restore: 39500
  timesteps_this_iter: 500
  timesteps_total: 39500
  training_iteration: 79
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     79 |          15983.5 | 39500 | 0.487238 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-51-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9531871043721478
  episode_reward_mean: 0.49705779927994687
  episode_reward_min: -0.029900332225913623
  episodes_this_iter: 500
  episodes_total: 40000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1815.44
    learner:
      default_policy:
        cur_kl_coeff: 0.06328125298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.36278682947158813
        entropy_coeff: 0.0
        kl: 0.026838624849915504
        model: {}
        policy_loss: -0.037114113569259644
        total_loss: -0.020762266591191292
        vf_explained_var: 0.5419310331344604
        vf_loss: 0.014653464779257774
    load_time_ms: 2.553
    num_steps_sampled: 40000
    num_steps_trained: 40000
    sample_time_ms: 36167.73
    update_time_ms: 5.971
  iterations_since_restore: 80
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.189230769230768
    ram_util_percent: 15.744615384615386
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 394.18705752282074
    mean_inference_ms: 1.5078368167520053
    mean_processing_ms: 1.2033961331295087
  time_since_restore: 16028.71424627304
  time_this_iter_s: 45.223270654678345
  time_total_s: 16028.71424627304
  timestamp: 1638651082
  timesteps_since_restore: 40000
  timesteps_this_iter: 500
  timesteps_total: 40000
  training_iteration: 80
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     80 |          16028.7 | 40000 | 0.497058 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-51-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8921298844248762
  episode_reward_mean: 0.4896469475221879
  episode_reward_min: -0.15137614678899083
  episodes_this_iter: 500
  episodes_total: 40500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1816.742
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.4118219017982483
        entropy_coeff: 0.0
        kl: 0.009324397891759872
        model: {}
        policy_loss: -0.026095710694789886
        total_loss: -0.011080357246100903
        vf_explained_var: 0.6033236980438232
        vf_loss: 0.014130257070064545
    load_time_ms: 2.582
    num_steps_sampled: 40500
    num_steps_trained: 40500
    sample_time_ms: 36048.471
    update_time_ms: 5.995
  iterations_since_restore: 81
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.919607843137252
    ram_util_percent: 15.776470588235297
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 390.1294332466456
    mean_inference_ms: 1.503958519245471
    mean_processing_ms: 1.2001722601471925
  time_since_restore: 16064.328045368195
  time_this_iter_s: 35.61379909515381
  time_total_s: 16064.328045368195
  timestamp: 1638651117
  timesteps_since_restore: 40500
  timesteps_this_iter: 500
  timesteps_total: 40500
  training_iteration: 81
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     81 |          16064.3 | 40500 | 0.489647 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-52-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8945362134688691
  episode_reward_mean: 0.5057087268078543
  episode_reward_min: 0.02912621359223301
  episodes_this_iter: 500
  episodes_total: 41000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1730.569
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.38637641072273254
        entropy_coeff: 0.0
        kl: 0.006873117759823799
        model: {}
        policy_loss: -0.0245701614767313
        total_loss: -0.010883757844567299
        vf_explained_var: 0.572528600692749
        vf_loss: 0.013033999130129814
    load_time_ms: 2.539
    num_steps_sampled: 41000
    num_steps_trained: 41000
    sample_time_ms: 35812.962
    update_time_ms: 5.961
  iterations_since_restore: 82
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.263333333333332
    ram_util_percent: 15.790000000000003
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 386.32154403083257
    mean_inference_ms: 1.5007249814894563
    mean_processing_ms: 1.1974860946101877
  time_since_restore: 16106.137115240097
  time_this_iter_s: 41.809069871902466
  time_total_s: 16106.137115240097
  timestamp: 1638651159
  timesteps_since_restore: 41000
  timesteps_this_iter: 500
  timesteps_total: 41000
  training_iteration: 82
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     82 |          16106.1 | 41000 | 0.505709 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-53-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8564954682779456
  episode_reward_mean: 0.4730133372092877
  episode_reward_min: 0.04371584699453552
  episodes_this_iter: 500
  episodes_total: 41500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1742.847
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.4048357307910919
        entropy_coeff: 0.0
        kl: 0.005710559897124767
        model: {}
        policy_loss: -0.017079826444387436
        total_loss: -0.0038693267852067947
        vf_explained_var: 0.6019690632820129
        vf_loss: 0.012668442912399769
    load_time_ms: 2.57
    num_steps_sampled: 41500
    num_steps_trained: 41500
    sample_time_ms: 34336.473
    update_time_ms: 5.823
  iterations_since_restore: 83
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.607894736842105
    ram_util_percent: 15.810526315789476
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 382.2384658760256
    mean_inference_ms: 1.496661476610839
    mean_processing_ms: 1.1940720207659423
  time_since_restore: 16132.746789932251
  time_this_iter_s: 26.60967469215393
  time_total_s: 16132.746789932251
  timestamp: 1638651186
  timesteps_since_restore: 41500
  timesteps_this_iter: 500
  timesteps_total: 41500
  training_iteration: 83
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     83 |          16132.7 | 41500 | 0.473013 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-53-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8521959459459459
  episode_reward_mean: 0.4288824376879614
  episode_reward_min: -0.3640661938534279
  episodes_this_iter: 500
  episodes_total: 42000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1726.746
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.4174487292766571
        entropy_coeff: 0.0
        kl: 0.008578694425523281
        model: {}
        policy_loss: -0.025781378149986267
        total_loss: -0.008266624063253403
        vf_explained_var: 0.5529900193214417
        vf_loss: 0.01670045219361782
    load_time_ms: 2.531
    num_steps_sampled: 42000
    num_steps_trained: 42000
    sample_time_ms: 33426.701
    update_time_ms: 5.788
  iterations_since_restore: 84
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.133333333333333
    ram_util_percent: 15.840350877192984
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 378.5626301438816
    mean_inference_ms: 1.4932423028936614
    mean_processing_ms: 1.1910486640239009
  time_since_restore: 16172.439459085464
  time_this_iter_s: 39.6926691532135
  time_total_s: 16172.439459085464
  timestamp: 1638651226
  timesteps_since_restore: 42000
  timesteps_this_iter: 500
  timesteps_total: 42000
  training_iteration: 84
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     84 |          16172.4 | 42000 | 0.428882 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-54-25
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8568935427574171
  episode_reward_mean: 0.4263224254018339
  episode_reward_min: -0.04918032786885246
  episodes_this_iter: 500
  episodes_total: 42500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1720.747
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.4533129930496216
        entropy_coeff: 0.0
        kl: 0.011383527889847755
        model: {}
        policy_loss: -0.028477240353822708
        total_loss: -0.013222383335232735
        vf_explained_var: 0.603003740310669
        vf_loss: 0.014174304902553558
    load_time_ms: 2.56
    num_steps_sampled: 42500
    num_steps_trained: 42500
    sample_time_ms: 32919.897
    update_time_ms: 5.77
  iterations_since_restore: 85
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.148214285714285
    ram_util_percent: 15.744642857142859
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 374.9583266807476
    mean_inference_ms: 1.4901596732269842
    mean_processing_ms: 1.188521519713883
  time_since_restore: 16211.439230918884
  time_this_iter_s: 38.9997718334198
  time_total_s: 16211.439230918884
  timestamp: 1638651265
  timesteps_since_restore: 42500
  timesteps_this_iter: 500
  timesteps_total: 42500
  training_iteration: 85
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     85 |          16211.4 | 42500 | 0.426322 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-55-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.4270122847832636
  episode_reward_min: -0.16791044776119404
  episodes_this_iter: 500
  episodes_total: 43000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1725.415
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.43003594875335693
        entropy_coeff: 0.0
        kl: 0.007606932893395424
        model: {}
        policy_loss: -0.024214282631874084
        total_loss: -0.007348563522100449
        vf_explained_var: 0.5580453276634216
        vf_loss: 0.01614365540444851
    load_time_ms: 2.501
    num_steps_sampled: 43000
    num_steps_trained: 43000
    sample_time_ms: 33963.129
    update_time_ms: 5.821
  iterations_since_restore: 86
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.067857142857141
    ram_util_percent: 15.764285714285714
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 371.4407264003948
    mean_inference_ms: 1.4871798466284363
    mean_processing_ms: 1.1862298643385816
  time_since_restore: 16250.644756793976
  time_this_iter_s: 39.20552587509155
  time_total_s: 16250.644756793976
  timestamp: 1638651304
  timesteps_since_restore: 43000
  timesteps_this_iter: 500
  timesteps_total: 43000
  training_iteration: 86
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     86 |          16250.6 | 43000 | 0.427012 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-55-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8560250391236307
  episode_reward_mean: 0.44008793329386564
  episode_reward_min: -0.7339901477832512
  episodes_this_iter: 500
  episodes_total: 43500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1725.843
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.4029681384563446
        entropy_coeff: 0.0
        kl: 0.0065032485872507095
        model: {}
        policy_loss: -0.019380753859877586
        total_loss: -0.000858003506436944
        vf_explained_var: 0.5073183178901672
        vf_loss: 0.017905447632074356
    load_time_ms: 2.448
    num_steps_sampled: 43500
    num_steps_trained: 43500
    sample_time_ms: 34181.941
    update_time_ms: 5.933
  iterations_since_restore: 87
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.96326530612245
    ram_util_percent: 15.791836734693877
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 367.8910530303248
    mean_inference_ms: 1.4839130764306165
    mean_processing_ms: 1.1835286640353053
  time_since_restore: 16284.883342504501
  time_this_iter_s: 34.23858571052551
  time_total_s: 16284.883342504501
  timestamp: 1638651339
  timesteps_since_restore: 43500
  timesteps_this_iter: 500
  timesteps_total: 43500
  training_iteration: 87
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     87 |          16284.9 | 43500 | 0.440088 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-56-21
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647845468053492
  episode_reward_mean: 0.4588231089590983
  episode_reward_min: -0.3115727002967359
  episodes_this_iter: 500
  episodes_total: 44000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1725.608
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.3724497854709625
        entropy_coeff: 0.0
        kl: 0.009088144637644291
        model: {}
        policy_loss: -0.03114125318825245
        total_loss: -0.015039300546050072
        vf_explained_var: 0.5828862190246582
        vf_loss: 0.015239293687045574
    load_time_ms: 2.357
    num_steps_sampled: 44000
    num_steps_trained: 44000
    sample_time_ms: 35438.71
    update_time_ms: 5.911
  iterations_since_restore: 88
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.779999999999998
    ram_util_percent: 15.745000000000003
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 364.60157713102546
    mean_inference_ms: 1.4817880225754316
    mean_processing_ms: 1.1820407356013738
  time_since_restore: 16327.123193979263
  time_this_iter_s: 42.23985147476196
  time_total_s: 16327.123193979263
  timestamp: 1638651381
  timesteps_since_restore: 44000
  timesteps_this_iter: 500
  timesteps_total: 44000
  training_iteration: 88
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     88 |          16327.1 | 44000 | 0.458823 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-57-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.4637051849155281
  episode_reward_min: -1.3027027027027027
  episodes_this_iter: 500
  episodes_total: 44500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1726.439
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.37708812952041626
        entropy_coeff: 0.0
        kl: 0.00892388354986906
        model: {}
        policy_loss: -0.03608772158622742
        total_loss: -0.016854876652359962
        vf_explained_var: 0.6056884527206421
        vf_loss: 0.01838577538728714
    load_time_ms: 2.412
    num_steps_sampled: 44500
    num_steps_trained: 44500
    sample_time_ms: 37474.03
    update_time_ms: 5.964
  iterations_since_restore: 89
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.028571428571428
    ram_util_percent: 15.76
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 361.53003353555135
    mean_inference_ms: 1.4796853373552747
    mean_processing_ms: 1.180162242507858
  time_since_restore: 16375.74369263649
  time_this_iter_s: 48.62049865722656
  time_total_s: 16375.74369263649
  timestamp: 1638651430
  timesteps_since_restore: 44500
  timesteps_this_iter: 500
  timesteps_total: 44500
  training_iteration: 89
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     89 |          16375.7 | 44500 | 0.463705 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-57-43
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647058823529412
  episode_reward_mean: 0.46924885587345655
  episode_reward_min: 0.01
  episodes_this_iter: 500
  episodes_total: 45000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1713.438
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.35785508155822754
        entropy_coeff: 0.0
        kl: 0.014527562074363232
        model: {}
        policy_loss: -0.02665693126618862
        total_loss: -0.014288773760199547
        vf_explained_var: 0.643257200717926
        vf_loss: 0.010989177972078323
    load_time_ms: 2.421
    num_steps_sampled: 45000
    num_steps_trained: 45000
    sample_time_ms: 36270.445
    update_time_ms: 5.916
  iterations_since_restore: 90
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.695744680851066
    ram_util_percent: 15.738297872340432
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 358.18455508596554
    mean_inference_ms: 1.4765444751506467
    mean_processing_ms: 1.1774382615936576
  time_since_restore: 16408.80077815056
  time_this_iter_s: 33.0570855140686
  time_total_s: 16408.80077815056
  timestamp: 1638651463
  timesteps_since_restore: 45000
  timesteps_this_iter: 500
  timesteps_total: 45000
  training_iteration: 90
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     90 |          16408.8 | 45000 | 0.469249 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-58-17
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.4757955778343952
  episode_reward_min: -0.15192743764172337
  episodes_this_iter: 500
  episodes_total: 45500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1723.237
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.31405478715896606
        entropy_coeff: 0.0
        kl: 0.010047059506177902
        model: {}
        policy_loss: -0.02937573939561844
        total_loss: -0.016347257420420647
        vf_explained_var: 0.6191346049308777
        vf_loss: 0.012074797414243221
    load_time_ms: 2.384
    num_steps_sampled: 45500
    num_steps_trained: 45500
    sample_time_ms: 36091.02
    update_time_ms: 5.891
  iterations_since_restore: 91
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.32448979591837
    ram_util_percent: 15.720408163265308
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 354.92808671420056
    mean_inference_ms: 1.474068328885256
    mean_processing_ms: 1.1751497659821353
  time_since_restore: 16442.718210935593
  time_this_iter_s: 33.91743278503418
  time_total_s: 16442.718210935593
  timestamp: 1638651497
  timesteps_since_restore: 45500
  timesteps_this_iter: 500
  timesteps_total: 45500
  training_iteration: 91
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     91 |          16442.7 | 45500 | 0.475796 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-58-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8646362098138748
  episode_reward_mean: 0.4805519596997202
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 46000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1727.258
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.2918740212917328
        entropy_coeff: 0.0
        kl: 0.007596945855766535
        model: {}
        policy_loss: -0.017567884176969528
        total_loss: -0.0045034512877464294
        vf_explained_var: 0.5890876650810242
        vf_loss: 0.012343306094408035
    load_time_ms: 2.425
    num_steps_sampled: 46000
    num_steps_trained: 46000
    sample_time_ms: 34785.972
    update_time_ms: 5.871
  iterations_since_restore: 92
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.395121951219513
    ram_util_percent: 15.7219512195122
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 351.6342806242355
    mean_inference_ms: 1.4708457295058779
    mean_processing_ms: 1.1724897582713256
  time_since_restore: 16471.515278100967
  time_this_iter_s: 28.797067165374756
  time_total_s: 16471.515278100967
  timestamp: 1638651526
  timesteps_since_restore: 46000
  timesteps_this_iter: 500
  timesteps_total: 46000
  training_iteration: 92
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     92 |          16471.5 | 46000 | 0.480552 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-59-15
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.874926943308007
  episode_reward_mean: 0.4962272712041163
  episode_reward_min: -0.31215469613259667
  episodes_this_iter: 500
  episodes_total: 46500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1721.601
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.27353402972221375
        entropy_coeff: 0.0
        kl: 0.005877685733139515
        model: {}
        policy_loss: -0.022109301760792732
        total_loss: -0.00918626505881548
        vf_explained_var: 0.6343305706977844
        vf_loss: 0.012365113943815231
    load_time_ms: 2.511
    num_steps_sampled: 46500
    num_steps_trained: 46500
    sample_time_ms: 35055.026
    update_time_ms: 5.813
  iterations_since_restore: 93
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.635714285714284
    ram_util_percent: 15.714285714285717
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 348.4203772955958
    mean_inference_ms: 1.4680055789451607
    mean_processing_ms: 1.1698994692216722
  time_since_restore: 16500.758937120438
  time_this_iter_s: 29.243659019470215
  time_total_s: 16500.758937120438
  timestamp: 1638651555
  timesteps_since_restore: 46500
  timesteps_this_iter: 500
  timesteps_total: 46500
  training_iteration: 93
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     93 |          16500.8 | 46500 | 0.496227 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-59-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.48916577478570444
  episode_reward_min: -0.0032258064516129032
  episodes_this_iter: 500
  episodes_total: 47000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1710.741
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.2678280770778656
        entropy_coeff: 0.0
        kl: 0.006586444564163685
        model: {}
        policy_loss: -0.018314993008971214
        total_loss: -0.003857575124129653
        vf_explained_var: 0.5571328401565552
        vf_loss: 0.0138322152197361
    load_time_ms: 2.502
    num_steps_sampled: 47000
    num_steps_trained: 47000
    sample_time_ms: 32733.041
    update_time_ms: 5.829
  iterations_since_restore: 94
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.0
    ram_util_percent: 15.730434782608693
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 345.00216060525696
    mean_inference_ms: 1.4649307709298627
    mean_processing_ms: 1.1670388773865825
  time_since_restore: 16517.12428355217
  time_this_iter_s: 16.365346431732178
  time_total_s: 16517.12428355217
  timestamp: 1638651572
  timesteps_since_restore: 47000
  timesteps_this_iter: 500
  timesteps_total: 47000
  training_iteration: 94
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     94 |          16517.1 | 47000 | 0.489166 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_15-59-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9531871043721478
  episode_reward_mean: 0.49752853432605165
  episode_reward_min: 0.0035335689045936395
  episodes_this_iter: 500
  episodes_total: 47500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1712.997
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.27308064699172974
        entropy_coeff: 0.0
        kl: 0.012622794136404991
        model: {}
        policy_loss: -0.01651172526180744
        total_loss: -0.0009892749367281795
        vf_explained_var: 0.5889624953269958
        vf_loss: 0.014324264600872993
    load_time_ms: 2.463
    num_steps_sampled: 47500
    num_steps_trained: 47500
    sample_time_ms: 31356.71
    update_time_ms: 5.803
  iterations_since_restore: 95
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.218918918918924
    ram_util_percent: 15.783783783783786
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 341.8411087411089
    mean_inference_ms: 1.4623145836684195
    mean_processing_ms: 1.164826590704523
  time_since_restore: 16542.3817384243
  time_this_iter_s: 25.257454872131348
  time_total_s: 16542.3817384243
  timestamp: 1638651597
  timesteps_since_restore: 47500
  timesteps_this_iter: 500
  timesteps_total: 47500
  training_iteration: 95
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     95 |          16542.4 | 47500 | 0.497529 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-00-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8814285714285715
  episode_reward_mean: 0.4838135050641376
  episode_reward_min: -0.1111111111111111
  episodes_this_iter: 500
  episodes_total: 48000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1715.67
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.29261431097984314
        entropy_coeff: 0.0
        kl: 0.007031117100268602
        model: {}
        policy_loss: -0.014532654546201229
        total_loss: 0.0010863452916964889
        vf_explained_var: 0.5431199669837952
        vf_loss: 0.014951599761843681
    load_time_ms: 2.496
    num_steps_sampled: 48000
    num_steps_trained: 48000
    sample_time_ms: 30261.52
    update_time_ms: 5.818
  iterations_since_restore: 96
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.565000000000001
    ram_util_percent: 15.735000000000003
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 338.8082769964564
    mean_inference_ms: 1.4592780686624818
    mean_processing_ms: 1.1622550842605583
  time_since_restore: 16570.591106653214
  time_this_iter_s: 28.209368228912354
  time_total_s: 16570.591106653214
  timestamp: 1638651626
  timesteps_since_restore: 48000
  timesteps_this_iter: 500
  timesteps_total: 48000
  training_iteration: 96
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     96 |          16570.6 | 48000 | 0.483814 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-00-48
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8926802421574023
  episode_reward_mean: 0.498781482156071
  episode_reward_min: -0.272
  episodes_this_iter: 500
  episodes_total: 48500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1765.663
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.3068650960922241
        entropy_coeff: 0.0
        kl: 0.010315838269889355
        model: {}
        policy_loss: -0.030887091532349586
        total_loss: -0.01665106788277626
        vf_explained_var: 0.6056566834449768
        vf_loss: 0.013256829231977463
    load_time_ms: 2.557
    num_steps_sampled: 48500
    num_steps_trained: 48500
    sample_time_ms: 29034.549
    update_time_ms: 5.796
  iterations_since_restore: 97
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.946875
    ram_util_percent: 15.725
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 335.70254350189805
    mean_inference_ms: 1.459081832488707
    mean_processing_ms: 1.1629562781414087
  time_since_restore: 16593.066154241562
  time_this_iter_s: 22.47504758834839
  time_total_s: 16593.066154241562
  timestamp: 1638651648
  timesteps_since_restore: 48500
  timesteps_this_iter: 500
  timesteps_total: 48500
  training_iteration: 97
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     97 |          16593.1 | 48500 | 0.498781 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-01-11
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8945362134688691
  episode_reward_mean: 0.5028518787844994
  episode_reward_min: 0.029850746268656716
  episodes_this_iter: 500
  episodes_total: 49000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1767.645
    learner:
      default_policy:
        cur_kl_coeff: 0.09492187201976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.2704648971557617
        entropy_coeff: 0.0
        kl: 0.004151792731136084
        model: {}
        policy_loss: -0.015179507434368134
        total_loss: -0.0013827424263581634
        vf_explained_var: 0.5993539094924927
        vf_loss: 0.013402669690549374
    load_time_ms: 2.581
    num_steps_sampled: 49000
    num_steps_trained: 49000
    sample_time_ms: 27044.295
    update_time_ms: 5.665
  iterations_since_restore: 98
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.659375
    ram_util_percent: 15.70625
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 332.67209663242426
    mean_inference_ms: 1.4569934529992128
    mean_processing_ms: 1.1614850753594541
  time_since_restore: 16615.422302007675
  time_this_iter_s: 22.35614776611328
  time_total_s: 16615.422302007675
  timestamp: 1638651671
  timesteps_since_restore: 49000
  timesteps_this_iter: 500
  timesteps_total: 49000
  training_iteration: 98
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     98 |          16615.4 | 49000 | 0.502852 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-01-35
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8564954682779456
  episode_reward_mean: 0.4580639194344187
  episode_reward_min: -0.06875
  episodes_this_iter: 500
  episodes_total: 49500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1769.67
    learner:
      default_policy:
        cur_kl_coeff: 0.04746093600988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.2671676278114319
        entropy_coeff: 0.0
        kl: 0.006568362005054951
        model: {}
        policy_loss: -0.02335141971707344
        total_loss: -0.009665001183748245
        vf_explained_var: 0.5711066722869873
        vf_loss: 0.01337466761469841
    load_time_ms: 2.617
    num_steps_sampled: 49500
    num_steps_trained: 49500
    sample_time_ms: 24603.372
    update_time_ms: 5.562
  iterations_since_restore: 99
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.417142857142856
    ram_util_percent: 15.748571428571433
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 329.74252812836045
    mean_inference_ms: 1.4540494874242278
    mean_processing_ms: 1.1591903465121338
  time_since_restore: 16639.65427350998
  time_this_iter_s: 24.231971502304077
  time_total_s: 16639.65427350998
  timestamp: 1638651695
  timesteps_since_restore: 49500
  timesteps_this_iter: 500
  timesteps_total: 49500
  training_iteration: 99
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |     99 |          16639.7 | 49500 | 0.458064 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-01-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8378378378378378
  episode_reward_mean: 0.42264562695713564
  episode_reward_min: -0.3640661938534279
  episodes_this_iter: 500
  episodes_total: 50000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1773.643
    learner:
      default_policy:
        cur_kl_coeff: 0.04746093600988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.3602904975414276
        entropy_coeff: 0.0
        kl: 0.014458248391747475
        model: {}
        policy_loss: -0.020428096875548363
        total_loss: -0.0035828424151986837
        vf_explained_var: 0.5721772313117981
        vf_loss: 0.016159052029252052
    load_time_ms: 2.547
    num_steps_sampled: 50000
    num_steps_trained: 50000
    sample_time_ms: 23428.237
    update_time_ms: 5.485
  iterations_since_restore: 100
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.483870967741932
    ram_util_percent: 15.712903225806448
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 326.815190352153
    mean_inference_ms: 1.4510747230123757
    mean_processing_ms: 1.1567072649864751
  time_since_restore: 16660.998272180557
  time_this_iter_s: 21.343998670578003
  time_total_s: 16660.998272180557
  timestamp: 1638651717
  timesteps_since_restore: 50000
  timesteps_this_iter: 500
  timesteps_total: 50000
  training_iteration: 100
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    100 |            16661 | 50000 | 0.422646 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-02-17
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.42541870879041893
  episode_reward_min: -0.07336683417085427
  episodes_this_iter: 500
  episodes_total: 50500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1760.02
    learner:
      default_policy:
        cur_kl_coeff: 0.04746093600988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.32416126132011414
        entropy_coeff: 0.0
        kl: 0.00634024990722537
        model: {}
        policy_loss: -0.016259867697954178
        total_loss: -0.001078941859304905
        vf_explained_var: 0.6018057465553284
        vf_loss: 0.014880015514791012
    load_time_ms: 2.646
    num_steps_sampled: 50500
    num_steps_trained: 50500
    sample_time_ms: 22058.043
    update_time_ms: 5.49
  iterations_since_restore: 101
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.855172413793102
    ram_util_percent: 15.713793103448273
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 323.9208635548615
    mean_inference_ms: 1.4487485343075155
    mean_processing_ms: 1.1548049681111279
  time_since_restore: 16681.08095407486
  time_this_iter_s: 20.082681894302368
  time_total_s: 16681.08095407486
  timestamp: 1638651737
  timesteps_since_restore: 50500
  timesteps_this_iter: 500
  timesteps_total: 50500
  training_iteration: 101
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    101 |          16681.1 | 50500 | 0.425419 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-02-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8504273504273504
  episode_reward_mean: 0.4369499606262312
  episode_reward_min: -0.16791044776119404
  episodes_this_iter: 500
  episodes_total: 51000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1759.426
    learner:
      default_policy:
        cur_kl_coeff: 0.04746093600988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.4540432393550873
        entropy_coeff: 0.0
        kl: 0.0416155606508255
        model: {}
        policy_loss: -0.026336276903748512
        total_loss: -0.008918661624193192
        vf_explained_var: 0.6061418056488037
        vf_loss: 0.01544249802827835
    load_time_ms: 2.599
    num_steps_sampled: 51000
    num_steps_trained: 51000
    sample_time_ms: 21568.965
    update_time_ms: 5.45
  iterations_since_restore: 102
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.605882352941178
    ram_util_percent: 15.711764705882354
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 321.15767051705154
    mean_inference_ms: 1.446387718285802
    mean_processing_ms: 1.1527809717428874
  time_since_restore: 16704.981528759003
  time_this_iter_s: 23.900574684143066
  time_total_s: 16704.981528759003
  timestamp: 1638651761
  timesteps_since_restore: 51000
  timesteps_this_iter: 500
  timesteps_total: 51000
  training_iteration: 102
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    102 |            16705 | 51000 |  0.43695 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-03-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647845468053492
  episode_reward_mean: 0.4481019343785999
  episode_reward_min: -0.10632911392405063
  episodes_this_iter: 500
  episodes_total: 51500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1762.951
    learner:
      default_policy:
        cur_kl_coeff: 0.07119140774011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4821641445159912
        entropy_coeff: 0.0
        kl: 0.008939734660089016
        model: {}
        policy_loss: -0.026684017851948738
        total_loss: -0.006085393019020557
        vf_explained_var: 0.45450276136398315
        vf_loss: 0.019962193444371223
    load_time_ms: 2.543
    num_steps_sampled: 51500
    num_steps_trained: 51500
    sample_time_ms: 23361.899
    update_time_ms: 5.522
  iterations_since_restore: 103
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.985294117647058
    ram_util_percent: 15.779411764705879
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 318.8994230570111
    mean_inference_ms: 1.4442590664355293
    mean_processing_ms: 1.1507782162338762
  time_since_restore: 16752.189623832703
  time_this_iter_s: 47.20809507369995
  time_total_s: 16752.189623832703
  timestamp: 1638651808
  timesteps_since_restore: 51500
  timesteps_this_iter: 500
  timesteps_total: 51500
  training_iteration: 103
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    103 |          16752.2 | 51500 | 0.448102 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-04-00
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8609053497942387
  episode_reward_mean: 0.46535414250567314
  episode_reward_min: -0.1444043321299639
  episodes_this_iter: 500
  episodes_total: 52000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1808.143
    learner:
      default_policy:
        cur_kl_coeff: 0.07119140774011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.41022738814353943
        entropy_coeff: 0.0
        kl: 0.0062452880665659904
        model: {}
        policy_loss: -0.025674251839518547
        total_loss: -0.012939061969518661
        vf_explained_var: 0.5930410623550415
        vf_loss: 0.01229056715965271
    load_time_ms: 2.542
    num_steps_sampled: 52000
    num_steps_trained: 52000
    sample_time_ms: 24795.367
    update_time_ms: 5.584
  iterations_since_restore: 104
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.799999999999999
    ram_util_percent: 15.725000000000005
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 316.3683077286823
    mean_inference_ms: 1.442137480868722
    mean_processing_ms: 1.1488909822333666
  time_since_restore: 16783.3443274498
  time_this_iter_s: 31.154703617095947
  time_total_s: 16783.3443274498
  timestamp: 1638651840
  timesteps_since_restore: 52000
  timesteps_this_iter: 500
  timesteps_total: 52000
  training_iteration: 104
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    104 |          16783.3 | 52000 | 0.465354 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-04-37
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.45652500272560936
  episode_reward_min: -0.2025
  episodes_this_iter: 500
  episodes_total: 52500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1805.956
    learner:
      default_policy:
        cur_kl_coeff: 0.07119140774011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.42497289180755615
        entropy_coeff: 0.0
        kl: 0.01279400009661913
        model: {}
        policy_loss: -0.027111362665891647
        total_loss: -0.01350527536123991
        vf_explained_var: 0.6561762094497681
        vf_loss: 0.012695270590484142
    load_time_ms: 2.59
    num_steps_sampled: 52500
    num_steps_trained: 52500
    sample_time_ms: 25966.411
    update_time_ms: 5.659
  iterations_since_restore: 105
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.901886792452832
    ram_util_percent: 15.896226415094343
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 314.0015108799112
    mean_inference_ms: 1.44128961015076
    mean_processing_ms: 1.1481887324533313
  time_since_restore: 16820.292184114456
  time_this_iter_s: 36.94785666465759
  time_total_s: 16820.292184114456
  timestamp: 1638651877
  timesteps_since_restore: 52500
  timesteps_this_iter: 500
  timesteps_total: 52500
  training_iteration: 105
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    105 |          16820.3 | 52500 | 0.456525 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-05-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647058823529412
  episode_reward_mean: 0.47565890888555634
  episode_reward_min: -0.7362637362637363
  episodes_this_iter: 500
  episodes_total: 53000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1803.886
    learner:
      default_policy:
        cur_kl_coeff: 0.07119140774011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3596241772174835
        entropy_coeff: 0.0
        kl: 0.012684205546975136
        model: {}
        policy_loss: -0.029634159058332443
        total_loss: -0.012368004769086838
        vf_explained_var: 0.571281373500824
        vf_loss: 0.016363145783543587
    load_time_ms: 2.539
    num_steps_sampled: 53000
    num_steps_trained: 53000
    sample_time_ms: 27487.466
    update_time_ms: 5.564
  iterations_since_restore: 106
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.072580645161292
    ram_util_percent: 15.704838709677423
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 311.8036648266333
    mean_inference_ms: 1.439103247820167
    mean_processing_ms: 1.1462830648798126
  time_since_restore: 16863.688543319702
  time_this_iter_s: 43.39635920524597
  time_total_s: 16863.688543319702
  timestamp: 1638651920
  timesteps_since_restore: 53000
  timesteps_this_iter: 500
  timesteps_total: 53000
  training_iteration: 106
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    106 |          16863.7 | 53000 | 0.475659 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-05-54
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8503740648379052
  episode_reward_mean: 0.4734662197238355
  episode_reward_min: 0.051111111111111114
  episodes_this_iter: 500
  episodes_total: 53500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1746.28
    learner:
      default_policy:
        cur_kl_coeff: 0.07119140774011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.42320406436920166
        entropy_coeff: 0.0
        kl: 0.01598929800093174
        model: {}
        policy_loss: -0.02878171019256115
        total_loss: -0.015881381928920746
        vf_explained_var: 0.6237384080886841
        vf_loss: 0.011762023903429508
    load_time_ms: 2.503
    num_steps_sampled: 53500
    num_steps_trained: 53500
    sample_time_ms: 28647.353
    update_time_ms: 5.515
  iterations_since_restore: 107
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.31875
    ram_util_percent: 15.708333333333334
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 309.46257008304974
    mean_inference_ms: 1.4367860441232305
    mean_processing_ms: 1.144171237936644
  time_since_restore: 16897.18135523796
  time_this_iter_s: 33.49281191825867
  time_total_s: 16897.18135523796
  timestamp: 1638651954
  timesteps_since_restore: 53500
  timesteps_this_iter: 500
  timesteps_total: 53500
  training_iteration: 107
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    107 |          16897.2 | 53500 | 0.473466 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-06-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8646362098138748
  episode_reward_mean: 0.4774157521786252
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 54000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1754.616
    learner:
      default_policy:
        cur_kl_coeff: 0.07119140774011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3541809320449829
        entropy_coeff: 0.0
        kl: 0.01126871444284916
        model: {}
        policy_loss: -0.021505599841475487
        total_loss: -0.008443862199783325
        vf_explained_var: 0.6098896265029907
        vf_loss: 0.012259501963853836
    load_time_ms: 2.511
    num_steps_sampled: 54000
    num_steps_trained: 54000
    sample_time_ms: 29554.409
    update_time_ms: 5.748
  iterations_since_restore: 108
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.373913043478263
    ram_util_percent: 15.754347826086962
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 307.1231995950603
    mean_inference_ms: 1.4353854062700664
    mean_processing_ms: 1.143172958096262
  time_since_restore: 16928.69165110588
  time_this_iter_s: 31.510295867919922
  time_total_s: 16928.69165110588
  timestamp: 1638651986
  timesteps_since_restore: 54000
  timesteps_this_iter: 500
  timesteps_total: 54000
  training_iteration: 108
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    108 |          16928.7 | 54000 | 0.477416 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-06-54
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.49708633096078403
  episode_reward_min: -0.5656108597285068
  episodes_this_iter: 500
  episodes_total: 54500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1749.939
    learner:
      default_policy:
        cur_kl_coeff: 0.07119140774011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.2842895984649658
        entropy_coeff: 0.0
        kl: 0.00733247259631753
        model: {}
        policy_loss: -0.030156690627336502
        total_loss: -0.013873028568923473
        vf_explained_var: 0.5505196452140808
        vf_loss: 0.01576165296137333
    load_time_ms: 2.449
    num_steps_sampled: 54500
    num_steps_trained: 54500
    sample_time_ms: 29981.358
    update_time_ms: 5.804
  iterations_since_restore: 109
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.6125
    ram_util_percent: 15.722500000000002
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 304.77397262200327
    mean_inference_ms: 1.4334821549689596
    mean_processing_ms: 1.1418095418233238
  time_since_restore: 16957.14462542534
  time_this_iter_s: 28.452974319458008
  time_total_s: 16957.14462542534
  timestamp: 1638652014
  timesteps_since_restore: 54500
  timesteps_this_iter: 500
  timesteps_total: 54500
  training_iteration: 109
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    109 |          16957.1 | 54500 | 0.497086 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-07-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8821316614420063
  episode_reward_mean: 0.48196616345133275
  episode_reward_min: -0.2910602910602911
  episodes_this_iter: 500
  episodes_total: 55000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1752.793
    learner:
      default_policy:
        cur_kl_coeff: 0.07119140774011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.2721043527126312
        entropy_coeff: 0.0
        kl: 0.0063182939775288105
        model: {}
        policy_loss: -0.02104947529733181
        total_loss: -0.003933875355869532
        vf_explained_var: 0.540050745010376
        vf_loss: 0.016665801405906677
    load_time_ms: 2.478
    num_steps_sampled: 55000
    num_steps_trained: 55000
    sample_time_ms: 30239.237
    update_time_ms: 5.864
  iterations_since_restore: 110
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.874285714285715
    ram_util_percent: 15.714285714285717
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 302.38519310767003
    mean_inference_ms: 1.431745116605457
    mean_processing_ms: 1.140286039411821
  time_since_restore: 16981.09704232216
  time_this_iter_s: 23.95241689682007
  time_total_s: 16981.09704232216
  timestamp: 1638652038
  timesteps_since_restore: 55000
  timesteps_this_iter: 500
  timesteps_total: 55000
  training_iteration: 110
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    110 |          16981.1 | 55000 | 0.481966 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-07-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9531871043721478
  episode_reward_mean: 0.491265796703444
  episode_reward_min: -0.8440860215053764
  episodes_this_iter: 500
  episodes_total: 55500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1761.865
    learner:
      default_policy:
        cur_kl_coeff: 0.07119140774011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.21888744831085205
        entropy_coeff: 0.0
        kl: 0.005762383807450533
        model: {}
        policy_loss: -0.023076705634593964
        total_loss: -0.0062372926622629166
        vf_explained_var: 0.5733955502510071
        vf_loss: 0.016429178416728973
    load_time_ms: 2.392
    num_steps_sampled: 55500
    num_steps_trained: 55500
    sample_time_ms: 30283.003
    update_time_ms: 6.041
  iterations_since_restore: 111
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.693103448275863
    ram_util_percent: 15.85862068965517
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 299.9807798386273
    mean_inference_ms: 1.429192038416289
    mean_processing_ms: 1.138171505982596
  time_since_restore: 17001.70871925354
  time_this_iter_s: 20.611676931381226
  time_total_s: 17001.70871925354
  timestamp: 1638652059
  timesteps_since_restore: 55500
  timesteps_this_iter: 500
  timesteps_total: 55500
  training_iteration: 111
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    111 |          17001.7 | 55500 | 0.491266 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-07-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8937809576224546
  episode_reward_mean: 0.4968336036368121
  episode_reward_min: -0.1111111111111111
  episodes_this_iter: 500
  episodes_total: 56000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1762.763
    learner:
      default_policy:
        cur_kl_coeff: 0.07119140774011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.26096367835998535
        entropy_coeff: 0.0
        kl: 0.01737309619784355
        model: {}
        policy_loss: -0.022001957520842552
        total_loss: -0.0056411027908325195
        vf_explained_var: 0.5540534853935242
        vf_loss: 0.015124036930501461
    load_time_ms: 2.437
    num_steps_sampled: 56000
    num_steps_trained: 56000
    sample_time_ms: 29583.605
    update_time_ms: 6.125
  iterations_since_restore: 112
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.264
    ram_util_percent: 15.703999999999999
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 297.55285669166267
    mean_inference_ms: 1.4273957655609972
    mean_processing_ms: 1.1365984114610141
  time_since_restore: 17018.62648153305
  time_this_iter_s: 16.917762279510498
  time_total_s: 17018.62648153305
  timestamp: 1638652076
  timesteps_since_restore: 56000
  timesteps_this_iter: 500
  timesteps_total: 56000
  training_iteration: 112
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    112 |          17018.6 | 56000 | 0.496834 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-08-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.878494623655914
  episode_reward_mean: 0.49496551132415206
  episode_reward_min: 0.024
  episodes_this_iter: 500
  episodes_total: 56500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1760.989
    learner:
      default_policy:
        cur_kl_coeff: 0.07119140774011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.26482540369033813
        entropy_coeff: 0.0
        kl: 0.004748648032546043
        model: {}
        policy_loss: -0.008816796354949474
        total_loss: 0.003983515314757824
        vf_explained_var: 0.6008524894714355
        vf_loss: 0.012462249957025051
    load_time_ms: 2.397
    num_steps_sampled: 56500
    num_steps_trained: 56500
    sample_time_ms: 27022.268
    update_time_ms: 6.148
  iterations_since_restore: 113
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.906451612903224
    ram_util_percent: 15.806451612903224
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 295.2495507503117
    mean_inference_ms: 1.425666688060371
    mean_processing_ms: 1.135385575960114
  time_since_restore: 17040.203736305237
  time_this_iter_s: 21.57725477218628
  time_total_s: 17040.203736305237
  timestamp: 1638652098
  timesteps_since_restore: 56500
  timesteps_this_iter: 500
  timesteps_total: 56500
  training_iteration: 113
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    113 |          17040.2 | 56500 | 0.494966 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-08-42
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8945362134688691
  episode_reward_mean: 0.491525243708365
  episode_reward_min: -0.4880382775119617
  episodes_this_iter: 500
  episodes_total: 57000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1720.371
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.25485774874687195
        entropy_coeff: 0.0
        kl: 0.007563546299934387
        model: {}
        policy_loss: -0.014199089258909225
        total_loss: -9.594082803232595e-05
        vf_explained_var: 0.5816880464553833
        vf_loss: 0.013833915814757347
    load_time_ms: 2.407
    num_steps_sampled: 57000
    num_steps_trained: 57000
    sample_time_ms: 26352.005
    update_time_ms: 6.142
  iterations_since_restore: 114
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.323529411764707
    ram_util_percent: 15.726470588235296
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 293.0315778819333
    mean_inference_ms: 1.4232275132595371
    mean_processing_ms: 1.1332455134132875
  time_since_restore: 17064.245863199234
  time_this_iter_s: 24.042126893997192
  time_total_s: 17064.245863199234
  timestamp: 1638652122
  timesteps_since_restore: 57000
  timesteps_this_iter: 500
  timesteps_total: 57000
  training_iteration: 114
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    114 |          17064.2 | 57000 | 0.491525 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-09-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8564954682779456
  episode_reward_mean: 0.4397355284115691
  episode_reward_min: -0.15210355987055016
  episodes_this_iter: 500
  episodes_total: 57500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1725.225
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.25496506690979004
        entropy_coeff: 0.0
        kl: 0.0058492254465818405
        model: {}
        policy_loss: -0.010994301177561283
        total_loss: 0.003711151424795389
        vf_explained_var: 0.5767295360565186
        vf_loss: 0.014497251249849796
    load_time_ms: 2.347
    num_steps_sampled: 57500
    num_steps_trained: 57500
    sample_time_ms: 24479.702
    update_time_ms: 6.074
  iterations_since_restore: 115
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.307407407407407
    ram_util_percent: 15.714814814814813
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 290.75175427044604
    mean_inference_ms: 1.4207951286701892
    mean_processing_ms: 1.130937246676663
  time_since_restore: 17082.517467975616
  time_this_iter_s: 18.271604776382446
  time_total_s: 17082.517467975616
  timestamp: 1638652141
  timesteps_since_restore: 57500
  timesteps_this_iter: 500
  timesteps_total: 57500
  training_iteration: 115
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    115 |          17082.5 | 57500 | 0.439736 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-09-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8568935427574171
  episode_reward_mean: 0.42826870475613205
  episode_reward_min: -0.04590163934426229
  episodes_this_iter: 500
  episodes_total: 58000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1732.425
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.281810462474823
        entropy_coeff: 0.0
        kl: 0.0060056583024561405
        model: {}
        policy_loss: -0.015530773438513279
        total_loss: -0.0018165535293519497
        vf_explained_var: 0.6147933602333069
        vf_loss: 0.013500457629561424
    load_time_ms: 2.349
    num_steps_sampled: 58000
    num_steps_trained: 58000
    sample_time_ms: 21880.813
    update_time_ms: 6.176
  iterations_since_restore: 116
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.304
    ram_util_percent: 15.723999999999998
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 288.49709391793294
    mean_inference_ms: 1.4183293256086988
    mean_processing_ms: 1.1287216227563608
  time_since_restore: 17099.997837543488
  time_this_iter_s: 17.480369567871094
  time_total_s: 17099.997837543488
  timestamp: 1638652158
  timesteps_since_restore: 58000
  timesteps_this_iter: 500
  timesteps_total: 58000
  training_iteration: 116
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    116 |            17100 | 58000 | 0.428269 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-09-43
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.4338905567238299
  episode_reward_min: -0.16791044776119404
  episodes_this_iter: 500
  episodes_total: 58500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1738.289
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2917071580886841
        entropy_coeff: 0.0
        kl: 0.006449506152421236
        model: {}
        policy_loss: -0.017388945445418358
        total_loss: -0.0005279675242491066
        vf_explained_var: 0.5623007416725159
        vf_loss: 0.01663140207529068
    load_time_ms: 2.33
    num_steps_sampled: 58500
    num_steps_trained: 58500
    sample_time_ms: 20960.35
    update_time_ms: 6.289
  iterations_since_restore: 117
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.745714285714286
    ram_util_percent: 15.725714285714288
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 286.3986358522597
    mean_inference_ms: 1.4161146864300354
    mean_processing_ms: 1.1266719516335453
  time_since_restore: 17124.343740940094
  time_this_iter_s: 24.345903396606445
  time_total_s: 17124.343740940094
  timestamp: 1638652183
  timesteps_since_restore: 58500
  timesteps_this_iter: 500
  timesteps_total: 58500
  training_iteration: 117
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    117 |          17124.3 | 58500 | 0.433891 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-10-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8504273504273504
  episode_reward_mean: 0.42994645128572173
  episode_reward_min: -0.07863974495217853
  episodes_this_iter: 500
  episodes_total: 59000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1725.601
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.301260381937027
        entropy_coeff: 0.0
        kl: 0.007831405848264694
        model: {}
        policy_loss: -0.0182088203728199
        total_loss: -0.002283794339746237
        vf_explained_var: 0.5427283644676208
        vf_loss: 0.01564626581966877
    load_time_ms: 2.289
    num_steps_sampled: 59000
    num_steps_trained: 59000
    sample_time_ms: 19844.27
    update_time_ms: 6.143
  iterations_since_restore: 118
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.989655172413793
    ram_util_percent: 15.731034482758618
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 284.2664075757271
    mean_inference_ms: 1.4139091105192882
    mean_processing_ms: 1.1244797770854704
  time_since_restore: 17144.564972162247
  time_this_iter_s: 20.22123122215271
  time_total_s: 17144.564972162247
  timestamp: 1638652203
  timesteps_since_restore: 59000
  timesteps_this_iter: 500
  timesteps_total: 59000
  training_iteration: 118
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    118 |          17144.6 | 59000 | 0.429946 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-10-24
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647845468053492
  episode_reward_mean: 0.4646878101369389
  episode_reward_min: -0.1444043321299639
  episodes_this_iter: 500
  episodes_total: 59500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1721.099
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.29395467042922974
        entropy_coeff: 0.0
        kl: 0.009932695887982845
        model: {}
        policy_loss: -0.0207317303866148
        total_loss: -0.0037759114056825638
        vf_explained_var: 0.5441742539405823
        vf_loss: 0.016602253541350365
    load_time_ms: 2.308
    num_steps_sampled: 59500
    num_steps_trained: 59500
    sample_time_ms: 19027.742
    update_time_ms: 6.171
  iterations_since_restore: 119
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.600000000000001
    ram_util_percent: 15.748275862068965
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 282.1709558191673
    mean_inference_ms: 1.4117254922134381
    mean_processing_ms: 1.1225770524392755
  time_since_restore: 17164.807463407516
  time_this_iter_s: 20.242491245269775
  time_total_s: 17164.807463407516
  timestamp: 1638652224
  timesteps_since_restore: 59500
  timesteps_this_iter: 500
  timesteps_total: 59500
  training_iteration: 119
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    119 |          17164.8 | 59500 | 0.464688 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-10-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.4700380770280165
  episode_reward_min: -0.5221238938053098
  episodes_this_iter: 500
  episodes_total: 60000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1716.672
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.25312909483909607
        entropy_coeff: 0.0
        kl: 0.008741595782339573
        model: {}
        policy_loss: -0.017674781382083893
        total_loss: -0.00396279152482748
        vf_explained_var: 0.5986863970756531
        vf_loss: 0.013400823809206486
    load_time_ms: 2.288
    num_steps_sampled: 60000
    num_steps_trained: 60000
    sample_time_ms: 18634.553
    update_time_ms: 6.109
  iterations_since_restore: 120
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.365517241379308
    ram_util_percent: 15.734482758620688
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 280.105622604953
    mean_inference_ms: 1.4094067554458298
    mean_processing_ms: 1.120729892723274
  time_since_restore: 17184.782783985138
  time_this_iter_s: 19.97532057762146
  time_total_s: 17184.782783985138
  timestamp: 1638652244
  timesteps_since_restore: 60000
  timesteps_this_iter: 500
  timesteps_total: 60000
  training_iteration: 120
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    120 |          17184.8 | 60000 | 0.470038 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-11-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647058823529412
  episode_reward_mean: 0.46156668975889015
  episode_reward_min: -0.11563169164882227
  episodes_this_iter: 500
  episodes_total: 60500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1710.038
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.263233482837677
        entropy_coeff: 0.0
        kl: 0.006270389072597027
        model: {}
        policy_loss: -0.015984708443284035
        total_loss: -0.005055837798863649
        vf_explained_var: 0.6455994248390198
        vf_loss: 0.010705684311687946
    load_time_ms: 2.285
    num_steps_sampled: 60500
    num_steps_trained: 60500
    sample_time_ms: 18504.837
    update_time_ms: 6.02
  iterations_since_restore: 121
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.537037037037036
    ram_util_percent: 15.733333333333334
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 278.0627235909383
    mean_inference_ms: 1.4073972384718159
    mean_processing_ms: 1.1186764217842096
  time_since_restore: 17204.027416467667
  time_this_iter_s: 19.244632482528687
  time_total_s: 17204.027416467667
  timestamp: 1638652263
  timesteps_since_restore: 60500
  timesteps_this_iter: 500
  timesteps_total: 60500
  training_iteration: 121
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    121 |            17204 | 60500 | 0.461567 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-11-24
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.4819303927919423
  episode_reward_min: -0.20402298850574713
  episodes_this_iter: 500
  episodes_total: 61000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1707.975
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2836041748523712
        entropy_coeff: 0.0
        kl: 0.004069286864250898
        model: {}
        policy_loss: -0.015438206493854523
        total_loss: -0.002929462119936943
        vf_explained_var: 0.5785760879516602
        vf_loss: 0.01236389484256506
    load_time_ms: 2.256
    num_steps_sampled: 61000
    num_steps_trained: 61000
    sample_time_ms: 18908.168
    update_time_ms: 6.073
  iterations_since_restore: 122
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.129032258064516
    ram_util_percent: 15.738709677419354
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 276.0810378230936
    mean_inference_ms: 1.4050869341297303
    mean_processing_ms: 1.1166784970913282
  time_since_restore: 17224.95600295067
  time_this_iter_s: 20.92858648300171
  time_total_s: 17224.95600295067
  timestamp: 1638652284
  timesteps_since_restore: 61000
  timesteps_this_iter: 500
  timesteps_total: 61000
  training_iteration: 122
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    122 |            17225 | 61000 |  0.48193 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-11-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8646362098138748
  episode_reward_mean: 0.4749652176295637
  episode_reward_min: -0.9261363636363636
  episodes_this_iter: 500
  episodes_total: 61500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1700.877
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.260488897562027
        entropy_coeff: 0.0
        kl: 0.012135953642427921
        model: {}
        policy_loss: -0.021772010251879692
        total_loss: -0.005764555186033249
        vf_explained_var: 0.5880658626556396
        vf_loss: 0.01579146459698677
    load_time_ms: 2.219
    num_steps_sampled: 61500
    num_steps_trained: 61500
    sample_time_ms: 18711.04
    update_time_ms: 6.05
  iterations_since_restore: 123
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.239285714285714
    ram_util_percent: 15.735714285714284
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 274.10927761806886
    mean_inference_ms: 1.4028099617863714
    mean_processing_ms: 1.1148555645393985
  time_since_restore: 17244.491604328156
  time_this_iter_s: 19.535601377487183
  time_total_s: 17244.491604328156
  timestamp: 1638652304
  timesteps_since_restore: 61500
  timesteps_this_iter: 500
  timesteps_total: 61500
  training_iteration: 123
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    123 |          17244.5 | 61500 | 0.474965 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-11-59
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.874926943308007
  episode_reward_mean: 0.48974553907038904
  episode_reward_min: 0.03807106598984772
  episodes_this_iter: 500
  episodes_total: 62000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1694.12
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.2836107313632965
        entropy_coeff: 0.0
        kl: 0.01335866004228592
        model: {}
        policy_loss: -0.027762627229094505
        total_loss: -0.016876623034477234
        vf_explained_var: 0.622727632522583
        vf_loss: 0.01064824964851141
    load_time_ms: 2.179
    num_steps_sampled: 62000
    num_steps_trained: 62000
    sample_time_ms: 17813.159
    update_time_ms: 5.968
  iterations_since_restore: 124
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.40952380952381
    ram_util_percent: 15.728571428571426
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 272.0958646736853
    mean_inference_ms: 1.4005588894130638
    mean_processing_ms: 1.1133423286246396
  time_since_restore: 17259.486211538315
  time_this_iter_s: 14.994607210159302
  time_total_s: 17259.486211538315
  timestamp: 1638652319
  timesteps_since_restore: 62000
  timesteps_this_iter: 500
  timesteps_total: 62000
  training_iteration: 124
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    124 |          17259.5 | 62000 | 0.489746 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-12-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.4952792039446059
  episode_reward_min: -0.0032258064516129032
  episodes_this_iter: 500
  episodes_total: 62500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1683.719
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.2312832474708557
        entropy_coeff: 0.0
        kl: 0.006281850393861532
        model: {}
        policy_loss: -0.019139550626277924
        total_loss: -0.005458572413772345
        vf_explained_var: 0.5749634504318237
        vf_loss: 0.013569175265729427
    load_time_ms: 2.2
    num_steps_sampled: 62500
    num_steps_trained: 62500
    sample_time_ms: 17713.965
    update_time_ms: 5.949
  iterations_since_restore: 125
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.248
    ram_util_percent: 15.728
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 270.15096623505286
    mean_inference_ms: 1.3979091176765297
    mean_processing_ms: 1.1111105753496908
  time_since_restore: 17276.662225484848
  time_this_iter_s: 17.176013946533203
  time_total_s: 17276.662225484848
  timestamp: 1638652336
  timesteps_since_restore: 62500
  timesteps_this_iter: 500
  timesteps_total: 62500
  training_iteration: 125
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    125 |          17276.7 | 62500 | 0.495279 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-12-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8821316614420063
  episode_reward_mean: 0.48803781343810126
  episode_reward_min: -0.2866043613707165
  episodes_this_iter: 500
  episodes_total: 63000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1681.792
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.23448458313941956
        entropy_coeff: 0.0
        kl: 0.014149385504424572
        model: {}
        policy_loss: -0.032981470227241516
        total_loss: -0.018615180626511574
        vf_explained_var: 0.5992555618286133
        vf_loss: 0.014114458113908768
    load_time_ms: 2.201
    num_steps_sampled: 63000
    num_steps_trained: 63000
    sample_time_ms: 18256.269
    update_time_ms: 5.871
  iterations_since_restore: 126
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.021212121212123
    ram_util_percent: 15.821212121212122
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 268.3220647429307
    mean_inference_ms: 1.3970900042844445
    mean_processing_ms: 1.1106974563796026
  time_since_restore: 17299.545743703842
  time_this_iter_s: 22.88351821899414
  time_total_s: 17299.545743703842
  timestamp: 1638652359
  timesteps_since_restore: 63000
  timesteps_this_iter: 500
  timesteps_total: 63000
  training_iteration: 126
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    126 |          17299.5 | 63000 | 0.488038 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-12-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9531871043721478
  episode_reward_mean: 0.49711700043673995
  episode_reward_min: -0.1111111111111111
  episodes_this_iter: 500
  episodes_total: 63500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1679.936
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.22566495835781097
        entropy_coeff: 0.0
        kl: 0.005564265418797731
        model: {}
        policy_loss: -0.010576212778687477
        total_loss: 0.005309683736413717
        vf_explained_var: 0.5098425149917603
        vf_loss: 0.015786871314048767
    load_time_ms: 2.217
    num_steps_sampled: 63500
    num_steps_trained: 63500
    sample_time_ms: 17214.39
    update_time_ms: 5.761
  iterations_since_restore: 127
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.825000000000003
    ram_util_percent: 15.794999999999998
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 266.38408008030046
    mean_inference_ms: 1.3949486971318243
    mean_processing_ms: 1.1088414612035071
  time_since_restore: 17313.45327758789
  time_this_iter_s: 13.907533884048462
  time_total_s: 17313.45327758789
  timestamp: 1638652373
  timesteps_since_restore: 63500
  timesteps_this_iter: 500
  timesteps_total: 63500
  training_iteration: 127
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    127 |          17313.5 | 63500 | 0.497117 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-13-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8926802421574023
  episode_reward_mean: 0.49620583471063984
  episode_reward_min: 0.024
  episodes_this_iter: 500
  episodes_total: 64000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1676.621
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.2683126926422119
        entropy_coeff: 0.0
        kl: 0.007657524198293686
        model: {}
        policy_loss: -0.012884030118584633
        total_loss: -0.00040507258381694555
        vf_explained_var: 0.6043698787689209
        vf_loss: 0.012342673726379871
    load_time_ms: 2.199
    num_steps_sampled: 64000
    num_steps_trained: 64000
    sample_time_ms: 16683.686
    update_time_ms: 5.789
  iterations_since_restore: 128
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.190476190476186
    ram_util_percent: 15.766666666666667
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 264.49125733323905
    mean_inference_ms: 1.3933939810173652
    mean_processing_ms: 1.107307883404625
  time_since_restore: 17328.334349155426
  time_this_iter_s: 14.8810715675354
  time_total_s: 17328.334349155426
  timestamp: 1638652389
  timesteps_since_restore: 64000
  timesteps_this_iter: 500
  timesteps_total: 64000
  training_iteration: 128
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    128 |          17328.3 | 64000 | 0.496206 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-13-27
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8945362134688691
  episode_reward_mean: 0.5097031133254927
  episode_reward_min: 0.05084745762711865
  episodes_this_iter: 500
  episodes_total: 64500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1677.616
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.23355212807655334
        entropy_coeff: 0.0
        kl: 0.006611242890357971
        model: {}
        policy_loss: -0.018977941945195198
        total_loss: -0.005904285237193108
        vf_explained_var: 0.5812199711799622
        vf_loss: 0.012955994345247746
    load_time_ms: 2.176
    num_steps_sampled: 64500
    num_steps_trained: 64500
    sample_time_ms: 16514.096
    update_time_ms: 5.735
  iterations_since_restore: 129
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.14074074074074
    ram_util_percent: 15.733333333333333
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 262.6851653740761
    mean_inference_ms: 1.3915507531465856
    mean_processing_ms: 1.1057419303117748
  time_since_restore: 17346.8907020092
  time_this_iter_s: 18.556352853775024
  time_total_s: 17346.8907020092
  timestamp: 1638652407
  timesteps_since_restore: 64500
  timesteps_this_iter: 500
  timesteps_total: 64500
  training_iteration: 129
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    129 |          17346.9 | 64500 | 0.509703 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-13-37
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8564954682779456
  episode_reward_mean: 0.46270272784874894
  episode_reward_min: 0.04371584699453552
  episodes_this_iter: 500
  episodes_total: 65000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1674.702
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.23148685693740845
        entropy_coeff: 0.0
        kl: 0.00454577524214983
        model: {}
        policy_loss: -0.017632033675909042
        total_loss: -0.005378544796258211
        vf_explained_var: 0.5762808322906494
        vf_loss: 0.01217259094119072
    load_time_ms: 2.15
    num_steps_sampled: 65000
    num_steps_trained: 65000
    sample_time_ms: 15442.726
    update_time_ms: 5.802
  iterations_since_restore: 130
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.35
    ram_util_percent: 15.757142857142854
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 260.76451684270984
    mean_inference_ms: 1.3893689102921927
    mean_processing_ms: 1.1037221272316964
  time_since_restore: 17356.123002290726
  time_this_iter_s: 9.232300281524658
  time_total_s: 17356.123002290726
  timestamp: 1638652417
  timesteps_since_restore: 65000
  timesteps_this_iter: 500
  timesteps_total: 65000
  training_iteration: 130
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    130 |          17356.1 | 65000 | 0.462703 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-13-54
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8462837837837838
  episode_reward_mean: 0.42881027085511836
  episode_reward_min: -0.3640661938534279
  episodes_this_iter: 500
  episodes_total: 65500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1673.7
    learner:
      default_policy:
        cur_kl_coeff: 0.008898925967514515
        cur_lr: 4.999999873689376e-05
        entropy: 0.26035362482070923
        entropy_coeff: 0.0
        kl: 0.00475554633885622
        model: {}
        policy_loss: -0.010266751982271671
        total_loss: 0.006238968577235937
        vf_explained_var: 0.5412541031837463
        vf_loss: 0.016463393345475197
    load_time_ms: 2.152
    num_steps_sampled: 65500
    num_steps_trained: 65500
    sample_time_ms: 15261.435
    update_time_ms: 5.692
  iterations_since_restore: 131
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.224
    ram_util_percent: 15.748
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 258.9977581434287
    mean_inference_ms: 1.3874200017897658
    mean_processing_ms: 1.1019441630501385
  time_since_restore: 17373.54364466667
  time_this_iter_s: 17.420642375946045
  time_total_s: 17373.54364466667
  timestamp: 1638652434
  timesteps_since_restore: 65500
  timesteps_this_iter: 500
  timesteps_total: 65500
  training_iteration: 131
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    131 |          17373.5 | 65500 |  0.42881 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-14-17
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.42948626562869285
  episode_reward_min: -0.07087988826815643
  episodes_this_iter: 500
  episodes_total: 66000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1674.711
    learner:
      default_policy:
        cur_kl_coeff: 0.0044494629837572575
        cur_lr: 4.999999873689376e-05
        entropy: 0.2571867108345032
        entropy_coeff: 0.0
        kl: 0.006298799533396959
        model: {}
        policy_loss: -0.017837844789028168
        total_loss: -0.0026511179748922586
        vf_explained_var: 0.5947203040122986
        vf_loss: 0.0151586988940835
    load_time_ms: 2.102
    num_steps_sampled: 66000
    num_steps_trained: 66000
    sample_time_ms: 15429.619
    update_time_ms: 5.519
  iterations_since_restore: 132
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.425
    ram_util_percent: 15.731250000000001
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 257.33598530526416
    mean_inference_ms: 1.3855988595599875
    mean_processing_ms: 1.1002594419588518
  time_since_restore: 17396.161737442017
  time_this_iter_s: 22.61809277534485
  time_total_s: 17396.161737442017
  timestamp: 1638652457
  timesteps_since_restore: 66000
  timesteps_this_iter: 500
  timesteps_total: 66000
  training_iteration: 132
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    132 |          17396.2 | 66000 | 0.429486 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-14-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8270799347471451
  episode_reward_mean: 0.4275625641014686
  episode_reward_min: -0.4639175257731959
  episodes_this_iter: 500
  episodes_total: 66500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1679.603
    learner:
      default_policy:
        cur_kl_coeff: 0.0044494629837572575
        cur_lr: 4.999999873689376e-05
        entropy: 0.2203834354877472
        entropy_coeff: 0.0
        kl: 0.003041560761630535
        model: {}
        policy_loss: -0.015334698371589184
        total_loss: 0.0018801861442625523
        vf_explained_var: 0.5593306422233582
        vf_loss: 0.017201349139213562
    load_time_ms: 2.128
    num_steps_sampled: 66500
    num_steps_trained: 66500
    sample_time_ms: 15613.257
    update_time_ms: 5.49
  iterations_since_restore: 133
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.977419354838712
    ram_util_percent: 15.73548387096774
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 255.67791826594032
    mean_inference_ms: 1.385209087185339
    mean_processing_ms: 1.100116972726022
  time_since_restore: 17417.582140922546
  time_this_iter_s: 21.420403480529785
  time_total_s: 17417.582140922546
  timestamp: 1638652479
  timesteps_since_restore: 66500
  timesteps_this_iter: 500
  timesteps_total: 66500
  training_iteration: 133
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    133 |          17417.6 | 66500 | 0.427563 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-14-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8560250391236307
  episode_reward_mean: 0.43543661834970937
  episode_reward_min: -0.1514476614699332
  episodes_this_iter: 500
  episodes_total: 67000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1701.536
    learner:
      default_policy:
        cur_kl_coeff: 0.0022247314918786287
        cur_lr: 4.999999873689376e-05
        entropy: 0.22370412945747375
        entropy_coeff: 0.0
        kl: 0.004786767531186342
        model: {}
        policy_loss: -0.017116565257310867
        total_loss: 8.350968710146844e-05
        vf_explained_var: 0.5286367535591125
        vf_loss: 0.017189431935548782
    load_time_ms: 2.138
    num_steps_sampled: 67000
    num_steps_trained: 67000
    sample_time_ms: 15792.622
    update_time_ms: 5.46
  iterations_since_restore: 134
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.355999999999998
    ram_util_percent: 15.731999999999998
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 253.97528092705775
    mean_inference_ms: 1.3850175402605382
    mean_processing_ms: 1.1006589024884046
  time_since_restore: 17434.590376377106
  time_this_iter_s: 17.008235454559326
  time_total_s: 17434.590376377106
  timestamp: 1638652496
  timesteps_since_restore: 67000
  timesteps_this_iter: 500
  timesteps_total: 67000
  training_iteration: 134
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    134 |          17434.6 | 67000 | 0.435437 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-15-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647845468053492
  episode_reward_mean: 0.47170022385528193
  episode_reward_min: -0.1444043321299639
  episodes_this_iter: 500
  episodes_total: 67500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1715.792
    learner:
      default_policy:
        cur_kl_coeff: 0.0011123657459393144
        cur_lr: 4.999999873689376e-05
        entropy: 0.19872182607650757
        entropy_coeff: 0.0
        kl: 0.012170694768428802
        model: {}
        policy_loss: -0.02534487284719944
        total_loss: -0.012348761782050133
        vf_explained_var: 0.6114374399185181
        vf_loss: 0.012982574291527271
    load_time_ms: 2.205
    num_steps_sampled: 67500
    num_steps_trained: 67500
    sample_time_ms: 15871.307
    update_time_ms: 5.424
  iterations_since_restore: 135
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.546153846153846
    ram_util_percent: 15.72307692307692
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 252.31764781061992
    mean_inference_ms: 1.383993449425659
    mean_processing_ms: 1.0999005023918262
  time_since_restore: 17452.697418689728
  time_this_iter_s: 18.10704231262207
  time_total_s: 17452.697418689728
  timestamp: 1638652514
  timesteps_since_restore: 67500
  timesteps_this_iter: 500
  timesteps_total: 67500
  training_iteration: 135
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    135 |          17452.7 | 67500 |   0.4717 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-15-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.4691013545250795
  episode_reward_min: -0.25679012345679014
  episodes_this_iter: 500
  episodes_total: 68000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1713.69
    learner:
      default_policy:
        cur_kl_coeff: 0.0011123657459393144
        cur_lr: 4.999999873689376e-05
        entropy: 0.18220928311347961
        entropy_coeff: 0.0
        kl: 0.009374018758535385
        model: {}
        policy_loss: -0.01759357750415802
        total_loss: -0.005197243764996529
        vf_explained_var: 0.6384809613227844
        vf_loss: 0.012385908514261246
    load_time_ms: 2.204
    num_steps_sampled: 68000
    num_steps_trained: 68000
    sample_time_ms: 15205.743
    update_time_ms: 5.448
  iterations_since_restore: 136
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.98695652173913
    ram_util_percent: 15.730434782608697
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 250.65894832390342
    mean_inference_ms: 1.382166055284478
    mean_processing_ms: 1.0983344290239356
  time_since_restore: 17468.903953313828
  time_this_iter_s: 16.20653462409973
  time_total_s: 17468.903953313828
  timestamp: 1638652531
  timesteps_since_restore: 68000
  timesteps_this_iter: 500
  timesteps_total: 68000
  training_iteration: 136
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    136 |          17468.9 | 68000 | 0.469101 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-15-40
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647058823529412
  episode_reward_mean: 0.475946461429944
  episode_reward_min: 0.06798245614035088
  episodes_this_iter: 500
  episodes_total: 68500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1714.03
    learner:
      default_policy:
        cur_kl_coeff: 0.0011123657459393144
        cur_lr: 4.999999873689376e-05
        entropy: 0.1927320659160614
        entropy_coeff: 0.0
        kl: 0.007867665961384773
        model: {}
        policy_loss: -0.01053599826991558
        total_loss: 0.0006441086297854781
        vf_explained_var: 0.6370271444320679
        vf_loss: 0.011171359568834305
    load_time_ms: 2.16
    num_steps_sampled: 68500
    num_steps_trained: 68500
    sample_time_ms: 14741.463
    update_time_ms: 5.415
  iterations_since_restore: 137
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.571428571428566
    ram_util_percent: 15.728571428571426
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 248.923809124159
    mean_inference_ms: 1.3802182063404012
    mean_processing_ms: 1.0965706089100136
  time_since_restore: 17478.1707406044
  time_this_iter_s: 9.26678729057312
  time_total_s: 17478.1707406044
  timestamp: 1638652540
  timesteps_since_restore: 68500
  timesteps_this_iter: 500
  timesteps_total: 68500
  training_iteration: 137
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    137 |          17478.2 | 68500 | 0.475946 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-15-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.4741126228731983
  episode_reward_min: -0.06618531889290012
  episodes_this_iter: 500
  episodes_total: 69000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1717.717
    learner:
      default_policy:
        cur_kl_coeff: 0.0011123657459393144
        cur_lr: 4.999999873689376e-05
        entropy: 0.1515713632106781
        entropy_coeff: 0.0
        kl: 0.0066602700389921665
        model: {}
        policy_loss: -0.01856340281665325
        total_loss: -0.005992094986140728
        vf_explained_var: 0.5952616930007935
        vf_loss: 0.012563906610012054
    load_time_ms: 2.181
    num_steps_sampled: 69000
    num_steps_trained: 69000
    sample_time_ms: 14831.94
    update_time_ms: 5.418
  iterations_since_restore: 138
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.918181818181818
    ram_util_percent: 15.72272727272727
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 247.30841512723316
    mean_inference_ms: 1.378454454888351
    mean_processing_ms: 1.095053976897656
  time_since_restore: 17493.994721651077
  time_this_iter_s: 15.823981046676636
  time_total_s: 17493.994721651077
  timestamp: 1638652556
  timesteps_since_restore: 69000
  timesteps_this_iter: 500
  timesteps_total: 69000
  training_iteration: 138
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    138 |            17494 | 69000 | 0.474113 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-16-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8646362098138748
  episode_reward_mean: 0.48099948578468693
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 69500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1722.931
    learner:
      default_policy:
        cur_kl_coeff: 0.0011123657459393144
        cur_lr: 4.999999873689376e-05
        entropy: 0.16565494239330292
        entropy_coeff: 0.0
        kl: 0.003481421386823058
        model: {}
        policy_loss: -0.01343938335776329
        total_loss: -0.0011195152765139937
        vf_explained_var: 0.5741322040557861
        vf_loss: 0.012315996922552586
    load_time_ms: 2.158
    num_steps_sampled: 69500
    num_steps_trained: 69500
    sample_time_ms: 13820.854
    update_time_ms: 5.412
  iterations_since_restore: 139
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.692307692307693
    ram_util_percent: 15.730769230769228
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 245.6100252339779
    mean_inference_ms: 1.376995235770296
    mean_processing_ms: 1.0939897923992274
  time_since_restore: 17502.49319076538
  time_this_iter_s: 8.498469114303589
  time_total_s: 17502.49319076538
  timestamp: 1638652565
  timesteps_since_restore: 69500
  timesteps_this_iter: 500
  timesteps_total: 69500
  training_iteration: 139
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    139 |          17502.5 | 69500 | 0.480999 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-16-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.874926943308007
  episode_reward_mean: 0.5042556042606137
  episode_reward_min: 0.047516198704103674
  episodes_this_iter: 500
  episodes_total: 70000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1743.441
    learner:
      default_policy:
        cur_kl_coeff: 0.0005561828729696572
        cur_lr: 4.999999873689376e-05
        entropy: 0.15876051783561707
        entropy_coeff: 0.0
        kl: 0.01083759218454361
        model: {}
        policy_loss: -0.019422776997089386
        total_loss: -0.007162116933614016
        vf_explained_var: 0.6035103797912598
        vf_loss: 0.012254636734724045
    load_time_ms: 2.282
    num_steps_sampled: 70000
    num_steps_trained: 70000
    sample_time_ms: 13371.407
    update_time_ms: 5.427
  iterations_since_restore: 140
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.985714285714284
    ram_util_percent: 15.757142857142858
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 243.88417907650867
    mean_inference_ms: 1.3751274766149668
    mean_processing_ms: 1.0923090475756525
  time_since_restore: 17507.43779349327
  time_this_iter_s: 4.944602727890015
  time_total_s: 17507.43779349327
  timestamp: 1638652570
  timesteps_since_restore: 70000
  timesteps_this_iter: 500
  timesteps_total: 70000
  training_iteration: 140
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    140 |          17507.4 | 70000 | 0.504256 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-16-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.4875380072273367
  episode_reward_min: -0.0032258064516129032
  episodes_this_iter: 500
  episodes_total: 70500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1747.116
    learner:
      default_policy:
        cur_kl_coeff: 0.0005561828729696572
        cur_lr: 4.999999873689376e-05
        entropy: 0.2456478327512741
        entropy_coeff: 0.0
        kl: 0.05242086574435234
        model: {}
        policy_loss: -0.030332891270518303
        total_loss: -0.01598261296749115
        vf_explained_var: 0.5760533809661865
        vf_loss: 0.014321129769086838
    load_time_ms: 2.257
    num_steps_sampled: 70500
    num_steps_trained: 70500
    sample_time_ms: 12655.872
    update_time_ms: 5.57
  iterations_since_restore: 141
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.106666666666666
    ram_util_percent: 15.719999999999997
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 242.2611984560212
    mean_inference_ms: 1.3733007213216852
    mean_processing_ms: 1.0907088619105616
  time_since_restore: 17517.741305351257
  time_this_iter_s: 10.30351185798645
  time_total_s: 17517.741305351257
  timestamp: 1638652580
  timesteps_since_restore: 70500
  timesteps_this_iter: 500
  timesteps_total: 70500
  training_iteration: 141
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    141 |          17517.7 | 70500 | 0.487538 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-16-40
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9531871043721478
  episode_reward_mean: 0.4914214465662056
  episode_reward_min: -0.6397849462365591
  episodes_this_iter: 500
  episodes_total: 71000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1748.634
    learner:
      default_policy:
        cur_kl_coeff: 0.0008342742803506553
        cur_lr: 4.999999873689376e-05
        entropy: 0.2222033143043518
        entropy_coeff: 0.0
        kl: 0.013361254706978798
        model: {}
        policy_loss: -0.022390522062778473
        total_loss: -0.006886905524879694
        vf_explained_var: 0.6060172915458679
        vf_loss: 0.015492474660277367
    load_time_ms: 2.273
    num_steps_sampled: 71000
    num_steps_trained: 71000
    sample_time_ms: 12371.32
    update_time_ms: 5.648
  iterations_since_restore: 142
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.435714285714285
    ram_util_percent: 15.782142857142857
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 240.79439361703785
    mean_inference_ms: 1.3715719780793194
    mean_processing_ms: 1.089175904855411
  time_since_restore: 17537.53135418892
  time_this_iter_s: 19.790048837661743
  time_total_s: 17537.53135418892
  timestamp: 1638652600
  timesteps_since_restore: 71000
  timesteps_this_iter: 500
  timesteps_total: 71000
  training_iteration: 142
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    142 |          17537.5 | 71000 | 0.491421 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-16-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8814285714285715
  episode_reward_mean: 0.489252792425778
  episode_reward_min: -1.3774647887323943
  episodes_this_iter: 500
  episodes_total: 71500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1754.159
    learner:
      default_policy:
        cur_kl_coeff: 0.0008342742803506553
        cur_lr: 4.999999873689376e-05
        entropy: 0.22292478382587433
        entropy_coeff: 0.0
        kl: 0.006360652390867472
        model: {}
        policy_loss: -0.01470991037786007
        total_loss: 0.005975687876343727
        vf_explained_var: 0.527651309967041
        vf_loss: 0.020680291578173637
    load_time_ms: 2.244
    num_steps_sampled: 71500
    num_steps_trained: 71500
    sample_time_ms: 11860.489
    update_time_ms: 5.617
  iterations_since_restore: 143
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.65833333333333
    ram_util_percent: 15.758333333333335
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 239.29984600793622
    mean_inference_ms: 1.3698419273033837
    mean_processing_ms: 1.08743237774865
  time_since_restore: 17553.897428274155
  time_this_iter_s: 16.366074085235596
  time_total_s: 17553.897428274155
  timestamp: 1638652617
  timesteps_since_restore: 71500
  timesteps_this_iter: 500
  timesteps_total: 71500
  training_iteration: 143
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    143 |          17553.9 | 71500 | 0.489253 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-17-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8926802421574023
  episode_reward_mean: 0.5011554748270755
  episode_reward_min: 0.024
  episodes_this_iter: 500
  episodes_total: 72000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1736.829
    learner:
      default_policy:
        cur_kl_coeff: 0.0008342742803506553
        cur_lr: 4.999999873689376e-05
        entropy: 0.2224469929933548
        entropy_coeff: 0.0
        kl: 0.007131372112780809
        model: {}
        policy_loss: -0.014160148799419403
        total_loss: -0.002445995807647705
        vf_explained_var: 0.6112573146820068
        vf_loss: 0.011708194389939308
    load_time_ms: 2.259
    num_steps_sampled: 72000
    num_steps_trained: 72000
    sample_time_ms: 11241.59
    update_time_ms: 5.557
  iterations_since_restore: 144
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.86
    ram_util_percent: 15.753333333333336
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 237.74675345368183
    mean_inference_ms: 1.3684225261871177
    mean_processing_ms: 1.0860218402221844
  time_since_restore: 17564.542827129364
  time_this_iter_s: 10.64539885520935
  time_total_s: 17564.542827129364
  timestamp: 1638652628
  timesteps_since_restore: 72000
  timesteps_this_iter: 500
  timesteps_total: 72000
  training_iteration: 144
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    144 |          17564.5 | 72000 | 0.501155 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-17-24
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8945362134688691
  episode_reward_mean: 0.5025139519901571
  episode_reward_min: -0.3188405797101449
  episodes_this_iter: 500
  episodes_total: 72500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1727.507
    learner:
      default_policy:
        cur_kl_coeff: 0.0008342742803506553
        cur_lr: 4.999999873689376e-05
        entropy: 0.20701681077480316
        entropy_coeff: 0.0
        kl: 0.010019450448453426
        model: {}
        policy_loss: -0.01805057004094124
        total_loss: -0.004871783312410116
        vf_explained_var: 0.597234845161438
        vf_loss: 0.013170430436730385
    load_time_ms: 2.211
    num_steps_sampled: 72500
    num_steps_trained: 72500
    sample_time_ms: 11039.904
    update_time_ms: 5.578
  iterations_since_restore: 145
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.154166666666665
    ram_util_percent: 15.795833333333334
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 236.28762608516547
    mean_inference_ms: 1.3676574892133595
    mean_processing_ms: 1.0853146219600147
  time_since_restore: 17580.541263580322
  time_this_iter_s: 15.998436450958252
  time_total_s: 17580.541263580322
  timestamp: 1638652644
  timesteps_since_restore: 72500
  timesteps_this_iter: 500
  timesteps_total: 72500
  training_iteration: 145
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    145 |          17580.5 | 72500 | 0.502514 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-17-37
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8564954682779456
  episode_reward_mean: 0.4482343209272386
  episode_reward_min: -0.3640661938534279
  episodes_this_iter: 500
  episodes_total: 73000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1720.022
    learner:
      default_policy:
        cur_kl_coeff: 0.0008342742803506553
        cur_lr: 4.999999873689376e-05
        entropy: 0.2418050765991211
        entropy_coeff: 0.0
        kl: 0.004162854515016079
        model: {}
        policy_loss: -0.010361487977206707
        total_loss: 0.004518694709986448
        vf_explained_var: 0.559551477432251
        vf_loss: 0.014876720495522022
    load_time_ms: 2.238
    num_steps_sampled: 73000
    num_steps_trained: 73000
    sample_time_ms: 10684.917
    update_time_ms: 5.541
  iterations_since_restore: 146
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.944444444444443
    ram_util_percent: 15.800000000000002
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 234.80273259489329
    mean_inference_ms: 1.3665354230142914
    mean_processing_ms: 1.084411629742021
  time_since_restore: 17593.122893571854
  time_this_iter_s: 12.581629991531372
  time_total_s: 17593.122893571854
  timestamp: 1638652657
  timesteps_since_restore: 73000
  timesteps_this_iter: 500
  timesteps_total: 73000
  training_iteration: 146
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    146 |          17593.1 | 73000 | 0.448234 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-17-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8568935427574171
  episode_reward_mean: 0.4259662797241566
  episode_reward_min: -0.15210355987055016
  episodes_this_iter: 500
  episodes_total: 73500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1716.309
    learner:
      default_policy:
        cur_kl_coeff: 0.00041713714017532766
        cur_lr: 4.999999873689376e-05
        entropy: 0.3577031195163727
        entropy_coeff: 0.0
        kl: 0.034603677690029144
        model: {}
        policy_loss: -0.021903114393353462
        total_loss: -0.007834944874048233
        vf_explained_var: 0.595188319683075
        vf_loss: 0.014053733088076115
    load_time_ms: 2.248
    num_steps_sampled: 73500
    num_steps_trained: 73500
    sample_time_ms: 11207.95
    update_time_ms: 5.617
  iterations_since_restore: 147
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.514285714285716
    ram_util_percent: 15.795238095238098
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 233.36423070568196
    mean_inference_ms: 1.3650213153528907
    mean_processing_ms: 1.0830731530155195
  time_since_restore: 17607.583921194077
  time_this_iter_s: 14.4610276222229
  time_total_s: 17607.583921194077
  timestamp: 1638652671
  timesteps_since_restore: 73500
  timesteps_this_iter: 500
  timesteps_total: 73500
  training_iteration: 147
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    147 |          17607.6 | 73500 | 0.425966 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-18-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.43097330342786444
  episode_reward_min: -0.08206686930091185
  episodes_this_iter: 500
  episodes_total: 74000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1714.255
    learner:
      default_policy:
        cur_kl_coeff: 0.0006257056957110763
        cur_lr: 4.999999873689376e-05
        entropy: 0.3546421527862549
        entropy_coeff: 0.0
        kl: 0.006714475806802511
        model: {}
        policy_loss: -0.014068526215851307
        total_loss: 0.0018721282249316573
        vf_explained_var: 0.5774391293525696
        vf_loss: 0.015936441719532013
    load_time_ms: 2.304
    num_steps_sampled: 74000
    num_steps_trained: 74000
    sample_time_ms: 11916.234
    update_time_ms: 5.624
  iterations_since_restore: 148
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.803030303030303
    ram_util_percent: 15.796969696969695
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 232.0583499725912
    mean_inference_ms: 1.3637441655828866
    mean_processing_ms: 1.0818737400307676
  time_since_restore: 17630.470288991928
  time_this_iter_s: 22.886367797851562
  time_total_s: 17630.470288991928
  timestamp: 1638652694
  timesteps_since_restore: 74000
  timesteps_this_iter: 500
  timesteps_total: 74000
  training_iteration: 148
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    148 |          17630.5 | 74000 | 0.430973 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-18-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8427707531610775
  episode_reward_mean: 0.4422906991150757
  episode_reward_min: -0.16791044776119404
  episodes_this_iter: 500
  episodes_total: 74500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1706.653
    learner:
      default_policy:
        cur_kl_coeff: 0.0006257056957110763
        cur_lr: 4.999999873689376e-05
        entropy: 0.40759631991386414
        entropy_coeff: 0.0
        kl: 0.013647054322063923
        model: {}
        policy_loss: -0.02364768274128437
        total_loss: -0.00872588437050581
        vf_explained_var: 0.5595970749855042
        vf_loss: 0.014913266524672508
    load_time_ms: 2.34
    num_steps_sampled: 74500
    num_steps_trained: 74500
    sample_time_ms: 14536.279
    update_time_ms: 5.677
  iterations_since_restore: 149
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.691836734693878
    ram_util_percent: 15.804081632653059
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 230.92744077487743
    mean_inference_ms: 1.3628094723169561
    mean_processing_ms: 1.080970642808328
  time_since_restore: 17665.093910694122
  time_this_iter_s: 34.623621702194214
  time_total_s: 17665.093910694122
  timestamp: 1638652729
  timesteps_since_restore: 74500
  timesteps_this_iter: 500
  timesteps_total: 74500
  training_iteration: 149
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    149 |          17665.1 | 74500 | 0.442291 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-19-19
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647845468053492
  episode_reward_mean: 0.4536648751541336
  episode_reward_min: -0.1444043321299639
  episodes_this_iter: 500
  episodes_total: 75000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1692.934
    learner:
      default_policy:
        cur_kl_coeff: 0.0006257056957110763
        cur_lr: 4.999999873689376e-05
        entropy: 0.38049179315567017
        entropy_coeff: 0.0
        kl: 0.011997632682323456
        model: {}
        policy_loss: -0.021403757855296135
        total_loss: -0.003994736820459366
        vf_explained_var: 0.5482285022735596
        vf_loss: 0.017401522025465965
    load_time_ms: 2.227
    num_steps_sampled: 75000
    num_steps_trained: 75000
    sample_time_ms: 17025.513
    update_time_ms: 5.602
  iterations_since_restore: 150
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.209302325581396
    ram_util_percent: 15.800000000000002
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 229.74559564313637
    mean_inference_ms: 1.3614587962720393
    mean_processing_ms: 1.0798700990566383
  time_since_restore: 17694.79253220558
  time_this_iter_s: 29.69862151145935
  time_total_s: 17694.79253220558
  timestamp: 1638652759
  timesteps_since_restore: 75000
  timesteps_this_iter: 500
  timesteps_total: 75000
  training_iteration: 150
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    150 |          17694.8 | 75000 | 0.453665 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-19-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.4682322037205212
  episode_reward_min: -0.5221238938053098
  episodes_this_iter: 500
  episodes_total: 75500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1693.812
    learner:
      default_policy:
        cur_kl_coeff: 0.0006257056957110763
        cur_lr: 4.999999873689376e-05
        entropy: 0.3919669985771179
        entropy_coeff: 0.0
        kl: 0.021250220015645027
        model: {}
        policy_loss: -0.024708431214094162
        total_loss: -0.011930955573916435
        vf_explained_var: 0.6331348419189453
        vf_loss: 0.012764177285134792
    load_time_ms: 2.207
    num_steps_sampled: 75500
    num_steps_trained: 75500
    sample_time_ms: 18750.309
    update_time_ms: 5.478
  iterations_since_restore: 151
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.290000000000001
    ram_util_percent: 15.775
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 228.55135765810323
    mean_inference_ms: 1.3601701402757023
    mean_processing_ms: 1.0787755899468099
  time_since_restore: 17722.351429462433
  time_this_iter_s: 27.558897256851196
  time_total_s: 17722.351429462433
  timestamp: 1638652787
  timesteps_since_restore: 75500
  timesteps_this_iter: 500
  timesteps_total: 75500
  training_iteration: 151
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    151 |          17722.4 | 75500 | 0.468232 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-20-21
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8637083993660856
  episode_reward_mean: 0.4561521015404233
  episode_reward_min: -1.0
  episodes_this_iter: 500
  episodes_total: 76000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1689.001
    learner:
      default_policy:
        cur_kl_coeff: 0.0009385586017742753
        cur_lr: 4.999999873689376e-05
        entropy: 0.4110505282878876
        entropy_coeff: 0.0
        kl: 0.01107704546302557
        model: {}
        policy_loss: -0.03453933075070381
        total_loss: -0.017648912966251373
        vf_explained_var: 0.6185741424560547
        vf_loss: 0.016880016773939133
    load_time_ms: 2.232
    num_steps_sampled: 76000
    num_steps_trained: 76000
    sample_time_ms: 20183.633
    update_time_ms: 5.388
  iterations_since_restore: 152
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.353061224489798
    ram_util_percent: 15.789795918367348
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 227.45825299758548
    mean_inference_ms: 1.3594447659046414
    mean_processing_ms: 1.0781153881434236
  time_since_restore: 17756.425203561783
  time_this_iter_s: 34.073774099349976
  time_total_s: 17756.425203561783
  timestamp: 1638652821
  timesteps_since_restore: 76000
  timesteps_this_iter: 500
  timesteps_total: 76000
  training_iteration: 152
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    152 |          17756.4 | 76000 | 0.456152 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-20-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647058823529412
  episode_reward_mean: 0.47716802159436483
  episode_reward_min: -0.7362637362637363
  episodes_this_iter: 500
  episodes_total: 76500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1691.37
    learner:
      default_policy:
        cur_kl_coeff: 0.0009385586017742753
        cur_lr: 4.999999873689376e-05
        entropy: 0.4032955467700958
        entropy_coeff: 0.0
        kl: 0.0038233459927141666
        model: {}
        policy_loss: -0.006902369204908609
        total_loss: 0.00817799847573042
        vf_explained_var: 0.5955211520195007
        vf_loss: 0.015076782554388046
    load_time_ms: 2.249
    num_steps_sampled: 76500
    num_steps_trained: 76500
    sample_time_ms: 21328.676
    update_time_ms: 5.406
  iterations_since_restore: 153
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.132499999999999
    ram_util_percent: 15.7775
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 226.2971593567572
    mean_inference_ms: 1.3583214136106876
    mean_processing_ms: 1.0771208439862356
  time_since_restore: 17784.265755176544
  time_this_iter_s: 27.840551614761353
  time_total_s: 17784.265755176544
  timestamp: 1638652849
  timesteps_since_restore: 76500
  timesteps_this_iter: 500
  timesteps_total: 76500
  training_iteration: 153
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    153 |          17784.3 | 76500 | 0.477168 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-21-29
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8375
  episode_reward_mean: 0.46606563248949245
  episode_reward_min: -1.4680851063829787
  episodes_this_iter: 500
  episodes_total: 77000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1688.147
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.41114184260368347
        entropy_coeff: 0.0
        kl: 0.00619048997759819
        model: {}
        policy_loss: -0.015469729900360107
        total_loss: 0.005122005473822355
        vf_explained_var: 0.5937405228614807
        vf_loss: 0.020588837563991547
    load_time_ms: 2.239
    num_steps_sampled: 77000
    num_steps_trained: 77000
    sample_time_ms: 24248.245
    update_time_ms: 5.566
  iterations_since_restore: 154
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.678947368421053
    ram_util_percent: 15.77017543859649
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 225.30739381498142
    mean_inference_ms: 1.3575077558486168
    mean_processing_ms: 1.0763600535786675
  time_since_restore: 17824.07599234581
  time_this_iter_s: 39.81023716926575
  time_total_s: 17824.07599234581
  timestamp: 1638652889
  timesteps_since_restore: 77000
  timesteps_this_iter: 500
  timesteps_total: 77000
  training_iteration: 154
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    154 |          17824.1 | 77000 | 0.466066 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-21-58
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8646362098138748
  episode_reward_mean: 0.48157092982898864
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 77500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1684.896
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.3766515254974365
        entropy_coeff: 0.0
        kl: 0.006823859177529812
        model: {}
        policy_loss: -0.019405672326683998
        total_loss: -0.007223384454846382
        vf_explained_var: 0.5869947075843811
        vf_loss: 0.01217909436672926
    load_time_ms: 2.263
    num_steps_sampled: 77500
    num_steps_trained: 77500
    sample_time_ms: 25497.189
    update_time_ms: 5.567
  iterations_since_restore: 155
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.224390243902441
    ram_util_percent: 15.78048780487805
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 224.18442584427234
    mean_inference_ms: 1.356532673034617
    mean_processing_ms: 1.0754398939014291
  time_since_restore: 17852.52943611145
  time_this_iter_s: 28.45344376564026
  time_total_s: 17852.52943611145
  timestamp: 1638652918
  timesteps_since_restore: 77500
  timesteps_this_iter: 500
  timesteps_total: 77500
  training_iteration: 155
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    155 |          17852.5 | 77500 | 0.481571 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-22-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.49482165982533205
  episode_reward_min: -0.712707182320442
  episodes_this_iter: 500
  episodes_total: 78000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1684.731
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.34165000915527344
        entropy_coeff: 0.0
        kl: 0.007362270727753639
        model: {}
        policy_loss: -0.017535757273435593
        total_loss: -0.0007029077387414873
        vf_explained_var: 0.5522103309631348
        vf_loss: 0.01682940497994423
    load_time_ms: 2.274
    num_steps_sampled: 78000
    num_steps_trained: 78000
    sample_time_ms: 27567.723
    update_time_ms: 5.593
  iterations_since_restore: 156
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.47872340425532
    ram_util_percent: 15.793617021276598
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 223.1376633577042
    mean_inference_ms: 1.3556614867956314
    mean_processing_ms: 1.0745972603174743
  time_since_restore: 17885.817580223083
  time_this_iter_s: 33.2881441116333
  time_total_s: 17885.817580223083
  timestamp: 1638652951
  timesteps_since_restore: 78000
  timesteps_this_iter: 500
  timesteps_total: 78000
  training_iteration: 156
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    156 |          17885.8 | 78000 | 0.494822 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-23-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.870846394984326
  episode_reward_mean: 0.4785464361198816
  episode_reward_min: -0.9202453987730062
  episodes_this_iter: 500
  episodes_total: 78500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1682.023
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.3908034563064575
        entropy_coeff: 0.0
        kl: 0.011288842186331749
        model: {}
        policy_loss: -0.033113304525613785
        total_loss: -0.013150844722986221
        vf_explained_var: 0.5207793712615967
        vf_loss: 0.019957156851887703
    load_time_ms: 2.32
    num_steps_sampled: 78500
    num_steps_trained: 78500
    sample_time_ms: 29574.068
    update_time_ms: 5.488
  iterations_since_restore: 157
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.517999999999999
    ram_util_percent: 15.76
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 222.11970941098434
    mean_inference_ms: 1.3546959822139102
    mean_processing_ms: 1.0738276069804293
  time_since_restore: 17920.315309762955
  time_this_iter_s: 34.497729539871216
  time_total_s: 17920.315309762955
  timestamp: 1638652986
  timesteps_since_restore: 78500
  timesteps_this_iter: 500
  timesteps_total: 78500
  training_iteration: 157
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    157 |          17920.3 | 78500 | 0.478546 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-23-30
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9531871043721478
  episode_reward_mean: 0.49235838262305204
  episode_reward_min: -0.6397849462365591
  episodes_this_iter: 500
  episodes_total: 79000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1690.384
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.3529442846775055
        entropy_coeff: 0.0
        kl: 0.0064353663474321365
        model: {}
        policy_loss: -0.009811856783926487
        total_loss: 0.007265518419444561
        vf_explained_var: 0.5464878082275391
        vf_loss: 0.017074352130293846
    load_time_ms: 2.243
    num_steps_sampled: 79000
    num_steps_trained: 79000
    sample_time_ms: 29632.566
    update_time_ms: 5.555
  iterations_since_restore: 158
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.75
    ram_util_percent: 15.776470588235297
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 220.9753278970667
    mean_inference_ms: 1.3533688362932703
    mean_processing_ms: 1.0727194613700344
  time_since_restore: 17943.869480371475
  time_this_iter_s: 23.554170608520508
  time_total_s: 17943.869480371475
  timestamp: 1638653010
  timesteps_since_restore: 79000
  timesteps_this_iter: 500
  timesteps_total: 79000
  training_iteration: 158
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    158 |          17943.9 | 79000 | 0.492358 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-23-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8921298844248762
  episode_reward_mean: 0.49601686830307296
  episode_reward_min: -0.91875
  episodes_this_iter: 500
  episodes_total: 79500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1690.822
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.3864995539188385
        entropy_coeff: 0.0
        kl: 0.0059848930686712265
        model: {}
        policy_loss: -0.0161444004625082
        total_loss: 0.002833707258105278
        vf_explained_var: 0.5363048315048218
        vf_loss: 0.018975302577018738
    load_time_ms: 2.223
    num_steps_sampled: 79500
    num_steps_trained: 79500
    sample_time_ms: 28763.959
    update_time_ms: 5.559
  iterations_since_restore: 159
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.754054054054054
    ram_util_percent: 15.8
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 219.87671315061974
    mean_inference_ms: 1.3522436222315324
    mean_processing_ms: 1.0716089402994573
  time_since_restore: 17969.809819936752
  time_this_iter_s: 25.9403395652771
  time_total_s: 17969.809819936752
  timestamp: 1638653036
  timesteps_since_restore: 79500
  timesteps_this_iter: 500
  timesteps_total: 79500
  training_iteration: 159
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    159 |          17969.8 | 79500 | 0.496017 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-24-17
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.878494623655914
  episode_reward_mean: 0.49619145810077203
  episode_reward_min: -1.2694610778443114
  episodes_this_iter: 500
  episodes_total: 80000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1686.916
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.33012089133262634
        entropy_coeff: 0.0
        kl: 0.008540058508515358
        model: {}
        policy_loss: -0.01930314116179943
        total_loss: -0.0015152049018070102
        vf_explained_var: 0.5715643167495728
        vf_loss: 0.017783932387828827
    load_time_ms: 2.238
    num_steps_sampled: 80000
    num_steps_trained: 80000
    sample_time_ms: 27887.064
    update_time_ms: 5.597
  iterations_since_restore: 160
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.79
    ram_util_percent: 15.803333333333336
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 218.72814396223689
    mean_inference_ms: 1.3511441942766351
    mean_processing_ms: 1.070604600187668
  time_since_restore: 17990.700521707535
  time_this_iter_s: 20.89070177078247
  time_total_s: 17990.700521707535
  timestamp: 1638653057
  timesteps_since_restore: 80000
  timesteps_this_iter: 500
  timesteps_total: 80000
  training_iteration: 160
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    160 |          17990.7 | 80000 | 0.496191 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-24-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8945362134688691
  episode_reward_mean: 0.48605387014822415
  episode_reward_min: -0.018518518518518517
  episodes_this_iter: 500
  episodes_total: 80500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1687.055
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.3199630677700043
        entropy_coeff: 0.0
        kl: 0.010253104381263256
        model: {}
        policy_loss: -0.01598604954779148
        total_loss: -0.0033055392559617758
        vf_explained_var: 0.6024479866027832
        vf_loss: 0.012675698846578598
    load_time_ms: 2.261
    num_steps_sampled: 80500
    num_steps_trained: 80500
    sample_time_ms: 27498.838
    update_time_ms: 5.622
  iterations_since_restore: 161
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.488235294117647
    ram_util_percent: 15.802941176470586
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 217.6283767398956
    mean_inference_ms: 1.3499992106802285
    mean_processing_ms: 1.0695905087519897
  time_since_restore: 18014.38031387329
  time_this_iter_s: 23.679792165756226
  time_total_s: 18014.38031387329
  timestamp: 1638653081
  timesteps_since_restore: 80500
  timesteps_this_iter: 500
  timesteps_total: 80500
  training_iteration: 161
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    161 |          18014.4 | 80500 | 0.486054 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-25-00
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8533123028391167
  episode_reward_mean: 0.4359395501625321
  episode_reward_min: -0.9807692307692307
  episodes_this_iter: 500
  episodes_total: 81000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1701.682
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.33289873600006104
        entropy_coeff: 0.0
        kl: 0.009835019707679749
        model: {}
        policy_loss: -0.016359340399503708
        total_loss: 0.0026886654086411
        vf_explained_var: 0.5651912093162537
        vf_loss: 0.019043397158384323
    load_time_ms: 2.218
    num_steps_sampled: 81000
    num_steps_trained: 81000
    sample_time_ms: 25985.642
    update_time_ms: 5.64
  iterations_since_restore: 162
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.45
    ram_util_percent: 15.810714285714287
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 216.48466944837267
    mean_inference_ms: 1.3487904418040348
    mean_processing_ms: 1.0684080676436964
  time_since_restore: 18033.46786546707
  time_this_iter_s: 19.087551593780518
  time_total_s: 18033.46786546707
  timestamp: 1638653100
  timesteps_since_restore: 81000
  timesteps_this_iter: 500
  timesteps_total: 81000
  training_iteration: 162
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    162 |          18033.5 | 81000 |  0.43594 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-25-21
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8568935427574171
  episode_reward_mean: 0.4249958536988903
  episode_reward_min: -0.11751662971175167
  episodes_this_iter: 500
  episodes_total: 81500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1692.601
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.44089409708976746
        entropy_coeff: 0.0
        kl: 0.01589963212609291
        model: {}
        policy_loss: -0.021464847028255463
        total_loss: -0.006850410718470812
        vf_explained_var: 0.6083433628082275
        vf_loss: 0.014606982469558716
    load_time_ms: 2.256
    num_steps_sampled: 81500
    num_steps_trained: 81500
    sample_time_ms: 25257.677
    update_time_ms: 5.757
  iterations_since_restore: 163
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.2
    ram_util_percent: 15.80344827586207
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 215.37360987518926
    mean_inference_ms: 1.3474149105219788
    mean_processing_ms: 1.0671622943203005
  time_since_restore: 18053.939807891846
  time_this_iter_s: 20.47194242477417
  time_total_s: 18053.939807891846
  timestamp: 1638653121
  timesteps_since_restore: 81500
  timesteps_this_iter: 500
  timesteps_total: 81500
  training_iteration: 163
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    163 |          18053.9 | 81500 | 0.424996 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-25-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.4417354362077196
  episode_reward_min: -0.16791044776119404
  episodes_this_iter: 500
  episodes_total: 82000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1696.535
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.41047802567481995
        entropy_coeff: 0.0
        kl: 0.010960038751363754
        model: {}
        policy_loss: -0.02427324466407299
        total_loss: -0.008273174986243248
        vf_explained_var: 0.5606325268745422
        vf_loss: 0.015994930639863014
    load_time_ms: 2.242
    num_steps_sampled: 82000
    num_steps_trained: 82000
    sample_time_ms: 23713.092
    update_time_ms: 5.818
  iterations_since_restore: 164
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.377142857142859
    ram_util_percent: 15.802857142857146
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 214.3228034682626
    mean_inference_ms: 1.346541335513796
    mean_processing_ms: 1.0664001970564094
  time_since_restore: 18078.344077587128
  time_this_iter_s: 24.404269695281982
  time_total_s: 18078.344077587128
  timestamp: 1638653146
  timesteps_since_restore: 82000
  timesteps_this_iter: 500
  timesteps_total: 82000
  training_iteration: 164
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    164 |          18078.3 | 82000 | 0.441735 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-26-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8560250391236307
  episode_reward_mean: 0.4389531860596679
  episode_reward_min: -0.2802547770700637
  episodes_this_iter: 500
  episodes_total: 82500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1704.315
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.433094322681427
        entropy_coeff: 0.0
        kl: 0.011208247393369675
        model: {}
        policy_loss: -0.020899442955851555
        total_loss: -0.004305258393287659
        vf_explained_var: 0.5286772847175598
        vf_loss: 0.016588924452662468
    load_time_ms: 2.213
    num_steps_sampled: 82500
    num_steps_trained: 82500
    sample_time_ms: 23865.119
    update_time_ms: 5.91
  iterations_since_restore: 165
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.54318181818182
    ram_util_percent: 15.818181818181813
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 213.35291916528692
    mean_inference_ms: 1.3455951464245393
    mean_processing_ms: 1.0656486318925822
  time_since_restore: 18108.395024061203
  time_this_iter_s: 30.050946474075317
  time_total_s: 18108.395024061203
  timestamp: 1638653176
  timesteps_since_restore: 82500
  timesteps_this_iter: 500
  timesteps_total: 82500
  training_iteration: 165
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    165 |          18108.4 | 82500 | 0.438953 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-26-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647845468053492
  episode_reward_mean: 0.4642033581339736
  episode_reward_min: -0.1444043321299639
  episodes_this_iter: 500
  episodes_total: 83000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1713.118
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.4292166233062744
        entropy_coeff: 0.0
        kl: 0.010973230935633183
        model: {}
        policy_loss: -0.022256426513195038
        total_loss: -0.007899368181824684
        vf_explained_var: 0.572587788105011
        vf_loss: 0.014351918362081051
    load_time_ms: 2.164
    num_steps_sampled: 83000
    num_steps_trained: 83000
    sample_time_ms: 23303.392
    update_time_ms: 5.843
  iterations_since_restore: 166
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.857499999999998
    ram_util_percent: 15.819999999999999
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 212.36720156209154
    mean_inference_ms: 1.3446143112378404
    mean_processing_ms: 1.06475427666882
  time_since_restore: 18136.151214838028
  time_this_iter_s: 27.75619077682495
  time_total_s: 18136.151214838028
  timestamp: 1638653204
  timesteps_since_restore: 83000
  timesteps_this_iter: 500
  timesteps_total: 83000
  training_iteration: 166
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    166 |          18136.2 | 83000 | 0.464203 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-27-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.46705255084524866
  episode_reward_min: -0.6808510638297872
  episodes_this_iter: 500
  episodes_total: 83500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1725.676
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.43296462297439575
        entropy_coeff: 0.0
        kl: 0.011688578873872757
        model: {}
        policy_loss: -0.014771081507205963
        total_loss: 0.0002794978499878198
        vf_explained_var: 0.5988116264343262
        vf_loss: 0.015045102685689926
    load_time_ms: 2.132
    num_steps_sampled: 83500
    num_steps_trained: 83500
    sample_time_ms: 23189.179
    update_time_ms: 5.9
  iterations_since_restore: 167
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.925000000000002
    ram_util_percent: 15.810416666666667
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 211.4608262285092
    mean_inference_ms: 1.343891938456995
    mean_processing_ms: 1.0641761554834925
  time_since_restore: 18169.63221859932
  time_this_iter_s: 33.481003761291504
  time_total_s: 18169.63221859932
  timestamp: 1638653238
  timesteps_since_restore: 83500
  timesteps_this_iter: 500
  timesteps_total: 83500
  training_iteration: 167
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    167 |          18169.6 | 83500 | 0.467053 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-27-40
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647058823529412
  episode_reward_mean: 0.4653566547263562
  episode_reward_min: -0.14743589743589744
  episodes_this_iter: 500
  episodes_total: 84000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1722.681
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.3954094350337982
        entropy_coeff: 0.0
        kl: 0.01428073551505804
        model: {}
        policy_loss: -0.029144635424017906
        total_loss: -0.01654760167002678
        vf_explained_var: 0.5959699153900146
        vf_loss: 0.012590330094099045
    load_time_ms: 2.244
    num_steps_sampled: 84000
    num_steps_trained: 84000
    sample_time_ms: 23043.827
    update_time_ms: 5.763
  iterations_since_restore: 168
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.471875
    ram_util_percent: 15.815625
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 210.42969387455565
    mean_inference_ms: 1.3432267566483411
    mean_processing_ms: 1.0636542402868194
  time_since_restore: 18191.703815937042
  time_this_iter_s: 22.07159733772278
  time_total_s: 18191.703815937042
  timestamp: 1638653260
  timesteps_since_restore: 84000
  timesteps_this_iter: 500
  timesteps_total: 84000
  training_iteration: 168
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    168 |          18191.7 | 84000 | 0.465357 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-28-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.475382847899526
  episode_reward_min: -0.36904761904761907
  episodes_this_iter: 500
  episodes_total: 84500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1721.83
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.3987729549407959
        entropy_coeff: 0.0
        kl: 0.012805014848709106
        model: {}
        policy_loss: -0.020842690020799637
        total_loss: -0.007587948814034462
        vf_explained_var: 0.585110604763031
        vf_loss: 0.013248732313513756
    load_time_ms: 2.283
    num_steps_sampled: 84500
    num_steps_trained: 84500
    sample_time_ms: 22544.679
    update_time_ms: 5.69
  iterations_since_restore: 169
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.303333333333333
    ram_util_percent: 15.813333333333336
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 209.39950542849698
    mean_inference_ms: 1.3421302792520955
    mean_processing_ms: 1.0626385197018906
  time_since_restore: 18212.64479136467
  time_this_iter_s: 20.940975427627563
  time_total_s: 18212.64479136467
  timestamp: 1638653281
  timesteps_since_restore: 84500
  timesteps_this_iter: 500
  timesteps_total: 84500
  training_iteration: 169
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    169 |          18212.6 | 84500 | 0.475383 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-28-30
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8646362098138748
  episode_reward_mean: 0.4723614075590552
  episode_reward_min: -0.27595628415300544
  episodes_this_iter: 500
  episodes_total: 85000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1720.108
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.34037408232688904
        entropy_coeff: 0.0
        kl: 0.006369649898260832
        model: {}
        policy_loss: -0.01983034797012806
        total_loss: -0.004165042191743851
        vf_explained_var: 0.5520618557929993
        vf_loss: 0.015662318095564842
    load_time_ms: 2.346
    num_steps_sampled: 85000
    num_steps_trained: 85000
    sample_time_ms: 23347.525
    update_time_ms: 5.752
  iterations_since_restore: 170
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.041463414634144
    ram_util_percent: 15.812195121951218
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 208.47453690252854
    mean_inference_ms: 1.3411185992209906
    mean_processing_ms: 1.061771834895599
  time_since_restore: 18241.548251628876
  time_this_iter_s: 28.903460264205933
  time_total_s: 18241.548251628876
  timestamp: 1638653310
  timesteps_since_restore: 85000
  timesteps_this_iter: 500
  timesteps_total: 85000
  training_iteration: 170
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    170 |          18241.5 | 85000 | 0.472361 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-28-54
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.874926943308007
  episode_reward_mean: 0.4969816343398895
  episode_reward_min: -0.15637319316688567
  episodes_this_iter: 500
  episodes_total: 85500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1723.508
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.32440146803855896
        entropy_coeff: 0.0
        kl: 0.012765029445290565
        model: {}
        policy_loss: -0.02290850691497326
        total_loss: -0.012107041664421558
        vf_explained_var: 0.6526293754577637
        vf_loss: 0.010795474983751774
    load_time_ms: 2.347
    num_steps_sampled: 85500
    num_steps_trained: 85500
    sample_time_ms: 23348.29
    update_time_ms: 5.786
  iterations_since_restore: 171
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.46857142857143
    ram_util_percent: 15.822857142857139
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 207.499499374021
    mean_inference_ms: 1.3399203868402008
    mean_processing_ms: 1.0607088966381675
  time_since_restore: 18265.269360780716
  time_this_iter_s: 23.72110915184021
  time_total_s: 18265.269360780716
  timestamp: 1638653334
  timesteps_since_restore: 85500
  timesteps_this_iter: 500
  timesteps_total: 85500
  training_iteration: 171
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    171 |          18265.3 | 85500 | 0.496982 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-29-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.49146791805937184
  episode_reward_min: -0.06774193548387097
  episodes_this_iter: 500
  episodes_total: 86000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1728.841
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.3199574649333954
        entropy_coeff: 0.0
        kl: 0.012091594748198986
        model: {}
        policy_loss: -0.018020696938037872
        total_loss: -0.002648635534569621
        vf_explained_var: 0.5487236976623535
        vf_loss: 0.015366382896900177
    load_time_ms: 2.356
    num_steps_sampled: 86000
    num_steps_trained: 86000
    sample_time_ms: 23341.926
    update_time_ms: 5.774
  iterations_since_restore: 172
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.951851851851849
    ram_util_percent: 15.818518518518522
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 206.48035615992058
    mean_inference_ms: 1.3388336994605259
    mean_processing_ms: 1.0596863789702071
  time_since_restore: 18284.348050117493
  time_this_iter_s: 19.078689336776733
  time_total_s: 18284.348050117493
  timestamp: 1638653354
  timesteps_since_restore: 86000
  timesteps_this_iter: 500
  timesteps_total: 86000
  training_iteration: 172
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    172 |          18284.3 | 86000 | 0.491468 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-29-37
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8821316614420063
  episode_reward_mean: 0.4852746657061373
  episode_reward_min: -0.5048543689320388
  episodes_this_iter: 500
  episodes_total: 86500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1725.496
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.3203479051589966
        entropy_coeff: 0.0
        kl: 0.007256021723151207
        model: {}
        policy_loss: -0.018819576129317284
        total_loss: -0.004427524283528328
        vf_explained_var: 0.6089913845062256
        vf_loss: 0.014388653449714184
    load_time_ms: 2.306
    num_steps_sampled: 86500
    num_steps_trained: 86500
    sample_time_ms: 23589.229
    update_time_ms: 5.659
  iterations_since_restore: 173
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.506060606060606
    ram_util_percent: 15.821212121212122
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 205.51984054176998
    mean_inference_ms: 1.3376832955134472
    mean_processing_ms: 1.0585649965997388
  time_since_restore: 18307.257249832153
  time_this_iter_s: 22.909199714660645
  time_total_s: 18307.257249832153
  timestamp: 1638653377
  timesteps_since_restore: 86500
  timesteps_this_iter: 500
  timesteps_total: 86500
  training_iteration: 173
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    173 |          18307.3 | 86500 | 0.485275 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-30-00
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9531871043721478
  episode_reward_mean: 0.49431136663614617
  episode_reward_min: -0.03165938864628821
  episodes_this_iter: 500
  episodes_total: 87000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1740.633
    learner:
      default_policy:
        cur_kl_coeff: 0.00046927930088713765
        cur_lr: 4.999999873689376e-05
        entropy: 0.22168073058128357
        entropy_coeff: 0.0
        kl: 0.04677566513419151
        model: {}
        policy_loss: -0.03681265935301781
        total_loss: -0.021167458966374397
        vf_explained_var: 0.5248852372169495
        vf_loss: 0.015623245388269424
    load_time_ms: 2.366
    num_steps_sampled: 87000
    num_steps_trained: 87000
    sample_time_ms: 23446.17
    update_time_ms: 5.522
  iterations_since_restore: 174
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.06060606060606
    ram_util_percent: 15.806060606060607
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 204.5703205757747
    mean_inference_ms: 1.336515890444982
    mean_processing_ms: 1.0575938283163253
  time_since_restore: 18330.381250858307
  time_this_iter_s: 23.124001026153564
  time_total_s: 18330.381250858307
  timestamp: 1638653400
  timesteps_since_restore: 87000
  timesteps_this_iter: 500
  timesteps_total: 87000
  training_iteration: 174
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    174 |          18330.4 | 87000 | 0.494311 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-30-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8926802421574023
  episode_reward_mean: 0.5014268207363337
  episode_reward_min: 0.024
  episodes_this_iter: 500
  episodes_total: 87500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1738.745
    learner:
      default_policy:
        cur_kl_coeff: 0.000703918922226876
        cur_lr: 4.999999873689376e-05
        entropy: 0.26539984345436096
        entropy_coeff: 0.0
        kl: 0.008662479929625988
        model: {}
        policy_loss: -0.01660853810608387
        total_loss: -0.0038600137922912836
        vf_explained_var: 0.5841380953788757
        vf_loss: 0.012742421589791775
    load_time_ms: 2.409
    num_steps_sampled: 87500
    num_steps_trained: 87500
    sample_time_ms: 21831.133
    update_time_ms: 5.461
  iterations_since_restore: 175
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.90476190476191
    ram_util_percent: 15.814285714285718
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 203.5279537279662
    mean_inference_ms: 1.3353409363179058
    mean_processing_ms: 1.0564522904475955
  time_since_restore: 18344.262944936752
  time_this_iter_s: 13.881694078445435
  time_total_s: 18344.262944936752
  timestamp: 1638653414
  timesteps_since_restore: 87500
  timesteps_this_iter: 500
  timesteps_total: 87500
  training_iteration: 175
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    175 |          18344.3 | 87500 | 0.501427 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-30-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8945362134688691
  episode_reward_mean: 0.5050644721134258
  episode_reward_min: -0.31026252983293556
  episodes_this_iter: 500
  episodes_total: 88000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1735.251
    learner:
      default_policy:
        cur_kl_coeff: 0.000703918922226876
        cur_lr: 4.999999873689376e-05
        entropy: 0.27003493905067444
        entropy_coeff: 0.0
        kl: 0.009535624645650387
        model: {}
        policy_loss: -0.0207911878824234
        total_loss: -0.007682023104280233
        vf_explained_var: 0.6200229525566101
        vf_loss: 0.013102450408041477
    load_time_ms: 2.41
    num_steps_sampled: 88000
    num_steps_trained: 88000
    sample_time_ms: 20688.827
    update_time_ms: 5.559
  iterations_since_restore: 176
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.00869565217391
    ram_util_percent: 15.813043478260875
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 202.5248206023055
    mean_inference_ms: 1.3342558544476806
    mean_processing_ms: 1.0553860051801447
  time_since_restore: 18360.561923742294
  time_this_iter_s: 16.298978805541992
  time_total_s: 18360.561923742294
  timestamp: 1638653431
  timesteps_since_restore: 88000
  timesteps_this_iter: 500
  timesteps_total: 88000
  training_iteration: 176
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    176 |          18360.6 | 88000 | 0.505064 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-30-48
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8564954682779456
  episode_reward_mean: 0.45999246265367605
  episode_reward_min: -0.3062200956937799
  episodes_this_iter: 500
  episodes_total: 88500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1722.405
    learner:
      default_policy:
        cur_kl_coeff: 0.000703918922226876
        cur_lr: 4.999999873689376e-05
        entropy: 0.255311518907547
        entropy_coeff: 0.0
        kl: 0.011041286401450634
        model: {}
        policy_loss: -0.020196938887238503
        total_loss: -0.006484623998403549
        vf_explained_var: 0.5581752061843872
        vf_loss: 0.013704555109143257
    load_time_ms: 2.415
    num_steps_sampled: 88500
    num_steps_trained: 88500
    sample_time_ms: 19100.23
    update_time_ms: 5.596
  iterations_since_restore: 177
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.888
    ram_util_percent: 15.832
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 201.54643673270226
    mean_inference_ms: 1.3334281032292128
    mean_processing_ms: 1.0545059653497992
  time_since_restore: 18378.028393030167
  time_this_iter_s: 17.466469287872314
  time_total_s: 18378.028393030167
  timestamp: 1638653448
  timesteps_since_restore: 88500
  timesteps_this_iter: 500
  timesteps_total: 88500
  training_iteration: 177
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    177 |            18378 | 88500 | 0.459992 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-31-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8521959459459459
  episode_reward_mean: 0.4257819835624443
  episode_reward_min: -0.3640661938534279
  episodes_this_iter: 500
  episodes_total: 89000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1715.408
    learner:
      default_policy:
        cur_kl_coeff: 0.000703918922226876
        cur_lr: 4.999999873689376e-05
        entropy: 0.36709046363830566
        entropy_coeff: 0.0
        kl: 0.010143413208425045
        model: {}
        policy_loss: -0.015292415395379066
        total_loss: 0.0005792340380139649
        vf_explained_var: 0.6020541191101074
        vf_loss: 0.015864504501223564
    load_time_ms: 2.302
    num_steps_sampled: 89000
    num_steps_trained: 89000
    sample_time_ms: 19843.521
    update_time_ms: 5.658
  iterations_since_restore: 178
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.423255813953489
    ram_util_percent: 15.830232558139533
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 200.71157768771045
    mean_inference_ms: 1.3332784197973155
    mean_processing_ms: 1.054524627972546
  time_since_restore: 18407.461156368256
  time_this_iter_s: 29.43276333808899
  time_total_s: 18407.461156368256
  timestamp: 1638653478
  timesteps_since_restore: 89000
  timesteps_this_iter: 500
  timesteps_total: 89000
  training_iteration: 178
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    178 |          18407.5 | 89000 | 0.425782 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-31-35
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.42640313749097863
  episode_reward_min: -0.04918032786885246
  episodes_this_iter: 500
  episodes_total: 89500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1724.627
    learner:
      default_policy:
        cur_kl_coeff: 0.000703918922226876
        cur_lr: 4.999999873689376e-05
        entropy: 0.37530818581581116
        entropy_coeff: 0.0
        kl: 0.03088648058474064
        model: {}
        policy_loss: -0.032489072531461716
        total_loss: -0.018373506143689156
        vf_explained_var: 0.6295204758644104
        vf_loss: 0.014093827456235886
    load_time_ms: 2.249
    num_steps_sampled: 89500
    num_steps_trained: 89500
    sample_time_ms: 19380.498
    update_time_ms: 5.762
  iterations_since_restore: 179
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.86521739130435
    ram_util_percent: 15.856521739130434
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 199.74121043040665
    mean_inference_ms: 1.332396186331387
    mean_processing_ms: 1.0538642333820025
  time_since_restore: 18423.864757299423
  time_this_iter_s: 16.403600931167603
  time_total_s: 18423.864757299423
  timestamp: 1638653495
  timesteps_since_restore: 89500
  timesteps_this_iter: 500
  timesteps_total: 89500
  training_iteration: 179
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    179 |          18423.9 | 89500 | 0.426403 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-31-54
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.841025641025641
  episode_reward_mean: 0.4432055270791166
  episode_reward_min: -0.16791044776119404
  episodes_this_iter: 500
  episodes_total: 90000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1730.553
    learner:
      default_policy:
        cur_kl_coeff: 0.0010558783542364836
        cur_lr: 4.999999873689376e-05
        entropy: 0.38833895325660706
        entropy_coeff: 0.0
        kl: 0.019933128729462624
        model: {}
        policy_loss: -0.029377061873674393
        total_loss: -0.012960049323737621
        vf_explained_var: 0.5915288329124451
        vf_loss: 0.016395974904298782
    load_time_ms: 2.223
    num_steps_sampled: 90000
    num_steps_trained: 90000
    sample_time_ms: 18417.048
    update_time_ms: 5.738
  iterations_since_restore: 180
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.7
    ram_util_percent: 15.825000000000001
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 198.81455991346596
    mean_inference_ms: 1.3313447897572597
    mean_processing_ms: 1.0530339327270821
  time_since_restore: 18443.192014455795
  time_this_iter_s: 19.32725715637207
  time_total_s: 18443.192014455795
  timestamp: 1638653514
  timesteps_since_restore: 90000
  timesteps_this_iter: 500
  timesteps_total: 90000
  training_iteration: 180
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    180 |          18443.2 | 90000 | 0.443206 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-32-23
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647845468053492
  episode_reward_mean: 0.4439574369747977
  episode_reward_min: -0.1609907120743034
  episodes_this_iter: 500
  episodes_total: 90500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1735.036
    learner:
      default_policy:
        cur_kl_coeff: 0.0010558783542364836
        cur_lr: 4.999999873689376e-05
        entropy: 0.35780566930770874
        entropy_coeff: 0.0
        kl: 0.010834754444658756
        model: {}
        policy_loss: -0.021729106083512306
        total_loss: -0.003669525496661663
        vf_explained_var: 0.49946269392967224
        vf_loss: 0.01804814301431179
    load_time_ms: 2.233
    num_steps_sampled: 90500
    num_steps_trained: 90500
    sample_time_ms: 18860.142
    update_time_ms: 5.775
  iterations_since_restore: 181
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.77073170731707
    ram_util_percent: 15.819512195121948
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 197.99411902104848
    mean_inference_ms: 1.3310241970038192
    mean_processing_ms: 1.052789385888504
  time_since_restore: 18471.389555215836
  time_this_iter_s: 28.197540760040283
  time_total_s: 18471.389555215836
  timestamp: 1638653543
  timesteps_since_restore: 90500
  timesteps_this_iter: 500
  timesteps_total: 90500
  training_iteration: 181
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    181 |          18471.4 | 90500 | 0.443957 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-32-42
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8565340909090909
  episode_reward_mean: 0.4712029155571445
  episode_reward_min: -0.1444043321299639
  episodes_this_iter: 500
  episodes_total: 91000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1717.051
    learner:
      default_policy:
        cur_kl_coeff: 0.0010558783542364836
        cur_lr: 4.999999873689376e-05
        entropy: 0.30676424503326416
        entropy_coeff: 0.0
        kl: 0.014432269148528576
        model: {}
        policy_loss: -0.019485587254166603
        total_loss: -0.006841444876044989
        vf_explained_var: 0.6117714643478394
        vf_loss: 0.012628903612494469
    load_time_ms: 2.308
    num_steps_sampled: 91000
    num_steps_trained: 91000
    sample_time_ms: 18877.551
    update_time_ms: 5.886
  iterations_since_restore: 182
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.296296296296294
    ram_util_percent: 15.855555555555558
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 197.08539251953647
    mean_inference_ms: 1.329904168458107
    mean_processing_ms: 1.0517619169433947
  time_since_restore: 18490.46333384514
  time_this_iter_s: 19.07377862930298
  time_total_s: 18490.46333384514
  timestamp: 1638653562
  timesteps_since_restore: 91000
  timesteps_this_iter: 500
  timesteps_total: 91000
  training_iteration: 182
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    182 |          18490.5 | 91000 | 0.471203 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-33-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.4529956500747399
  episode_reward_min: -0.25526315789473686
  episodes_this_iter: 500
  episodes_total: 91500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1720.069
    learner:
      default_policy:
        cur_kl_coeff: 0.0010558783542364836
        cur_lr: 4.999999873689376e-05
        entropy: 0.29556721448898315
        entropy_coeff: 0.0
        kl: 0.008774335496127605
        model: {}
        policy_loss: -0.028389163315296173
        total_loss: -0.014943582937121391
        vf_explained_var: 0.6360331773757935
        vf_loss: 0.01343631837517023
    load_time_ms: 2.297
    num_steps_sampled: 91500
    num_steps_trained: 91500
    sample_time_ms: 19586.399
    update_time_ms: 5.948
  iterations_since_restore: 183
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.672727272727274
    ram_util_percent: 15.822727272727269
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 196.30582210067874
    mean_inference_ms: 1.3288733068095497
    mean_processing_ms: 1.0510347231902877
  time_since_restore: 18520.491763591766
  time_this_iter_s: 30.028429746627808
  time_total_s: 18520.491763591766
  timestamp: 1638653592
  timesteps_since_restore: 91500
  timesteps_this_iter: 500
  timesteps_total: 91500
  training_iteration: 183
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    183 |          18520.5 | 91500 | 0.452996 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-33-37
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647058823529412
  episode_reward_mean: 0.48323716679729534
  episode_reward_min: 0.06798245614035088
  episodes_this_iter: 500
  episodes_total: 92000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1702.374
    learner:
      default_policy:
        cur_kl_coeff: 0.0010558783542364836
        cur_lr: 4.999999873689376e-05
        entropy: 0.3067570924758911
        entropy_coeff: 0.0
        kl: 0.007484946399927139
        model: {}
        policy_loss: -0.021168459206819534
        total_loss: -0.009717350825667381
        vf_explained_var: 0.6307011246681213
        vf_loss: 0.011443208903074265
    load_time_ms: 2.239
    num_steps_sampled: 92000
    num_steps_trained: 92000
    sample_time_ms: 19785.702
    update_time_ms: 6.02
  iterations_since_restore: 184
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.583333333333334
    ram_util_percent: 15.852777777777773
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 195.47932064871034
    mean_inference_ms: 1.328056212944865
    mean_processing_ms: 1.0502151745254389
  time_since_restore: 18545.43165206909
  time_this_iter_s: 24.93988847732544
  time_total_s: 18545.43165206909
  timestamp: 1638653617
  timesteps_since_restore: 92000
  timesteps_this_iter: 500
  timesteps_total: 92000
  training_iteration: 184
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    184 |          18545.4 | 92000 | 0.483237 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-33-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.4745041918167789
  episode_reward_min: 0.051111111111111114
  episodes_this_iter: 500
  episodes_total: 92500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1693.769
    learner:
      default_policy:
        cur_kl_coeff: 0.0010558783542364836
        cur_lr: 4.999999873689376e-05
        entropy: 0.2453029453754425
        entropy_coeff: 0.0
        kl: 0.008961540646851063
        model: {}
        policy_loss: -0.01634529046714306
        total_loss: -0.0043480354361236095
        vf_explained_var: 0.5801024436950684
        vf_loss: 0.011987801641225815
    load_time_ms: 2.161
    num_steps_sampled: 92500
    num_steps_trained: 92500
    sample_time_ms: 19816.358
    update_time_ms: 5.964
  iterations_since_restore: 185
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.55
    ram_util_percent: 15.855
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 194.54571090168974
    mean_inference_ms: 1.32694365886715
    mean_processing_ms: 1.0492568534072222
  time_since_restore: 18559.53197145462
  time_this_iter_s: 14.100319385528564
  time_total_s: 18559.53197145462
  timestamp: 1638653632
  timesteps_since_restore: 92500
  timesteps_this_iter: 500
  timesteps_total: 92500
  training_iteration: 185
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    185 |          18559.5 | 92500 | 0.474504 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-34-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8646362098138748
  episode_reward_mean: 0.48238077404802665
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 93000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1703.47
    learner:
      default_policy:
        cur_kl_coeff: 0.0010558783542364836
        cur_lr: 4.999999873689376e-05
        entropy: 0.22482796013355255
        entropy_coeff: 0.0
        kl: 0.008467226289212704
        model: {}
        policy_loss: -0.017397116869688034
        total_loss: -0.003956233151257038
        vf_explained_var: 0.5359175205230713
        vf_loss: 0.013431942090392113
    load_time_ms: 2.241
    num_steps_sampled: 93000
    num_steps_trained: 93000
    sample_time_ms: 20326.193
    update_time_ms: 5.958
  iterations_since_restore: 186
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.538709677419357
    ram_util_percent: 15.848387096774195
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 193.69955156489365
    mean_inference_ms: 1.325862028090139
    mean_processing_ms: 1.0483888163069095
  time_since_restore: 18581.02898478508
  time_this_iter_s: 21.497013330459595
  time_total_s: 18581.02898478508
  timestamp: 1638653654
  timesteps_since_restore: 93000
  timesteps_this_iter: 500
  timesteps_total: 93000
  training_iteration: 186
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    186 |            18581 | 93000 | 0.482381 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-34-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.5007833923574833
  episode_reward_min: 0.047516198704103674
  episodes_this_iter: 500
  episodes_total: 93500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1714.167
    learner:
      default_policy:
        cur_kl_coeff: 0.0010558783542364836
        cur_lr: 4.999999873689376e-05
        entropy: 0.1802421510219574
        entropy_coeff: 0.0
        kl: 0.003623177297413349
        model: {}
        policy_loss: -0.014494313858449459
        total_loss: -0.0013786250492557883
        vf_explained_var: 0.5871834754943848
        vf_loss: 0.013111856766045094
    load_time_ms: 2.232
    num_steps_sampled: 93500
    num_steps_trained: 93500
    sample_time_ms: 20573.336
    update_time_ms: 5.939
  iterations_since_restore: 187
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.813793103448273
    ram_util_percent: 15.858620689655176
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 192.8434501763858
    mean_inference_ms: 1.3267835118977371
    mean_processing_ms: 1.049498122225032
  time_since_restore: 18601.0744535923
  time_this_iter_s: 20.04546880722046
  time_total_s: 18601.0744535923
  timestamp: 1638653674
  timesteps_since_restore: 93500
  timesteps_this_iter: 500
  timesteps_total: 93500
  training_iteration: 187
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    187 |          18601.1 | 93500 | 0.500783 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-34-45
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8821316614420063
  episode_reward_mean: 0.48343494429820166
  episode_reward_min: -0.20408163265306123
  episodes_this_iter: 500
  episodes_total: 94000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1736.665
    learner:
      default_policy:
        cur_kl_coeff: 0.0005279391771182418
        cur_lr: 4.999999873689376e-05
        entropy: 0.16748270392417908
        entropy_coeff: 0.0
        kl: 0.009154405444860458
        model: {}
        policy_loss: -0.02005615644156933
        total_loss: -0.004679315257817507
        vf_explained_var: 0.5592834949493408
        vf_loss: 0.015372009016573429
    load_time_ms: 2.302
    num_steps_sampled: 94000
    num_steps_trained: 94000
    sample_time_ms: 18656.125
    update_time_ms: 5.961
  iterations_since_restore: 188
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.933333333333337
    ram_util_percent: 15.820000000000004
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 191.89603371492908
    mean_inference_ms: 1.3262907549000331
    mean_processing_ms: 1.0491863144043776
  time_since_restore: 18611.563189983368
  time_this_iter_s: 10.488736391067505
  time_total_s: 18611.563189983368
  timestamp: 1638653685
  timesteps_since_restore: 94000
  timesteps_this_iter: 500
  timesteps_total: 94000
  training_iteration: 188
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    188 |          18611.6 | 94000 | 0.483435 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-34-58
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9531871043721478
  episode_reward_mean: 0.49861064314125864
  episode_reward_min: 0.009966777408637873
  episodes_this_iter: 500
  episodes_total: 94500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1730.521
    learner:
      default_policy:
        cur_kl_coeff: 0.0005279391771182418
        cur_lr: 4.999999873689376e-05
        entropy: 0.16270074248313904
        entropy_coeff: 0.0
        kl: 0.010756032541394234
        model: {}
        policy_loss: -0.023082254454493523
        total_loss: -0.010273553431034088
        vf_explained_var: 0.5942193269729614
        vf_loss: 0.012803031131625175
    load_time_ms: 2.343
    num_steps_sampled: 94500
    num_steps_trained: 94500
    sample_time_ms: 18308.477
    update_time_ms: 5.929
  iterations_since_restore: 189
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.347368421052636
    ram_util_percent: 15.826315789473687
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 190.98641296397864
    mean_inference_ms: 1.3257899870538312
    mean_processing_ms: 1.0487240895577996
  time_since_restore: 18624.428040266037
  time_this_iter_s: 12.864850282669067
  time_total_s: 18624.428040266037
  timestamp: 1638653698
  timesteps_since_restore: 94500
  timesteps_this_iter: 500
  timesteps_total: 94500
  training_iteration: 189
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    189 |          18624.4 | 94500 | 0.498611 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-35-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8814285714285715
  episode_reward_mean: 0.48727305558481554
  episode_reward_min: -0.18055555555555555
  episodes_this_iter: 500
  episodes_total: 95000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1726.922
    learner:
      default_policy:
        cur_kl_coeff: 0.0005279391771182418
        cur_lr: 4.999999873689376e-05
        entropy: 0.15171070396900177
        entropy_coeff: 0.0
        kl: 0.011148341000080109
        model: {}
        policy_loss: -0.013741407543420792
        total_loss: 0.0013079302152618766
        vf_explained_var: 0.551633358001709
        vf_loss: 0.015043455176055431
    load_time_ms: 2.281
    num_steps_sampled: 95000
    num_steps_trained: 95000
    sample_time_ms: 16952.716
    update_time_ms: 5.923
  iterations_since_restore: 190
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.17777777777778
    ram_util_percent: 15.822222222222223
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 190.01206958825077
    mean_inference_ms: 1.3248118760366165
    mean_processing_ms: 1.047844427565339
  time_since_restore: 18630.16114425659
  time_this_iter_s: 5.73310399055481
  time_total_s: 18630.16114425659
  timestamp: 1638653704
  timesteps_since_restore: 95000
  timesteps_this_iter: 500
  timesteps_total: 95000
  training_iteration: 190
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    190 |          18630.2 | 95000 | 0.487273 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-35-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8926802421574023
  episode_reward_mean: 0.4881321432449581
  episode_reward_min: -0.28991596638655465
  episodes_this_iter: 500
  episodes_total: 95500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1728.922
    learner:
      default_policy:
        cur_kl_coeff: 0.0005279391771182418
        cur_lr: 4.999999873689376e-05
        entropy: 0.16078589856624603
        entropy_coeff: 0.0
        kl: 0.004911554977297783
        model: {}
        policy_loss: -0.01803666353225708
        total_loss: -0.004687322303652763
        vf_explained_var: 0.6019299030303955
        vf_loss: 0.013346749357879162
    load_time_ms: 2.346
    num_steps_sampled: 95500
    num_steps_trained: 95500
    sample_time_ms: 15734.665
    update_time_ms: 5.841
  iterations_since_restore: 191
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.87826086956522
    ram_util_percent: 15.847826086956525
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 189.15264702166812
    mean_inference_ms: 1.3248074625293889
    mean_processing_ms: 1.047945006605385
  time_since_restore: 18646.19784092903
  time_this_iter_s: 16.036696672439575
  time_total_s: 18646.19784092903
  timestamp: 1638653720
  timesteps_since_restore: 95500
  timesteps_this_iter: 500
  timesteps_total: 95500
  training_iteration: 191
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    191 |          18646.2 | 95500 | 0.488132 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-35-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8945362134688691
  episode_reward_mean: 0.5093861594591418
  episode_reward_min: 0.050314465408805034
  episodes_this_iter: 500
  episodes_total: 96000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1736.937
    learner:
      default_policy:
        cur_kl_coeff: 0.0002639695885591209
        cur_lr: 4.999999873689376e-05
        entropy: 0.15411804616451263
        entropy_coeff: 0.0
        kl: 0.008380104787647724
        model: {}
        policy_loss: -0.012011373415589333
        total_loss: 0.00047529846779070795
        vf_explained_var: 0.6009353399276733
        vf_loss: 0.012484470382332802
    load_time_ms: 2.266
    num_steps_sampled: 96000
    num_steps_trained: 96000
    sample_time_ms: 14929.677
    update_time_ms: 5.835
  iterations_since_restore: 192
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.30625
    ram_util_percent: 15.875
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 188.25188965684723
    mean_inference_ms: 1.3245351699412826
    mean_processing_ms: 1.0478245991098198
  time_since_restore: 18657.30082345009
  time_this_iter_s: 11.102982521057129
  time_total_s: 18657.30082345009
  timestamp: 1638653731
  timesteps_since_restore: 96000
  timesteps_this_iter: 500
  timesteps_total: 96000
  training_iteration: 192
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    192 |          18657.3 | 96000 | 0.509386 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-35-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8564954682779456
  episode_reward_mean: 0.43690684832932924
  episode_reward_min: -0.3640661938534279
  episodes_this_iter: 500
  episodes_total: 96500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1737.196
    learner:
      default_policy:
        cur_kl_coeff: 0.0002639695885591209
        cur_lr: 4.999999873689376e-05
        entropy: 0.1313222199678421
        entropy_coeff: 0.0
        kl: 0.004127951804548502
        model: {}
        policy_loss: -0.010847235098481178
        total_loss: 0.004226194228976965
        vf_explained_var: 0.5547588467597961
        vf_loss: 0.01507234014570713
    load_time_ms: 2.281
    num_steps_sampled: 96500
    num_steps_trained: 96500
    sample_time_ms: 12914.763
    update_time_ms: 5.715
  iterations_since_restore: 193
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.466666666666665
    ram_util_percent: 15.826666666666672
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 187.34980853962443
    mean_inference_ms: 1.3237168675977267
    mean_processing_ms: 1.0469728125877187
  time_since_restore: 18667.18232870102
  time_this_iter_s: 9.881505250930786
  time_total_s: 18667.18232870102
  timestamp: 1638653741
  timesteps_since_restore: 96500
  timesteps_this_iter: 500
  timesteps_total: 96500
  training_iteration: 193
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    193 |          18667.2 | 96500 | 0.436907 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-35-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8568935427574171
  episode_reward_mean: 0.42599896545091187
  episode_reward_min: -0.25
  episodes_this_iter: 500
  episodes_total: 97000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1738.481
    learner:
      default_policy:
        cur_kl_coeff: 0.00013198479427956045
        cur_lr: 4.999999873689376e-05
        entropy: 0.14075495302677155
        entropy_coeff: 0.0
        kl: 0.003176395082846284
        model: {}
        policy_loss: -0.007409730460494757
        total_loss: 0.0075653172098100185
        vf_explained_var: 0.6007023453712463
        vf_loss: 0.014974629506468773
    load_time_ms: 2.266
    num_steps_sampled: 97000
    num_steps_trained: 97000
    sample_time_ms: 11481.63
    update_time_ms: 5.625
  iterations_since_restore: 194
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.12
    ram_util_percent: 15.83333333333334
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 186.4636523963419
    mean_inference_ms: 1.323307864800014
    mean_processing_ms: 1.0466195066186987
  time_since_restore: 18677.80291867256
  time_this_iter_s: 10.620589971542358
  time_total_s: 18677.80291867256
  timestamp: 1638653752
  timesteps_since_restore: 97000
  timesteps_this_iter: 500
  timesteps_total: 97000
  training_iteration: 194
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    194 |          18677.8 | 97000 | 0.425999 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-36-02
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.43330226481203277
  episode_reward_min: -0.07336683417085427
  episodes_this_iter: 500
  episodes_total: 97500
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1746.591
    learner:
      default_policy:
        cur_kl_coeff: 6.599239713978022e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.11583416163921356
        entropy_coeff: 0.0
        kl: 0.004943296313285828
        model: {}
        policy_loss: -0.009988387115299702
        total_loss: 0.004902769811451435
        vf_explained_var: 0.5860627293586731
        vf_loss: 0.014890840277075768
    load_time_ms: 2.281
    num_steps_sampled: 97500
    num_steps_trained: 97500
    sample_time_ms: 10959.506
    update_time_ms: 5.754
  iterations_since_restore: 195
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.361538461538466
    ram_util_percent: 15.869230769230775
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 185.57031031071878
    mean_inference_ms: 1.3224517143334726
    mean_processing_ms: 1.0458505859979081
  time_since_restore: 18686.76464009285
  time_this_iter_s: 8.961721420288086
  time_total_s: 18686.76464009285
  timestamp: 1638653762
  timesteps_since_restore: 97500
  timesteps_this_iter: 500
  timesteps_total: 97500
  training_iteration: 195
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    195 |          18686.8 | 97500 | 0.433302 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-36-07
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.841025641025641
  episode_reward_mean: 0.4267857722541683
  episode_reward_min: -0.16791044776119404
  episodes_this_iter: 500
  episodes_total: 98000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1743.256
    learner:
      default_policy:
        cur_kl_coeff: 3.299619856989011e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.11466410756111145
        entropy_coeff: 0.0
        kl: 0.005372531246393919
        model: {}
        policy_loss: -0.009027688764035702
        total_loss: 0.007768094539642334
        vf_explained_var: 0.5239955186843872
        vf_loss: 0.01679561473429203
    load_time_ms: 2.266
    num_steps_sampled: 98000
    num_steps_trained: 98000
    sample_time_ms: 9308.425
    update_time_ms: 5.812
  iterations_since_restore: 196
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.0625
    ram_util_percent: 15.8125
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 184.64407223737788
    mean_inference_ms: 1.3217994606524952
    mean_processing_ms: 1.0453324769414463
  time_since_restore: 18691.719938516617
  time_this_iter_s: 4.95529842376709
  time_total_s: 18691.719938516617
  timestamp: 1638653767
  timesteps_since_restore: 98000
  timesteps_this_iter: 500
  timesteps_total: 98000
  training_iteration: 196
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    196 |          18691.7 | 98000 | 0.426786 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


[2m[36m(pid=21334)[0m Program ./new_max8_garbage_21334/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-36-21
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.4741465635431553
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 99000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1721.888
    learner:
      default_policy:
        cur_kl_coeff: 3.299619856989011e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.12056701630353928
        entropy_coeff: 0.0
        kl: 0.006478858180344105
        model: {}
        policy_loss: -0.013512909412384033
        total_loss: -0.002380541292950511
        vf_explained_var: 0.6418949961662292
        vf_loss: 0.011132150888442993
    load_time_ms: 2.249
    num_steps_sampled: 99000
    num_steps_trained: 99000
    sample_time_ms: 7662.711
    update_time_ms: 5.921
  iterations_since_restore: 198
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.485714285714288
    ram_util_percent: 15.857142857142861
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 182.8607990963746
    mean_inference_ms: 1.3203951610731222
    mean_processing_ms: 1.0443395333398904
  time_since_restore: 18705.584763288498
  time_this_iter_s: 9.282903909683228
  time_total_s: 18705.584763288498
  timestamp: 1638653781
  timesteps_since_restore: 99000
  timesteps_this_iter: 500
  timesteps_total: 99000
  training_iteration: 198
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+----------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    198 |          18705.6 | 99000 | 0.474147 |
+-------------------+----------+----------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_16-36-36
  done: true
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.4869767243375238
  episode_reward_min: 0.059850374064837904
  episodes_this_iter: 500
  episodes_total: 100000
  experiment_id: 5966317209d748628ea7c513126aa3b7
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1736.373
    learner:
      default_policy:
        cur_kl_coeff: 3.299619856989011e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.13882584869861603
        entropy_coeff: 0.0
        kl: 0.007195836398750544
        model: {}
        policy_loss: -0.012523428536951542
        total_loss: -0.0013694658409804106
        vf_explained_var: 0.6233003735542297
        vf_loss: 0.011153736151754856
    load_time_ms: 2.263
    num_steps_sampled: 100000
    num_steps_trained: 100000
    sample_time_ms: 7232.182
    update_time_ms: 5.827
  iterations_since_restore: 200
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.285714285714285
    ram_util_percent: 15.842857142857147
  pid: 21329
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 181.1182806417251
    mean_inference_ms: 1.3190844949689544
    mean_processing_ms: 1.043149825841219
  time_since_restore: 18720.029692173004
  time_this_iter_s: 9.866389751434326
  time_total_s: 18720.029692173004
  timestamp: 1638653796
  timesteps_since_restore: 100000
  timesteps_this_iter: 500
  timesteps_total: 100000
  training_iteration: 200
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+----------------------+--------+------------------+--------+----------+
| Trial name        | status   | loc                  |   iter |   total time (s) |     ts |   reward |
|-------------------+----------+----------------------+--------+------------------+--------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:21329 |    200 |            18720 | 100000 | 0.486977 |
+-------------------+----------+----------------------+--------+------------------+--------+----------+


== Status ==
Memory usage on this node: 2.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 TERMINATED)
+-------------------+------------+-------+--------+------------------+--------+----------+
| Trial name        | status     | loc   |   iter |   total time (s) |     ts |   reward |
|-------------------+------------+-------+--------+------------------+--------+----------|
| PPO_autovec_00000 | TERMINATED |       |    200 |            18720 | 100000 | 0.486977 |
+-------------------+------------+-------+--------+------------------+--------+----------+


