== Status ==
Memory usage on this node: 1.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+-------+
| Trial name        | status   | loc   |
|-------------------+----------+-------|
| PPO_autovec_00000 | RUNNING  |       |
+-------------------+----------+-------+


[2m[36m(pid=2025)[0m /home/bdmanley/anaconda3/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.
[2m[36m(pid=2025)[0m   for external in metadata.entry_points().get(self.group, []):
[2m[36m(pid=2025)[0m 2021-12-11 19:07:54,128	INFO trainer.py:428 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
[2m[36m(pid=2025)[0m 2021-12-11 19:07:54,134	WARNING deprecation.py:30 -- DeprecationWarning: `sample_batch_size` has been deprecated. Use `rollout_fragment_length` instead. This will raise an error in the future!
[2m[36m(pid=2025)[0m 2021-12-11 19:07:54,134	INFO trainer.py:585 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=2025)[0m cp: cannot stat './training_data/*': No such file or directory
[2m[36m(pid=2025)[0m creating ./new_scramble_unroll_garbage_2025 directory
[2m[36m(pid=2025)[0m running: cp -r ./training_data/* ./new_scramble_unroll_garbage_2025
[2m[36m(pid=2025)[0m Checking if local obs_encodings.pkl file exists.
[2m[36m(pid=2025)[0m Checking if local O3_runtimes.pkl file exists to avoid waste of compilation.
[2m[36m(pid=2025)[0m Did not find O3_runtimes.pkl... Compiling to get -O3 runtimes.
[2m[36m(pid=2024)[0m /home/bdmanley/anaconda3/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.
[2m[36m(pid=2024)[0m   for external in metadata.entry_points().get(self.group, []):
[2m[36m(pid=2025)[0m 2021-12-11 19:07:58,350	INFO trainable.py:217 -- Getting current IP.
[2m[36m(pid=2025)[0m 2021-12-11 19:07:58,350	WARNING util.py:37 -- Install gputil for GPU system monitoring.
[2m[36m(pid=2024)[0m creating ./new_scramble_unroll_garbage_2024 directory
[2m[36m(pid=2024)[0m running: cp -r ./training_data/* ./new_scramble_unroll_garbage_2024
[2m[36m(pid=2024)[0m Checking if local obs_encodings.pkl file exists.
[2m[36m(pid=2024)[0m found local obs_encodings.pkl.
[2m[36m(pid=2024)[0m Checking if local O3_runtimes.pkl file exists to avoid waste of compilation.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_19-15-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7850467289719626
  episode_reward_mean: -0.018646247521460445
  episode_reward_min: -6.865168539325842
  episodes_this_iter: 500
  episodes_total: 500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 2069.53
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 1.927067518234253
        entropy_coeff: 0.0
        kl: 0.019640980288386345
        model: {}
        policy_loss: -0.06115579232573509
        total_loss: 0.31542083621025085
        vf_explained_var: 0.3076168894767761
        vf_loss: 0.3726484179496765
    load_time_ms: 55.976
    num_steps_sampled: 500
    num_steps_trained: 500
    sample_time_ms: 460087.706
    update_time_ms: 542.461
  iterations_since_restore: 1
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.186232980332827
    ram_util_percent: 13.059455370650529
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 904.7993219303278
    mean_inference_ms: 1.9004635230271878
    mean_processing_ms: 1.42840663354078
  time_since_restore: 462.80569434165955
  time_this_iter_s: 462.80569434165955
  time_total_s: 462.80569434165955
  timestamp: 1639268141
  timesteps_since_restore: 500
  timesteps_this_iter: 500
  timesteps_total: 500
  training_iteration: 1
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+------------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |     reward |
|-------------------+----------+--------------------+--------+------------------+------+------------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |      1 |          462.806 |  500 | -0.0186462 |
+-------------------+----------+--------------------+--------+------------------+------+------------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_19-23-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.768595041322314
  episode_reward_mean: -0.022121448026349383
  episode_reward_min: -3.5
  episodes_this_iter: 500
  episodes_total: 1000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1894.095
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 1.8802964687347412
        entropy_coeff: 0.0
        kl: 0.021953659132122993
        model: {}
        policy_loss: -0.09396832436323166
        total_loss: 0.12864819169044495
        vf_explained_var: 0.2645898759365082
        vf_loss: 0.21822577714920044
    load_time_ms: 29.201
    num_steps_sampled: 1000
    num_steps_trained: 1000
    sample_time_ms: 451163.978
    update_time_ms: 273.885
  iterations_since_restore: 2
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.177567140600312
    ram_util_percent: 13.30268562401264
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 892.9638140923254
    mean_inference_ms: 1.8274695961387242
    mean_processing_ms: 1.4124971765142817
  time_since_restore: 906.7806532382965
  time_this_iter_s: 443.97495889663696
  time_total_s: 906.7806532382965
  timestamp: 1639268585
  timesteps_since_restore: 1000
  timesteps_this_iter: 500
  timesteps_total: 1000
  training_iteration: 2
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+------------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |     reward |
|-------------------+----------+--------------------+--------+------------------+------+------------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |      2 |          906.781 | 1000 | -0.0221214 |
+-------------------+----------+--------------------+--------+------------------+------+------------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_19-30-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.771117166212534
  episode_reward_mean: 0.009098799966667508
  episode_reward_min: -6.081081081081081
  episodes_this_iter: 500
  episodes_total: 1500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1807.746
    learner:
      default_policy:
        cur_kl_coeff: 0.30000001192092896
        cur_lr: 4.999999873689376e-05
        entropy: 1.8144644498825073
        entropy_coeff: 0.0
        kl: 0.021108917891979218
        model: {}
        policy_loss: -0.09078994393348694
        total_loss: 0.13616271317005157
        vf_explained_var: 0.2779983580112457
        vf_loss: 0.22061997652053833
    load_time_ms: 20.212
    num_steps_sampled: 1500
    num_steps_trained: 1500
    sample_time_ms: 445865.439
    update_time_ms: 184.112
  iterations_since_restore: 3
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.328846153846156
    ram_util_percent: 13.363942307692309
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 884.3364328006994
    mean_inference_ms: 1.8208995808926043
    mean_processing_ms: 1.4219987718047178
  time_since_restore: 1343.6995174884796
  time_this_iter_s: 436.9188642501831
  time_total_s: 1343.6995174884796
  timestamp: 1639269022
  timesteps_since_restore: 1500
  timesteps_this_iter: 500
  timesteps_total: 1500
  training_iteration: 3
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+-----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |    reward |
|-------------------+----------+--------------------+--------+------------------+------+-----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |      3 |           1343.7 | 1500 | 0.0090988 |
+-------------------+----------+--------------------+--------+------------------+------+-----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_19-37-36
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7774725274725275
  episode_reward_mean: 0.07785624219378792
  episode_reward_min: -6.129032258064516
  episodes_this_iter: 500
  episodes_total: 2000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1749.861
    learner:
      default_policy:
        cur_kl_coeff: 0.44999998807907104
        cur_lr: 4.999999873689376e-05
        entropy: 1.7608953714370728
        entropy_coeff: 0.0
        kl: 0.014062013477087021
        model: {}
        policy_loss: -0.07218217104673386
        total_loss: 0.06571467220783234
        vf_explained_var: 0.4081524908542633
        vf_loss: 0.13156892359256744
    load_time_ms: 15.676
    num_steps_sampled: 2000
    num_steps_trained: 2000
    sample_time_ms: 442617.559
    update_time_ms: 139.263
  iterations_since_restore: 4
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.240967741935483
    ram_util_percent: 13.378387096774194
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 878.8379589835744
    mean_inference_ms: 1.8116671225239431
    mean_processing_ms: 1.4189544288829707
  time_since_restore: 1778.1648216247559
  time_this_iter_s: 434.46530413627625
  time_total_s: 1778.1648216247559
  timestamp: 1639269456
  timesteps_since_restore: 2000
  timesteps_this_iter: 500
  timesteps_total: 2000
  training_iteration: 4
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+-----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |    reward |
|-------------------+----------+--------------------+--------+------------------+------+-----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |      4 |          1778.16 | 2000 | 0.0778562 |
+-------------------+----------+--------------------+--------+------------------+------+-----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_19-44-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7664429530201342
  episode_reward_mean: 0.025430146497522746
  episode_reward_min: -6.550561797752809
  episodes_this_iter: 500
  episodes_total: 2500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1751.152
    learner:
      default_policy:
        cur_kl_coeff: 0.44999998807907104
        cur_lr: 4.999999873689376e-05
        entropy: 1.7015182971954346
        entropy_coeff: 0.0
        kl: 0.007733810693025589
        model: {}
        policy_loss: -0.05707657337188721
        total_loss: 0.35747405886650085
        vf_explained_var: 0.028551988303661346
        vf_loss: 0.41107040643692017
    load_time_ms: 12.992
    num_steps_sampled: 2500
    num_steps_trained: 2500
    sample_time_ms: 439354.294
    update_time_ms: 112.291
  iterations_since_restore: 5
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.263442622950818
    ram_util_percent: 13.419508196721313
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 872.9042771433601
    mean_inference_ms: 1.8062880400513135
    mean_processing_ms: 1.4231523386434
  time_since_restore: 2206.2378313541412
  time_this_iter_s: 428.0730097293854
  time_total_s: 2206.2378313541412
  timestamp: 1639269884
  timesteps_since_restore: 2500
  timesteps_this_iter: 500
  timesteps_total: 2500
  training_iteration: 5
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+-----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |    reward |
|-------------------+----------+--------------------+--------+------------------+------+-----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |      5 |          2206.24 | 2500 | 0.0254301 |
+-------------------+----------+--------------------+--------+------------------+------+-----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_19-51-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7804878048780488
  episode_reward_mean: 0.08379219576096485
  episode_reward_min: -6.098958333333333
  episodes_this_iter: 500
  episodes_total: 3000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1737.571
    learner:
      default_policy:
        cur_kl_coeff: 0.44999998807907104
        cur_lr: 4.999999873689376e-05
        entropy: 1.6426723003387451
        entropy_coeff: 0.0
        kl: 0.010433588176965714
        model: {}
        policy_loss: -0.06553903222084045
        total_loss: 0.09612658619880676
        vf_explained_var: 0.3116808235645294
        vf_loss: 0.15697048604488373
    load_time_ms: 11.178
    num_steps_sampled: 3000
    num_steps_trained: 3000
    sample_time_ms: 434892.531
    update_time_ms: 94.295
  iterations_since_restore: 6
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.132487309644668
    ram_util_percent: 13.449746192893404
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 864.377254964669
    mean_inference_ms: 1.8014766422361983
    mean_processing_ms: 1.4256978185921265
  time_since_restore: 2620.505772829056
  time_this_iter_s: 414.26794147491455
  time_total_s: 2620.505772829056
  timestamp: 1639270299
  timesteps_since_restore: 3000
  timesteps_this_iter: 500
  timesteps_total: 3000
  training_iteration: 6
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+-----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |    reward |
|-------------------+----------+--------------------+--------+------------------+------+-----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |      6 |          2620.51 | 3000 | 0.0837922 |
+-------------------+----------+--------------------+--------+------------------+------+-----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_19-58-29
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7747183979974969
  episode_reward_mean: 0.15097967771950274
  episode_reward_min: -2.8978494623655915
  episodes_this_iter: 500
  episodes_total: 3500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1742.358
    learner:
      default_policy:
        cur_kl_coeff: 0.44999998807907104
        cur_lr: 4.999999873689376e-05
        entropy: 1.6233853101730347
        entropy_coeff: 0.0
        kl: 0.0098186694085598
        model: {}
        policy_loss: -0.052838049829006195
        total_loss: 0.03316037729382515
        vf_explained_var: 0.5735808610916138
        vf_loss: 0.0815800279378891
    load_time_ms: 9.874
    num_steps_sampled: 3500
    num_steps_trained: 3500
    sample_time_ms: 431064.447
    update_time_ms: 81.366
  iterations_since_restore: 7
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.133846153846152
    ram_util_percent: 13.429401709401711
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 857.0058549414085
    mean_inference_ms: 1.7999528102008524
    mean_processing_ms: 1.424726708484901
  time_since_restore: 3030.3883028030396
  time_this_iter_s: 409.88252997398376
  time_total_s: 3030.3883028030396
  timestamp: 1639270709
  timesteps_since_restore: 3500
  timesteps_this_iter: 500
  timesteps_total: 3500
  training_iteration: 7
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |      7 |          3030.39 | 3500 |  0.15098 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_20-05-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.782608695652174
  episode_reward_mean: 0.1404489760798395
  episode_reward_min: -2.8304093567251463
  episodes_this_iter: 500
  episodes_total: 4000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1716.216
    learner:
      default_policy:
        cur_kl_coeff: 0.44999998807907104
        cur_lr: 4.999999873689376e-05
        entropy: 1.5542412996292114
        entropy_coeff: 0.0
        kl: 0.010257127694785595
        model: {}
        policy_loss: -0.056905001401901245
        total_loss: 0.0018799686804413795
        vf_explained_var: 0.5823943614959717
        vf_loss: 0.05416926369071007
    load_time_ms: 8.899
    num_steps_sampled: 4000
    num_steps_trained: 4000
    sample_time_ms: 428412.326
    update_time_ms: 71.784
  iterations_since_restore: 8
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.190119250425893
    ram_util_percent: 13.436456558773425
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 851.9155790852893
    mean_inference_ms: 1.7971875696770996
    mean_processing_ms: 1.4245975497245076
  time_since_restore: 3441.7842020988464
  time_this_iter_s: 411.3958992958069
  time_total_s: 3441.7842020988464
  timestamp: 1639271120
  timesteps_since_restore: 4000
  timesteps_this_iter: 500
  timesteps_total: 4000
  training_iteration: 8
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |      8 |          3441.78 | 4000 | 0.140449 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_20-12-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7621951219512195
  episode_reward_mean: 0.10220158483455442
  episode_reward_min: -6.163841807909605
  episodes_this_iter: 500
  episodes_total: 4500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1706.357
    learner:
      default_policy:
        cur_kl_coeff: 0.44999998807907104
        cur_lr: 4.999999873689376e-05
        entropy: 1.508211612701416
        entropy_coeff: 0.0
        kl: 0.0058978283777832985
        model: {}
        policy_loss: -0.04130682349205017
        total_loss: 0.121159628033638
        vf_explained_var: 0.4341531991958618
        vf_loss: 0.15981243550777435
    load_time_ms: 8.149
    num_steps_sampled: 4500
    num_steps_trained: 4500
    sample_time_ms: 428165.012
    update_time_ms: 64.458
  iterations_since_restore: 9
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.270540098199671
    ram_util_percent: 13.476432078559741
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 851.5873697433859
    mean_inference_ms: 1.7949920366986862
    mean_processing_ms: 1.4232245320030068
  time_since_restore: 3869.614267349243
  time_this_iter_s: 427.83006525039673
  time_total_s: 3869.614267349243
  timestamp: 1639271548
  timesteps_since_restore: 4500
  timesteps_this_iter: 500
  timesteps_total: 4500
  training_iteration: 9
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |      9 |          3869.61 | 4500 | 0.102202 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_20-19-19
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7670157068062827
  episode_reward_mean: 0.11684799782475389
  episode_reward_min: -6.066666666666666
  episodes_this_iter: 500
  episodes_total: 5000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1697.614
    learner:
      default_policy:
        cur_kl_coeff: 0.44999998807907104
        cur_lr: 4.999999873689376e-05
        entropy: 1.4428106546401978
        entropy_coeff: 0.0
        kl: 0.009116191416978836
        model: {}
        policy_loss: -0.054416999220848083
        total_loss: 0.047554269433021545
        vf_explained_var: 0.44434428215026855
        vf_loss: 0.09786898642778397
    load_time_ms: 7.584
    num_steps_sampled: 5000
    num_steps_trained: 5000
    sample_time_ms: 426293.575
    update_time_ms: 58.432
  iterations_since_restore: 10
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.037713310580205
    ram_util_percent: 13.500682593856657
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 847.9780378972881
    mean_inference_ms: 1.792835583807921
    mean_processing_ms: 1.4225137016816605
  time_since_restore: 4280.6994972229
  time_this_iter_s: 411.0852298736572
  time_total_s: 4280.6994972229
  timestamp: 1639271959
  timesteps_since_restore: 5000
  timesteps_this_iter: 500
  timesteps_total: 5000
  training_iteration: 10
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     10 |           4280.7 | 5000 | 0.116848 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_20-26-19
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7780821917808219
  episode_reward_mean: 0.15150856547238628
  episode_reward_min: -6.342541436464089
  episodes_this_iter: 500
  episodes_total: 5500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1666.795
    learner:
      default_policy:
        cur_kl_coeff: 0.44999998807907104
        cur_lr: 4.999999873689376e-05
        entropy: 1.4298266172409058
        entropy_coeff: 0.0
        kl: 0.00452588452026248
        model: {}
        policy_loss: -0.031566422432661057
        total_loss: 0.06732804328203201
        vf_explained_var: 0.5248869061470032
        vf_loss: 0.09685781598091125
    load_time_ms: 2.197
    num_steps_sampled: 5500
    num_steps_trained: 5500
    sample_time_ms: 422056.366
    update_time_ms: 4.604
  iterations_since_restore: 11
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.189649415692822
    ram_util_percent: 13.508681135225377
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 846.5241095604105
    mean_inference_ms: 1.7936366663220096
    mean_processing_ms: 1.4226760371904592
  time_since_restore: 4700.191375017166
  time_this_iter_s: 419.49187779426575
  time_total_s: 4700.191375017166
  timestamp: 1639272379
  timesteps_since_restore: 5500
  timesteps_this_iter: 500
  timesteps_total: 5500
  training_iteration: 11
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     11 |          4700.19 | 5500 | 0.151509 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_20-33-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8307984790874525
  episode_reward_mean: 0.1637783461331179
  episode_reward_min: -2.1415929203539825
  episodes_this_iter: 500
  episodes_total: 6000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1656.099
    learner:
      default_policy:
        cur_kl_coeff: 0.22499999403953552
        cur_lr: 4.999999873689376e-05
        entropy: 1.3322699069976807
        entropy_coeff: 0.0
        kl: 0.015707239508628845
        model: {}
        policy_loss: -0.04805320128798485
        total_loss: -0.009478759951889515
        vf_explained_var: 0.6281591057777405
        vf_loss: 0.03504031524062157
    load_time_ms: 2.229
    num_steps_sampled: 6000
    num_steps_trained: 6000
    sample_time_ms: 418613.379
    update_time_ms: 4.534
  iterations_since_restore: 12
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.10513698630137
    ram_util_percent: 13.48458904109589
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 843.6636544132091
    mean_inference_ms: 1.7925822482548488
    mean_processing_ms: 1.4230430255312068
  time_since_restore: 5109.62996506691
  time_this_iter_s: 409.43859004974365
  time_total_s: 5109.62996506691
  timestamp: 1639272788
  timesteps_since_restore: 6000
  timesteps_this_iter: 500
  timesteps_total: 6000
  training_iteration: 12
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     12 |          5109.63 | 6000 | 0.163778 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_20-40-02
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7897435897435897
  episode_reward_mean: 0.17568119014623246
  episode_reward_min: -2.0317460317460316
  episodes_this_iter: 500
  episodes_total: 6500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1661.817
    learner:
      default_policy:
        cur_kl_coeff: 0.22499999403953552
        cur_lr: 4.999999873689376e-05
        entropy: 1.222891092300415
        entropy_coeff: 0.0
        kl: 0.015622916631400585
        model: {}
        policy_loss: -0.03504147008061409
        total_loss: -0.004123916383832693
        vf_explained_var: 0.66142737865448
        vf_loss: 0.027402402833104134
    load_time_ms: 2.219
    num_steps_sampled: 6500
    num_steps_trained: 6500
    sample_time_ms: 416299.831
    update_time_ms: 4.607
  iterations_since_restore: 13
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.023559322033897
    ram_util_percent: 13.495932203389831
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 841.9087320048152
    mean_inference_ms: 1.7923011979292478
    mean_processing_ms: 1.4216973220104623
  time_since_restore: 5523.4707860946655
  time_this_iter_s: 413.84082102775574
  time_total_s: 5523.4707860946655
  timestamp: 1639273202
  timesteps_since_restore: 6500
  timesteps_this_iter: 500
  timesteps_total: 6500
  training_iteration: 13
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     13 |          5523.47 | 6500 | 0.175681 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_20-46-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.775623268698061
  episode_reward_mean: 0.16773784057096447
  episode_reward_min: -1.505
  episodes_this_iter: 500
  episodes_total: 7000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1660.312
    learner:
      default_policy:
        cur_kl_coeff: 0.22499999403953552
        cur_lr: 4.999999873689376e-05
        entropy: 1.2317825555801392
        entropy_coeff: 0.0
        kl: 0.010351103730499744
        model: {}
        policy_loss: -0.037908464670181274
        total_loss: -0.012012486346065998
        vf_explained_var: 0.7009037137031555
        vf_loss: 0.02356698364019394
    load_time_ms: 2.224
    num_steps_sampled: 7000
    num_steps_trained: 7000
    sample_time_ms: 413845.356
    update_time_ms: 4.601
  iterations_since_restore: 14
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.981025641025642
    ram_util_percent: 13.521025641025641
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 839.8589526665345
    mean_inference_ms: 1.7931683712934638
    mean_processing_ms: 1.421728469255804
  time_since_restore: 5933.376361608505
  time_this_iter_s: 409.9055755138397
  time_total_s: 5933.376361608505
  timestamp: 1639273612
  timesteps_since_restore: 7000
  timesteps_this_iter: 500
  timesteps_total: 7000
  training_iteration: 14
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     14 |          5933.38 | 7000 | 0.167738 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_20-53-27
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.764344262295082
  episode_reward_mean: 0.190191478957123
  episode_reward_min: -2.7747252747252746
  episodes_this_iter: 500
  episodes_total: 7500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1646.205
    learner:
      default_policy:
        cur_kl_coeff: 0.22499999403953552
        cur_lr: 4.999999873689376e-05
        entropy: 1.159296989440918
        entropy_coeff: 0.0
        kl: 0.011957738548517227
        model: {}
        policy_loss: -0.04491390287876129
        total_loss: -0.012085777707397938
        vf_explained_var: 0.7166687846183777
        vf_loss: 0.030137643218040466
    load_time_ms: 2.211
    num_steps_sampled: 7500
    num_steps_trained: 7500
    sample_time_ms: 410563.743
    update_time_ms: 4.633
  iterations_since_restore: 15
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.154078014184398
    ram_util_percent: 13.553014184397162
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 836.1042844281327
    mean_inference_ms: 1.7939646583194022
    mean_processing_ms: 1.4209943427322484
  time_since_restore: 6328.492531299591
  time_this_iter_s: 395.1161696910858
  time_total_s: 6328.492531299591
  timestamp: 1639274007
  timesteps_since_restore: 7500
  timesteps_this_iter: 500
  timesteps_total: 7500
  training_iteration: 15
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     15 |          6328.49 | 7500 | 0.190191 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_20-59-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7850467289719626
  episode_reward_mean: 0.1716796729495649
  episode_reward_min: -1.5401459854014599
  episodes_this_iter: 500
  episodes_total: 8000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1641.899
    learner:
      default_policy:
        cur_kl_coeff: 0.22499999403953552
        cur_lr: 4.999999873689376e-05
        entropy: 1.1144455671310425
        entropy_coeff: 0.0
        kl: 0.011049428023397923
        model: {}
        policy_loss: -0.03624444454908371
        total_loss: -0.014597413130104542
        vf_explained_var: 0.6834905743598938
        vf_loss: 0.019160903990268707
    load_time_ms: 2.223
    num_steps_sampled: 8000
    num_steps_trained: 8000
    sample_time_ms: 407929.333
    update_time_ms: 4.81
  iterations_since_restore: 16
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.17757685352622
    ram_util_percent: 13.6126582278481
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 831.919341068866
    mean_inference_ms: 1.7906146531640819
    mean_processing_ms: 1.418700383284914
  time_since_restore: 6716.375485897064
  time_this_iter_s: 387.88295459747314
  time_total_s: 6716.375485897064
  timestamp: 1639274395
  timesteps_since_restore: 8000
  timesteps_this_iter: 500
  timesteps_total: 8000
  training_iteration: 16
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     16 |          6716.38 | 8000 |  0.17168 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_21-05-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.768762677484787
  episode_reward_mean: 0.17296127545361603
  episode_reward_min: -1.3130841121495327
  episodes_this_iter: 500
  episodes_total: 8500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1618.808
    learner:
      default_policy:
        cur_kl_coeff: 0.22499999403953552
        cur_lr: 4.999999873689376e-05
        entropy: 1.089645266532898
        entropy_coeff: 0.0
        kl: 0.014362870715558529
        model: {}
        policy_loss: -0.039659351110458374
        total_loss: -0.018318235874176025
        vf_explained_var: 0.7536548376083374
        vf_loss: 0.01810946874320507
    load_time_ms: 2.23
    num_steps_sampled: 8500
    num_steps_trained: 8500
    sample_time_ms: 402938.101
    update_time_ms: 4.875
  iterations_since_restore: 17
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.250389105058366
    ram_util_percent: 13.565564202334627
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 824.9317124203754
    mean_inference_ms: 1.7849117878562855
    mean_processing_ms: 1.413991066753521
  time_since_restore: 7076.114523649216
  time_this_iter_s: 359.7390377521515
  time_total_s: 7076.114523649216
  timestamp: 1639274755
  timesteps_since_restore: 8500
  timesteps_this_iter: 500
  timesteps_total: 8500
  training_iteration: 17
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     17 |          7076.11 | 8500 | 0.172961 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_21-11-33
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7747252747252747
  episode_reward_mean: 0.14085847962281026
  episode_reward_min: -2.50531914893617
  episodes_this_iter: 500
  episodes_total: 9000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1635.844
    learner:
      default_policy:
        cur_kl_coeff: 0.22499999403953552
        cur_lr: 4.999999873689376e-05
        entropy: 1.0283983945846558
        entropy_coeff: 0.0
        kl: 0.008251811377704144
        model: {}
        policy_loss: -0.026189317926764488
        total_loss: 0.01101470086723566
        vf_explained_var: 0.5453583002090454
        vf_loss: 0.035347357392311096
    load_time_ms: 2.219
    num_steps_sampled: 9000
    num_steps_trained: 9000
    sample_time_ms: 395647.103
    update_time_ms: 4.915
  iterations_since_restore: 18
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.365217391304347
    ram_util_percent: 13.561076604554865
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 816.3656238555484
    mean_inference_ms: 1.7764014464565785
    mean_processing_ms: 1.4078239906683137
  time_since_restore: 7414.7712297439575
  time_this_iter_s: 338.6567060947418
  time_total_s: 7414.7712297439575
  timestamp: 1639275093
  timesteps_since_restore: 9000
  timesteps_this_iter: 500
  timesteps_total: 9000
  training_iteration: 18
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     18 |          7414.77 | 9000 | 0.140858 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_21-17-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.779291553133515
  episode_reward_mean: 0.13810100323267824
  episode_reward_min: -6.0520231213872835
  episodes_this_iter: 500
  episodes_total: 9500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1644.128
    learner:
      default_policy:
        cur_kl_coeff: 0.22499999403953552
        cur_lr: 4.999999873689376e-05
        entropy: 1.02987539768219
        entropy_coeff: 0.0
        kl: 0.003489755094051361
        model: {}
        policy_loss: -0.02600160986185074
        total_loss: 0.0734068900346756
        vf_explained_var: 0.5769037008285522
        vf_loss: 0.09862331300973892
    load_time_ms: 2.215
    num_steps_sampled: 9500
    num_steps_trained: 9500
    sample_time_ms: 386388.533
    update_time_ms: 4.908
  iterations_since_restore: 19
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.034309623430962
    ram_util_percent: 13.532845188284519
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 808.3493850843716
    mean_inference_ms: 1.769605278655135
    mean_processing_ms: 1.4019368535756385
  time_since_restore: 7750.098673582077
  time_this_iter_s: 335.3274438381195
  time_total_s: 7750.098673582077
  timestamp: 1639275429
  timesteps_since_restore: 9500
  timesteps_this_iter: 500
  timesteps_total: 9500
  training_iteration: 19
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     19 |           7750.1 | 9500 | 0.138101 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_21-22-36
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7747252747252747
  episode_reward_mean: 0.16005095275867212
  episode_reward_min: -2.82183908045977
  episodes_this_iter: 500
  episodes_total: 10000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1635.192
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.9672396779060364
        entropy_coeff: 0.0
        kl: 0.01529355626553297
        model: {}
        policy_loss: -0.037691015750169754
        total_loss: -0.0013784675393253565
        vf_explained_var: 0.6345242261886597
        vf_loss: 0.03459202125668526
    load_time_ms: 2.183
    num_steps_sampled: 10000
    num_steps_trained: 10000
    sample_time_ms: 378001.517
    update_time_ms: 5.064
  iterations_since_restore: 20
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.135546038543898
    ram_util_percent: 13.558886509635974
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 800.3343265422068
    mean_inference_ms: 1.762472597459187
    mean_processing_ms: 1.396163989634362
  time_since_restore: 8077.225413799286
  time_this_iter_s: 327.12674021720886
  time_total_s: 8077.225413799286
  timestamp: 1639275756
  timesteps_since_restore: 10000
  timesteps_this_iter: 500
  timesteps_total: 10000
  training_iteration: 20
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     20 |          8077.23 | 10000 | 0.160051 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_21-27-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7692307692307693
  episode_reward_mean: 0.16081254968944877
  episode_reward_min: -1.0336538461538463
  episodes_this_iter: 500
  episodes_total: 10500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1622.033
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.9486595392227173
        entropy_coeff: 0.0
        kl: 0.01628538779914379
        model: {}
        policy_loss: -0.03222385793924332
        total_loss: -0.0114443926140666
        vf_explained_var: 0.7039318680763245
        vf_loss: 0.018947357311844826
    load_time_ms: 2.175
    num_steps_sampled: 10500
    num_steps_trained: 10500
    sample_time_ms: 367738.009
    update_time_ms: 5.138
  iterations_since_restore: 21
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.074115044247788
    ram_util_percent: 13.580973451327434
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 792.0837600325848
    mean_inference_ms: 1.756140759145404
    mean_processing_ms: 1.3895807646760576
  time_since_restore: 8393.951754570007
  time_this_iter_s: 316.72634077072144
  time_total_s: 8393.951754570007
  timestamp: 1639276073
  timesteps_since_restore: 10500
  timesteps_this_iter: 500
  timesteps_total: 10500
  training_iteration: 21
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     21 |          8393.95 | 10500 | 0.160813 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_21-33-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7816711590296496
  episode_reward_mean: 0.17682724982010198
  episode_reward_min: -1.0579710144927537
  episodes_this_iter: 500
  episodes_total: 11000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1618.011
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.8828858733177185
        entropy_coeff: 0.0
        kl: 0.019189123064279556
        model: {}
        policy_loss: -0.03928416967391968
        total_loss: -0.022189006209373474
        vf_explained_var: 0.7257513403892517
        vf_loss: 0.014936384744942188
    load_time_ms: 2.129
    num_steps_sampled: 11000
    num_steps_trained: 11000
    sample_time_ms: 357629.701
    update_time_ms: 5.131
  iterations_since_restore: 22
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.077727272727275
    ram_util_percent: 13.542272727272728
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 783.8254467312524
    mean_inference_ms: 1.7495305091074929
    mean_processing_ms: 1.3831386500277874
  time_since_restore: 8702.265862941742
  time_this_iter_s: 308.3141083717346
  time_total_s: 8702.265862941742
  timestamp: 1639276381
  timesteps_since_restore: 11000
  timesteps_this_iter: 500
  timesteps_total: 11000
  training_iteration: 22
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     22 |          8702.27 | 11000 | 0.176827 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_21-37-35
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7793594306049823
  episode_reward_mean: 0.18686632677021073
  episode_reward_min: -2.8
  episodes_this_iter: 500
  episodes_total: 11500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1621.72
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.779573380947113
        entropy_coeff: 0.0
        kl: 0.016157887876033783
        model: {}
        policy_loss: -0.035638272762298584
        total_loss: -0.0027605360373854637
        vf_explained_var: 0.7044679522514343
        vf_loss: 0.03105997107923031
    load_time_ms: 2.132
    num_steps_sampled: 11500
    num_steps_trained: 11500
    sample_time_ms: 343641.119
    update_time_ms: 5.1
  iterations_since_restore: 23
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.131969309462914
    ram_util_percent: 13.550127877237848
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 773.2893471593036
    mean_inference_ms: 1.742151589738153
    mean_processing_ms: 1.3763860830710506
  time_since_restore: 8976.257835388184
  time_this_iter_s: 273.99197244644165
  time_total_s: 8976.257835388184
  timestamp: 1639276655
  timesteps_since_restore: 11500
  timesteps_this_iter: 500
  timesteps_total: 11500
  training_iteration: 23
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     23 |          8976.26 | 11500 | 0.186866 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_21-42-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7675962815405046
  episode_reward_mean: 0.1827442442966893
  episode_reward_min: -0.4431818181818182
  episodes_this_iter: 500
  episodes_total: 12000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1624.149
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.7601956129074097
        entropy_coeff: 0.0
        kl: 0.020920397713780403
        model: {}
        policy_loss: -0.032425858080387115
        total_loss: -0.019643845036625862
        vf_explained_var: 0.7914734482765198
        vf_loss: 0.01042846217751503
    load_time_ms: 2.157
    num_steps_sampled: 12000
    num_steps_trained: 12000
    sample_time_ms: 332321.116
    update_time_ms: 5.188
  iterations_since_restore: 24
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.142316784869976
    ram_util_percent: 13.56430260047281
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 765.5365478594138
    mean_inference_ms: 1.735912999573593
    mean_processing_ms: 1.3709370866039179
  time_since_restore: 9272.98880815506
  time_this_iter_s: 296.7309727668762
  time_total_s: 9272.98880815506
  timestamp: 1639276952
  timesteps_since_restore: 12000
  timesteps_this_iter: 500
  timesteps_total: 12000
  training_iteration: 24
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     24 |          9272.99 | 12000 | 0.182744 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_21-47-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.763268156424581
  episode_reward_mean: 0.1610874233634513
  episode_reward_min: -1.964071856287425
  episodes_this_iter: 500
  episodes_total: 12500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1619.049
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.7513807415962219
        entropy_coeff: 0.0
        kl: 0.01293052826076746
        model: {}
        policy_loss: -0.03633836284279823
        total_loss: -0.013039758428931236
        vf_explained_var: 0.7293403744697571
        vf_loss: 0.021116580814123154
    load_time_ms: 2.151
    num_steps_sampled: 12500
    num_steps_trained: 12500
    sample_time_ms: 322211.561
    update_time_ms: 5.178
  iterations_since_restore: 25
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.24238095238095
    ram_util_percent: 13.563571428571427
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 758.1855613378016
    mean_inference_ms: 1.7296889907559838
    mean_processing_ms: 1.3655939156337218
  time_since_restore: 9566.957491636276
  time_this_iter_s: 293.96868348121643
  time_total_s: 9566.957491636276
  timestamp: 1639277246
  timesteps_since_restore: 12500
  timesteps_this_iter: 500
  timesteps_total: 12500
  training_iteration: 25
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     25 |          9566.96 | 12500 | 0.161087 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_21-52-25
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8
  episode_reward_mean: 0.16711826082503514
  episode_reward_min: -2.7953216374269005
  episodes_this_iter: 500
  episodes_total: 13000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1617.078
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.7656598091125488
        entropy_coeff: 0.0
        kl: 0.0062506599351763725
        model: {}
        policy_loss: -0.01884743943810463
        total_loss: 0.019947394728660583
        vf_explained_var: 0.6589376926422119
        vf_loss: 0.037740033119916916
    load_time_ms: 2.178
    num_steps_sampled: 13000
    num_steps_trained: 13000
    sample_time_ms: 313329.172
    update_time_ms: 5.09
  iterations_since_restore: 26
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.259953161592506
    ram_util_percent: 13.627166276346603
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 751.7867482595191
    mean_inference_ms: 1.7238949163263924
    mean_processing_ms: 1.3605642938566216
  time_since_restore: 9865.995929956436
  time_this_iter_s: 299.0384383201599
  time_total_s: 9865.995929956436
  timestamp: 1639277545
  timesteps_since_restore: 13000
  timesteps_this_iter: 500
  timesteps_total: 13000
  training_iteration: 26
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     26 |             9866 | 13000 | 0.167118 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_21-57-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7780821917808219
  episode_reward_mean: 0.17636514707373946
  episode_reward_min: -2.745664739884393
  episodes_this_iter: 500
  episodes_total: 13500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1648.327
    learner:
      default_policy:
        cur_kl_coeff: 0.16875000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.724951982498169
        entropy_coeff: 0.0
        kl: 0.004945625551044941
        model: {}
        policy_loss: -0.02374248579144478
        total_loss: 0.005816012620925903
        vf_explained_var: 0.7219816446304321
        vf_loss: 0.028723927214741707
    load_time_ms: 2.186
    num_steps_sampled: 13500
    num_steps_trained: 13500
    sample_time_ms: 306555.8
    update_time_ms: 5.21
  iterations_since_restore: 27
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.000719424460431
    ram_util_percent: 13.558273381294962
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 745.3466340459089
    mean_inference_ms: 1.718563995010967
    mean_processing_ms: 1.3552201552688081
  time_since_restore: 10158.315214633942
  time_this_iter_s: 292.3192846775055
  time_total_s: 10158.315214633942
  timestamp: 1639277838
  timesteps_since_restore: 13500
  timesteps_this_iter: 500
  timesteps_total: 13500
  training_iteration: 27
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     27 |          10158.3 | 13500 | 0.176365 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-02-13
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8279467680608364
  episode_reward_mean: 0.2049044069379223
  episode_reward_min: -0.786096256684492
  episodes_this_iter: 500
  episodes_total: 14000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1655.36
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.6605445742607117
        entropy_coeff: 0.0
        kl: 0.013238477520644665
        model: {}
        policy_loss: -0.02903974987566471
        total_loss: -0.01391996257007122
        vf_explained_var: 0.7433149814605713
        vf_loss: 0.014002788811922073
    load_time_ms: 2.208
    num_steps_sampled: 14000
    num_steps_trained: 14000
    sample_time_ms: 302229.49
    update_time_ms: 5.255
  iterations_since_restore: 28
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.157957244655583
    ram_util_percent: 13.573871733966744
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 739.5957278469684
    mean_inference_ms: 1.7140228214812925
    mean_processing_ms: 1.3508305073840199
  time_since_restore: 10453.7797935009
  time_this_iter_s: 295.4645788669586
  time_total_s: 10453.7797935009
  timestamp: 1639278133
  timesteps_since_restore: 14000
  timesteps_this_iter: 500
  timesteps_total: 14000
  training_iteration: 28
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     28 |          10453.8 | 14000 | 0.204904 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-06-38
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7653478854024557
  episode_reward_mean: 0.17989978006482737
  episode_reward_min: -6.181286549707602
  episodes_this_iter: 500
  episodes_total: 14500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1657.73
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.5888057947158813
        entropy_coeff: 0.0
        kl: 0.004929727409034967
        model: {}
        policy_loss: -0.020997637882828712
        total_loss: 0.06233075261116028
        vf_explained_var: 0.648298442363739
        vf_loss: 0.08291244506835938
    load_time_ms: 2.219
    num_steps_sampled: 14500
    num_steps_trained: 14500
    sample_time_ms: 295204.44
    update_time_ms: 5.317
  iterations_since_restore: 29
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.308443271767809
    ram_util_percent: 13.583377308707123
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 732.1544576288051
    mean_inference_ms: 1.7073304560601927
    mean_processing_ms: 1.3452707574364398
  time_since_restore: 10718.881177425385
  time_this_iter_s: 265.10138392448425
  time_total_s: 10718.881177425385
  timestamp: 1639278398
  timesteps_since_restore: 14500
  timesteps_this_iter: 500
  timesteps_total: 14500
  training_iteration: 29
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     29 |          10718.9 | 14500 |   0.1799 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-11-07
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7645429362880887
  episode_reward_mean: 0.15991778366874518
  episode_reward_min: -2.68
  episodes_this_iter: 500
  episodes_total: 15000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1679.598
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.5946627855300903
        entropy_coeff: 0.0
        kl: 0.00741851981729269
        model: {}
        policy_loss: -0.030281251296401024
        total_loss: 0.007006920408457518
        vf_explained_var: 0.6509317755699158
        vf_loss: 0.0369752012193203
    load_time_ms: 2.23
    num_steps_sampled: 15000
    num_steps_trained: 15000
    sample_time_ms: 289338.07
    update_time_ms: 5.321
  iterations_since_restore: 30
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.264751958224542
    ram_util_percent: 13.60313315926893
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 725.4475424364562
    mean_inference_ms: 1.7006817948586956
    mean_processing_ms: 1.3399250975736547
  time_since_restore: 10987.56246304512
  time_this_iter_s: 268.6812856197357
  time_total_s: 10987.56246304512
  timestamp: 1639278667
  timesteps_since_restore: 15000
  timesteps_this_iter: 500
  timesteps_total: 15000
  training_iteration: 30
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     30 |          10987.6 | 15000 | 0.159918 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-15-23
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7628458498023716
  episode_reward_mean: 0.187448144358336
  episode_reward_min: -0.5714285714285714
  episodes_this_iter: 500
  episodes_total: 15500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1698.428
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.5399948358535767
        entropy_coeff: 0.0
        kl: 0.01039990782737732
        model: {}
        policy_loss: -0.036945998668670654
        total_loss: -0.02165529504418373
        vf_explained_var: 0.7397720217704773
        vf_loss: 0.014851963147521019
    load_time_ms: 2.247
    num_steps_sampled: 15500
    num_steps_trained: 15500
    sample_time_ms: 283203.455
    update_time_ms: 5.384
  iterations_since_restore: 31
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.327123287671231
    ram_util_percent: 13.59835616438356
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 718.3242972824131
    mean_inference_ms: 1.6937479189338778
    mean_processing_ms: 1.334196413326983
  time_since_restore: 11243.131446123123
  time_this_iter_s: 255.56898307800293
  time_total_s: 11243.131446123123
  timestamp: 1639278923
  timesteps_since_restore: 15500
  timesteps_this_iter: 500
  timesteps_total: 15500
  training_iteration: 31
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     31 |          11243.1 | 15500 | 0.187448 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-19-00
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7873831775700935
  episode_reward_mean: 0.19080915272797153
  episode_reward_min: -0.5698924731182796
  episodes_this_iter: 500
  episodes_total: 16000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1718.456
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.5612192749977112
        entropy_coeff: 0.0
        kl: 0.009207567200064659
        model: {}
        policy_loss: -0.02112901210784912
        total_loss: -0.005510603077709675
        vf_explained_var: 0.6573269367218018
        vf_loss: 0.015229962766170502
    load_time_ms: 2.211
    num_steps_sampled: 16000
    num_steps_trained: 16000
    sample_time_ms: 274051.37
    update_time_ms: 5.435
  iterations_since_restore: 32
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.314886731391587
    ram_util_percent: 13.598381877022652
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 709.2421169124852
    mean_inference_ms: 1.6851121057205574
    mean_processing_ms: 1.3272735478170112
  time_since_restore: 11460.125254392624
  time_this_iter_s: 216.99380826950073
  time_total_s: 11460.125254392624
  timestamp: 1639279140
  timesteps_since_restore: 16000
  timesteps_this_iter: 500
  timesteps_total: 16000
  training_iteration: 32
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     32 |          11460.1 | 16000 | 0.190809 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-22-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7747252747252747
  episode_reward_mean: 0.16810074212437506
  episode_reward_min: -0.989501312335958
  episodes_this_iter: 500
  episodes_total: 16500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1720.285
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.5499571561813354
        entropy_coeff: 0.0
        kl: 0.005348645616322756
        model: {}
        policy_loss: -0.02170444279909134
        total_loss: -0.007451380603015423
        vf_explained_var: 0.763241171836853
        vf_loss: 0.014027422294020653
    load_time_ms: 2.217
    num_steps_sampled: 16500
    num_steps_trained: 16500
    sample_time_ms: 266266.756
    update_time_ms: 5.551
  iterations_since_restore: 33
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.358571428571429
    ram_util_percent: 13.610714285714286
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 699.4509199490496
    mean_inference_ms: 1.6764415032169642
    mean_processing_ms: 1.320167365460517
  time_since_restore: 11656.29124379158
  time_this_iter_s: 196.1659893989563
  time_total_s: 11656.29124379158
  timestamp: 1639279336
  timesteps_since_restore: 16500
  timesteps_this_iter: 500
  timesteps_total: 16500
  training_iteration: 33
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     33 |          11656.3 | 16500 | 0.168101 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-25-33
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.779291553133515
  episode_reward_mean: 0.17481730824737154
  episode_reward_min: -1.0784313725490196
  episodes_this_iter: 500
  episodes_total: 17000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1734.27
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.5232893228530884
        entropy_coeff: 0.0
        kl: 0.010194960050284863
        model: {}
        policy_loss: -0.02039615623652935
        total_loss: -0.0026360268238931894
        vf_explained_var: 0.7249637842178345
        vf_loss: 0.017330026254057884
    load_time_ms: 2.225
    num_steps_sampled: 17000
    num_steps_trained: 17000
    sample_time_ms: 256255.622
    update_time_ms: 5.54
  iterations_since_restore: 34
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.385053380782917
    ram_util_percent: 13.587188612099645
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 690.2734838536987
    mean_inference_ms: 1.6679057415271747
    mean_processing_ms: 1.312408564504571
  time_since_restore: 11853.050775289536
  time_this_iter_s: 196.75953149795532
  time_total_s: 11853.050775289536
  timestamp: 1639279533
  timesteps_since_restore: 17000
  timesteps_this_iter: 500
  timesteps_total: 17000
  training_iteration: 34
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     34 |          11853.1 | 17000 | 0.174817 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-29-02
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7647058823529411
  episode_reward_mean: 0.15465997523092898
  episode_reward_min: -0.7935054121565362
  episodes_this_iter: 500
  episodes_total: 17500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1732.149
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.5093024373054504
        entropy_coeff: 0.0
        kl: 0.006789324805140495
        model: {}
        policy_loss: -0.022122910246253014
        total_loss: -0.00801541842520237
        vf_explained_var: 0.7062050700187683
        vf_loss: 0.0138210728764534
    load_time_ms: 2.256
    num_steps_sampled: 17500
    num_steps_trained: 17500
    sample_time_ms: 247752.608
    update_time_ms: 5.524
  iterations_since_restore: 35
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.445973154362415
    ram_util_percent: 13.628187919463086
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 682.3224528340854
    mean_inference_ms: 1.6616799137836307
    mean_processing_ms: 1.3062373330733297
  time_since_restore: 12061.968816757202
  time_this_iter_s: 208.91804146766663
  time_total_s: 12061.968816757202
  timestamp: 1639279742
  timesteps_since_restore: 17500
  timesteps_this_iter: 500
  timesteps_total: 17500
  training_iteration: 35
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     35 |            12062 | 17500 |  0.15466 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-32-54
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7747252747252747
  episode_reward_mean: 0.16447641996503448
  episode_reward_min: -0.971830985915493
  episodes_this_iter: 500
  episodes_total: 18000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1733.237
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.5125514268875122
        entropy_coeff: 0.0
        kl: 0.008851912803947926
        model: {}
        policy_loss: -0.02181091159582138
        total_loss: -0.004106500651687384
        vf_explained_var: 0.7172918915748596
        vf_loss: 0.017330976203083992
    load_time_ms: 2.219
    num_steps_sampled: 18000
    num_steps_trained: 18000
    sample_time_ms: 241066.493
    update_time_ms: 5.607
  iterations_since_restore: 36
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.533734939759038
    ram_util_percent: 13.67921686746988
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 676.098690464208
    mean_inference_ms: 1.6569043058771848
    mean_processing_ms: 1.3020700311986588
  time_since_restore: 12294.158757686615
  time_this_iter_s: 232.18994092941284
  time_total_s: 12294.158757686615
  timestamp: 1639279974
  timesteps_since_restore: 18000
  timesteps_this_iter: 500
  timesteps_total: 18000
  training_iteration: 36
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     36 |          12294.2 | 18000 | 0.164476 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-35-42
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7804878048780488
  episode_reward_mean: 0.17284315218322763
  episode_reward_min: -1.0336538461538463
  episodes_this_iter: 500
  episodes_total: 18500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1710.727
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.4822128713130951
        entropy_coeff: 0.0
        kl: 0.008743086829781532
        model: {}
        policy_loss: -0.022315019741654396
        total_loss: -0.010071280412375927
        vf_explained_var: 0.7855649590492249
        vf_loss: 0.01187489740550518
    load_time_ms: 2.2
    num_steps_sampled: 18500
    num_steps_trained: 18500
    sample_time_ms: 228609.422
    update_time_ms: 5.591
  iterations_since_restore: 37
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.551882845188285
    ram_util_percent: 13.597071129707112
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 666.7227469278758
    mean_inference_ms: 1.6484909280300994
    mean_processing_ms: 1.2951274284394543
  time_since_restore: 12461.681511163712
  time_this_iter_s: 167.52275347709656
  time_total_s: 12461.681511163712
  timestamp: 1639280142
  timesteps_since_restore: 18500
  timesteps_this_iter: 500
  timesteps_total: 18500
  training_iteration: 37
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     37 |          12461.7 | 18500 | 0.172843 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-37-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7935943060498221
  episode_reward_mean: 0.1930916154845439
  episode_reward_min: -1.0579710144927537
  episodes_this_iter: 500
  episodes_total: 19000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1693.598
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.527053713798523
        entropy_coeff: 0.0
        kl: 0.007698503322899342
        model: {}
        policy_loss: -0.017803575843572617
        total_loss: -0.0012554996646940708
        vf_explained_var: 0.7503941059112549
        vf_loss: 0.016223305836319923
    load_time_ms: 2.186
    num_steps_sampled: 19000
    num_steps_trained: 19000
    sample_time_ms: 212411.958
    update_time_ms: 5.512
  iterations_since_restore: 38
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.304736842105262
    ram_util_percent: 13.617368421052628
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 656.0436332296694
    mean_inference_ms: 1.6396092864113296
    mean_processing_ms: 1.2874035739652747
  time_since_restore: 12594.998993873596
  time_this_iter_s: 133.31748270988464
  time_total_s: 12594.998993873596
  timestamp: 1639280275
  timesteps_since_restore: 19000
  timesteps_this_iter: 500
  timesteps_total: 19000
  training_iteration: 38
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     38 |            12595 | 19000 | 0.193092 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-40-21
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7744565217391305
  episode_reward_mean: 0.19450136292205106
  episode_reward_min: -2.7314285714285713
  episodes_this_iter: 500
  episodes_total: 19500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1677.338
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.5136870741844177
        entropy_coeff: 0.0
        kl: 0.008001911453902721
        model: {}
        policy_loss: -0.02473548799753189
        total_loss: -0.0014198455028235912
        vf_explained_var: 0.7426461577415466
        vf_loss: 0.02297806181013584
    load_time_ms: 2.177
    num_steps_sampled: 19500
    num_steps_trained: 19500
    sample_time_ms: 200468.816
    update_time_ms: 5.371
  iterations_since_restore: 39
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.38701923076923
    ram_util_percent: 13.635576923076922
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 646.5385679183671
    mean_inference_ms: 1.6311143680778102
    mean_processing_ms: 1.2803009232339673
  time_since_restore: 12740.50503540039
  time_this_iter_s: 145.50604152679443
  time_total_s: 12740.50503540039
  timestamp: 1639280421
  timesteps_since_restore: 19500
  timesteps_this_iter: 500
  timesteps_total: 19500
  training_iteration: 39
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     39 |          12740.5 | 19500 | 0.194501 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-42-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7603143418467584
  episode_reward_mean: 0.16966078493775513
  episode_reward_min: -1.4292682926829268
  episodes_this_iter: 500
  episodes_total: 20000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1667.106
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.48727190494537354
        entropy_coeff: 0.0
        kl: 0.009633690118789673
        model: {}
        policy_loss: -0.019067175686359406
        total_loss: -0.0014501416590064764
        vf_explained_var: 0.7190023064613342
        vf_loss: 0.01721060834825039
    load_time_ms: 2.24
    num_steps_sampled: 20000
    num_steps_trained: 20000
    sample_time_ms: 188419.135
    update_time_ms: 5.281
  iterations_since_restore: 40
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.537440758293837
    ram_util_percent: 13.62559241706161
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 637.6329209767463
    mean_inference_ms: 1.62348322412752
    mean_processing_ms: 1.273963506338233
  time_since_restore: 12888.586970090866
  time_this_iter_s: 148.08193469047546
  time_total_s: 12888.586970090866
  timestamp: 1639280569
  timesteps_since_restore: 20000
  timesteps_this_iter: 500
  timesteps_total: 20000
  training_iteration: 40
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     40 |          12888.6 | 20000 | 0.169661 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-44-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7638326585695007
  episode_reward_mean: 0.16938579316319527
  episode_reward_min: -1.0628019323671498
  episodes_this_iter: 500
  episodes_total: 20500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1660.21
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.4982074499130249
        entropy_coeff: 0.0
        kl: 0.007877476513385773
        model: {}
        policy_loss: -0.01741088181734085
        total_loss: -0.0012225921964272857
        vf_explained_var: 0.7467344403266907
        vf_loss: 0.015855953097343445
    load_time_ms: 2.218
    num_steps_sampled: 20500
    num_steps_trained: 20500
    sample_time_ms: 172634.692
    update_time_ms: 5.336
  iterations_since_restore: 41
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.523021582733813
    ram_util_percent: 13.679856115107913
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 626.7012398124679
    mean_inference_ms: 1.6140374001814242
    mean_processing_ms: 1.2658859635497244
  time_since_restore: 12986.242411375046
  time_this_iter_s: 97.65544128417969
  time_total_s: 12986.242411375046
  timestamp: 1639280666
  timesteps_since_restore: 20500
  timesteps_this_iter: 500
  timesteps_total: 20500
  training_iteration: 41
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     41 |          12986.2 | 20500 | 0.169386 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-46-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7618110236220472
  episode_reward_mean: 0.17476860718167445
  episode_reward_min: -0.4911242603550296
  episodes_this_iter: 500
  episodes_total: 21000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1653.553
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.5065081119537354
        entropy_coeff: 0.0
        kl: 0.008905657567083836
        model: {}
        policy_loss: -0.01592477597296238
        total_loss: -0.0050417399033904076
        vf_explained_var: 0.748138427734375
        vf_loss: 0.01050732284784317
    load_time_ms: 2.212
    num_steps_sampled: 21000
    num_steps_trained: 21000
    sample_time_ms: 161483.525
    update_time_ms: 5.357
  iterations_since_restore: 42
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.570198675496687
    ram_util_percent: 13.769536423841055
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 616.6598608729828
    mean_inference_ms: 1.6060032496468903
    mean_processing_ms: 1.2591293860455877
  time_since_restore: 13091.65759396553
  time_this_iter_s: 105.41518259048462
  time_total_s: 13091.65759396553
  timestamp: 1639280772
  timesteps_since_restore: 21000
  timesteps_this_iter: 500
  timesteps_total: 21000
  training_iteration: 42
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     42 |          13091.7 | 21000 | 0.174769 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-47-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7780821917808219
  episode_reward_mean: 0.18949838776203753
  episode_reward_min: -0.46107784431137727
  episodes_this_iter: 500
  episodes_total: 21500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1656.894
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.49615243077278137
        entropy_coeff: 0.0
        kl: 0.007409050595015287
        model: {}
        policy_loss: -0.022594144567847252
        total_loss: -0.009784161113202572
        vf_explained_var: 0.7898208498954773
        vf_loss: 0.012497409246861935
    load_time_ms: 2.206
    num_steps_sampled: 21500
    num_steps_trained: 21500
    sample_time_ms: 151536.566
    update_time_ms: 5.321
  iterations_since_restore: 43
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.49057971014493
    ram_util_percent: 13.693478260869563
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 606.6800824132478
    mean_inference_ms: 1.5969840511433622
    mean_processing_ms: 1.2518129738634298
  time_since_restore: 13188.386751174927
  time_this_iter_s: 96.72915720939636
  time_total_s: 13188.386751174927
  timestamp: 1639280869
  timesteps_since_restore: 21500
  timesteps_this_iter: 500
  timesteps_total: 21500
  training_iteration: 43
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     43 |          13188.4 | 21500 | 0.189498 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-49-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8070342205323194
  episode_reward_mean: 0.19906360680104848
  episode_reward_min: -0.5208333333333334
  episodes_this_iter: 500
  episodes_total: 22000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1652.642
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.4199792146682739
        entropy_coeff: 0.0
        kl: 0.011392060667276382
        model: {}
        policy_loss: -0.023702654987573624
        total_loss: -0.011950487270951271
        vf_explained_var: 0.7823835015296936
        vf_loss: 0.01127157174050808
    load_time_ms: 2.165
    num_steps_sampled: 22000
    num_steps_trained: 22000
    sample_time_ms: 139889.711
    update_time_ms: 5.376
  iterations_since_restore: 44
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.52782608695652
    ram_util_percent: 13.67565217391304
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 596.4101790991714
    mean_inference_ms: 1.5881300937001865
    mean_processing_ms: 1.2443821070752443
  time_since_restore: 13268.635524749756
  time_this_iter_s: 80.2487735748291
  time_total_s: 13268.635524749756
  timestamp: 1639280949
  timesteps_since_restore: 22000
  timesteps_this_iter: 500
  timesteps_total: 22000
  training_iteration: 44
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     44 |          13268.6 | 22000 | 0.199064 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-50-30
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7645429362880887
  episode_reward_mean: 0.169007003114614
  episode_reward_min: -6.102702702702703
  episodes_this_iter: 500
  episodes_total: 22500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1662.71
    learner:
      default_policy:
        cur_kl_coeff: 0.04218750074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.42109423875808716
        entropy_coeff: 0.0
        kl: 0.0034346759784966707
        model: {}
        policy_loss: -0.01979164034128189
        total_loss: 0.07111973315477371
        vf_explained_var: 0.5534400939941406
        vf_loss: 0.09076647460460663
    load_time_ms: 2.142
    num_steps_sampled: 22500
    num_steps_trained: 22500
    sample_time_ms: 127110.802
    update_time_ms: 5.493
  iterations_since_restore: 45
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.588793103448278
    ram_util_percent: 13.695689655172412
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 586.6413830407519
    mean_inference_ms: 1.580088939949023
    mean_processing_ms: 1.2374576645572206
  time_since_restore: 13349.866418838501
  time_this_iter_s: 81.23089408874512
  time_total_s: 13349.866418838501
  timestamp: 1639281030
  timesteps_since_restore: 22500
  timesteps_this_iter: 500
  timesteps_total: 22500
  training_iteration: 45
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     45 |          13349.9 | 22500 | 0.169007 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-51-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.767379679144385
  episode_reward_mean: 0.19996180416277176
  episode_reward_min: -1.0985221674876848
  episodes_this_iter: 500
  episodes_total: 23000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1671.659
    learner:
      default_policy:
        cur_kl_coeff: 0.02109375037252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.44056782126426697
        entropy_coeff: 0.0
        kl: 0.010637998580932617
        model: {}
        policy_loss: -0.020902270451188087
        total_loss: -0.004160439595580101
        vf_explained_var: 0.7308142185211182
        vf_loss: 0.016517437994480133
    load_time_ms: 2.158
    num_steps_sampled: 23000
    num_steps_trained: 23000
    sample_time_ms: 112001.322
    update_time_ms: 5.378
  iterations_since_restore: 46
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.0
    ram_util_percent: 13.71206896551724
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 577.2927693971151
    mean_inference_ms: 1.5721885822455852
    mean_processing_ms: 1.230868851224794
  time_since_restore: 13431.048951148987
  time_this_iter_s: 81.18253231048584
  time_total_s: 13431.048951148987
  timestamp: 1639281112
  timesteps_since_restore: 23000
  timesteps_this_iter: 500
  timesteps_total: 23000
  training_iteration: 46
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     46 |            13431 | 23000 | 0.199962 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-52-58
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7836812144212524
  episode_reward_mean: 0.18447300738992436
  episode_reward_min: -0.5714285714285714
  episodes_this_iter: 500
  episodes_total: 23500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1681.831
    learner:
      default_policy:
        cur_kl_coeff: 0.02109375037252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.40412643551826477
        entropy_coeff: 0.0
        kl: 0.0056328852660954
        model: {}
        policy_loss: -0.021091002970933914
        total_loss: -0.006237817928195
        vf_explained_var: 0.6906517148017883
        vf_loss: 0.01473436038941145
    load_time_ms: 2.16
    num_steps_sampled: 23500
    num_steps_trained: 23500
    sample_time_ms: 101884.6
    update_time_ms: 5.302
  iterations_since_restore: 47
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.629473684210526
    ram_util_percent: 13.721052631578942
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 567.7163819445788
    mean_inference_ms: 1.5634734104767307
    mean_processing_ms: 1.22379735197789
  time_since_restore: 13497.505079507828
  time_this_iter_s: 66.45612835884094
  time_total_s: 13497.505079507828
  timestamp: 1639281178
  timesteps_since_restore: 23500
  timesteps_this_iter: 500
  timesteps_total: 23500
  training_iteration: 47
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     47 |          13497.5 | 23500 | 0.184473 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-54-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7873831775700935
  episode_reward_mean: 0.1762601141801988
  episode_reward_min: -2.545945945945946
  episodes_this_iter: 500
  episodes_total: 24000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1687.764
    learner:
      default_policy:
        cur_kl_coeff: 0.02109375037252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.4115498661994934
        entropy_coeff: 0.0
        kl: 0.005459082778543234
        model: {}
        policy_loss: -0.021399471908807755
        total_loss: -0.00010461091733304784
        vf_explained_var: 0.7637603878974915
        vf_loss: 0.02117970772087574
    load_time_ms: 2.165
    num_steps_sampled: 24000
    num_steps_trained: 24000
    sample_time_ms: 95192.681
    update_time_ms: 5.425
  iterations_since_restore: 48
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.70744680851064
    ram_util_percent: 13.802127659574461
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 558.541322726964
    mean_inference_ms: 1.5556294641605606
    mean_processing_ms: 1.2169829964970535
  time_since_restore: 13563.963691711426
  time_this_iter_s: 66.45861220359802
  time_total_s: 13563.963691711426
  timestamp: 1639281245
  timesteps_since_restore: 24000
  timesteps_this_iter: 500
  timesteps_total: 24000
  training_iteration: 48
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     48 |            13564 | 24000 |  0.17626 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-54-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7774725274725275
  episode_reward_mean: 0.1680123859643914
  episode_reward_min: -1.0092592592592593
  episodes_this_iter: 500
  episodes_total: 24500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1691.297
    learner:
      default_policy:
        cur_kl_coeff: 0.02109375037252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.32579275965690613
        entropy_coeff: 0.0
        kl: 0.006373124197125435
        model: {}
        policy_loss: -0.0161444079130888
        total_loss: -0.004086825996637344
        vf_explained_var: 0.7769585251808167
        vf_loss: 0.011923148296773434
    load_time_ms: 2.158
    num_steps_sampled: 24500
    num_steps_trained: 24500
    sample_time_ms: 85224.722
    update_time_ms: 5.477
  iterations_since_restore: 49
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.027272727272727
    ram_util_percent: 13.94090909090909
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 548.9039708242569
    mean_inference_ms: 1.5472872423340385
    mean_processing_ms: 1.2098748091994331
  time_since_restore: 13609.825569152832
  time_this_iter_s: 45.86187744140625
  time_total_s: 13609.825569152832
  timestamp: 1639281291
  timesteps_since_restore: 24500
  timesteps_this_iter: 500
  timesteps_total: 24500
  training_iteration: 49
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     49 |          13609.8 | 24500 | 0.168012 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-55-42
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.779291553133515
  episode_reward_mean: 0.16557990386617885
  episode_reward_min: -1.0784313725490196
  episodes_this_iter: 500
  episodes_total: 25000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1692.254
    learner:
      default_policy:
        cur_kl_coeff: 0.02109375037252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.32192501425743103
        entropy_coeff: 0.0
        kl: 0.00528411939740181
        model: {}
        policy_loss: -0.01689704693853855
        total_loss: 0.0006113989511504769
        vf_explained_var: 0.6725727319717407
        vf_loss: 0.01739698089659214
    load_time_ms: 2.067
    num_steps_sampled: 25000
    num_steps_trained: 25000
    sample_time_ms: 75576.911
    update_time_ms: 5.515
  iterations_since_restore: 50
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.779729729729734
    ram_util_percent: 13.7
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 539.879016411609
    mean_inference_ms: 1.5398815276026654
    mean_processing_ms: 1.203416094847295
  time_since_restore: 13661.438549280167
  time_this_iter_s: 51.612980127334595
  time_total_s: 13661.438549280167
  timestamp: 1639281342
  timesteps_since_restore: 25000
  timesteps_this_iter: 500
  timesteps_total: 25000
  training_iteration: 50
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     50 |          13661.4 | 25000 |  0.16558 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-56-25
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7747252747252747
  episode_reward_mean: 0.16697939018040325
  episode_reward_min: -0.971830985915493
  episodes_this_iter: 500
  episodes_total: 25500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1679.485
    learner:
      default_policy:
        cur_kl_coeff: 0.02109375037252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.332208514213562
        entropy_coeff: 0.0
        kl: 0.0063632880337536335
        model: {}
        policy_loss: -0.013621118851006031
        total_loss: 0.0015757590299472213
        vf_explained_var: 0.6982190012931824
        vf_loss: 0.015062655322253704
    load_time_ms: 2.118
    num_steps_sampled: 25500
    num_steps_trained: 25500
    sample_time_ms: 70072.057
    update_time_ms: 5.486
  iterations_since_restore: 51
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.571666666666667
    ram_util_percent: 13.688333333333333
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 530.8524678956809
    mean_inference_ms: 1.5321187676460077
    mean_processing_ms: 1.1966425944045918
  time_since_restore: 13703.917857170105
  time_this_iter_s: 42.479307889938354
  time_total_s: 13703.917857170105
  timestamp: 1639281385
  timesteps_since_restore: 25500
  timesteps_this_iter: 500
  timesteps_total: 25500
  training_iteration: 51
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     51 |          13703.9 | 25500 | 0.166979 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-57-02
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7664429530201342
  episode_reward_mean: 0.16071592193961556
  episode_reward_min: -1.0336538461538463
  episodes_this_iter: 500
  episodes_total: 26000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1680.862
    learner:
      default_policy:
        cur_kl_coeff: 0.02109375037252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.34503892064094543
        entropy_coeff: 0.0
        kl: 0.003991473000496626
        model: {}
        policy_loss: -0.013675150461494923
        total_loss: 0.004315658006817102
        vf_explained_var: 0.6760991811752319
        vf_loss: 0.01790662109851837
    load_time_ms: 2.15
    num_steps_sampled: 26000
    num_steps_trained: 26000
    sample_time_ms: 63245.313
    update_time_ms: 5.535
  iterations_since_restore: 52
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.666666666666664
    ram_util_percent: 13.683333333333335
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 521.9654795765982
    mean_inference_ms: 1.5243016171054673
    mean_processing_ms: 1.1899823395317644
  time_since_restore: 13741.080444097519
  time_this_iter_s: 37.16258692741394
  time_total_s: 13741.080444097519
  timestamp: 1639281422
  timesteps_since_restore: 26000
  timesteps_this_iter: 500
  timesteps_total: 26000
  training_iteration: 52
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     52 |          13741.1 | 26000 | 0.160716 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-57-59
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7859078590785907
  episode_reward_mean: 0.18502239454544514
  episode_reward_min: -0.4602272727272727
  episodes_this_iter: 500
  episodes_total: 26500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1666.754
    learner:
      default_policy:
        cur_kl_coeff: 0.010546875186264515
        cur_lr: 4.999999873689376e-05
        entropy: 0.3753889203071594
        entropy_coeff: 0.0
        kl: 0.011018198914825916
        model: {}
        policy_loss: -0.017571257427334785
        total_loss: -0.0060705519281327724
        vf_explained_var: 0.7961239814758301
        vf_loss: 0.011384495534002781
    load_time_ms: 2.152
    num_steps_sampled: 26500
    num_steps_trained: 26500
    sample_time_ms: 59229.936
    update_time_ms: 5.473
  iterations_since_restore: 53
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.447500000000002
    ram_util_percent: 13.66875
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 514.1418981874202
    mean_inference_ms: 1.51790783929895
    mean_processing_ms: 1.184321705752789
  time_since_restore: 13797.51339173317
  time_this_iter_s: 56.432947635650635
  time_total_s: 13797.51339173317
  timestamp: 1639281479
  timesteps_since_restore: 26500
  timesteps_this_iter: 500
  timesteps_total: 26500
  training_iteration: 53
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     53 |          13797.5 | 26500 | 0.185022 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-58-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7935943060498221
  episode_reward_mean: 0.19287292806850093
  episode_reward_min: -2.7085714285714286
  episodes_this_iter: 500
  episodes_total: 27000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1669.74
    learner:
      default_policy:
        cur_kl_coeff: 0.010546875186264515
        cur_lr: 4.999999873689376e-05
        entropy: 0.36904093623161316
        entropy_coeff: 0.0
        kl: 0.005682585295289755
        model: {}
        policy_loss: -0.016475865617394447
        total_loss: 0.010473801754415035
        vf_explained_var: 0.7103322744369507
        vf_loss: 0.026889732107520103
    load_time_ms: 2.175
    num_steps_sampled: 27000
    num_steps_trained: 27000
    sample_time_ms: 56555.466
    update_time_ms: 5.353
  iterations_since_restore: 54
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.854545454545457
    ram_util_percent: 13.696103896103892
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 506.49903235684997
    mean_inference_ms: 1.511041749243798
    mean_processing_ms: 1.1785390893510834
  time_since_restore: 13851.046261787415
  time_this_iter_s: 53.532870054244995
  time_total_s: 13851.046261787415
  timestamp: 1639281532
  timesteps_since_restore: 27000
  timesteps_this_iter: 500
  timesteps_total: 27000
  training_iteration: 54
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     54 |            13851 | 27000 | 0.192873 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_22-59-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.768
  episode_reward_mean: 0.19842573394169993
  episode_reward_min: -0.4431818181818182
  episodes_this_iter: 500
  episodes_total: 27500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1678.728
    learner:
      default_policy:
        cur_kl_coeff: 0.010546875186264515
        cur_lr: 4.999999873689376e-05
        entropy: 0.40235206484794617
        entropy_coeff: 0.0
        kl: 0.028079891577363014
        model: {}
        policy_loss: -0.01858963817358017
        total_loss: -0.008262851275503635
        vf_explained_var: 0.8012474179267883
        vf_loss: 0.01003063004463911
    load_time_ms: 2.155
    num_steps_sampled: 27500
    num_steps_trained: 27500
    sample_time_ms: 52253.321
    update_time_ms: 5.331
  iterations_since_restore: 55
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.70740740740741
    ram_util_percent: 13.694444444444446
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 498.5798306779158
    mean_inference_ms: 1.504290602839273
    mean_processing_ms: 1.1726900393874171
  time_since_restore: 13889.344279527664
  time_this_iter_s: 38.298017740249634
  time_total_s: 13889.344279527664
  timestamp: 1639281571
  timesteps_since_restore: 27500
  timesteps_this_iter: 500
  timesteps_total: 27500
  training_iteration: 55
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     55 |          13889.3 | 27500 | 0.198426 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-00-25
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7607003891050583
  episode_reward_mean: 0.16859614693884867
  episode_reward_min: -0.5376344086021505
  episodes_this_iter: 500
  episodes_total: 28000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1678.999
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.4342779219150543
        entropy_coeff: 0.0
        kl: 0.007201851811259985
        model: {}
        policy_loss: -0.015674354508519173
        total_loss: -0.0027108285576105118
        vf_explained_var: 0.787229597568512
        vf_loss: 0.012849589809775352
    load_time_ms: 2.222
    num_steps_sampled: 28000
    num_steps_trained: 28000
    sample_time_ms: 49566.808
    update_time_ms: 5.299
  iterations_since_restore: 56
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.77692307692308
    ram_util_percent: 13.744871794871793
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 491.5149424749673
    mean_inference_ms: 1.4983355362523196
    mean_processing_ms: 1.1678927243000685
  time_since_restore: 13943.665067195892
  time_this_iter_s: 54.32078766822815
  time_total_s: 13943.665067195892
  timestamp: 1639281625
  timesteps_since_restore: 28000
  timesteps_this_iter: 500
  timesteps_total: 28000
  training_iteration: 56
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     56 |          13943.7 | 28000 | 0.168596 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-01-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8
  episode_reward_mean: 0.1617823674347137
  episode_reward_min: -1.0628019323671498
  episodes_this_iter: 500
  episodes_total: 28500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1680.047
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.41651448607444763
        entropy_coeff: 0.0
        kl: 0.008119071833789349
        model: {}
        policy_loss: -0.01653573103249073
        total_loss: -0.0008453032351098955
        vf_explained_var: 0.735178530216217
        vf_loss: 0.015561992302536964
    load_time_ms: 2.242
    num_steps_sampled: 28500
    num_steps_trained: 28500
    sample_time_ms: 47607.897
    update_time_ms: 5.329
  iterations_since_restore: 57
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.171641791044776
    ram_util_percent: 13.841791044776121
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 484.4366649440171
    mean_inference_ms: 1.4921455089512476
    mean_processing_ms: 1.1628861385648084
  time_since_restore: 13990.543330192566
  time_this_iter_s: 46.878262996673584
  time_total_s: 13990.543330192566
  timestamp: 1639281672
  timesteps_since_restore: 28500
  timesteps_this_iter: 500
  timesteps_total: 28500
  training_iteration: 57
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     57 |          13990.5 | 28500 | 0.161782 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-01-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7780821917808219
  episode_reward_mean: 0.17911276293335776
  episode_reward_min: -0.4911242603550296
  episodes_this_iter: 500
  episodes_total: 29000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1691.479
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.382191002368927
        entropy_coeff: 0.0
        kl: 0.008867562748491764
        model: {}
        policy_loss: -0.018645595759153366
        total_loss: -0.0078115020878612995
        vf_explained_var: 0.7884859442710876
        vf_loss: 0.010693804360926151
    load_time_ms: 2.231
    num_steps_sampled: 29000
    num_steps_trained: 29000
    sample_time_ms: 45225.876
    update_time_ms: 5.285
  iterations_since_restore: 58
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.698360655737703
    ram_util_percent: 13.89672131147541
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 477.4588454629193
    mean_inference_ms: 1.4863442455520752
    mean_processing_ms: 1.1579753785235136
  time_since_restore: 14033.295939683914
  time_this_iter_s: 42.75260949134827
  time_total_s: 14033.295939683914
  timestamp: 1639281715
  timesteps_since_restore: 29000
  timesteps_this_iter: 500
  timesteps_total: 29000
  training_iteration: 58
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     58 |          14033.3 | 29000 | 0.179113 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-02-40
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8279467680608364
  episode_reward_mean: 0.20715695214491087
  episode_reward_min: -0.4375
  episodes_this_iter: 500
  episodes_total: 29500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1690.639
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.4428269863128662
        entropy_coeff: 0.0
        kl: 0.02180737815797329
        model: {}
        policy_loss: -0.021109700202941895
        total_loss: -0.007695858366787434
        vf_explained_var: 0.7788985967636108
        vf_loss: 0.013068843632936478
    load_time_ms: 2.231
    num_steps_sampled: 29500
    num_steps_trained: 29500
    sample_time_ms: 45112.814
    update_time_ms: 5.345
  iterations_since_restore: 59
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.1765625
    ram_util_percent: 13.6921875
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 470.7910043700849
    mean_inference_ms: 1.480609133083462
    mean_processing_ms: 1.1527779053754352
  time_since_restore: 14078.01940703392
  time_this_iter_s: 44.7234673500061
  time_total_s: 14078.01940703392
  timestamp: 1639281760
  timesteps_since_restore: 29500
  timesteps_this_iter: 500
  timesteps_total: 29500
  training_iteration: 59
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     59 |            14078 | 29500 | 0.207157 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-03-24
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7897435897435897
  episode_reward_mean: 0.18983025384709776
  episode_reward_min: -0.5208333333333334
  episodes_this_iter: 500
  episodes_total: 30000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1689.183
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.3700181245803833
        entropy_coeff: 0.0
        kl: 0.010412823408842087
        model: {}
        policy_loss: -0.020466001704335213
        total_loss: -0.00912146270275116
        vf_explained_var: 0.7812805771827698
        vf_loss: 0.011097443290054798
    load_time_ms: 2.248
    num_steps_sampled: 30000
    num_steps_trained: 30000
    sample_time_ms: 44404.026
    update_time_ms: 5.277
  iterations_since_restore: 60
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.9125
    ram_util_percent: 13.7421875
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 464.33622454576533
    mean_inference_ms: 1.4751977250757295
    mean_processing_ms: 1.1483338080955774
  time_since_restore: 14122.529261350632
  time_this_iter_s: 44.509854316711426
  time_total_s: 14122.529261350632
  timestamp: 1639281804
  timesteps_since_restore: 30000
  timesteps_this_iter: 500
  timesteps_total: 30000
  training_iteration: 60
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     60 |          14122.5 | 30000 |  0.18983 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-04-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7728531855955678
  episode_reward_mean: 0.17884175059828877
  episode_reward_min: -2.6277777777777778
  episodes_this_iter: 500
  episodes_total: 30500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1689.291
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.4195760488510132
        entropy_coeff: 0.0
        kl: 0.010089119896292686
        model: {}
        policy_loss: -0.01816542074084282
        total_loss: 0.011141407303512096
        vf_explained_var: 0.6635183691978455
        vf_loss: 0.02906741574406624
    load_time_ms: 2.196
    num_steps_sampled: 30500
    num_steps_trained: 30500
    sample_time_ms: 44174.92
    update_time_ms: 5.258
  iterations_since_restore: 61
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.69824561403509
    ram_util_percent: 13.791228070175439
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 457.9531900070014
    mean_inference_ms: 1.4693821607224336
    mean_processing_ms: 1.1433862099150847
  time_since_restore: 14162.717834472656
  time_this_iter_s: 40.188573122024536
  time_total_s: 14162.717834472656
  timestamp: 1639281845
  timesteps_since_restore: 30500
  timesteps_this_iter: 500
  timesteps_total: 30500
  training_iteration: 61
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     61 |          14162.7 | 30500 | 0.178842 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-04-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7628458498023716
  episode_reward_mean: 0.19809556689882005
  episode_reward_min: -0.5434782608695652
  episodes_this_iter: 500
  episodes_total: 31000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1667.261
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.3985831141471863
        entropy_coeff: 0.0
        kl: 0.012157632037997246
        model: {}
        policy_loss: -0.01893523335456848
        total_loss: -0.005430575460195541
        vf_explained_var: 0.7766466736793518
        vf_loss: 0.013216146267950535
    load_time_ms: 2.169
    num_steps_sampled: 31000
    num_steps_trained: 31000
    sample_time_ms: 45358.743
    update_time_ms: 5.228
  iterations_since_restore: 62
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.057142857142857
    ram_util_percent: 13.998571428571429
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 452.0562509002887
    mean_inference_ms: 1.4642046550055372
    mean_processing_ms: 1.1390646689668988
  time_since_restore: 14211.499069690704
  time_this_iter_s: 48.781235218048096
  time_total_s: 14211.499069690704
  timestamp: 1639281893
  timesteps_since_restore: 31000
  timesteps_this_iter: 500
  timesteps_total: 31000
  training_iteration: 62
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     62 |          14211.5 | 31000 | 0.198096 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-05-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7873831775700935
  episode_reward_mean: 0.19286607288825666
  episode_reward_min: -0.5714285714285714
  episodes_this_iter: 500
  episodes_total: 31500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1655.928
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.3613908290863037
        entropy_coeff: 0.0
        kl: 0.0075698657892644405
        model: {}
        policy_loss: -0.01613001897931099
        total_loss: -0.002900923602283001
        vf_explained_var: 0.7323095202445984
        vf_loss: 0.013049465604126453
    load_time_ms: 2.152
    num_steps_sampled: 31500
    num_steps_trained: 31500
    sample_time_ms: 44246.856
    update_time_ms: 5.274
  iterations_since_restore: 63
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.35846153846154
    ram_util_percent: 13.873846153846154
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 446.2325672267608
    mean_inference_ms: 1.4589423887472537
    mean_processing_ms: 1.1345808939163144
  time_since_restore: 14256.700405597687
  time_this_iter_s: 45.20133590698242
  time_total_s: 14256.700405597687
  timestamp: 1639281939
  timesteps_since_restore: 31500
  timesteps_this_iter: 500
  timesteps_total: 31500
  training_iteration: 63
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     63 |          14256.7 | 31500 | 0.192866 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-06-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7747252747252747
  episode_reward_mean: 0.18166283030406072
  episode_reward_min: -0.5698924731182796
  episodes_this_iter: 500
  episodes_total: 32000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1659.146
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.37264129519462585
        entropy_coeff: 0.0
        kl: 0.011056332848966122
        model: {}
        policy_loss: -0.02218945510685444
        total_loss: -0.007178821135312319
        vf_explained_var: 0.7629678249359131
        vf_loss: 0.014748264104127884
    load_time_ms: 2.126
    num_steps_sampled: 32000
    num_steps_trained: 32000
    sample_time_ms: 41940.179
    update_time_ms: 5.249
  iterations_since_restore: 64
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.05813953488372
    ram_util_percent: 13.883720930232558
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 440.12530512118514
    mean_inference_ms: 1.4536074558528775
    mean_processing_ms: 1.1298076528552357
  time_since_restore: 14287.198600292206
  time_this_iter_s: 30.498194694519043
  time_total_s: 14287.198600292206
  timestamp: 1639281969
  timesteps_since_restore: 32000
  timesteps_this_iter: 500
  timesteps_total: 32000
  training_iteration: 64
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     64 |          14287.2 | 32000 | 0.181663 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-06-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7741046831955923
  episode_reward_mean: 0.15757702944211907
  episode_reward_min: -2.50531914893617
  episodes_this_iter: 500
  episodes_total: 32500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1651.998
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.36311349272727966
        entropy_coeff: 0.0
        kl: 0.005394430365413427
        model: {}
        policy_loss: -0.010292088612914085
        total_loss: 0.016774175688624382
        vf_explained_var: 0.6195834279060364
        vf_loss: 0.02693825028836727
    load_time_ms: 2.139
    num_steps_sampled: 32500
    num_steps_trained: 32500
    sample_time_ms: 42350.52
    update_time_ms: 5.288
  iterations_since_restore: 65
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.268852459016394
    ram_util_percent: 13.849180327868854
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 434.57184526422304
    mean_inference_ms: 1.4487058616580202
    mean_processing_ms: 1.1256144584565855
  time_since_restore: 14329.529482126236
  time_this_iter_s: 42.33088183403015
  time_total_s: 14329.529482126236
  timestamp: 1639282012
  timesteps_since_restore: 32500
  timesteps_this_iter: 500
  timesteps_total: 32500
  training_iteration: 65
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     65 |          14329.5 | 32500 | 0.157577 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-07-27
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.776566757493188
  episode_reward_mean: 0.15701439151798144
  episode_reward_min: -2.675675675675676
  episodes_this_iter: 500
  episodes_total: 33000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1661.367
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.37695011496543884
        entropy_coeff: 0.0
        kl: 0.009553750976920128
        model: {}
        policy_loss: -0.01839340850710869
        total_loss: 0.0071983314119279385
        vf_explained_var: 0.7139554619789124
        vf_loss: 0.02536502107977867
    load_time_ms: 2.036
    num_steps_sampled: 33000
    num_steps_trained: 33000
    sample_time_ms: 40439.775
    update_time_ms: 5.385
  iterations_since_restore: 66
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.538
    ram_util_percent: 13.77
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 428.9687715990285
    mean_inference_ms: 1.4441658130526807
    mean_processing_ms: 1.122009797167198
  time_since_restore: 14364.83615732193
  time_this_iter_s: 35.30667519569397
  time_total_s: 14364.83615732193
  timestamp: 1639282047
  timesteps_since_restore: 33000
  timesteps_this_iter: 500
  timesteps_total: 33000
  training_iteration: 66
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     66 |          14364.8 | 33000 | 0.157014 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-08-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7747252747252747
  episode_reward_mean: 0.16152574722630447
  episode_reward_min: -2.690058479532164
  episodes_this_iter: 500
  episodes_total: 33500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1647.1
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.3948831260204315
        entropy_coeff: 0.0
        kl: 0.007872145622968674
        model: {}
        policy_loss: -0.02337634563446045
        total_loss: 0.012312453240156174
        vf_explained_var: 0.6922560930252075
        vf_loss: 0.03550199046730995
    load_time_ms: 2.012
    num_steps_sampled: 33500
    num_steps_trained: 33500
    sample_time_ms: 40589.832
    update_time_ms: 5.478
  iterations_since_restore: 67
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.56376811594203
    ram_util_percent: 13.836231884057973
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 423.92415815472765
    mean_inference_ms: 1.4400925124881128
    mean_processing_ms: 1.1191540542123837
  time_since_restore: 14413.072951555252
  time_this_iter_s: 48.236794233322144
  time_total_s: 14413.072951555252
  timestamp: 1639282096
  timesteps_since_restore: 33500
  timesteps_this_iter: 500
  timesteps_total: 33500
  training_iteration: 67
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     67 |          14413.1 | 33500 | 0.161526 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-08-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7804878048780488
  episode_reward_mean: 0.16207793386057343
  episode_reward_min: -1.0336538461538463
  episodes_this_iter: 500
  episodes_total: 34000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1643.301
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.3558107614517212
        entropy_coeff: 0.0
        kl: 0.006925118155777454
        model: {}
        policy_loss: -0.01639878936111927
        total_loss: -0.000754399283323437
        vf_explained_var: 0.7316101789474487
        vf_loss: 0.015480061993002892
    load_time_ms: 2.032
    num_steps_sampled: 34000
    num_steps_trained: 34000
    sample_time_ms: 39426.618
    update_time_ms: 5.404
  iterations_since_restore: 68
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.771111111111113
    ram_util_percent: 13.648888888888893
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 418.5209063157515
    mean_inference_ms: 1.435416764551911
    mean_processing_ms: 1.1154976680956779
  time_since_restore: 14444.154781341553
  time_this_iter_s: 31.08182978630066
  time_total_s: 14444.154781341553
  timestamp: 1639282127
  timesteps_since_restore: 34000
  timesteps_this_iter: 500
  timesteps_total: 34000
  training_iteration: 68
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     68 |          14444.2 | 34000 | 0.162078 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-09-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7789757412398922
  episode_reward_mean: 0.19207968540734105
  episode_reward_min: -1.0579710144927537
  episodes_this_iter: 500
  episodes_total: 34500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1646.525
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.3926016688346863
        entropy_coeff: 0.0
        kl: 0.011304503306746483
        model: {}
        policy_loss: -0.018259132280945778
        total_loss: -0.004397865384817123
        vf_explained_var: 0.7664991021156311
        vf_loss: 0.013593006879091263
    load_time_ms: 2.051
    num_steps_sampled: 34500
    num_steps_trained: 34500
    sample_time_ms: 39058.711
    update_time_ms: 5.341
  iterations_since_restore: 69
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.140677966101695
    ram_util_percent: 13.798305084745763
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 413.5665854855982
    mean_inference_ms: 1.431333531863738
    mean_processing_ms: 1.111946079420776
  time_since_restore: 14485.231546401978
  time_this_iter_s: 41.076765060424805
  time_total_s: 14485.231546401978
  timestamp: 1639282168
  timesteps_since_restore: 34500
  timesteps_this_iter: 500
  timesteps_total: 34500
  training_iteration: 69
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     69 |          14485.2 | 34500 |  0.19208 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-10-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7935943060498221
  episode_reward_mean: 0.2009282204995926
  episode_reward_min: -2.68
  episodes_this_iter: 500
  episodes_total: 35000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1635.37
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.3734026253223419
        entropy_coeff: 0.0
        kl: 0.005144808907061815
        model: {}
        policy_loss: -0.014275594614446163
        total_loss: 0.012790772132575512
        vf_explained_var: 0.7421269416809082
        vf_loss: 0.02694428525865078
    load_time_ms: 2.074
    num_steps_sampled: 35000
    num_steps_trained: 35000
    sample_time_ms: 39063.919
    update_time_ms: 5.429
  iterations_since_restore: 70
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.549206349206353
    ram_util_percent: 13.704761904761906
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 408.85335375746945
    mean_inference_ms: 1.4271080785129944
    mean_processing_ms: 1.1084565761848766
  time_since_restore: 14529.683708190918
  time_this_iter_s: 44.45216178894043
  time_total_s: 14529.683708190918
  timestamp: 1639282212
  timesteps_since_restore: 35000
  timesteps_this_iter: 500
  timesteps_total: 35000
  training_iteration: 70
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     70 |          14529.7 | 35000 | 0.200928 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-10-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.768
  episode_reward_mean: 0.1782540915025232
  episode_reward_min: -0.4742268041237113
  episodes_this_iter: 500
  episodes_total: 35500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1627.64
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.35079261660575867
        entropy_coeff: 0.0
        kl: 0.008580287918448448
        model: {}
        policy_loss: -0.016998855397105217
        total_loss: -0.005004710052162409
        vf_explained_var: 0.7752180695533752
        vf_loss: 0.011790536344051361
    load_time_ms: 2.089
    num_steps_sampled: 35500
    num_steps_trained: 35500
    sample_time_ms: 38778.383
    update_time_ms: 5.419
  iterations_since_restore: 71
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.960377358490568
    ram_util_percent: 13.70754716981132
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 404.06967271183896
    mean_inference_ms: 1.4232600736925627
    mean_processing_ms: 1.1049213115539234
  time_since_restore: 14566.939932107925
  time_this_iter_s: 37.256223917007446
  time_total_s: 14566.939932107925
  timestamp: 1639282250
  timesteps_since_restore: 35500
  timesteps_this_iter: 500
  timesteps_total: 35500
  training_iteration: 71
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     71 |          14566.9 | 35500 | 0.178254 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-11-21
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.763268156424581
  episode_reward_mean: 0.17428259919170655
  episode_reward_min: -1.0628019323671498
  episodes_this_iter: 500
  episodes_total: 36000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1653.018
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.3749428689479828
        entropy_coeff: 0.0
        kl: 0.004971885588020086
        model: {}
        policy_loss: -0.013519215397536755
        total_loss: 0.0026800832711160183
        vf_explained_var: 0.7316794395446777
        vf_loss: 0.01608131267130375
    load_time_ms: 2.112
    num_steps_sampled: 36000
    num_steps_trained: 36000
    sample_time_ms: 36972.6
    update_time_ms: 5.445
  iterations_since_restore: 72
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.924444444444443
    ram_util_percent: 13.682222222222226
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 399.2396932532895
    mean_inference_ms: 1.4189339118521598
    mean_processing_ms: 1.1011032835516228
  time_since_restore: 14597.916150093079
  time_this_iter_s: 30.9762179851532
  time_total_s: 14597.916150093079
  timestamp: 1639282281
  timesteps_since_restore: 36000
  timesteps_this_iter: 500
  timesteps_total: 36000
  training_iteration: 72
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     72 |          14597.9 | 36000 | 0.174283 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-11-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7926829268292683
  episode_reward_mean: 0.1761519029967371
  episode_reward_min: -2.111111111111111
  episodes_this_iter: 500
  episodes_total: 36500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1665.253
    learner:
      default_policy:
        cur_kl_coeff: 0.01186523400247097
        cur_lr: 4.999999873689376e-05
        entropy: 0.3440014719963074
        entropy_coeff: 0.0
        kl: 0.007318003103137016
        model: {}
        policy_loss: -0.02372870221734047
        total_loss: -0.0018555873539298773
        vf_explained_var: 0.7290981411933899
        vf_loss: 0.0217862818390131
    load_time_ms: 2.125
    num_steps_sampled: 36500
    num_steps_trained: 36500
    sample_time_ms: 35479.786
    update_time_ms: 5.402
  iterations_since_restore: 73
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.211627906976744
    ram_util_percent: 13.741860465116279
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 394.5281343921752
    mean_inference_ms: 1.4151923248419773
    mean_processing_ms: 1.0977384211354018
  time_since_restore: 14628.311368227005
  time_this_iter_s: 30.39521813392639
  time_total_s: 14628.311368227005
  timestamp: 1639282311
  timesteps_since_restore: 36500
  timesteps_this_iter: 500
  timesteps_total: 36500
  training_iteration: 73
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     73 |          14628.3 | 36500 | 0.176152 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-12-23
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7780821917808219
  episode_reward_mean: 0.18071942901411336
  episode_reward_min: -0.47023809523809523
  episodes_this_iter: 500
  episodes_total: 37000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1661.447
    learner:
      default_policy:
        cur_kl_coeff: 0.01186523400247097
        cur_lr: 4.999999873689376e-05
        entropy: 0.31226375699043274
        entropy_coeff: 0.0
        kl: 0.006951821036636829
        model: {}
        policy_loss: -0.020893096923828125
        total_loss: -0.007895935326814651
        vf_explained_var: 0.7484814524650574
        vf_loss: 0.012914678081870079
    load_time_ms: 2.115
    num_steps_sampled: 37000
    num_steps_trained: 37000
    sample_time_ms: 35549.634
    update_time_ms: 5.562
  iterations_since_restore: 74
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.640000000000002
    ram_util_percent: 13.700000000000003
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 389.963675781165
    mean_inference_ms: 1.4111441356588519
    mean_processing_ms: 1.0942426334442035
  time_since_restore: 14659.47112774849
  time_this_iter_s: 31.159759521484375
  time_total_s: 14659.47112774849
  timestamp: 1639282343
  timesteps_since_restore: 37000
  timesteps_this_iter: 500
  timesteps_total: 37000
  training_iteration: 74
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     74 |          14659.5 | 37000 | 0.180719 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-12-59
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8070342205323194
  episode_reward_mean: 0.2005620830839116
  episode_reward_min: -2.611428571428571
  episodes_this_iter: 500
  episodes_total: 37500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1662.18
    learner:
      default_policy:
        cur_kl_coeff: 0.01186523400247097
        cur_lr: 4.999999873689376e-05
        entropy: 0.3562728464603424
        entropy_coeff: 0.0
        kl: 0.004639779217541218
        model: {}
        policy_loss: -0.02096523530781269
        total_loss: 0.006998809520155191
        vf_explained_var: 0.7358821034431458
        vf_loss: 0.027908995747566223
    load_time_ms: 2.149
    num_steps_sampled: 37500
    num_steps_trained: 37500
    sample_time_ms: 34960.426
    update_time_ms: 5.559
  iterations_since_restore: 75
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.067307692307692
    ram_util_percent: 13.688461538461537
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 385.6625640994056
    mean_inference_ms: 1.4073830096423667
    mean_processing_ms: 1.0909791317104591
  time_since_restore: 14695.917189598083
  time_this_iter_s: 36.446061849594116
  time_total_s: 14695.917189598083
  timestamp: 1639282379
  timesteps_since_restore: 37500
  timesteps_this_iter: 500
  timesteps_total: 37500
  training_iteration: 75
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     75 |          14695.9 | 37500 | 0.200562 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-13-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7728531855955678
  episode_reward_mean: 0.1829388358892685
  episode_reward_min: -2.6839080459770117
  episodes_this_iter: 500
  episodes_total: 38000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1662.242
    learner:
      default_policy:
        cur_kl_coeff: 0.005932617001235485
        cur_lr: 4.999999873689376e-05
        entropy: 0.31622394919395447
        entropy_coeff: 0.0
        kl: 0.0036237877793610096
        model: {}
        policy_loss: -0.011603525839745998
        total_loss: 0.01085277646780014
        vf_explained_var: 0.7615073919296265
        vf_loss: 0.02243480458855629
    load_time_ms: 2.182
    num_steps_sampled: 38000
    num_steps_trained: 38000
    sample_time_ms: 34922.499
    update_time_ms: 5.615
  iterations_since_restore: 76
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.575999999999999
    ram_util_percent: 13.698
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 381.43142703733855
    mean_inference_ms: 1.40355310986906
    mean_processing_ms: 1.0876578659274847
  time_since_restore: 14730.845998048782
  time_this_iter_s: 34.92880845069885
  time_total_s: 14730.845998048782
  timestamp: 1639282414
  timesteps_since_restore: 38000
  timesteps_this_iter: 500
  timesteps_total: 38000
  training_iteration: 76
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     76 |          14730.8 | 38000 | 0.182939 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-14-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7615384615384615
  episode_reward_mean: 0.1750553706178865
  episode_reward_min: -2.68
  episodes_this_iter: 500
  episodes_total: 38500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1667.715
    learner:
      default_policy:
        cur_kl_coeff: 0.0029663085006177425
        cur_lr: 4.999999873689376e-05
        entropy: 0.34555584192276
        entropy_coeff: 0.0
        kl: 0.01005109678953886
        model: {}
        policy_loss: -0.028496017679572105
        total_loss: 0.003101860173046589
        vf_explained_var: 0.6661621332168579
        vf_loss: 0.03156806528568268
    load_time_ms: 2.205
    num_steps_sampled: 38500
    num_steps_trained: 38500
    sample_time_ms: 33208.544
    update_time_ms: 5.548
  iterations_since_restore: 77
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.42
    ram_util_percent: 13.733333333333336
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 377.2157139878581
    mean_inference_ms: 1.4000294106411801
    mean_processing_ms: 1.084600577759794
  time_since_restore: 14761.997371435165
  time_this_iter_s: 31.151373386383057
  time_total_s: 14761.997371435165
  timestamp: 1639282446
  timesteps_since_restore: 38500
  timesteps_this_iter: 500
  timesteps_total: 38500
  training_iteration: 77
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     77 |            14762 | 38500 | 0.175055 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-14-33
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7614314115308151
  episode_reward_mean: 0.18549901292609133
  episode_reward_min: -0.5714285714285714
  episodes_this_iter: 500
  episodes_total: 39000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1655.712
    learner:
      default_policy:
        cur_kl_coeff: 0.0029663085006177425
        cur_lr: 4.999999873689376e-05
        entropy: 0.38500678539276123
        entropy_coeff: 0.0
        kl: 0.024016113951802254
        model: {}
        policy_loss: -0.02044494077563286
        total_loss: -0.005812598392367363
        vf_explained_var: 0.6790686249732971
        vf_loss: 0.014561102725565434
    load_time_ms: 2.182
    num_steps_sampled: 39000
    num_steps_trained: 39000
    sample_time_ms: 32868.689
    update_time_ms: 5.687
  iterations_since_restore: 78
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.853846153846156
    ram_util_percent: 13.720512820512822
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 373.0158696666484
    mean_inference_ms: 1.396914304322131
    mean_processing_ms: 1.0823960738415472
  time_since_restore: 14789.561675786972
  time_this_iter_s: 27.56430435180664
  time_total_s: 14789.561675786972
  timestamp: 1639282473
  timesteps_since_restore: 39000
  timesteps_this_iter: 500
  timesteps_total: 39000
  training_iteration: 78
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     78 |          14789.6 | 39000 | 0.185499 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-15-11
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7873831775700935
  episode_reward_mean: 0.1879198339051311
  episode_reward_min: -0.5698924731182796
  episodes_this_iter: 500
  episodes_total: 39500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1656.682
    learner:
      default_policy:
        cur_kl_coeff: 0.0044494629837572575
        cur_lr: 4.999999873689376e-05
        entropy: 0.3420860767364502
        entropy_coeff: 0.0
        kl: 0.006706515327095985
        model: {}
        policy_loss: -0.007296015042811632
        total_loss: 0.006999066099524498
        vf_explained_var: 0.739132821559906
        vf_loss: 0.014265243895351887
    load_time_ms: 2.164
    num_steps_sampled: 39500
    num_steps_trained: 39500
    sample_time_ms: 32548.504
    update_time_ms: 5.705
  iterations_since_restore: 79
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.194444444444445
    ram_util_percent: 13.894444444444446
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 369.18424723441143
    mean_inference_ms: 1.3934174766027734
    mean_processing_ms: 1.0795192366500306
  time_since_restore: 14827.445932626724
  time_this_iter_s: 37.8842568397522
  time_total_s: 14827.445932626724
  timestamp: 1639282511
  timesteps_since_restore: 39500
  timesteps_this_iter: 500
  timesteps_total: 39500
  training_iteration: 79
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     79 |          14827.4 | 39500 |  0.18792 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-15-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7747252747252747
  episode_reward_mean: 0.1757544912296634
  episode_reward_min: -0.47619047619047616
  episodes_this_iter: 500
  episodes_total: 40000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1666.653
    learner:
      default_policy:
        cur_kl_coeff: 0.0044494629837572575
        cur_lr: 4.999999873689376e-05
        entropy: 0.3454587161540985
        entropy_coeff: 0.0
        kl: 0.004884093534201384
        model: {}
        policy_loss: -0.01932317204773426
        total_loss: -0.008204293437302113
        vf_explained_var: 0.8076967597007751
        vf_loss: 0.011097146198153496
    load_time_ms: 2.116
    num_steps_sampled: 40000
    num_steps_trained: 40000
    sample_time_ms: 31102.511
    update_time_ms: 5.774
  iterations_since_restore: 80
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.38139534883721
    ram_util_percent: 14.14418604651163
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 365.25376917514166
    mean_inference_ms: 1.3901345512455177
    mean_processing_ms: 1.0767230385318558
  time_since_restore: 14857.537746429443
  time_this_iter_s: 30.091813802719116
  time_total_s: 14857.537746429443
  timestamp: 1639282541
  timesteps_since_restore: 40000
  timesteps_this_iter: 500
  timesteps_total: 40000
  training_iteration: 80
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     80 |          14857.5 | 40000 | 0.175754 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-16-11
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.779291553133515
  episode_reward_mean: 0.16304535284152558
  episode_reward_min: -1.0784313725490196
  episodes_this_iter: 500
  episodes_total: 40500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1678.414
    learner:
      default_policy:
        cur_kl_coeff: 0.0022247314918786287
        cur_lr: 4.999999873689376e-05
        entropy: 0.31864142417907715
        entropy_coeff: 0.0
        kl: 0.005971370730549097
        model: {}
        policy_loss: -0.01375298947095871
        total_loss: 0.0044237966649234295
        vf_explained_var: 0.702045738697052
        vf_loss: 0.018163509666919708
    load_time_ms: 2.12
    num_steps_sampled: 40500
    num_steps_trained: 40500
    sample_time_ms: 30335.404
    update_time_ms: 5.761
  iterations_since_restore: 81
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.888372093023257
    ram_util_percent: 13.77674418604651
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 361.4096069173465
    mean_inference_ms: 1.3869296756515603
    mean_processing_ms: 1.0742894637932299
  time_since_restore: 14887.240633249283
  time_this_iter_s: 29.702886819839478
  time_total_s: 14887.240633249283
  timestamp: 1639282571
  timesteps_since_restore: 40500
  timesteps_this_iter: 500
  timesteps_total: 40500
  training_iteration: 81
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     81 |          14887.2 | 40500 | 0.163045 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-16-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7747252747252747
  episode_reward_mean: 0.16490744259933796
  episode_reward_min: -0.7935054121565362
  episodes_this_iter: 500
  episodes_total: 41000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1661.961
    learner:
      default_policy:
        cur_kl_coeff: 0.0022247314918786287
        cur_lr: 4.999999873689376e-05
        entropy: 0.283226877450943
        entropy_coeff: 0.0
        kl: 0.006855360697954893
        model: {}
        policy_loss: -0.020743414759635925
        total_loss: -0.006010554265230894
        vf_explained_var: 0.7435327172279358
        vf_loss: 0.014717607758939266
    load_time_ms: 2.111
    num_steps_sampled: 41000
    num_steps_trained: 41000
    sample_time_ms: 29565.248
    update_time_ms: 5.665
  iterations_since_restore: 82
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.481818181818184
    ram_util_percent: 13.912121212121212
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 357.50029596514014
    mean_inference_ms: 1.3837931560355305
    mean_processing_ms: 1.0718533720686039
  time_since_restore: 14910.35032081604
  time_this_iter_s: 23.109687566757202
  time_total_s: 14910.35032081604
  timestamp: 1639282594
  timesteps_since_restore: 41000
  timesteps_this_iter: 500
  timesteps_total: 41000
  training_iteration: 82
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     82 |          14910.4 | 41000 | 0.164907 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-16-54
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7676630434782609
  episode_reward_mean: 0.16354588463936914
  episode_reward_min: -1.0336538461538463
  episodes_this_iter: 500
  episodes_total: 41500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1676.093
    learner:
      default_policy:
        cur_kl_coeff: 0.0022247314918786287
        cur_lr: 4.999999873689376e-05
        entropy: 0.32452502846717834
        entropy_coeff: 0.0
        kl: 0.0038696189876645803
        model: {}
        policy_loss: -0.007973953150212765
        total_loss: 0.010759714059531689
        vf_explained_var: 0.7224142551422119
        vf_loss: 0.018725061789155006
    load_time_ms: 2.116
    num_steps_sampled: 41500
    num_steps_trained: 41500
    sample_time_ms: 28432.946
    update_time_ms: 5.715
  iterations_since_restore: 83
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.1
    ram_util_percent: 13.721428571428575
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 353.58688989371205
    mean_inference_ms: 1.3804830288858874
    mean_processing_ms: 1.069310125030755
  time_since_restore: 14929.564716339111
  time_this_iter_s: 19.21439552307129
  time_total_s: 14929.564716339111
  timestamp: 1639282614
  timesteps_since_restore: 41500
  timesteps_this_iter: 500
  timesteps_total: 41500
  training_iteration: 83
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     83 |          14929.6 | 41500 | 0.163546 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-17-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7804878048780488
  episode_reward_mean: 0.17768768482146163
  episode_reward_min: -0.5
  episodes_this_iter: 500
  episodes_total: 42000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1662.493
    learner:
      default_policy:
        cur_kl_coeff: 0.0011123657459393144
        cur_lr: 4.999999873689376e-05
        entropy: 0.344438374042511
        entropy_coeff: 0.0
        kl: 0.030852220952510834
        model: {}
        policy_loss: -0.021593308076262474
        total_loss: -0.010897854343056679
        vf_explained_var: 0.7442038655281067
        vf_loss: 0.010661127977073193
    load_time_ms: 2.123
    num_steps_sampled: 42000
    num_steps_trained: 42000
    sample_time_ms: 27185.414
    update_time_ms: 5.582
  iterations_since_restore: 84
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.22307692307692
    ram_util_percent: 13.700000000000001
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 349.75699233354857
    mean_inference_ms: 1.3769005131759529
    mean_processing_ms: 1.066222576518186
  time_since_restore: 14948.111645936966
  time_this_iter_s: 18.546929597854614
  time_total_s: 14948.111645936966
  timestamp: 1639282632
  timesteps_since_restore: 42000
  timesteps_this_iter: 500
  timesteps_total: 42000
  training_iteration: 84
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     84 |          14948.1 | 42000 | 0.177688 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-17-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7935943060498221
  episode_reward_mean: 0.20296182669681262
  episode_reward_min: -1.0579710144927537
  episodes_this_iter: 500
  episodes_total: 42500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1659.975
    learner:
      default_policy:
        cur_kl_coeff: 0.0016685485607013106
        cur_lr: 4.999999873689376e-05
        entropy: 0.3919229507446289
        entropy_coeff: 0.0
        kl: 0.00895674154162407
        model: {}
        policy_loss: -0.008252010680735111
        total_loss: 0.0066625382751226425
        vf_explained_var: 0.7715580463409424
        vf_loss: 0.01489960215985775
    load_time_ms: 2.09
    num_steps_sampled: 42500
    num_steps_trained: 42500
    sample_time_ms: 27286.499
    update_time_ms: 5.649
  iterations_since_restore: 85
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.846296296296291
    ram_util_percent: 13.774074074074074
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 346.4588853954492
    mean_inference_ms: 1.3737376781158546
    mean_processing_ms: 1.0636836197097954
  time_since_restore: 14985.543629169464
  time_this_iter_s: 37.43198323249817
  time_total_s: 14985.543629169464
  timestamp: 1639282670
  timesteps_since_restore: 42500
  timesteps_this_iter: 500
  timesteps_total: 42500
  training_iteration: 85
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     85 |          14985.5 | 42500 | 0.202962 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-18-27
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7744565217391305
  episode_reward_mean: 0.19011747597111833
  episode_reward_min: -0.48484848484848486
  episodes_this_iter: 500
  episodes_total: 43000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1644.829
    learner:
      default_policy:
        cur_kl_coeff: 0.0016685485607013106
        cur_lr: 4.999999873689376e-05
        entropy: 0.3928854763507843
        entropy_coeff: 0.0
        kl: 0.007316592149436474
        model: {}
        policy_loss: -0.011139996349811554
        total_loss: -0.0014858579961583018
        vf_explained_var: 0.8262936472892761
        vf_loss: 0.009641931392252445
    load_time_ms: 2.093
    num_steps_sampled: 43000
    num_steps_trained: 43000
    sample_time_ms: 27482.467
    update_time_ms: 5.584
  iterations_since_restore: 86
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.164150943396228
    ram_util_percent: 13.767924528301888
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 343.2213815655067
    mean_inference_ms: 1.3707406725823268
    mean_processing_ms: 1.0608688476116104
  time_since_restore: 15022.347248315811
  time_this_iter_s: 36.803619146347046
  time_total_s: 15022.347248315811
  timestamp: 1639282707
  timesteps_since_restore: 43000
  timesteps_this_iter: 500
  timesteps_total: 43000
  training_iteration: 86
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     86 |          15022.3 | 43000 | 0.190117 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-18-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7603143418467584
  episode_reward_mean: 0.1788224042909022
  episode_reward_min: -0.4742268041237113
  episodes_this_iter: 500
  episodes_total: 43500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1652.874
    learner:
      default_policy:
        cur_kl_coeff: 0.0016685485607013106
        cur_lr: 4.999999873689376e-05
        entropy: 0.3858238160610199
        entropy_coeff: 0.0
        kl: 0.010977281257510185
        model: {}
        policy_loss: -0.012998922728002071
        total_loss: -0.0006661850493401289
        vf_explained_var: 0.7622917294502258
        vf_loss: 0.012314426712691784
    load_time_ms: 2.088
    num_steps_sampled: 43500
    num_steps_trained: 43500
    sample_time_ms: 26937.846
    update_time_ms: 5.659
  iterations_since_restore: 87
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.044444444444444
    ram_util_percent: 13.741666666666667
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 339.80484869378137
    mean_inference_ms: 1.367676337832229
    mean_processing_ms: 1.0581739014426732
  time_since_restore: 15048.13389468193
  time_this_iter_s: 25.786646366119385
  time_total_s: 15048.13389468193
  timestamp: 1639282733
  timesteps_since_restore: 43500
  timesteps_this_iter: 500
  timesteps_total: 43500
  training_iteration: 87
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     87 |          15048.1 | 43500 | 0.178822 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-19-29
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.763268156424581
  episode_reward_mean: 0.1629053421112564
  episode_reward_min: -1.0628019323671498
  episodes_this_iter: 500
  episodes_total: 44000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1673.16
    learner:
      default_policy:
        cur_kl_coeff: 0.0016685485607013106
        cur_lr: 4.999999873689376e-05
        entropy: 0.39025744795799255
        entropy_coeff: 0.0
        kl: 0.007851661182940006
        model: {}
        policy_loss: -0.01024467684328556
        total_loss: 0.005068579688668251
        vf_explained_var: 0.7584378719329834
        vf_loss: 0.015300153754651546
    load_time_ms: 2.102
    num_steps_sampled: 44000
    num_steps_trained: 44000
    sample_time_ms: 27716.23
    update_time_ms: 5.552
  iterations_since_restore: 88
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.262745098039218
    ram_util_percent: 13.847058823529414
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 336.6848238679307
    mean_inference_ms: 1.3650176021251426
    mean_processing_ms: 1.0561815123864626
  time_since_restore: 15083.685430049896
  time_this_iter_s: 35.5515353679657
  time_total_s: 15083.685430049896
  timestamp: 1639282769
  timesteps_since_restore: 44000
  timesteps_this_iter: 500
  timesteps_total: 44000
  training_iteration: 88
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     88 |          15083.7 | 44000 | 0.162905 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-20-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7975609756097561
  episode_reward_mean: 0.18247580513805503
  episode_reward_min: -0.4911242603550296
  episodes_this_iter: 500
  episodes_total: 44500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1682.737
    learner:
      default_policy:
        cur_kl_coeff: 0.0016685485607013106
        cur_lr: 4.999999873689376e-05
        entropy: 0.38372790813446045
        entropy_coeff: 0.0
        kl: 0.009539778344333172
        model: {}
        policy_loss: -0.012840752489864826
        total_loss: -0.0024763101246207952
        vf_explained_var: 0.8075698614120483
        vf_loss: 0.010348529554903507
    load_time_ms: 2.111
    num_steps_sampled: 44500
    num_steps_trained: 44500
    sample_time_ms: 27979.649
    update_time_ms: 5.57
  iterations_since_restore: 89
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.293103448275861
    ram_util_percent: 13.815517241379311
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 333.750659477973
    mean_inference_ms: 1.3624663267351855
    mean_processing_ms: 1.054027772148535
  time_since_restore: 15124.300111293793
  time_this_iter_s: 40.614681243896484
  time_total_s: 15124.300111293793
  timestamp: 1639282809
  timesteps_since_restore: 44500
  timesteps_this_iter: 500
  timesteps_total: 44500
  training_iteration: 89
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     89 |          15124.3 | 44500 | 0.182476 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-21-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.773224043715847
  episode_reward_mean: 0.18144852462077823
  episode_reward_min: -2.1243243243243244
  episodes_this_iter: 500
  episodes_total: 45000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1686.826
    learner:
      default_policy:
        cur_kl_coeff: 0.0016685485607013106
        cur_lr: 4.999999873689376e-05
        entropy: 0.3776639997959137
        entropy_coeff: 0.0
        kl: 0.010067031718790531
        model: {}
        policy_loss: -0.02265140786767006
        total_loss: -0.004576903767883778
        vf_explained_var: 0.7743080258369446
        vf_loss: 0.01805771142244339
    load_time_ms: 2.119
    num_steps_sampled: 45000
    num_steps_trained: 45000
    sample_time_ms: 30812.734
    update_time_ms: 5.453
  iterations_since_restore: 90
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.191666666666668
    ram_util_percent: 13.867857142857144
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 331.2797953649584
    mean_inference_ms: 1.3600537963492167
    mean_processing_ms: 1.0518865747872026
  time_since_restore: 15182.76302742958
  time_this_iter_s: 58.462916135787964
  time_total_s: 15182.76302742958
  timestamp: 1639282868
  timesteps_since_restore: 45000
  timesteps_this_iter: 500
  timesteps_total: 45000
  training_iteration: 90
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     90 |          15182.8 | 45000 | 0.181449 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-21-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8070342205323194
  episode_reward_mean: 0.20001695322175528
  episode_reward_min: -0.5208333333333334
  episodes_this_iter: 500
  episodes_total: 45500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1683.512
    learner:
      default_policy:
        cur_kl_coeff: 0.0016685485607013106
        cur_lr: 4.999999873689376e-05
        entropy: 0.3665653467178345
        entropy_coeff: 0.0
        kl: 0.011140733025968075
        model: {}
        policy_loss: -0.019972048699855804
        total_loss: -0.007866837084293365
        vf_explained_var: 0.7564911842346191
        vf_loss: 0.012086626142263412
    load_time_ms: 2.163
    num_steps_sampled: 45500
    num_steps_trained: 45500
    sample_time_ms: 32142.455
    update_time_ms: 5.501
  iterations_since_restore: 91
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.638709677419355
    ram_util_percent: 13.864516129032259
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 328.52400458227663
    mean_inference_ms: 1.3575050448908137
    mean_processing_ms: 1.049557050970428
  time_since_restore: 15225.7307138443
  time_this_iter_s: 42.96768641471863
  time_total_s: 15225.7307138443
  timestamp: 1639282911
  timesteps_since_restore: 45500
  timesteps_this_iter: 500
  timesteps_total: 45500
  training_iteration: 91
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     91 |          15225.7 | 45500 | 0.200017 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-22-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.775623268698061
  episode_reward_mean: 0.18128952160165313
  episode_reward_min: -1.0985221674876848
  episodes_this_iter: 500
  episodes_total: 46000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1681.966
    learner:
      default_policy:
        cur_kl_coeff: 0.0016685485607013106
        cur_lr: 4.999999873689376e-05
        entropy: 0.4042106866836548
        entropy_coeff: 0.0
        kl: 0.012309126555919647
        model: {}
        policy_loss: -0.01828380674123764
        total_loss: -0.0029487675055861473
        vf_explained_var: 0.7448413372039795
        vf_loss: 0.015314500778913498
    load_time_ms: 2.185
    num_steps_sampled: 46000
    num_steps_trained: 46000
    sample_time_ms: 34658.176
    update_time_ms: 5.568
  iterations_since_restore: 92
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.947826086956523
    ram_util_percent: 13.784057971014493
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 325.94344614951535
    mean_inference_ms: 1.3553113958731475
    mean_processing_ms: 1.04776286749225
  time_since_restore: 15273.982272148132
  time_this_iter_s: 48.25155830383301
  time_total_s: 15273.982272148132
  timestamp: 1639282959
  timesteps_since_restore: 46000
  timesteps_this_iter: 500
  timesteps_total: 46000
  training_iteration: 92
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     92 |            15274 | 46000 |  0.18129 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-23-17
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7614314115308151
  episode_reward_mean: 0.20941539938605347
  episode_reward_min: -0.4742268041237113
  episodes_this_iter: 500
  episodes_total: 46500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1661.21
    learner:
      default_policy:
        cur_kl_coeff: 0.0016685485607013106
        cur_lr: 4.999999873689376e-05
        entropy: 0.4311090111732483
        entropy_coeff: 0.0
        kl: 0.007566454820334911
        model: {}
        policy_loss: -0.01711355522274971
        total_loss: -0.005328076891601086
        vf_explained_var: 0.8062953948974609
        vf_loss: 0.01177284587174654
    load_time_ms: 2.187
    num_steps_sampled: 46500
    num_steps_trained: 46500
    sample_time_ms: 36557.938
    update_time_ms: 5.543
  iterations_since_restore: 93
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.212962962962964
    ram_util_percent: 13.835185185185187
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 323.19866184296063
    mean_inference_ms: 1.3528432987784347
    mean_processing_ms: 1.0455422179831895
  time_since_restore: 15311.987159967422
  time_this_iter_s: 38.00488781929016
  time_total_s: 15311.987159967422
  timestamp: 1639282997
  timesteps_since_restore: 46500
  timesteps_this_iter: 500
  timesteps_total: 46500
  training_iteration: 93
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     93 |            15312 | 46500 | 0.209415 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-23-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7858032378580324
  episode_reward_mean: 0.18522014533922154
  episode_reward_min: -0.5714285714285714
  episodes_this_iter: 500
  episodes_total: 47000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1655.857
    learner:
      default_policy:
        cur_kl_coeff: 0.0016685485607013106
        cur_lr: 4.999999873689376e-05
        entropy: 0.37680163979530334
        entropy_coeff: 0.0
        kl: 0.003861084347590804
        model: {}
        policy_loss: -0.007021205499768257
        total_loss: 0.006797569803893566
        vf_explained_var: 0.714874267578125
        vf_loss: 0.013812338002026081
    load_time_ms: 2.234
    num_steps_sampled: 47000
    num_steps_trained: 47000
    sample_time_ms: 38432.493
    update_time_ms: 5.663
  iterations_since_restore: 94
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.133962264150941
    ram_util_percent: 13.87735849056604
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 320.4961395099318
    mean_inference_ms: 1.3508275327209525
    mean_processing_ms: 1.0441693622318593
  time_since_restore: 15349.22783946991
  time_this_iter_s: 37.24067950248718
  time_total_s: 15349.22783946991
  timestamp: 1639283035
  timesteps_since_restore: 47000
  timesteps_this_iter: 500
  timesteps_total: 47000
  training_iteration: 94
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     94 |          15349.2 | 47000 |  0.18522 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-24-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7873831775700935
  episode_reward_mean: 0.18837155292712277
  episode_reward_min: -0.5698924731182796
  episodes_this_iter: 500
  episodes_total: 47500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1648.321
    learner:
      default_policy:
        cur_kl_coeff: 0.0008342742803506553
        cur_lr: 4.999999873689376e-05
        entropy: 0.42349669337272644
        entropy_coeff: 0.0
        kl: 0.012965512461960316
        model: {}
        policy_loss: -0.013965629041194916
        total_loss: -0.00045296718599274755
        vf_explained_var: 0.7566263675689697
        vf_loss: 0.01350183505564928
    load_time_ms: 2.222
    num_steps_sampled: 47500
    num_steps_trained: 47500
    sample_time_ms: 39342.968
    update_time_ms: 5.556
  iterations_since_restore: 95
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.292537313432835
    ram_util_percent: 13.843283582089555
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 318.0441330418868
    mean_inference_ms: 1.3485930121117384
    mean_processing_ms: 1.0424794624942002
  time_since_restore: 15395.688873291016
  time_this_iter_s: 46.46103382110596
  time_total_s: 15395.688873291016
  timestamp: 1639283081
  timesteps_since_restore: 47500
  timesteps_this_iter: 500
  timesteps_total: 47500
  training_iteration: 95
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     95 |          15395.7 | 47500 | 0.188372 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-25-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7774725274725275
  episode_reward_mean: 0.15338832868607405
  episode_reward_min: -1.0092592592592593
  episodes_this_iter: 500
  episodes_total: 48000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1647.711
    learner:
      default_policy:
        cur_kl_coeff: 0.0008342742803506553
        cur_lr: 4.999999873689376e-05
        entropy: 0.38665467500686646
        entropy_coeff: 0.0
        kl: 0.012953653000295162
        model: {}
        policy_loss: -0.019043350592255592
        total_loss: -0.005723410286009312
        vf_explained_var: 0.742603600025177
        vf_loss: 0.01330913882702589
    load_time_ms: 2.186
    num_steps_sampled: 48000
    num_steps_trained: 48000
    sample_time_ms: 39689.322
    update_time_ms: 5.535
  iterations_since_restore: 96
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.010526315789477
    ram_util_percent: 13.95263157894737
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 315.51097662771093
    mean_inference_ms: 1.3465552734227504
    mean_processing_ms: 1.0407541879045303
  time_since_restore: 15435.882509708405
  time_this_iter_s: 40.193636417388916
  time_total_s: 15435.882509708405
  timestamp: 1639283122
  timesteps_since_restore: 48000
  timesteps_this_iter: 500
  timesteps_total: 48000
  training_iteration: 96
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     96 |          15435.9 | 48000 | 0.153388 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-26-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.776566757493188
  episode_reward_mean: 0.16354077352225582
  episode_reward_min: -1.0784313725490196
  episodes_this_iter: 500
  episodes_total: 48500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1649.743
    learner:
      default_policy:
        cur_kl_coeff: 0.0008342742803506553
        cur_lr: 4.999999873689376e-05
        entropy: 0.3862113058567047
        entropy_coeff: 0.0
        kl: 0.008675768971443176
        model: {}
        policy_loss: -0.018667785450816154
        total_loss: -0.0017960791010409594
        vf_explained_var: 0.7452760338783264
        vf_loss: 0.0168644767254591
    load_time_ms: 2.166
    num_steps_sampled: 48500
    num_steps_trained: 48500
    sample_time_ms: 41289.107
    update_time_ms: 5.476
  iterations_since_restore: 97
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.44833333333333
    ram_util_percent: 13.848333333333334
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 313.06129584732537
    mean_inference_ms: 1.344414156089505
    mean_processing_ms: 1.0389911128340041
  time_since_restore: 15477.686260700226
  time_this_iter_s: 41.80375099182129
  time_total_s: 15477.686260700226
  timestamp: 1639283164
  timesteps_since_restore: 48500
  timesteps_this_iter: 500
  timesteps_total: 48500
  training_iteration: 97
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     97 |          15477.7 | 48500 | 0.163541 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-26-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7747252747252747
  episode_reward_mean: 0.1640677719347016
  episode_reward_min: -1.1124260355029585
  episodes_this_iter: 500
  episodes_total: 49000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1633.223
    learner:
      default_policy:
        cur_kl_coeff: 0.0008342742803506553
        cur_lr: 4.999999873689376e-05
        entropy: 0.3968003988265991
        entropy_coeff: 0.0
        kl: 0.011827119626104832
        model: {}
        policy_loss: -0.018584027886390686
        total_loss: -0.00023455143673345447
        vf_explained_var: 0.7042054533958435
        vf_loss: 0.018339606001973152
    load_time_ms: 2.196
    num_steps_sampled: 49000
    num_steps_trained: 49000
    sample_time_ms: 41429.908
    update_time_ms: 5.645
  iterations_since_restore: 98
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.784905660377357
    ram_util_percent: 13.743396226415094
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 310.56169201818255
    mean_inference_ms: 1.3422195586532297
    mean_processing_ms: 1.0370348344561795
  time_since_restore: 15514.481762886047
  time_this_iter_s: 36.79550218582153
  time_total_s: 15514.481762886047
  timestamp: 1639283201
  timesteps_since_restore: 49000
  timesteps_this_iter: 500
  timesteps_total: 49000
  training_iteration: 98
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     98 |          15514.5 | 49000 | 0.164068 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-27-21
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.7747252747252747
  episode_reward_mean: 0.16853519679784926
  episode_reward_min: -1.0336538461538463
  episodes_this_iter: 500
  episodes_total: 49500
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1627.532
    learner:
      default_policy:
        cur_kl_coeff: 0.0008342742803506553
        cur_lr: 4.999999873689376e-05
        entropy: 0.3664308190345764
        entropy_coeff: 0.0
        kl: 0.008860806003212929
        model: {}
        policy_loss: -0.02408546768128872
        total_loss: -0.007917356677353382
        vf_explained_var: 0.7346028685569763
        vf_loss: 0.016160719096660614
    load_time_ms: 2.189
    num_steps_sampled: 49500
    num_steps_trained: 49500
    sample_time_ms: 41384.537
    update_time_ms: 5.594
  iterations_since_restore: 99
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.117543859649123
    ram_util_percent: 13.771929824561406
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 308.178994470706
    mean_inference_ms: 1.3399323401616123
    mean_processing_ms: 1.03517117730242
  time_since_restore: 15554.584913015366
  time_this_iter_s: 40.10315012931824
  time_total_s: 15554.584913015366
  timestamp: 1639283241
  timesteps_since_restore: 49500
  timesteps_this_iter: 500
  timesteps_total: 49500
  training_iteration: 99
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |     99 |          15554.6 | 49500 | 0.168535 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-11_23-27-54
  done: true
  episode_len_mean: 1.0
  episode_reward_max: 0.7804878048780488
  episode_reward_mean: 0.18271318336220707
  episode_reward_min: -0.4602272727272727
  episodes_this_iter: 500
  episodes_total: 50000
  experiment_id: a7460ca4d0894f278e985cb7c44ed152
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1614.771
    learner:
      default_policy:
        cur_kl_coeff: 0.0008342742803506553
        cur_lr: 4.999999873689376e-05
        entropy: 0.36260056495666504
        entropy_coeff: 0.0
        kl: 0.010001862421631813
        model: {}
        policy_loss: -0.011524613946676254
        total_loss: -0.001146348426118493
        vf_explained_var: 0.7753075957298279
        vf_loss: 0.010369925759732723
    load_time_ms: 2.206
    num_steps_sampled: 50000
    num_steps_trained: 50000
    sample_time_ms: 38804.239
    update_time_ms: 5.627
  iterations_since_restore: 100
  node_ip: 172.24.221.83
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.804255319148938
    ram_util_percent: 13.742553191489364
  pid: 2025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 305.6954972083725
    mean_inference_ms: 1.3376323869854392
    mean_processing_ms: 1.0332263628698983
  time_since_restore: 15587.117154359818
  time_this_iter_s: 32.532241344451904
  time_total_s: 15587.117154359818
  timestamp: 1639283274
  timesteps_since_restore: 50000
  timesteps_this_iter: 500
  timesteps_total: 50000
  training_iteration: 100
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.24.221.83:2025 |    100 |          15587.1 | 50000 | 0.182713 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 TERMINATED)
+-------------------+------------+-------+--------+------------------+-------+----------+
| Trial name        | status     | loc   |   iter |   total time (s) |    ts |   reward |
|-------------------+------------+-------+--------+------------------+-------+----------|
| PPO_autovec_00000 | TERMINATED |       |    100 |          15587.1 | 50000 | 0.182713 |
+-------------------+------------+-------+--------+------------------+-------+----------+


