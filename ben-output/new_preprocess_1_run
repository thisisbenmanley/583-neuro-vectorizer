== Status ==
Memory usage on this node: 1.0/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+-------+
| Trial name        | status   | loc   |
|-------------------+----------+-------|
| PPO_autovec_00000 | RUNNING  |       |
+-------------------+----------+-------+


[2m[36m(pid=3417)[0m /home/bdmanley/anaconda3/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.
[2m[36m(pid=3417)[0m   for external in metadata.entry_points().get(self.group, []):
[2m[36m(pid=3417)[0m creating ./new_garbage_3417 directory
[2m[36m(pid=3417)[0m running: cp -r ./training_data/* ./new_garbage_3417
[2m[36m(pid=3417)[0m 2021-11-26 14:41:03,291	INFO trainer.py:428 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
[2m[36m(pid=3417)[0m 2021-11-26 14:41:03,305	WARNING deprecation.py:30 -- DeprecationWarning: `sample_batch_size` has been deprecated. Use `rollout_fragment_length` instead. This will raise an error in the future!
[2m[36m(pid=3417)[0m 2021-11-26 14:41:03,305	INFO trainer.py:585 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=3417)[0m cp: cannot stat './training_data/*': No such file or directory
[2m[36m(pid=3417)[0m =-=-=-=-=-=-=-=-= BEAN BEAN BEAN BEAN BEAN =-=-=-=-=-=-=-=-=
[2m[36m(pid=3417)[0m Low for all Boxes is 0.
[2m[36m(pid=3417)[0m High for first and third is 134, second is 4239, last is 1
[2m[36m(pid=3417)[0m =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
[2m[36m(pid=3417)[0m Checking if local obs_encodings.pkl file exists.
[2m[36m(pid=3417)[0m Checking if local O3_runtimes.pkl file exists to avoid waste of compilation.
[2m[36m(pid=3417)[0m Did not find O3_runtimes.pkl... Compiling to get -O3 runtimes.
[2m[36m(pid=3420)[0m /home/bdmanley/anaconda3/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.
[2m[36m(pid=3420)[0m   for external in metadata.entry_points().get(self.group, []):
[2m[36m(pid=3420)[0m creating ./new_garbage_3420 directory
[2m[36m(pid=3420)[0m running: cp -r ./training_data/* ./new_garbage_3420
[2m[36m(pid=3417)[0m 2021-11-26 14:41:09,619	INFO trainable.py:217 -- Getting current IP.
[2m[36m(pid=3417)[0m 2021-11-26 14:41:09,619	WARNING util.py:37 -- Install gputil for GPU system monitoring.
[2m[36m(pid=3420)[0m =-=-=-=-=-=-=-=-= BEAN BEAN BEAN BEAN BEAN =-=-=-=-=-=-=-=-=
[2m[36m(pid=3420)[0m Low for all Boxes is 0.
[2m[36m(pid=3420)[0m High for first and third is 134, second is 4239, last is 1
[2m[36m(pid=3420)[0m =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
[2m[36m(pid=3420)[0m Checking if local obs_encodings.pkl file exists.
[2m[36m(pid=3420)[0m found local obs_encodings.pkl.
[2m[36m(pid=3420)[0m Checking if local O3_runtimes.pkl file exists to avoid waste of compilation.
[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_14-49-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8601880877742947
  episode_reward_mean: 0.2970653622516617
  episode_reward_min: -3.7252747252747254
  episodes_this_iter: 500
  episodes_total: 500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 2172.123
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 3.535874366760254
        entropy_coeff: 0.0
        kl: 0.01932174526154995
        model: {}
        policy_loss: -0.07700902968645096
        total_loss: 0.08363034576177597
        vf_explained_var: 0.03517365828156471
        vf_loss: 0.15677501261234283
    load_time_ms: 83.015
    num_steps_sampled: 500
    num_steps_trained: 500
    sample_time_ms: 511143.699
    update_time_ms: 888.475
  iterations_since_restore: 1
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.526666666666669
    ram_util_percent: 12.696190476190475
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 1013.3008171698293
    mean_inference_ms: 1.958899393291055
    mean_processing_ms: 1.3690865682270716
  time_since_restore: 514.3640508651733
  time_this_iter_s: 514.3640508651733
  time_total_s: 514.3640508651733
  timestamp: 1637959784
  timesteps_since_restore: 500
  timesteps_this_iter: 500
  timesteps_total: 500
  training_iteration: 1
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |      1 |          514.364 |  500 | 0.297065 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_14-57-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9398470097357441
  episode_reward_mean: 0.32202832316685126
  episode_reward_min: -2.7154088050314464
  episodes_this_iter: 500
  episodes_total: 1000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1964.981
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 3.5004119873046875
        entropy_coeff: 0.0
        kl: 0.017968423664569855
        model: {}
        policy_loss: -0.07598747313022614
        total_loss: 0.0794389545917511
        vf_explained_var: 0.08217800408601761
        vf_loss: 0.1518327295780182
    load_time_ms: 43.347
    num_steps_sampled: 1000
    num_steps_trained: 1000
    sample_time_ms: 493128.389
    update_time_ms: 446.792
  iterations_since_restore: 2
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.238823529411766
    ram_util_percent: 12.941323529411768
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 980.0492669199849
    mean_inference_ms: 1.9109539695076654
    mean_processing_ms: 1.3880377168302886
  time_since_restore: 991.2526922225952
  time_this_iter_s: 476.8886413574219
  time_total_s: 991.2526922225952
  timestamp: 1637960261
  timesteps_since_restore: 1000
  timesteps_this_iter: 500
  timesteps_total: 1000
  training_iteration: 2
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |      2 |          991.253 | 1000 | 0.322028 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_15-05-42
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8888277380297194
  episode_reward_mean: 0.3391469901696015
  episode_reward_min: -3.5239852398523985
  episodes_this_iter: 500
  episodes_total: 1500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1841.291
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 3.4599616527557373
        entropy_coeff: 0.0
        kl: 0.018760088831186295
        model: {}
        policy_loss: -0.08755240589380264
        total_loss: 0.031095078215003014
        vf_explained_var: 0.12837934494018555
        vf_loss: 0.11489544808864594
    load_time_ms: 29.85
    num_steps_sampled: 1500
    num_steps_trained: 1500
    sample_time_ms: 488647.195
    update_time_ms: 299.512
  iterations_since_restore: 3
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.340320232896653
    ram_util_percent: 13.002911208151383
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 971.9934153763315
    mean_inference_ms: 1.8958495824357655
    mean_processing_ms: 1.3968784121336102
  time_since_restore: 1472.5474927425385
  time_this_iter_s: 481.29480051994324
  time_total_s: 1472.5474927425385
  timestamp: 1637960742
  timesteps_since_restore: 1500
  timesteps_this_iter: 500
  timesteps_total: 1500
  training_iteration: 3
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |      3 |          1472.55 | 1500 | 0.339147 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_15-13-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8690763052208835
  episode_reward_mean: 0.34190663378998726
  episode_reward_min: -5.617161716171617
  episodes_this_iter: 500
  episodes_total: 2000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1829.445
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 3.3828165531158447
        entropy_coeff: 0.0
        kl: 0.018783675506711006
        model: {}
        policy_loss: -0.07516634464263916
        total_loss: 0.07474501430988312
        vf_explained_var: 0.06282849609851837
        vf_loss: 0.14615462720394135
    load_time_ms: 22.967
    num_steps_sampled: 2000
    num_steps_trained: 2000
    sample_time_ms: 488481.038
    update_time_ms: 225.831
  iterations_since_restore: 4
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.222063037249283
    ram_util_percent: 12.988108882521493
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 972.1108583853523
    mean_inference_ms: 1.8890733304231058
    mean_processing_ms: 1.3989962559232472
  time_since_restore: 1962.3408915996552
  time_this_iter_s: 489.7933988571167
  time_total_s: 1962.3408915996552
  timestamp: 1637961232
  timesteps_since_restore: 2000
  timesteps_this_iter: 500
  timesteps_total: 2000
  training_iteration: 4
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |      4 |          1962.34 | 2000 | 0.341907 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_15-21-36
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8318867062585655
  episode_reward_mean: 0.2886506411502569
  episode_reward_min: -4.038363171355499
  episodes_this_iter: 500
  episodes_total: 2500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1783.39
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 3.27333927154541
        entropy_coeff: 0.0
        kl: 0.022440481930971146
        model: {}
        policy_loss: -0.0935506522655487
        total_loss: 0.07536599040031433
        vf_explained_var: 0.15647050738334656
        vf_loss: 0.16442856192588806
    load_time_ms: 18.801
    num_steps_sampled: 2500
    num_steps_trained: 2500
    sample_time_ms: 483293.662
    update_time_ms: 181.53
  iterations_since_restore: 5
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.238914027149324
    ram_util_percent: 13.013423831070892
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 962.0083536638448
    mean_inference_ms: 1.8882560806243909
    mean_processing_ms: 1.3988836914574991
  time_since_restore: 2426.4992203712463
  time_this_iter_s: 464.1583287715912
  time_total_s: 2426.4992203712463
  timestamp: 1637961696
  timesteps_since_restore: 2500
  timesteps_this_iter: 500
  timesteps_total: 2500
  training_iteration: 5
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |      5 |           2426.5 | 2500 | 0.288651 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_15-28-48
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.850828729281768
  episode_reward_mean: 0.33004920143278244
  episode_reward_min: -3.1209964412811386
  episodes_this_iter: 500
  episodes_total: 3000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1762.767
    learner:
      default_policy:
        cur_kl_coeff: 0.30000001192092896
        cur_lr: 4.999999873689376e-05
        entropy: 3.1705048084259033
        entropy_coeff: 0.0
        kl: 0.023147497326135635
        model: {}
        policy_loss: -0.0944330245256424
        total_loss: 0.0003027954662684351
        vf_explained_var: 0.19911323487758636
        vf_loss: 0.08779158443212509
    load_time_ms: 16.134
    num_steps_sampled: 3000
    num_steps_trained: 3000
    sample_time_ms: 474410.288
    update_time_ms: 151.921
  iterations_since_restore: 6
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.119155844155843
    ram_util_percent: 13.028733766233767
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 944.422882185583
    mean_inference_ms: 1.8897283796229707
    mean_processing_ms: 1.3998118848333516
  time_since_restore: 2858.167146921158
  time_this_iter_s: 431.6679265499115
  time_total_s: 2858.167146921158
  timestamp: 1637962128
  timesteps_since_restore: 3000
  timesteps_this_iter: 500
  timesteps_total: 3000
  training_iteration: 6
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |      6 |          2858.17 | 3000 | 0.330049 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_15-35-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8580441640378549
  episode_reward_mean: 0.34573408923209886
  episode_reward_min: -2.8129032258064517
  episodes_this_iter: 500
  episodes_total: 3500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1743.555
    learner:
      default_policy:
        cur_kl_coeff: 0.44999998807907104
        cur_lr: 4.999999873689376e-05
        entropy: 3.0511584281921387
        entropy_coeff: 0.0
        kl: 0.018495352938771248
        model: {}
        policy_loss: -0.09330419450998306
        total_loss: 0.002870827680453658
        vf_explained_var: 0.2844543755054474
        vf_loss: 0.0878521129488945
    load_time_ms: 14.141
    num_steps_sampled: 3500
    num_steps_trained: 3500
    sample_time_ms: 467528.081
    update_time_ms: 130.862
  iterations_since_restore: 7
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.11344262295082
    ram_util_percent: 13.014426229508198
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 930.7874030843524
    mean_inference_ms: 1.8886900125180472
    mean_processing_ms: 1.402069248154789
  time_since_restore: 3286.0456953048706
  time_this_iter_s: 427.87854838371277
  time_total_s: 3286.0456953048706
  timestamp: 1637962556
  timesteps_since_restore: 3500
  timesteps_this_iter: 500
  timesteps_total: 3500
  training_iteration: 7
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |      7 |          3286.05 | 3500 | 0.345734 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_15-42-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8398009950248756
  episode_reward_mean: 0.3948070997730137
  episode_reward_min: -2.568862275449102
  episodes_this_iter: 500
  episodes_total: 4000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1717.681
    learner:
      default_policy:
        cur_kl_coeff: 0.44999998807907104
        cur_lr: 4.999999873689376e-05
        entropy: 2.8849010467529297
        entropy_coeff: 0.0
        kl: 0.021562008187174797
        model: {}
        policy_loss: -0.08958180248737335
        total_loss: -0.014622514136135578
        vf_explained_var: 0.03542729467153549
        vf_loss: 0.06525638699531555
    load_time_ms: 12.686
    num_steps_sampled: 4000
    num_steps_trained: 4000
    sample_time_ms: 460821.544
    update_time_ms: 115.028
  iterations_since_restore: 8
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.136593591905564
    ram_util_percent: 13.05362563237774
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 917.4717792538632
    mean_inference_ms: 1.887922375180131
    mean_processing_ms: 1.4028436569713467
  time_since_restore: 3701.4729237556458
  time_this_iter_s: 415.42722845077515
  time_total_s: 3701.4729237556458
  timestamp: 1637962971
  timesteps_since_restore: 4000
  timesteps_this_iter: 500
  timesteps_total: 4000
  training_iteration: 8
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |      8 |          3701.47 | 4000 | 0.394807 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_15-50-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8631578947368421
  episode_reward_mean: 0.39098371091042533
  episode_reward_min: -1.3836317135549872
  episodes_this_iter: 500
  episodes_total: 4500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1704.897
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 2.6949126720428467
        entropy_coeff: 0.0
        kl: 0.026270629838109016
        model: {}
        policy_loss: -0.11346988379955292
        total_loss: -0.043748315423727036
        vf_explained_var: 0.2592989206314087
        vf_loss: 0.05198889598250389
    load_time_ms: 11.529
    num_steps_sampled: 4500
    num_steps_trained: 4500
    sample_time_ms: 457218.037
    update_time_ms: 102.76
  iterations_since_restore: 9
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.238988580750409
    ram_util_percent: 13.05921696574225
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 910.3367941508263
    mean_inference_ms: 1.8888379541722116
    mean_processing_ms: 1.4040009283113684
  time_since_restore: 4131.481446266174
  time_this_iter_s: 430.00852251052856
  time_total_s: 4131.481446266174
  timestamp: 1637963401
  timesteps_since_restore: 4500
  timesteps_this_iter: 500
  timesteps_total: 4500
  training_iteration: 9
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |      9 |          4131.48 | 4500 | 0.390984 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_15-56-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721590909090909
  episode_reward_mean: 0.4254317611554062
  episode_reward_min: -1.1684549356223175
  episodes_this_iter: 500
  episodes_total: 5000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1695.488
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 2.5644326210021973
        entropy_coeff: 0.0
        kl: 0.017468035221099854
        model: {}
        policy_loss: -0.09550544619560242
        total_loss: -0.039085838943719864
        vf_explained_var: 0.3072064220905304
        vf_loss: 0.03873322531580925
    load_time_ms: 10.616
    num_steps_sampled: 5000
    num_steps_trained: 5000
    sample_time_ms: 451625.955
    update_time_ms: 92.97
  iterations_since_restore: 10
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.060869565217391
    ram_util_percent: 13.084347826086956
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 899.2131655513227
    mean_inference_ms: 1.8879570643488497
    mean_processing_ms: 1.4039693987624595
  time_since_restore: 4534.405058860779
  time_this_iter_s: 402.9236125946045
  time_total_s: 4534.405058860779
  timestamp: 1637963804
  timesteps_since_restore: 5000
  timesteps_this_iter: 500
  timesteps_total: 5000
  training_iteration: 10
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     10 |          4534.41 | 5000 | 0.425432 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_16-03-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.41825954546149535
  episode_reward_min: -3.3733333333333335
  episodes_this_iter: 500
  episodes_total: 5500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1642.114
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 2.485999822616577
        entropy_coeff: 0.0
        kl: 0.011960209347307682
        model: {}
        policy_loss: -0.06753640621900558
        total_loss: 0.006103712134063244
        vf_explained_var: 0.3446010947227478
        vf_loss: 0.061530400067567825
    load_time_ms: 2.547
    num_steps_sampled: 5500
    num_steps_trained: 5500
    sample_time_ms: 440763.452
    update_time_ms: 4.588
  iterations_since_restore: 11
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.145580589254767
    ram_util_percent: 13.098786828422877
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 890.3332342128065
    mean_inference_ms: 1.8883660758024907
    mean_processing_ms: 1.403779078561422
  time_since_restore: 4938.577355861664
  time_this_iter_s: 404.172297000885
  time_total_s: 4938.577355861664
  timestamp: 1637964208
  timesteps_since_restore: 5500
  timesteps_this_iter: 500
  timesteps_total: 5500
  training_iteration: 11
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     11 |          4938.58 | 5500 |  0.41826 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_16-10-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.4302239828232789
  episode_reward_min: -0.9052333804809052
  episodes_this_iter: 500
  episodes_total: 6000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1643.072
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 2.374502658843994
        entropy_coeff: 0.0
        kl: 0.014382770285010338
        model: {}
        policy_loss: -0.09046759456396103
        total_loss: -0.04584475979208946
        vf_explained_var: 0.45422419905662537
        vf_loss: 0.030060291290283203
    load_time_ms: 2.411
    num_steps_sampled: 6000
    num_steps_trained: 6000
    sample_time_ms: 432728.341
    update_time_ms: 4.493
  iterations_since_restore: 12
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.998233215547703
    ram_util_percent: 13.073498233215547
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 881.6440017238057
    mean_inference_ms: 1.8872101492453486
    mean_processing_ms: 1.4015909950448322
  time_since_restore: 5335.121924161911
  time_this_iter_s: 396.5445683002472
  time_total_s: 5335.121924161911
  timestamp: 1637964605
  timesteps_since_restore: 6000
  timesteps_this_iter: 500
  timesteps_total: 6000
  training_iteration: 12
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     12 |          5335.12 | 6000 | 0.430224 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_16-16-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.4421275937523154
  episode_reward_min: -2.4938650306748467
  episodes_this_iter: 500
  episodes_total: 6500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1640.734
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 2.3189783096313477
        entropy_coeff: 0.0
        kl: 0.010407681576907635
        model: {}
        policy_loss: -0.06557627022266388
        total_loss: -0.010833453387022018
        vf_explained_var: 0.4282989501953125
        vf_loss: 0.044205039739608765
    load_time_ms: 2.37
    num_steps_sampled: 6500
    num_steps_trained: 6500
    sample_time_ms: 423965.56
    update_time_ms: 4.463
  iterations_since_restore: 13
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.858645276292336
    ram_util_percent: 13.084670231729055
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 873.8742932376998
    mean_inference_ms: 1.886740040364696
    mean_processing_ms: 1.4000660711903699
  time_since_restore: 5728.765149354935
  time_this_iter_s: 393.6432251930237
  time_total_s: 5728.765149354935
  timestamp: 1637964999
  timesteps_since_restore: 6500
  timesteps_this_iter: 500
  timesteps_total: 6500
  training_iteration: 13
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     13 |          5728.77 | 6500 | 0.442128 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_16-23-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8629441624365483
  episode_reward_mean: 0.449490668270454
  episode_reward_min: -2.0920245398773005
  episodes_this_iter: 500
  episodes_total: 7000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1636.107
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 2.196699380874634
        entropy_coeff: 0.0
        kl: 0.010542037896811962
        model: {}
        policy_loss: -0.07201710343360901
        total_loss: -0.019248994067311287
        vf_explained_var: 0.35796108841896057
        vf_loss: 0.04209430143237114
    load_time_ms: 2.359
    num_steps_sampled: 7000
    num_steps_trained: 7000
    sample_time_ms: 413919.163
    update_time_ms: 4.44
  iterations_since_restore: 14
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.973021582733812
    ram_util_percent: 13.09046762589928
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 866.5642357267594
    mean_inference_ms: 1.8861598584366228
    mean_processing_ms: 1.4010457511698071
  time_since_restore: 6118.047442436218
  time_this_iter_s: 389.28229308128357
  time_total_s: 6118.047442436218
  timestamp: 1637965388
  timesteps_since_restore: 7000
  timesteps_this_iter: 500
  timesteps_total: 7000
  training_iteration: 14
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     14 |          6118.05 | 7000 | 0.449491 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_16-29-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8597285067873304
  episode_reward_mean: 0.48142226263249543
  episode_reward_min: -0.4692737430167598
  episodes_this_iter: 500
  episodes_total: 7500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1637.2
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 2.041062831878662
        entropy_coeff: 0.0
        kl: 0.00891162734478712
        model: {}
        policy_loss: -0.06820446252822876
        total_loss: -0.039027586579322815
        vf_explained_var: 0.45967015624046326
        vf_loss: 0.020153852179646492
    load_time_ms: 2.366
    num_steps_sampled: 7500
    num_steps_trained: 7500
    sample_time_ms: 404505.526
    update_time_ms: 4.611
  iterations_since_restore: 15
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.930492424242425
    ram_util_percent: 13.136931818181816
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 857.6784480366607
    mean_inference_ms: 1.8872563448957949
    mean_processing_ms: 1.402563547201275
  time_since_restore: 6488.082452297211
  time_this_iter_s: 370.03500986099243
  time_total_s: 6488.082452297211
  timestamp: 1637965758
  timesteps_since_restore: 7500
  timesteps_this_iter: 500
  timesteps_total: 7500
  training_iteration: 15
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     15 |          6488.08 | 7500 | 0.481422 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_16-35-43
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8840399002493765
  episode_reward_mean: 0.46918690774618615
  episode_reward_min: -0.8414464534075105
  episodes_this_iter: 500
  episodes_total: 8000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1625.946
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.965061068534851
        entropy_coeff: 0.0
        kl: 0.013003644533455372
        model: {}
        policy_loss: -0.07773500680923462
        total_loss: -0.03610984608530998
        vf_explained_var: 0.4047245383262634
        vf_loss: 0.02845897525548935
    load_time_ms: 2.334
    num_steps_sampled: 8000
    num_steps_trained: 8000
    sample_time_ms: 399835.068
    update_time_ms: 4.79
  iterations_since_restore: 16
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.040983606557377
    ram_util_percent: 13.165573770491802
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 851.7667149740553
    mean_inference_ms: 1.8865864897590776
    mean_processing_ms: 1.4020195455495128
  time_since_restore: 6872.934725046158
  time_this_iter_s: 384.85227274894714
  time_total_s: 6872.934725046158
  timestamp: 1637966143
  timesteps_since_restore: 8000
  timesteps_this_iter: 500
  timesteps_total: 8000
  training_iteration: 16
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     16 |          6872.93 | 8000 | 0.469187 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_16-41-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9583394670984837
  episode_reward_mean: 0.4879596375903726
  episode_reward_min: -2.7
  episodes_this_iter: 500
  episodes_total: 8500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1622.31
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.8588682413101196
        entropy_coeff: 0.0
        kl: 0.009393096901476383
        model: {}
        policy_loss: -0.0649450421333313
        total_loss: -0.02118123322725296
        vf_explained_var: 0.48051029443740845
        vf_loss: 0.034253302961587906
    load_time_ms: 2.375
    num_steps_sampled: 8500
    num_steps_trained: 8500
    sample_time_ms: 393831.653
    update_time_ms: 4.862
  iterations_since_restore: 17
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.0
    ram_util_percent: 13.163619047619045
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 844.543711996937
    mean_inference_ms: 1.8838057727228124
    mean_processing_ms: 1.4006247058810524
  time_since_restore: 7240.743561267853
  time_this_iter_s: 367.80883622169495
  time_total_s: 7240.743561267853
  timestamp: 1637966511
  timesteps_since_restore: 8500
  timesteps_this_iter: 500
  timesteps_total: 8500
  training_iteration: 17
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     17 |          7240.74 | 8500 |  0.48796 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_16-48-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8855345911949686
  episode_reward_mean: 0.48312147656683185
  episode_reward_min: -1.853968253968254
  episodes_this_iter: 500
  episodes_total: 9000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1631.247
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.901674747467041
        entropy_coeff: 0.0
        kl: 0.009037962183356285
        model: {}
        policy_loss: -0.059099841862916946
        total_loss: -0.016752079129219055
        vf_explained_var: 0.445715993642807
        vf_loss: 0.0331968292593956
    load_time_ms: 2.341
    num_steps_sampled: 9000
    num_steps_trained: 9000
    sample_time_ms: 389301.58
    update_time_ms: 4.84
  iterations_since_restore: 18
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.030492424242423
    ram_util_percent: 13.157954545454544
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 838.3867365031124
    mean_inference_ms: 1.8818342424792565
    mean_processing_ms: 1.3990829738163044
  time_since_restore: 7610.959516525269
  time_this_iter_s: 370.21595525741577
  time_total_s: 7610.959516525269
  timestamp: 1637966881
  timesteps_since_restore: 9000
  timesteps_this_iter: 500
  timesteps_total: 9000
  training_iteration: 18
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     18 |          7610.96 | 9000 | 0.483121 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_16-54-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722760290556901
  episode_reward_mean: 0.4927511208795977
  episode_reward_min: -1.8240343347639485
  episodes_this_iter: 500
  episodes_total: 9500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1616.298
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.8001530170440674
        entropy_coeff: 0.0
        kl: 0.008129797875881195
        model: {}
        policy_loss: -0.05539426952600479
        total_loss: -0.022608600556850433
        vf_explained_var: 0.5022688508033752
        vf_loss: 0.02455425076186657
    load_time_ms: 2.386
    num_steps_sampled: 9500
    num_steps_trained: 9500
    sample_time_ms: 382717.311
    update_time_ms: 4.871
  iterations_since_restore: 19
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.861657032755298
    ram_util_percent: 13.140655105973021
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 832.2452489055721
    mean_inference_ms: 1.8793453531332507
    mean_processing_ms: 1.3964981195136452
  time_since_restore: 7974.976033210754
  time_this_iter_s: 364.01651668548584
  time_total_s: 7974.976033210754
  timestamp: 1637967245
  timesteps_since_restore: 9500
  timesteps_this_iter: 500
  timesteps_total: 9500
  training_iteration: 19
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+--------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     19 |          7974.98 | 9500 | 0.492751 |
+-------------------+----------+--------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_17-00-24
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.4993891634478579
  episode_reward_min: -0.6794258373205742
  episodes_this_iter: 500
  episodes_total: 10000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1617.498
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.6822998523712158
        entropy_coeff: 0.0
        kl: 0.009741073474287987
        model: {}
        policy_loss: -0.07251781970262527
        total_loss: -0.044458478689193726
        vf_explained_var: 0.5325021147727966
        vf_loss: 0.018196504563093185
    load_time_ms: 2.375
    num_steps_sampled: 10000
    num_steps_trained: 10000
    sample_time_ms: 380333.617
    update_time_ms: 4.927
  iterations_since_restore: 20
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.980961182994456
    ram_util_percent: 13.156007393715342
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 828.2056444347552
    mean_inference_ms: 1.877989176332611
    mean_processing_ms: 1.3963284343257565
  time_since_restore: 8354.075517416
  time_this_iter_s: 379.099484205246
  time_total_s: 8354.075517416
  timestamp: 1637967624
  timesteps_since_restore: 10000
  timesteps_this_iter: 500
  timesteps_total: 10000
  training_iteration: 20
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     20 |          8354.08 | 10000 | 0.499389 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_17-06-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8650306748466258
  episode_reward_mean: 0.47228985374221155
  episode_reward_min: -3.2925925925925927
  episodes_this_iter: 500
  episodes_total: 10500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1632.984
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.7425123453140259
        entropy_coeff: 0.0
        kl: 0.007055049762129784
        model: {}
        policy_loss: -0.04640914499759674
        total_loss: 0.005510656628757715
        vf_explained_var: 0.4262678921222687
        vf_loss: 0.0447765551507473
    load_time_ms: 2.375
    num_steps_sampled: 10500
    num_steps_trained: 10500
    sample_time_ms: 375037.478
    update_time_ms: 4.964
  iterations_since_restore: 21
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.123306772908366
    ram_util_percent: 13.154780876494021
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 821.895926966575
    mean_inference_ms: 1.8762279131244268
    mean_processing_ms: 1.3948025652118299
  time_since_restore: 8705.442117452621
  time_this_iter_s: 351.3666000366211
  time_total_s: 8705.442117452621
  timestamp: 1637967976
  timesteps_since_restore: 10500
  timesteps_this_iter: 500
  timesteps_total: 10500
  training_iteration: 21
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     21 |          8705.44 | 10500 |  0.47229 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_17-11-59
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610634648370498
  episode_reward_mean: 0.46637237961957295
  episode_reward_min: -1.3791469194312795
  episodes_this_iter: 500
  episodes_total: 11000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1628.587
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.6274962425231934
        entropy_coeff: 0.0
        kl: 0.010500438511371613
        model: {}
        policy_loss: -0.06401211023330688
        total_loss: -0.02354452572762966
        vf_explained_var: 0.5183203220367432
        vf_loss: 0.0298358965665102
    load_time_ms: 2.38
    num_steps_sampled: 11000
    num_steps_trained: 11000
    sample_time_ms: 369709.946
    update_time_ms: 5.1
  iterations_since_restore: 22
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.933128834355827
    ram_util_percent: 13.160122699386502
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 815.4271814066998
    mean_inference_ms: 1.8741475290715097
    mean_processing_ms: 1.392827772160095
  time_since_restore: 9048.668890953064
  time_this_iter_s: 343.2267735004425
  time_total_s: 9048.668890953064
  timestamp: 1637968319
  timesteps_since_restore: 11000
  timesteps_this_iter: 500
  timesteps_total: 11000
  training_iteration: 22
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     22 |          9048.67 | 11000 | 0.466372 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_17-17-38
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.875
  episode_reward_mean: 0.46606609777847063
  episode_reward_min: -2.6144578313253013
  episodes_this_iter: 500
  episodes_total: 11500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1615.66
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.5251044034957886
        entropy_coeff: 0.0
        kl: 0.007366608828306198
        model: {}
        policy_loss: -0.04810503497719765
        total_loss: 0.0014201987069100142
        vf_explained_var: 0.43557456135749817
        vf_loss: 0.0420665368437767
    load_time_ms: 2.412
    num_steps_sampled: 11500
    num_steps_trained: 11500
    sample_time_ms: 364267.793
    update_time_ms: 5.271
  iterations_since_restore: 23
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.05103305785124
    ram_util_percent: 13.124380165289255
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 809.1869745427824
    mean_inference_ms: 1.8711158083103172
    mean_processing_ms: 1.3911530677364887
  time_since_restore: 9387.76360821724
  time_this_iter_s: 339.0947172641754
  time_total_s: 9387.76360821724
  timestamp: 1637968658
  timesteps_since_restore: 11500
  timesteps_this_iter: 500
  timesteps_total: 11500
  training_iteration: 23
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     23 |          9387.76 | 11500 | 0.466066 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_17-23-13
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.48010949277390214
  episode_reward_min: -1.5076142131979695
  episodes_this_iter: 500
  episodes_total: 12000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1597.968
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.4389985799789429
        entropy_coeff: 0.0
        kl: 0.006594141013920307
        model: {}
        policy_loss: -0.05664975941181183
        total_loss: -0.026427974924445152
        vf_explained_var: 0.48015257716178894
        vf_loss: 0.023545222356915474
    load_time_ms: 2.435
    num_steps_sampled: 12000
    num_steps_trained: 12000
    sample_time_ms: 358854.747
    update_time_ms: 5.36
  iterations_since_restore: 24
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.11234309623431
    ram_util_percent: 13.142677824267778
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 803.1137266533344
    mean_inference_ms: 1.8681693937309418
    mean_processing_ms: 1.388765058858366
  time_since_restore: 9722.73890542984
  time_this_iter_s: 334.9752972126007
  time_total_s: 9722.73890542984
  timestamp: 1637968993
  timesteps_since_restore: 12000
  timesteps_this_iter: 500
  timesteps_total: 12000
  training_iteration: 24
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     24 |          9722.74 | 12000 | 0.480109 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_17-28-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8631578947368421
  episode_reward_mean: 0.47589099845340976
  episode_reward_min: -4.605113636363637
  episodes_this_iter: 500
  episodes_total: 12500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1587.031
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.435325026512146
        entropy_coeff: 0.0
        kl: 0.0045650554820895195
        model: {}
        policy_loss: -0.03646228462457657
        total_loss: 0.02518691122531891
        vf_explained_var: 0.47992002964019775
        vf_loss: 0.05702707916498184
    load_time_ms: 2.5
    num_steps_sampled: 12500
    num_steps_trained: 12500
    sample_time_ms: 353153.22
    update_time_ms: 5.26
  iterations_since_restore: 25
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.050335570469798
    ram_util_percent: 13.176733780760623
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 795.7695983007578
    mean_inference_ms: 1.8636527876597992
    mean_processing_ms: 1.3858285982812295
  time_since_restore: 10035.649961471558
  time_this_iter_s: 312.91105604171753
  time_total_s: 10035.649961471558
  timestamp: 1637969306
  timesteps_since_restore: 12500
  timesteps_this_iter: 500
  timesteps_total: 12500
  training_iteration: 25
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     25 |          10035.6 | 12500 | 0.475891 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_17-33-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.4875056513186972
  episode_reward_min: -0.7477477477477478
  episodes_this_iter: 500
  episodes_total: 13000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1575.835
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.3577369451522827
        entropy_coeff: 0.0
        kl: 0.00979449413716793
        model: {}
        policy_loss: -0.05369649827480316
        total_loss: -0.03420163318514824
        vf_explained_var: 0.5976009964942932
        vf_loss: 0.014536399394273758
    load_time_ms: 2.48
    num_steps_sampled: 13000
    num_steps_trained: 13000
    sample_time_ms: 345133.552
    update_time_ms: 5.132
  iterations_since_restore: 26
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.157142857142857
    ram_util_percent: 13.197004608294927
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 788.3521829070648
    mean_inference_ms: 1.8594003660790182
    mean_processing_ms: 1.3830281433605447
  time_since_restore: 10340.192844867706
  time_this_iter_s: 304.5428833961487
  time_total_s: 10340.192844867706
  timestamp: 1637969611
  timesteps_since_restore: 13000
  timesteps_this_iter: 500
  timesteps_total: 13000
  training_iteration: 26
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     26 |          10340.2 | 13000 | 0.487506 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_17-38-36
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.4635884592037593
  episode_reward_min: -1.3566666666666667
  episodes_this_iter: 500
  episodes_total: 13500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1589.026
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.3803315162658691
        entropy_coeff: 0.0
        kl: 0.011650937609374523
        model: {}
        policy_loss: -0.059826064854860306
        total_loss: -0.028085432946681976
        vf_explained_var: 0.5523769855499268
        vf_loss: 0.025842344388365746
    load_time_ms: 2.447
    num_steps_sampled: 13500
    num_steps_trained: 13500
    sample_time_ms: 338865.541
    update_time_ms: 5.142
  iterations_since_restore: 27
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.045183486238532
    ram_util_percent: 13.139678899082563
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 781.516105649595
    mean_inference_ms: 1.8563082320417665
    mean_processing_ms: 1.379383589530749
  time_since_restore: 10645.453279972076
  time_this_iter_s: 305.2604351043701
  time_total_s: 10645.453279972076
  timestamp: 1637969916
  timesteps_since_restore: 13500
  timesteps_this_iter: 500
  timesteps_total: 13500
  training_iteration: 27
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     27 |          10645.5 | 13500 | 0.463588 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_17-43-37
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647058823529412
  episode_reward_mean: 0.4874406295930597
  episode_reward_min: -1.5
  episodes_this_iter: 500
  episodes_total: 14000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1589.235
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.3025016784667969
        entropy_coeff: 0.0
        kl: 0.010200283490121365
        model: {}
        policy_loss: -0.06425344198942184
        total_loss: -0.04113859310746193
        vf_explained_var: 0.5462670922279358
        vf_loss: 0.017950961366295815
    load_time_ms: 2.468
    num_steps_sampled: 14000
    num_steps_trained: 14000
    sample_time_ms: 331895.035
    update_time_ms: 5.196
  iterations_since_restore: 28
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.970862470862471
    ram_util_percent: 13.157575757575755
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 774.8385622419464
    mean_inference_ms: 1.8516027895895621
    mean_processing_ms: 1.3753328738182955
  time_since_restore: 10945.966920375824
  time_this_iter_s: 300.51364040374756
  time_total_s: 10945.966920375824
  timestamp: 1637970217
  timesteps_since_restore: 14000
  timesteps_this_iter: 500
  timesteps_total: 14000
  training_iteration: 28
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     28 |            10946 | 14000 | 0.487441 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_17-48-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8377581120943953
  episode_reward_mean: 0.48675412765270776
  episode_reward_min: -0.33766233766233766
  episodes_this_iter: 500
  episodes_total: 14500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1606.472
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.3319604396820068
        entropy_coeff: 0.0
        kl: 0.012117507867515087
        model: {}
        policy_loss: -0.062170252203941345
        total_loss: -0.041023384779691696
        vf_explained_var: 0.5772370100021362
        vf_loss: 0.015012369491159916
    load_time_ms: 2.442
    num_steps_sampled: 14500
    num_steps_trained: 14500
    sample_time_ms: 322590.678
    update_time_ms: 5.247
  iterations_since_restore: 29
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.806976744186047
    ram_util_percent: 13.171059431524546
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 766.5985962183967
    mean_inference_ms: 1.8463651029564299
    mean_processing_ms: 1.3702850770591894
  time_since_restore: 11217.112217187881
  time_this_iter_s: 271.1452968120575
  time_total_s: 11217.112217187881
  timestamp: 1637970488
  timesteps_since_restore: 14500
  timesteps_this_iter: 500
  timesteps_total: 14500
  training_iteration: 29
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     29 |          11217.1 | 14500 | 0.486754 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_17-52-36
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8629441624365483
  episode_reward_mean: 0.4911212021733846
  episode_reward_min: -0.32275132275132273
  episodes_this_iter: 500
  episodes_total: 15000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1615.288
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.2721103429794312
        entropy_coeff: 0.0
        kl: 0.011108546517789364
        model: {}
        policy_loss: -0.061122335493564606
        total_loss: -0.04108112305402756
        vf_explained_var: 0.5659359097480774
        vf_loss: 0.014417513273656368
    load_time_ms: 2.441
    num_steps_sampled: 15000
    num_steps_trained: 15000
    sample_time_ms: 311527.608
    update_time_ms: 5.253
  iterations_since_restore: 30
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.845691906005221
    ram_util_percent: 13.15718015665796
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 758.7301631298361
    mean_inference_ms: 1.8406675446948149
    mean_processing_ms: 1.3659530286431019
  time_since_restore: 11485.669307947159
  time_this_iter_s: 268.55709075927734
  time_total_s: 11485.669307947159
  timestamp: 1637970756
  timesteps_since_restore: 15000
  timesteps_this_iter: 500
  timesteps_total: 15000
  training_iteration: 30
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     30 |          11485.7 | 15000 | 0.491121 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_17-57-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8840399002493765
  episode_reward_mean: 0.4931557613918301
  episode_reward_min: -0.5708154506437768
  episodes_this_iter: 500
  episodes_total: 15500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1593.466
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.2082656621932983
        entropy_coeff: 0.0
        kl: 0.014189604669809341
        model: {}
        policy_loss: -0.0645408183336258
        total_loss: -0.04045432433485985
        vf_explained_var: 0.5226728916168213
        vf_loss: 0.016903003677725792
    load_time_ms: 2.433
    num_steps_sampled: 15500
    num_steps_trained: 15500
    sample_time_ms: 303157.082
    update_time_ms: 5.346
  iterations_since_restore: 31
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.971391076115486
    ram_util_percent: 13.176377952755903
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 751.3020131658889
    mean_inference_ms: 1.837616281796713
    mean_processing_ms: 1.3637697609783983
  time_since_restore: 11753.112950086594
  time_this_iter_s: 267.4436421394348
  time_total_s: 11753.112950086594
  timestamp: 1637971024
  timesteps_since_restore: 15500
  timesteps_this_iter: 500
  timesteps_total: 15500
  training_iteration: 31
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     31 |          11753.1 | 15500 | 0.493156 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-01-43
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8662790697674418
  episode_reward_mean: 0.45408775361114234
  episode_reward_min: -0.7033492822966507
  episodes_this_iter: 500
  episodes_total: 16000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1582.342
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.1661086082458496
        entropy_coeff: 0.0
        kl: 0.009163920767605305
        model: {}
        policy_loss: -0.056039225310087204
        total_loss: -0.030985616147518158
        vf_explained_var: 0.5703677535057068
        vf_loss: 0.020414363592863083
    load_time_ms: 2.426
    num_steps_sampled: 16000
    num_steps_trained: 16000
    sample_time_ms: 296761.342
    update_time_ms: 5.5
  iterations_since_restore: 32
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.040601503759396
    ram_util_percent: 13.22055137844611
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 745.0627921693108
    mean_inference_ms: 1.8374837344083617
    mean_processing_ms: 1.363809164907998
  time_since_restore: 12032.273502111435
  time_this_iter_s: 279.1605520248413
  time_total_s: 12032.273502111435
  timestamp: 1637971303
  timesteps_since_restore: 16000
  timesteps_this_iter: 500
  timesteps_total: 16000
  training_iteration: 32
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     32 |          12032.3 | 16000 | 0.454088 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-05-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9664360370970116
  episode_reward_mean: 0.4764881426068344
  episode_reward_min: -1.072936660268714
  episodes_this_iter: 500
  episodes_total: 16500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1592.538
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.1121214628219604
        entropy_coeff: 0.0
        kl: 0.009368982166051865
        model: {}
        policy_loss: -0.05869332328438759
        total_loss: -0.02582196518778801
        vf_explained_var: 0.5100535750389099
        vf_loss: 0.028128309175372124
    load_time_ms: 2.443
    num_steps_sampled: 16500
    num_steps_trained: 16500
    sample_time_ms: 287388.525
    update_time_ms: 5.389
  iterations_since_restore: 33
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.916857142857141
    ram_util_percent: 13.160857142857141
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 737.1704127599121
    mean_inference_ms: 1.8344804681609541
    mean_processing_ms: 1.3605113983385482
  time_since_restore: 12277.742015361786
  time_this_iter_s: 245.46851325035095
  time_total_s: 12277.742015361786
  timestamp: 1637971549
  timesteps_since_restore: 16500
  timesteps_this_iter: 500
  timesteps_total: 16500
  training_iteration: 33
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     33 |          12277.7 | 16500 | 0.476488 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-10-25
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8855345911949686
  episode_reward_mean: 0.46580362599612407
  episode_reward_min: -0.6887417218543046
  episodes_this_iter: 500
  episodes_total: 17000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1602.982
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.14690363407135
        entropy_coeff: 0.0
        kl: 0.007583274971693754
        model: {}
        policy_loss: -0.04559273645281792
        total_loss: -0.01799866557121277
        vf_explained_var: 0.5425485968589783
        vf_loss: 0.023755047470331192
    load_time_ms: 2.478
    num_steps_sampled: 17000
    num_steps_trained: 17000
    sample_time_ms: 281550.769
    update_time_ms: 5.281
  iterations_since_restore: 34
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.846835443037975
    ram_util_percent: 13.16556962025316
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 731.5641859055798
    mean_inference_ms: 1.834996594631576
    mean_processing_ms: 1.3615188931838238
  time_since_restore: 12554.44556427002
  time_this_iter_s: 276.70354890823364
  time_total_s: 12554.44556427002
  timestamp: 1637971825
  timesteps_since_restore: 17000
  timesteps_this_iter: 500
  timesteps_total: 17000
  training_iteration: 34
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     34 |          12554.4 | 17000 | 0.465804 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-14-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8801075268817204
  episode_reward_mean: 0.481787467669715
  episode_reward_min: -1.1358936484490398
  episodes_this_iter: 500
  episodes_total: 17500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1606.051
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.1248360872268677
        entropy_coeff: 0.0
        kl: 0.007527817506343126
        model: {}
        policy_loss: -0.04387766867876053
        total_loss: -0.022765062749385834
        vf_explained_var: 0.5936671495437622
        vf_loss: 0.0173016544431448
    load_time_ms: 2.467
    num_steps_sampled: 17500
    num_steps_trained: 17500
    sample_time_ms: 272272.479
    update_time_ms: 5.389
  iterations_since_restore: 35
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.010828025477705
    ram_util_percent: 13.169426751592356
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 723.0615790493387
    mean_inference_ms: 1.8324228731075503
    mean_processing_ms: 1.3596129467825053
  time_since_restore: 12774.60435128212
  time_this_iter_s: 220.15878701210022
  time_total_s: 12774.60435128212
  timestamp: 1637972046
  timesteps_since_restore: 17500
  timesteps_this_iter: 500
  timesteps_total: 17500
  training_iteration: 35
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     35 |          12774.6 | 17500 | 0.481787 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-17-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.4783994563842482
  episode_reward_min: -0.031746031746031744
  episodes_this_iter: 500
  episodes_total: 18000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1616.398
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.115238070487976
        entropy_coeff: 0.0
        kl: 0.010502215474843979
        model: {}
        policy_loss: -0.04690687358379364
        total_loss: -0.028149448335170746
        vf_explained_var: 0.611792802810669
        vf_loss: 0.013440677896142006
    load_time_ms: 2.539
    num_steps_sampled: 18000
    num_steps_trained: 18000
    sample_time_ms: 264392.265
    update_time_ms: 5.457
  iterations_since_restore: 36
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.918322981366458
    ram_util_percent: 13.200310559006208
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 715.3465261751263
    mean_inference_ms: 1.8299143153173072
    mean_processing_ms: 1.3581362375119852
  time_since_restore: 13000.450214624405
  time_this_iter_s: 225.84586334228516
  time_total_s: 13000.450214624405
  timestamp: 1637972272
  timesteps_since_restore: 18000
  timesteps_this_iter: 500
  timesteps_total: 18000
  training_iteration: 36
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     36 |          13000.5 | 18000 | 0.478399 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-21-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8571428571428571
  episode_reward_mean: 0.45291649210366874
  episode_reward_min: -1.053763440860215
  episodes_this_iter: 500
  episodes_total: 18500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1599.849
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.1073777675628662
        entropy_coeff: 0.0
        kl: 0.01012534648180008
        model: {}
        policy_loss: -0.05692783370614052
        total_loss: -0.03305301070213318
        vf_explained_var: 0.5933658480644226
        vf_loss: 0.01874886080622673
    load_time_ms: 2.547
    num_steps_sampled: 18500
    num_steps_trained: 18500
    sample_time_ms: 257599.86
    update_time_ms: 5.517
  iterations_since_restore: 37
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.057227138643066
    ram_util_percent: 13.239528023598817
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 708.6593849092848
    mean_inference_ms: 1.828240482274033
    mean_processing_ms: 1.356400487796789
  time_since_restore: 13237.622604370117
  time_this_iter_s: 237.17238974571228
  time_total_s: 13237.622604370117
  timestamp: 1637972509
  timesteps_since_restore: 18500
  timesteps_this_iter: 500
  timesteps_total: 18500
  training_iteration: 37
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     37 |          13237.6 | 18500 | 0.452916 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-25-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610634648370498
  episode_reward_mean: 0.4522432074665692
  episode_reward_min: -2.274390243902439
  episodes_this_iter: 500
  episodes_total: 19000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1590.476
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.0694059133529663
        entropy_coeff: 0.0
        kl: 0.007300279568880796
        model: {}
        policy_loss: -0.04481823369860649
        total_loss: -0.01346531230956316
        vf_explained_var: 0.5831762552261353
        vf_loss: 0.027657151222229004
    load_time_ms: 2.539
    num_steps_sampled: 19000
    num_steps_trained: 19000
    sample_time_ms: 248479.376
    update_time_ms: 5.655
  iterations_since_restore: 38
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.974161073825504
    ram_util_percent: 13.175167785234898
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 700.8557672983949
    mean_inference_ms: 1.8253309351162843
    mean_processing_ms: 1.3545561035045426
  time_since_restore: 13446.838948249817
  time_this_iter_s: 209.2163438796997
  time_total_s: 13446.838948249817
  timestamp: 1637972718
  timesteps_since_restore: 19000
  timesteps_this_iter: 500
  timesteps_total: 19000
  training_iteration: 38
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     38 |          13446.8 | 19000 | 0.452243 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-28-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8659476117103235
  episode_reward_mean: 0.46723947634902113
  episode_reward_min: -1.2507374631268438
  episodes_this_iter: 500
  episodes_total: 19500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1585.941
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.018610954284668
        entropy_coeff: 0.0
        kl: 0.008411427959799767
        model: {}
        policy_loss: -0.04812850430607796
        total_loss: -0.021563353016972542
        vf_explained_var: 0.5659559369087219
        vf_loss: 0.022306866943836212
    load_time_ms: 2.567
    num_steps_sampled: 19500
    num_steps_trained: 19500
    sample_time_ms: 242739.562
    update_time_ms: 5.572
  iterations_since_restore: 39
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.09344262295082
    ram_util_percent: 13.190819672131147
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 693.6805710035267
    mean_inference_ms: 1.8223943260900615
    mean_processing_ms: 1.3525009179725376
  time_since_restore: 13660.540711402893
  time_this_iter_s: 213.70176315307617
  time_total_s: 13660.540711402893
  timestamp: 1637972932
  timesteps_since_restore: 19500
  timesteps_this_iter: 500
  timesteps_total: 19500
  training_iteration: 39
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     39 |          13660.5 | 19500 | 0.467239 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-32-15
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.46180769232951796
  episode_reward_min: -1.8597014925373134
  episodes_this_iter: 500
  episodes_total: 20000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1567.097
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.9281771183013916
        entropy_coeff: 0.0
        kl: 0.009243949316442013
        model: {}
        policy_loss: -0.04594530537724495
        total_loss: -0.01152048259973526
        vf_explained_var: 0.4890650808811188
        vf_loss: 0.029745083302259445
    load_time_ms: 2.568
    num_steps_sampled: 20000
    num_steps_trained: 20000
    sample_time_ms: 236190.017
    update_time_ms: 5.517
  iterations_since_restore: 40
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.160344827586206
    ram_util_percent: 13.17448275862069
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 686.327692389661
    mean_inference_ms: 1.8185517840502012
    mean_processing_ms: 1.3495316106577788
  time_since_restore: 13863.413476228714
  time_this_iter_s: 202.87276482582092
  time_total_s: 13863.413476228714
  timestamp: 1637973135
  timesteps_since_restore: 20000
  timesteps_this_iter: 500
  timesteps_total: 20000
  training_iteration: 40
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     40 |          13863.4 | 20000 | 0.461808 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-35-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8650568181818182
  episode_reward_mean: 0.4676506024196633
  episode_reward_min: -1.1428571428571428
  episodes_this_iter: 500
  episodes_total: 20500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1567.318
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.9425926804542542
        entropy_coeff: 0.0
        kl: 0.007324468344449997
        model: {}
        policy_loss: -0.03912406787276268
        total_loss: -0.015629222616553307
        vf_explained_var: 0.5477720499038696
        vf_loss: 0.019786830991506577
    load_time_ms: 2.574
    num_steps_sampled: 20500
    num_steps_trained: 20500
    sample_time_ms: 229162.893
    update_time_ms: 5.514
  iterations_since_restore: 41
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.953380782918149
    ram_util_percent: 13.190747330960852
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 679.0516623275627
    mean_inference_ms: 1.8152422826119523
    mean_processing_ms: 1.3474802535706325
  time_since_restore: 14060.588264465332
  time_this_iter_s: 197.17478823661804
  time_total_s: 14060.588264465332
  timestamp: 1637973332
  timesteps_since_restore: 20500
  timesteps_this_iter: 500
  timesteps_total: 20500
  training_iteration: 41
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     41 |          14060.6 | 20500 | 0.467651 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-38-29
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8624161073825504
  episode_reward_mean: 0.4919744029664411
  episode_reward_min: -0.21164021164021163
  episodes_this_iter: 500
  episodes_total: 21000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1569.707
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.9006162285804749
        entropy_coeff: 0.0
        kl: 0.009387649595737457
        model: {}
        policy_loss: -0.04887969046831131
        total_loss: -0.03138427436351776
        vf_explained_var: 0.5856804847717285
        vf_loss: 0.012742932885885239
    load_time_ms: 2.553
    num_steps_sampled: 21000
    num_steps_trained: 21000
    sample_time_ms: 218956.45
    update_time_ms: 5.377
  iterations_since_restore: 42
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.938735177865613
    ram_util_percent: 13.290909090909091
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 671.1735469739463
    mean_inference_ms: 1.807657606652462
    mean_processing_ms: 1.3410078503450813
  time_since_restore: 14237.706361532211
  time_this_iter_s: 177.11809706687927
  time_total_s: 14237.706361532211
  timestamp: 1637973509
  timesteps_since_restore: 21000
  timesteps_this_iter: 500
  timesteps_total: 21000
  training_iteration: 42
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     42 |          14237.7 | 21000 | 0.491974 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-41-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.48577609879917055
  episode_reward_min: -0.1820388349514563
  episodes_this_iter: 500
  episodes_total: 21500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1580.911
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.9396717548370361
        entropy_coeff: 0.0
        kl: 0.01093238964676857
        model: {}
        policy_loss: -0.05100153386592865
        total_loss: -0.0348365381360054
        vf_explained_var: 0.6478650569915771
        vf_loss: 0.010630463249981403
    load_time_ms: 2.522
    num_steps_sampled: 21500
    num_steps_trained: 21500
    sample_time_ms: 211450.583
    update_time_ms: 5.385
  iterations_since_restore: 43
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.778600823045268
    ram_util_percent: 13.21975308641975
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 663.3541416907876
    mean_inference_ms: 1.800383142491096
    mean_processing_ms: 1.3348482735273115
  time_since_restore: 14408.226482152939
  time_this_iter_s: 170.52012062072754
  time_total_s: 14408.226482152939
  timestamp: 1637973680
  timesteps_since_restore: 21500
  timesteps_this_iter: 500
  timesteps_total: 21500
  training_iteration: 43
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     43 |          14408.2 | 21500 | 0.485776 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-44-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.4913146454410313
  episode_reward_min: -0.33766233766233766
  episodes_this_iter: 500
  episodes_total: 22000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1568.803
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.9195278882980347
        entropy_coeff: 0.0
        kl: 0.007968573831021786
        model: {}
        policy_loss: -0.04413952678442001
        total_loss: -0.028003010898828506
        vf_explained_var: 0.6127616763114929
        vf_loss: 0.012102422304451466
    load_time_ms: 2.47
    num_steps_sampled: 22000
    num_steps_trained: 22000
    sample_time_ms: 200213.95
    update_time_ms: 5.482
  iterations_since_restore: 44
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.95531914893617
    ram_util_percent: 13.237446808510636
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 655.6085807876932
    mean_inference_ms: 1.7929310462923567
    mean_processing_ms: 1.3289798265651953
  time_since_restore: 14572.440598249435
  time_this_iter_s: 164.21411609649658
  time_total_s: 14572.440598249435
  timestamp: 1637973844
  timesteps_since_restore: 22000
  timesteps_this_iter: 500
  timesteps_total: 22000
  training_iteration: 44
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     44 |          14572.4 | 22000 | 0.491315 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-46-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8690476190476191
  episode_reward_mean: 0.4953112575536734
  episode_reward_min: -1.8347457627118644
  episodes_this_iter: 500
  episodes_total: 22500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1579.193
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.9499552845954895
        entropy_coeff: 0.0
        kl: 0.008547878824174404
        model: {}
        policy_loss: -0.03463425859808922
        total_loss: -0.010136132128536701
        vf_explained_var: 0.5546562075614929
        vf_loss: 0.020170750096440315
    load_time_ms: 2.415
    num_steps_sampled: 22500
    num_steps_trained: 22500
    sample_time_ms: 194183.62
    update_time_ms: 5.492
  iterations_since_restore: 45
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.937280701754386
    ram_util_percent: 13.216228070175438
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 648.0150371756819
    mean_inference_ms: 1.7856516354264467
    mean_processing_ms: 1.3230412987877354
  time_since_restore: 14732.399390935898
  time_this_iter_s: 159.9587926864624
  time_total_s: 14732.399390935898
  timestamp: 1637974004
  timesteps_since_restore: 22500
  timesteps_this_iter: 500
  timesteps_total: 22500
  training_iteration: 45
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     45 |          14732.4 | 22500 | 0.495311 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-49-13
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8737580362361193
  episode_reward_mean: 0.5092341275621792
  episode_reward_min: 0.125
  episodes_this_iter: 500
  episodes_total: 23000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1574.821
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.8511906266212463
        entropy_coeff: 0.0
        kl: 0.009389454498887062
        model: {}
        policy_loss: -0.04360256344079971
        total_loss: -0.028965940698981285
        vf_explained_var: 0.6405237317085266
        vf_loss: 0.009883209131658077
    load_time_ms: 2.359
    num_steps_sampled: 23000
    num_steps_trained: 23000
    sample_time_ms: 186499.054
    update_time_ms: 5.595
  iterations_since_restore: 46
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.678403755868544
    ram_util_percent: 13.211737089201877
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 640.2796983128036
    mean_inference_ms: 1.7785294917006989
    mean_processing_ms: 1.3172645049739686
  time_since_restore: 14881.355691432953
  time_this_iter_s: 148.95630049705505
  time_total_s: 14881.355691432953
  timestamp: 1637974153
  timesteps_since_restore: 23000
  timesteps_this_iter: 500
  timesteps_total: 23000
  training_iteration: 46
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     46 |          14881.4 | 23000 | 0.509234 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-51-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8840399002493765
  episode_reward_mean: 0.49024142806385657
  episode_reward_min: -0.15421686746987953
  episodes_this_iter: 500
  episodes_total: 23500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1583.779
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.8632141947746277
        entropy_coeff: 0.0
        kl: 0.006537765264511108
        model: {}
        policy_loss: -0.02883043698966503
        total_loss: -0.008217666298151016
        vf_explained_var: 0.49459129571914673
        vf_loss: 0.01730302721261978
    load_time_ms: 2.364
    num_steps_sampled: 23500
    num_steps_trained: 23500
    sample_time_ms: 176865.954
    update_time_ms: 5.594
  iterations_since_restore: 47
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.890547263681592
    ram_util_percent: 13.261194029850746
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 632.5264684565853
    mean_inference_ms: 1.771033193186432
    mean_processing_ms: 1.3114405532557076
  time_since_restore: 15022.285564899445
  time_this_iter_s: 140.9298734664917
  time_total_s: 15022.285564899445
  timestamp: 1637974294
  timesteps_since_restore: 23500
  timesteps_this_iter: 500
  timesteps_total: 23500
  training_iteration: 47
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     47 |          15022.3 | 23500 | 0.490241 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-53-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8789968652037617
  episode_reward_mean: 0.4931345811043267
  episode_reward_min: -1.7835616438356163
  episodes_this_iter: 500
  episodes_total: 24000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1588.943
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.8175121545791626
        entropy_coeff: 0.0
        kl: 0.006664752960205078
        model: {}
        policy_loss: -0.042829480022192
        total_loss: -0.014091065153479576
        vf_explained_var: 0.5660479068756104
        vf_loss: 0.025364376604557037
    load_time_ms: 2.386
    num_steps_sampled: 24000
    num_steps_trained: 24000
    sample_time_ms: 168363.179
    update_time_ms: 5.577
  iterations_since_restore: 48
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.179096045197742
    ram_util_percent: 13.219209039548023
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 624.4045602426468
    mean_inference_ms: 1.7639123659859866
    mean_processing_ms: 1.3047377023442197
  time_since_restore: 15146.525344133377
  time_this_iter_s: 124.2397792339325
  time_total_s: 15146.525344133377
  timestamp: 1637974419
  timesteps_since_restore: 24000
  timesteps_this_iter: 500
  timesteps_total: 24000
  training_iteration: 48
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     48 |          15146.5 | 24000 | 0.493135 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-55-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9664360370970116
  episode_reward_mean: 0.5068078750588041
  episode_reward_min: -0.15955056179775282
  episodes_this_iter: 500
  episodes_total: 24500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1592.035
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.8254855871200562
        entropy_coeff: 0.0
        kl: 0.008630078285932541
        model: {}
        policy_loss: -0.044429369270801544
        total_loss: -0.025513090193271637
        vf_explained_var: 0.519827127456665
        vf_loss: 0.014547305181622505
    load_time_ms: 2.368
    num_steps_sampled: 24500
    num_steps_trained: 24500
    sample_time_ms: 160144.946
    update_time_ms: 5.729
  iterations_since_restore: 49
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.936170212765957
    ram_util_percent: 13.223936170212768
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 616.911733312503
    mean_inference_ms: 1.7565121227787694
    mean_processing_ms: 1.298635668922145
  time_since_restore: 15278.076860666275
  time_this_iter_s: 131.55151653289795
  time_total_s: 15278.076860666275
  timestamp: 1637974550
  timesteps_since_restore: 24500
  timesteps_this_iter: 500
  timesteps_total: 24500
  training_iteration: 49
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     49 |          15278.1 | 24500 | 0.506808 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_18-58-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8751733703190014
  episode_reward_mean: 0.49317573389663605
  episode_reward_min: -1.0829493087557605
  episodes_this_iter: 500
  episodes_total: 25000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1607.588
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.874951958656311
        entropy_coeff: 0.0
        kl: 0.007570029702037573
        model: {}
        policy_loss: -0.03928953781723976
        total_loss: -0.012842911295592785
        vf_explained_var: 0.49692654609680176
        vf_loss: 0.022614292800426483
    load_time_ms: 2.365
    num_steps_sampled: 25000
    num_steps_trained: 25000
    sample_time_ms: 153977.501
    update_time_ms: 5.734
  iterations_since_restore: 50
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.164356435643564
    ram_util_percent: 13.205445544554454
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 610.106533810852
    mean_inference_ms: 1.7500389271233348
    mean_processing_ms: 1.2936371621368052
  time_since_restore: 15419.430596351624
  time_this_iter_s: 141.3537356853485
  time_total_s: 15419.430596351624
  timestamp: 1637974692
  timesteps_since_restore: 25000
  timesteps_this_iter: 500
  timesteps_total: 25000
  training_iteration: 50
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     50 |          15419.4 | 25000 | 0.493176 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-00-25
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5053549501345075
  episode_reward_min: -0.23497267759562843
  episodes_this_iter: 500
  episodes_total: 25500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1616.651
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.8042708039283752
        entropy_coeff: 0.0
        kl: 0.009152066893875599
        model: {}
        policy_loss: -0.04738679900765419
        total_loss: -0.028843199834227562
        vf_explained_var: 0.5772445797920227
        vf_loss: 0.013910364359617233
    load_time_ms: 2.396
    num_steps_sampled: 25500
    num_steps_trained: 25500
    sample_time_ms: 147530.002
    update_time_ms: 5.713
  iterations_since_restore: 51
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.842857142857143
    ram_util_percent: 13.227513227513228
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 603.2340912803763
    mean_inference_ms: 1.7432525510306658
    mean_processing_ms: 1.2881415791850173
  time_since_restore: 15552.22090792656
  time_this_iter_s: 132.7903115749359
  time_total_s: 15552.22090792656
  timestamp: 1637974825
  timesteps_since_restore: 25500
  timesteps_this_iter: 500
  timesteps_total: 25500
  training_iteration: 51
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     51 |          15552.2 | 25500 | 0.505355 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-02-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595166163141994
  episode_reward_mean: 0.48598446014560714
  episode_reward_min: -0.9098591549295775
  episodes_this_iter: 500
  episodes_total: 26000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1609.434
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.8630499243736267
        entropy_coeff: 0.0
        kl: 0.008448121137917042
        model: {}
        policy_loss: -0.04093528911471367
        total_loss: -0.021055908873677254
        vf_explained_var: 0.5641106963157654
        vf_loss: 0.01560251135379076
    load_time_ms: 2.445
    num_steps_sampled: 26000
    num_steps_trained: 26000
    sample_time_ms: 144621.24
    update_time_ms: 5.685
  iterations_since_restore: 52
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.090566037735849
    ram_util_percent: 13.224528301886792
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 597.212179711835
    mean_inference_ms: 1.7374123129898396
    mean_processing_ms: 1.2832946545536446
  time_since_restore: 15700.178402423859
  time_this_iter_s: 147.9574944972992
  time_total_s: 15700.178402423859
  timestamp: 1637974973
  timesteps_since_restore: 26000
  timesteps_this_iter: 500
  timesteps_total: 26000
  training_iteration: 52
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     52 |          15700.2 | 26000 | 0.485984 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-05-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610634648370498
  episode_reward_mean: 0.4658254000283772
  episode_reward_min: -1.7527472527472527
  episodes_this_iter: 500
  episodes_total: 26500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1607.577
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.831817090511322
        entropy_coeff: 0.0
        kl: 0.005448256153613329
        model: {}
        policy_loss: -0.04000464081764221
        total_loss: -0.005210955161601305
        vf_explained_var: 0.4983069896697998
        vf_loss: 0.032035503536462784
    load_time_ms: 2.428
    num_steps_sampled: 26500
    num_steps_trained: 26500
    sample_time_ms: 140610.994
    update_time_ms: 5.697
  iterations_since_restore: 53
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.855913978494623
    ram_util_percent: 13.251612903225807
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 590.753520849916
    mean_inference_ms: 1.7311699520592005
    mean_processing_ms: 1.2779630070330759
  time_since_restore: 15830.577934265137
  time_this_iter_s: 130.39953184127808
  time_total_s: 15830.577934265137
  timestamp: 1637975103
  timesteps_since_restore: 26500
  timesteps_this_iter: 500
  timesteps_total: 26500
  training_iteration: 53
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     53 |          15830.6 | 26500 | 0.465825 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-07-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8659476117103235
  episode_reward_mean: 0.47926452160268107
  episode_reward_min: -0.10810810810810811
  episodes_this_iter: 500
  episodes_total: 27000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1616.339
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.8529914617538452
        entropy_coeff: 0.0
        kl: 0.008320945315063
        model: {}
        policy_loss: -0.04390089958906174
        total_loss: -0.02872401289641857
        vf_explained_var: 0.6582041382789612
        vf_loss: 0.010964401066303253
    load_time_ms: 2.45
    num_steps_sampled: 27000
    num_steps_trained: 27000
    sample_time_ms: 136635.876
    update_time_ms: 5.886
  iterations_since_restore: 54
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.175842696629214
    ram_util_percent: 13.243258426966293
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 584.3184317912373
    mean_inference_ms: 1.7245346685457366
    mean_processing_ms: 1.2722794539239433
  time_since_restore: 15955.131424427032
  time_this_iter_s: 124.55349016189575
  time_total_s: 15955.131424427032
  timestamp: 1637975228
  timesteps_since_restore: 27000
  timesteps_this_iter: 500
  timesteps_total: 27000
  training_iteration: 54
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     54 |          15955.1 | 27000 | 0.479265 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-09-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.4976447446582415
  episode_reward_min: -0.28717948717948716
  episodes_this_iter: 500
  episodes_total: 27500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1619.138
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.7756789922714233
        entropy_coeff: 0.0
        kl: 0.007565176114439964
        model: {}
        policy_loss: -0.04434762895107269
        total_loss: -0.026652030646800995
        vf_explained_var: 0.5645002126693726
        vf_loss: 0.013865734450519085
    load_time_ms: 2.465
    num_steps_sampled: 27500
    num_steps_trained: 27500
    sample_time_ms: 132349.597
    update_time_ms: 5.94
  iterations_since_restore: 55
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.92574850299401
    ram_util_percent: 13.237724550898205
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 577.845806884946
    mean_inference_ms: 1.718485608091701
    mean_processing_ms: 1.2671277417360156
  time_since_restore: 16072.25583076477
  time_this_iter_s: 117.12440633773804
  time_total_s: 16072.25583076477
  timestamp: 1637975345
  timesteps_since_restore: 27500
  timesteps_this_iter: 500
  timesteps_total: 27500
  training_iteration: 55
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     55 |          16072.3 | 27500 | 0.497645 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-10-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8631578947368421
  episode_reward_mean: 0.489032581381997
  episode_reward_min: -0.27341772151898736
  episodes_this_iter: 500
  episodes_total: 28000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1642.133
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.7481212019920349
        entropy_coeff: 0.0
        kl: 0.0070954286493361
        model: {}
        policy_loss: -0.03738174960017204
        total_loss: -0.017855599522590637
        vf_explained_var: 0.4928559362888336
        vf_loss: 0.015934089198708534
    load_time_ms: 2.48
    num_steps_sampled: 28000
    num_steps_trained: 28000
    sample_time_ms: 128168.258
    update_time_ms: 5.958
  iterations_since_restore: 56
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.08300653594771
    ram_util_percent: 13.219607843137256
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 571.2551438490419
    mean_inference_ms: 1.7119145964704277
    mean_processing_ms: 1.2617193287234019
  time_since_restore: 16179.62883234024
  time_this_iter_s: 107.37300157546997
  time_total_s: 16179.62883234024
  timestamp: 1637975452
  timesteps_since_restore: 28000
  timesteps_this_iter: 500
  timesteps_total: 28000
  training_iteration: 56
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     56 |          16179.6 | 28000 | 0.489033 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-12-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8650568181818182
  episode_reward_mean: 0.4827572772552077
  episode_reward_min: -1.086232980332829
  episodes_this_iter: 500
  episodes_total: 28500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1643.273
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.7750810980796814
        entropy_coeff: 0.0
        kl: 0.006556971464306116
        model: {}
        policy_loss: -0.035042136907577515
        total_loss: -0.014716041274368763
        vf_explained_var: 0.5589020848274231
        vf_loss: 0.01700661890208721
    load_time_ms: 2.466
    num_steps_sampled: 28500
    num_steps_trained: 28500
    sample_time_ms: 123607.122
    update_time_ms: 5.929
  iterations_since_restore: 57
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.929411764705883
    ram_util_percent: 13.308823529411766
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 564.476786636519
    mean_inference_ms: 1.7048872996579514
    mean_processing_ms: 1.2559389081788785
  time_since_restore: 16274.959637641907
  time_this_iter_s: 95.33080530166626
  time_total_s: 16274.959637641907
  timestamp: 1637975548
  timesteps_since_restore: 28500
  timesteps_this_iter: 500
  timesteps_total: 28500
  training_iteration: 57
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     57 |            16275 | 28500 | 0.482757 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-14-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.861244019138756
  episode_reward_mean: 0.4794866373500623
  episode_reward_min: -0.24675324675324675
  episodes_this_iter: 500
  episodes_total: 29000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1653.769
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.8185299038887024
        entropy_coeff: 0.0
        kl: 0.0065363007597625256
        model: {}
        policy_loss: -0.0320381298661232
        total_loss: -0.017049189656972885
        vf_explained_var: 0.6374847888946533
        vf_loss: 0.011679934337735176
    load_time_ms: 2.435
    num_steps_sampled: 29000
    num_steps_trained: 29000
    sample_time_ms: 123615.98
    update_time_ms: 5.832
  iterations_since_restore: 58
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.120786516853933
    ram_util_percent: 13.3061797752809
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 558.9305635098898
    mean_inference_ms: 1.7001045016986598
    mean_processing_ms: 1.2522896200758618
  time_since_restore: 16399.39281129837
  time_this_iter_s: 124.43317365646362
  time_total_s: 16399.39281129837
  timestamp: 1637975672
  timesteps_since_restore: 29000
  timesteps_this_iter: 500
  timesteps_total: 29000
  training_iteration: 58
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     58 |          16399.4 | 29000 | 0.479487 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-16-29
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.49994996167551753
  episode_reward_min: -0.26591760299625467
  episodes_this_iter: 500
  episodes_total: 29500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1659.864
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.7649477124214172
        entropy_coeff: 0.0
        kl: 0.00605763727799058
        model: {}
        policy_loss: -0.042560335248708725
        total_loss: -0.02719319611787796
        vf_explained_var: 0.6223382353782654
        vf_loss: 0.012300455942749977
    load_time_ms: 2.395
    num_steps_sampled: 29500
    num_steps_trained: 29500
    sample_time_ms: 122152.494
    update_time_ms: 5.782
  iterations_since_restore: 59
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.011976047904191
    ram_util_percent: 13.2125748502994
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 553.3219176604988
    mean_inference_ms: 1.6947007333620947
    mean_processing_ms: 1.2478829804066787
  time_since_restore: 16516.370640277863
  time_this_iter_s: 116.97782897949219
  time_total_s: 16516.370640277863
  timestamp: 1637975789
  timesteps_since_restore: 29500
  timesteps_this_iter: 500
  timesteps_total: 29500
  training_iteration: 59
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     59 |          16516.4 | 29500 |  0.49995 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-18-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.49295362129534814
  episode_reward_min: 0.07597765363128492
  episodes_this_iter: 500
  episodes_total: 30000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1650.245
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.7237884998321533
        entropy_coeff: 0.0
        kl: 0.007351654581725597
        model: {}
        policy_loss: -0.04204384982585907
        total_loss: -0.026996824890375137
        vf_explained_var: 0.5955030918121338
        vf_loss: 0.01132525596767664
    load_time_ms: 2.421
    num_steps_sampled: 30000
    num_steps_trained: 30000
    sample_time_ms: 118248.731
    update_time_ms: 5.811
  iterations_since_restore: 60
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.015068493150686
    ram_util_percent: 13.256849315068495
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 547.4128303303409
    mean_inference_ms: 1.6886014500632567
    mean_processing_ms: 1.2430208157922449
  time_since_restore: 16618.5908908844
  time_this_iter_s: 102.22025060653687
  time_total_s: 16618.5908908844
  timestamp: 1637975892
  timesteps_since_restore: 30000
  timesteps_this_iter: 500
  timesteps_total: 30000
  training_iteration: 60
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     60 |          16618.6 | 30000 | 0.492954 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-20-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8629441624365483
  episode_reward_mean: 0.4986654425835604
  episode_reward_min: -1.0661538461538462
  episodes_this_iter: 500
  episodes_total: 30500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1653.844
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.7533727884292603
        entropy_coeff: 0.0
        kl: 0.01001675520092249
        model: {}
        policy_loss: -0.05341443419456482
        total_loss: -0.032188061624765396
        vf_explained_var: 0.56052565574646
        vf_loss: 0.016155390068888664
    load_time_ms: 2.4
    num_steps_sampled: 30500
    num_steps_trained: 30500
    sample_time_ms: 117002.55
    update_time_ms: 5.783
  iterations_since_restore: 61
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.084883720930232
    ram_util_percent: 13.234302325581396
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 542.2870251965215
    mean_inference_ms: 1.683501875841017
    mean_processing_ms: 1.2388807262171642
  time_since_restore: 16738.955213546753
  time_this_iter_s: 120.36432266235352
  time_total_s: 16738.955213546753
  timestamp: 1637976012
  timesteps_since_restore: 30500
  timesteps_this_iter: 500
  timesteps_total: 30500
  training_iteration: 61
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     61 |            16739 | 30500 | 0.498665 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-21-38
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8737580362361193
  episode_reward_mean: 0.5106981581093231
  episode_reward_min: -0.5500770416024653
  episodes_this_iter: 500
  episodes_total: 31000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1657.299
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.6883628964424133
        entropy_coeff: 0.0
        kl: 0.004092755727469921
        model: {}
        policy_loss: -0.03524499014019966
        total_loss: -0.017100229859352112
        vf_explained_var: 0.5566430687904358
        vf_loss: 0.016072804108262062
    load_time_ms: 2.364
    num_steps_sampled: 31000
    num_steps_trained: 31000
    sample_time_ms: 110757.35
    update_time_ms: 5.829
  iterations_since_restore: 62
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.298360655737707
    ram_util_percent: 13.255737704918031
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 536.2083421307669
    mean_inference_ms: 1.6776007654774499
    mean_processing_ms: 1.2341982810513663
  time_since_restore: 16824.49580335617
  time_this_iter_s: 85.54058980941772
  time_total_s: 16824.49580335617
  timestamp: 1637976098
  timesteps_since_restore: 31000
  timesteps_this_iter: 500
  timesteps_total: 31000
  training_iteration: 62
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     62 |          16824.5 | 31000 | 0.510698 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-23-15
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8840399002493765
  episode_reward_mean: 0.4881145782513131
  episode_reward_min: -0.22872340425531915
  episodes_this_iter: 500
  episodes_total: 31500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1656.989
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.708586573600769
        entropy_coeff: 0.0
        kl: 0.010345589369535446
        model: {}
        policy_loss: -0.037143394351005554
        total_loss: -0.018769122660160065
        vf_explained_var: 0.5337101221084595
        vf_loss: 0.015755539759993553
    load_time_ms: 2.371
    num_steps_sampled: 31500
    num_steps_trained: 31500
    sample_time_ms: 107431.914
    update_time_ms: 5.818
  iterations_since_restore: 63
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.261870503597123
    ram_util_percent: 13.282733812949642
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 530.6888540481139
    mean_inference_ms: 1.6722903395905533
    mean_processing_ms: 1.2301461007352035
  time_since_restore: 16921.637817382812
  time_this_iter_s: 97.14201402664185
  time_total_s: 16921.637817382812
  timestamp: 1637976195
  timesteps_since_restore: 31500
  timesteps_this_iter: 500
  timesteps_total: 31500
  training_iteration: 63
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     63 |          16921.6 | 31500 | 0.488115 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-24-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9664360370970116
  episode_reward_mean: 0.5131473686943442
  episode_reward_min: -0.07088607594936709
  episodes_this_iter: 500
  episodes_total: 32000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1660.957
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.6665147542953491
        entropy_coeff: 0.0
        kl: 0.009758751839399338
        model: {}
        policy_loss: -0.04196257144212723
        total_loss: -0.026808353140950203
        vf_explained_var: 0.583230197429657
        vf_loss: 0.012684037908911705
    load_time_ms: 2.353
    num_steps_sampled: 32000
    num_steps_trained: 32000
    sample_time_ms: 104136.471
    update_time_ms: 5.674
  iterations_since_restore: 64
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.250381679389314
    ram_util_percent: 13.265648854961833
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 525.1694099742401
    mean_inference_ms: 1.666880314031477
    mean_processing_ms: 1.2254295809254572
  time_since_restore: 17013.274207353592
  time_this_iter_s: 91.63638997077942
  time_total_s: 17013.274207353592
  timestamp: 1637976287
  timesteps_since_restore: 32000
  timesteps_this_iter: 500
  timesteps_total: 32000
  training_iteration: 64
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     64 |          17013.3 | 32000 | 0.513147 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-26-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8855345911949686
  episode_reward_mean: 0.5022168594014629
  episode_reward_min: 0.025109170305676855
  episodes_this_iter: 500
  episodes_total: 32500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1659.402
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.6699910759925842
        entropy_coeff: 0.0
        kl: 0.007748390547931194
        model: {}
        policy_loss: -0.02865707315504551
        total_loss: -0.01327521726489067
        vf_explained_var: 0.5553023815155029
        vf_loss: 0.013420543633401394
    load_time_ms: 2.349
    num_steps_sampled: 32500
    num_steps_trained: 32500
    sample_time_ms: 100361.38
    update_time_ms: 5.542
  iterations_since_restore: 65
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.299999999999999
    ram_util_percent: 13.230973451327431
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 519.4433689014731
    mean_inference_ms: 1.6611551622996563
    mean_processing_ms: 1.2208996785647659
  time_since_restore: 17092.631014823914
  time_this_iter_s: 79.35680747032166
  time_total_s: 17092.631014823914
  timestamp: 1637976366
  timesteps_since_restore: 32500
  timesteps_this_iter: 500
  timesteps_total: 32500
  training_iteration: 65
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     65 |          17092.6 | 32500 | 0.502217 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-27-42
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8801075268817204
  episode_reward_mean: 0.49198255844363725
  episode_reward_min: -0.2833333333333333
  episodes_this_iter: 500
  episodes_total: 33000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1648.345
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.670070469379425
        entropy_coeff: 0.0
        kl: 0.0057146078906953335
        model: {}
        policy_loss: -0.026385918259620667
        total_loss: -0.010626113042235374
        vf_explained_var: 0.5563664436340332
        vf_loss: 0.014313298277556896
    load_time_ms: 2.326
    num_steps_sampled: 33000
    num_steps_trained: 33000
    sample_time_ms: 99203.232
    update_time_ms: 5.521
  iterations_since_restore: 66
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.38102189781022
    ram_util_percent: 13.22992700729927
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 514.3856840355319
    mean_inference_ms: 1.6562124045811755
    mean_processing_ms: 1.2167522659526007
  time_since_restore: 17188.311526060104
  time_this_iter_s: 95.6805112361908
  time_total_s: 17188.311526060104
  timestamp: 1637976462
  timesteps_since_restore: 33000
  timesteps_this_iter: 500
  timesteps_total: 33000
  training_iteration: 66
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     66 |          17188.3 | 33000 | 0.491983 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-29-27
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5157022083544068
  episode_reward_min: -0.27918781725888325
  episodes_this_iter: 500
  episodes_total: 33500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1635.282
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.6945028901100159
        entropy_coeff: 0.0
        kl: 0.00921717844903469
        model: {}
        policy_loss: -0.039794135838747025
        total_loss: -0.02364679053425789
        vf_explained_var: 0.5707448720932007
        vf_loss: 0.013814248144626617
    load_time_ms: 2.387
    num_steps_sampled: 33500
    num_steps_trained: 33500
    sample_time_ms: 100174.539
    update_time_ms: 5.445
  iterations_since_restore: 67
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.98993288590604
    ram_util_percent: 13.24295302013423
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 509.75679625347794
    mean_inference_ms: 1.651421194200939
    mean_processing_ms: 1.2130216073179982
  time_since_restore: 17293.22374200821
  time_this_iter_s: 104.91221594810486
  time_total_s: 17293.22374200821
  timestamp: 1637976567
  timesteps_since_restore: 33500
  timesteps_this_iter: 500
  timesteps_total: 33500
  training_iteration: 67
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     67 |          17293.2 | 33500 | 0.515702 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-31-07
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595166163141994
  episode_reward_mean: 0.47665358785233847
  episode_reward_min: -0.4534711964549483
  episodes_this_iter: 500
  episodes_total: 34000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1623.933
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.7129952907562256
        entropy_coeff: 0.0
        kl: 0.0098770372569561
        model: {}
        policy_loss: -0.04525964707136154
        total_loss: -0.028515005484223366
        vf_explained_var: 0.6002794504165649
        vf_loss: 0.01424451358616352
    load_time_ms: 2.393
    num_steps_sampled: 34000
    num_steps_trained: 34000
    sample_time_ms: 97690.493
    update_time_ms: 5.546
  iterations_since_restore: 68
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.016901408450705
    ram_util_percent: 13.255633802816906
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 505.10304321461166
    mean_inference_ms: 1.6466601063709343
    mean_processing_ms: 1.2092542228991554
  time_since_restore: 17392.702938079834
  time_this_iter_s: 99.47919607162476
  time_total_s: 17392.702938079834
  timestamp: 1637976667
  timesteps_since_restore: 34000
  timesteps_this_iter: 500
  timesteps_total: 34000
  training_iteration: 68
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     68 |          17392.7 | 34000 | 0.476654 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-32-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610634648370498
  episode_reward_mean: 0.48671761212540876
  episode_reward_min: -0.9411764705882353
  episodes_this_iter: 500
  episodes_total: 34500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1601.086
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.7230071425437927
        entropy_coeff: 0.0
        kl: 0.011564952321350574
        model: {}
        policy_loss: -0.050491105765104294
        total_loss: -0.03346901759505272
        vf_explained_var: 0.6195468306541443
        vf_loss: 0.014094715006649494
    load_time_ms: 2.423
    num_steps_sampled: 34500
    num_steps_trained: 34500
    sample_time_ms: 95401.697
    update_time_ms: 5.569
  iterations_since_restore: 69
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.134074074074073
    ram_util_percent: 13.202222222222224
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 500.42525590915557
    mean_inference_ms: 1.6420224774302243
    mean_processing_ms: 1.2055716339475757
  time_since_restore: 17486.564304590225
  time_this_iter_s: 93.86136651039124
  time_total_s: 17486.564304590225
  timestamp: 1637976761
  timesteps_since_restore: 34500
  timesteps_this_iter: 500
  timesteps_total: 34500
  training_iteration: 69
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     69 |          17486.6 | 34500 | 0.486718 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-34-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8659476117103235
  episode_reward_mean: 0.4891241539594432
  episode_reward_min: -0.13089005235602094
  episodes_this_iter: 500
  episodes_total: 35000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1611.284
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.7019321322441101
        entropy_coeff: 0.0
        kl: 0.009544864296913147
        model: {}
        policy_loss: -0.03282848000526428
        total_loss: -0.017984649166464806
        vf_explained_var: 0.6247180104255676
        vf_loss: 0.012427793815732002
    load_time_ms: 2.426
    num_steps_sampled: 35000
    num_steps_trained: 35000
    sample_time_ms: 94904.318
    update_time_ms: 5.623
  iterations_since_restore: 70
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.112949640287768
    ram_util_percent: 13.210071942446044
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 495.97410083392685
    mean_inference_ms: 1.6373615769508116
    mean_processing_ms: 1.2020024874289306
  time_since_restore: 17583.915389060974
  time_this_iter_s: 97.3510844707489
  time_total_s: 17583.915389060974
  timestamp: 1637976858
  timesteps_since_restore: 35000
  timesteps_this_iter: 500
  timesteps_total: 35000
  training_iteration: 70
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     70 |          17583.9 | 35000 | 0.489124 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-35-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.48500889338630715
  episode_reward_min: -1.144215530903328
  episodes_this_iter: 500
  episodes_total: 35500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1586.868
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.6691927313804626
        entropy_coeff: 0.0
        kl: 0.010961157269775867
        model: {}
        policy_loss: -0.044490374624729156
        total_loss: -0.021625986322760582
        vf_explained_var: 0.5164343118667603
        vf_loss: 0.020089853554964066
    load_time_ms: 2.414
    num_steps_sampled: 35500
    num_steps_trained: 35500
    sample_time_ms: 92188.972
    update_time_ms: 5.605
  iterations_since_restore: 71
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.18560606060606
    ram_util_percent: 13.220454545454547
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 491.5313642665214
    mean_inference_ms: 1.6327173198593459
    mean_processing_ms: 1.198513676208804
  time_since_restore: 17676.881827116013
  time_this_iter_s: 92.96643805503845
  time_total_s: 17676.881827116013
  timestamp: 1637976951
  timesteps_since_restore: 35500
  timesteps_this_iter: 500
  timesteps_total: 35500
  training_iteration: 71
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     71 |          17676.9 | 35500 | 0.485009 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-37-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8631578947368421
  episode_reward_mean: 0.4955275703219685
  episode_reward_min: 0.01282051282051282
  episodes_this_iter: 500
  episodes_total: 36000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1596.121
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.6721851825714111
        entropy_coeff: 0.0
        kl: 0.012022438459098339
        model: {}
        policy_loss: -0.039701659232378006
        total_loss: -0.02270648442208767
        vf_explained_var: 0.5606195330619812
        vf_loss: 0.01395199541002512
    load_time_ms: 2.421
    num_steps_sampled: 36000
    num_steps_trained: 36000
    sample_time_ms: 93276.389
    update_time_ms: 5.582
  iterations_since_restore: 72
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.124637681159422
    ram_util_percent: 13.218115942028987
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 487.302219558764
    mean_inference_ms: 1.6292053965547912
    mean_processing_ms: 1.1957370619989625
  time_since_restore: 17773.388835191727
  time_this_iter_s: 96.50700807571411
  time_total_s: 17773.388835191727
  timestamp: 1637977048
  timesteps_since_restore: 36000
  timesteps_this_iter: 500
  timesteps_total: 36000
  training_iteration: 72
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     72 |          17773.4 | 36000 | 0.495528 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-39-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8650568181818182
  episode_reward_mean: 0.49300600987666326
  episode_reward_min: -0.20151133501259447
  episodes_this_iter: 500
  episodes_total: 36500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1592.993
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.667715847492218
        entropy_coeff: 0.0
        kl: 0.009390796534717083
        model: {}
        policy_loss: -0.037220731377601624
        total_loss: -0.02341538481414318
        vf_explained_var: 0.6415103077888489
        vf_loss: 0.011428308673202991
    load_time_ms: 2.395
    num_steps_sampled: 36500
    num_steps_trained: 36500
    sample_time_ms: 92842.756
    update_time_ms: 5.546
  iterations_since_restore: 73
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.345112781954887
    ram_util_percent: 13.342105263157896
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 483.09119398739375
    mean_inference_ms: 1.6247509231352095
    mean_processing_ms: 1.1920632866910934
  time_since_restore: 17866.162267684937
  time_this_iter_s: 92.77343249320984
  time_total_s: 17866.162267684937
  timestamp: 1637977141
  timesteps_since_restore: 36500
  timesteps_this_iter: 500
  timesteps_total: 36500
  training_iteration: 73
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     73 |          17866.2 | 36500 | 0.493006 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-40-30
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.4817918152619219
  episode_reward_min: 0.02766798418972332
  episodes_this_iter: 500
  episodes_total: 37000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1587.408
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.6568211317062378
        entropy_coeff: 0.0
        kl: 0.011552918702363968
        model: {}
        policy_loss: -0.03382871299982071
        total_loss: -0.020130645483732224
        vf_explained_var: 0.6208660006523132
        vf_loss: 0.010773732326924801
    load_time_ms: 2.388
    num_steps_sampled: 37000
    num_steps_trained: 37000
    sample_time_ms: 92594.364
    update_time_ms: 5.51
  iterations_since_restore: 74
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.381889763779531
    ram_util_percent: 13.251968503937007
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 478.8933495876482
    mean_inference_ms: 1.6208237233843268
    mean_processing_ms: 1.188690039097388
  time_since_restore: 17955.25844478607
  time_this_iter_s: 89.09617710113525
  time_total_s: 17955.25844478607
  timestamp: 1637977230
  timesteps_since_restore: 37000
  timesteps_this_iter: 500
  timesteps_total: 37000
  training_iteration: 74
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     74 |          17955.3 | 37000 | 0.481792 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-42-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.5061115725243656
  episode_reward_min: -0.35260115606936415
  episodes_this_iter: 500
  episodes_total: 37500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1577.21
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.6773452162742615
        entropy_coeff: 0.0
        kl: 0.01053435355424881
        model: {}
        policy_loss: -0.04013814404606819
        total_loss: -0.027158532291650772
        vf_explained_var: 0.6362528800964355
        vf_loss: 0.010313105769455433
    load_time_ms: 2.391
    num_steps_sampled: 37500
    num_steps_trained: 37500
    sample_time_ms: 94897.283
    update_time_ms: 5.491
  iterations_since_restore: 75
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.429452054794519
    ram_util_percent: 13.254109589041098
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 475.16135019205893
    mean_inference_ms: 1.6166517719968543
    mean_processing_ms: 1.1855417790563834
  time_since_restore: 18057.54218173027
  time_this_iter_s: 102.28373694419861
  time_total_s: 18057.54218173027
  timestamp: 1637977332
  timesteps_since_restore: 37500
  timesteps_this_iter: 500
  timesteps_total: 37500
  training_iteration: 75
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     75 |          18057.5 | 37500 | 0.506112 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-43-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8629441624365483
  episode_reward_mean: 0.4955497373487108
  episode_reward_min: 0.08044692737430167
  episodes_this_iter: 500
  episodes_total: 38000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1584.254
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.670692503452301
        entropy_coeff: 0.0
        kl: 0.00974661111831665
        model: {}
        policy_loss: -0.03152786195278168
        total_loss: -0.017958302050828934
        vf_explained_var: 0.607786238193512
        vf_loss: 0.011102446354925632
    load_time_ms: 2.409
    num_steps_sampled: 38000
    num_steps_trained: 38000
    sample_time_ms: 94446.151
    update_time_ms: 5.442
  iterations_since_restore: 76
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.184615384615384
    ram_util_percent: 13.223076923076924
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 471.2332400493642
    mean_inference_ms: 1.612753984925057
    mean_processing_ms: 1.1824593004818098
  time_since_restore: 18148.781923294067
  time_this_iter_s: 91.239741563797
  time_total_s: 18148.781923294067
  timestamp: 1637977424
  timesteps_since_restore: 38000
  timesteps_this_iter: 500
  timesteps_total: 38000
  training_iteration: 76
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     76 |          18148.8 | 38000 |  0.49555 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-45-23
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8737580362361193
  episode_reward_mean: 0.4990975981259885
  episode_reward_min: -0.26440677966101694
  episodes_this_iter: 500
  episodes_total: 38500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1599.281
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.6607391238212585
        entropy_coeff: 0.0
        kl: 0.007297827396541834
        model: {}
        policy_loss: -0.03476613014936447
        total_loss: -0.02025756426155567
        vf_explained_var: 0.5861303210258484
        vf_loss: 0.012661310844123363
    load_time_ms: 2.335
    num_steps_sampled: 38500
    num_steps_trained: 38500
    sample_time_ms: 93830.504
    update_time_ms: 5.508
  iterations_since_restore: 77
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.154225352112675
    ram_util_percent: 13.243661971830988
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 467.6059111970198
    mean_inference_ms: 1.6093170552132223
    mean_processing_ms: 1.1795572217620907
  time_since_restore: 18247.688281536102
  time_this_iter_s: 98.90635824203491
  time_total_s: 18247.688281536102
  timestamp: 1637977523
  timesteps_since_restore: 38500
  timesteps_this_iter: 500
  timesteps_total: 38500
  training_iteration: 77
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     77 |          18247.7 | 38500 | 0.499098 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-46-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8840399002493765
  episode_reward_mean: 0.5034665000923634
  episode_reward_min: 0.04310344827586207
  episodes_this_iter: 500
  episodes_total: 39000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1619.18
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.618765652179718
        entropy_coeff: 0.0
        kl: 0.012612469494342804
        model: {}
        policy_loss: -0.03510294854640961
        total_loss: -0.01810939610004425
        vf_explained_var: 0.5281187295913696
        vf_loss: 0.01380101591348648
    load_time_ms: 2.355
    num_steps_sampled: 39000
    num_steps_trained: 39000
    sample_time_ms: 91720.605
    update_time_ms: 5.675
  iterations_since_restore: 78
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.319642857142858
    ram_util_percent: 13.236607142857142
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 463.5491781529882
    mean_inference_ms: 1.605146044520384
    mean_processing_ms: 1.176327528860266
  time_since_restore: 18326.271122694016
  time_this_iter_s: 78.58284115791321
  time_total_s: 18326.271122694016
  timestamp: 1637977601
  timesteps_since_restore: 39000
  timesteps_this_iter: 500
  timesteps_total: 39000
  training_iteration: 78
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     78 |          18326.3 | 39000 | 0.503467 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-48-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8802507836990595
  episode_reward_mean: 0.4988092024345113
  episode_reward_min: -0.8172043010752689
  episodes_this_iter: 500
  episodes_total: 39500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1654.348
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.5960384607315063
        entropy_coeff: 0.0
        kl: 0.009190745651721954
        model: {}
        policy_loss: -0.03503130376338959
        total_loss: -0.01844910904765129
        vf_explained_var: 0.6096341013908386
        vf_loss: 0.01425578910857439
    load_time_ms: 2.343
    num_steps_sampled: 39500
    num_steps_trained: 39500
    sample_time_ms: 90732.672
    update_time_ms: 5.67
  iterations_since_restore: 79
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.085833333333335
    ram_util_percent: 13.318333333333332
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 459.7397680020158
    mean_inference_ms: 1.601272756692859
    mean_processing_ms: 1.1734919549121106
  time_since_restore: 18410.604181051254
  time_this_iter_s: 84.33305835723877
  time_total_s: 18410.604181051254
  timestamp: 1637977686
  timesteps_since_restore: 39500
  timesteps_this_iter: 500
  timesteps_total: 39500
  training_iteration: 79
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     79 |          18410.6 | 39500 | 0.498809 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-49-25
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9664360370970116
  episode_reward_mean: 0.5166353727925486
  episode_reward_min: -0.07468354430379746
  episodes_this_iter: 500
  episodes_total: 40000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1655.878
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.5660991668701172
        entropy_coeff: 0.0
        kl: 0.012988687492907047
        model: {}
        policy_loss: -0.03707631677389145
        total_loss: -0.01977083645761013
        vf_explained_var: 0.5281675457954407
        vf_loss: 0.014017716981470585
    load_time_ms: 2.314
    num_steps_sampled: 40000
    num_steps_trained: 40000
    sample_time_ms: 88945.022
    update_time_ms: 5.641
  iterations_since_restore: 80
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.408771929824562
    ram_util_percent: 13.250877192982458
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 455.90738833437837
    mean_inference_ms: 1.5974228556330619
    mean_processing_ms: 1.1702947105658907
  time_since_restore: 18490.09189105034
  time_this_iter_s: 79.48770999908447
  time_total_s: 18490.09189105034
  timestamp: 1637977765
  timesteps_since_restore: 40000
  timesteps_this_iter: 500
  timesteps_total: 40000
  training_iteration: 80
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     80 |          18490.1 | 40000 | 0.516635 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-51-07
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8959823885525592
  episode_reward_mean: 0.5048407144150604
  episode_reward_min: -0.2833333333333333
  episodes_this_iter: 500
  episodes_total: 40500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1685.542
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.6267083287239075
        entropy_coeff: 0.0
        kl: 0.019125692546367645
        model: {}
        policy_loss: -0.039759453386068344
        total_loss: -0.02038581296801567
        vf_explained_var: 0.5652077198028564
        vf_loss: 0.014532442204654217
    load_time_ms: 2.324
    num_steps_sampled: 40500
    num_steps_trained: 40500
    sample_time_ms: 89814.37
    update_time_ms: 5.758
  iterations_since_restore: 81
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.301369863013699
    ram_util_percent: 13.225342465753425
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 452.721491227553
    mean_inference_ms: 1.594478649986058
    mean_processing_ms: 1.1678374651605616
  time_since_restore: 18592.04958987236
  time_this_iter_s: 101.95769882202148
  time_total_s: 18592.04958987236
  timestamp: 1637977867
  timesteps_since_restore: 40500
  timesteps_this_iter: 500
  timesteps_total: 40500
  training_iteration: 81
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     81 |            18592 | 40500 | 0.504841 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-52-25
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5148672597286448
  episode_reward_min: -1.0139442231075697
  episodes_this_iter: 500
  episodes_total: 41000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1674.063
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.6092489957809448
        entropy_coeff: 0.0
        kl: 0.006845030002295971
        model: {}
        policy_loss: -0.025093503296375275
        total_loss: -0.007944212295114994
        vf_explained_var: 0.5532698631286621
        vf_loss: 0.015416642650961876
    load_time_ms: 2.329
    num_steps_sampled: 41000
    num_steps_trained: 41000
    sample_time_ms: 87959.032
    update_time_ms: 5.752
  iterations_since_restore: 82
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.139639639639638
    ram_util_percent: 13.227027027027027
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 449.0306503885952
    mean_inference_ms: 1.5910201873876058
    mean_processing_ms: 1.1649250050893147
  time_since_restore: 18669.88804793358
  time_this_iter_s: 77.83845806121826
  time_total_s: 18669.88804793358
  timestamp: 1637977945
  timesteps_since_restore: 41000
  timesteps_this_iter: 500
  timesteps_total: 41000
  training_iteration: 82
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     82 |          18669.9 | 41000 | 0.514867 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-53-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595166163141994
  episode_reward_mean: 0.49084872804413693
  episode_reward_min: -0.9098591549295775
  episodes_this_iter: 500
  episodes_total: 41500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1677.983
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.5911394357681274
        entropy_coeff: 0.0
        kl: 0.010144807398319244
        model: {}
        policy_loss: -0.041462723165750504
        total_loss: -0.02387142926454544
        vf_explained_var: 0.5683785676956177
        vf_loss: 0.01502338144928217
    load_time_ms: 2.329
    num_steps_sampled: 41500
    num_steps_trained: 41500
    sample_time_ms: 86203.584
    update_time_ms: 5.805
  iterations_since_restore: 83
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.871962616822431
    ram_util_percent: 13.228971962616823
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 445.36489192693983
    mean_inference_ms: 1.5877987579513362
    mean_processing_ms: 1.1620441863819544
  time_since_restore: 18745.146702528
  time_this_iter_s: 75.25865459442139
  time_total_s: 18745.146702528
  timestamp: 1637978021
  timesteps_since_restore: 41500
  timesteps_this_iter: 500
  timesteps_total: 41500
  training_iteration: 83
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     83 |          18745.1 | 41500 | 0.490849 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-54-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8571428571428571
  episode_reward_mean: 0.4894645149211124
  episode_reward_min: -0.23684210526315788
  episodes_this_iter: 500
  episodes_total: 42000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1664.766
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.5474478006362915
        entropy_coeff: 0.0
        kl: 0.01236641500145197
        model: {}
        policy_loss: -0.039683856070041656
        total_loss: -0.024514753371477127
        vf_explained_var: 0.6181365847587585
        vf_loss: 0.01203884370625019
    load_time_ms: 2.333
    num_steps_sampled: 42000
    num_steps_trained: 42000
    sample_time_ms: 84310.994
    update_time_ms: 5.809
  iterations_since_restore: 84
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.172999999999996
    ram_util_percent: 13.226999999999999
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 441.6665015017764
    mean_inference_ms: 1.5840958233138032
    mean_processing_ms: 1.1589472806044145
  time_since_restore: 18815.18496489525
  time_this_iter_s: 70.03826236724854
  time_total_s: 18815.18496489525
  timestamp: 1637978091
  timesteps_since_restore: 42000
  timesteps_this_iter: 500
  timesteps_total: 42000
  training_iteration: 84
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     84 |          18815.2 | 42000 | 0.489465 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-56-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610634648370498
  episode_reward_mean: 0.48629536223182146
  episode_reward_min: 0.064343163538874
  episodes_this_iter: 500
  episodes_total: 42500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1678.965
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.5811573266983032
        entropy_coeff: 0.0
        kl: 0.008378847502171993
        model: {}
        policy_loss: -0.026200495660305023
        total_loss: -0.013902002945542336
        vf_explained_var: 0.682212233543396
        vf_loss: 0.010177590884268284
    load_time_ms: 2.338
    num_steps_sampled: 42500
    num_steps_trained: 42500
    sample_time_ms: 82529.338
    update_time_ms: 5.817
  iterations_since_restore: 85
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.01900826446281
    ram_util_percent: 13.236363636363636
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 438.3924356957233
    mean_inference_ms: 1.58088403753257
    mean_processing_ms: 1.156382778274803
  time_since_restore: 18899.794112682343
  time_this_iter_s: 84.60914778709412
  time_total_s: 18899.794112682343
  timestamp: 1637978176
  timesteps_since_restore: 42500
  timesteps_this_iter: 500
  timesteps_total: 42500
  training_iteration: 85
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     85 |          18899.8 | 42500 | 0.486295 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-57-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8659476117103235
  episode_reward_mean: 0.49261157154041
  episode_reward_min: -0.49612403100775193
  episodes_this_iter: 500
  episodes_total: 43000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1667.525
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.5254796743392944
        entropy_coeff: 0.0
        kl: 0.007654080167412758
        model: {}
        policy_loss: -0.03487493097782135
        total_loss: -0.019600074738264084
        vf_explained_var: 0.6049760580062866
        vf_loss: 0.013337417505681515
    load_time_ms: 2.319
    num_steps_sampled: 43000
    num_steps_trained: 43000
    sample_time_ms: 81933.33
    update_time_ms: 5.859
  iterations_since_restore: 86
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.148360655737704
    ram_util_percent: 13.25
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 435.20991278427675
    mean_inference_ms: 1.577994986519237
    mean_processing_ms: 1.1538517774253365
  time_since_restore: 18984.959173202515
  time_this_iter_s: 85.16506052017212
  time_total_s: 18984.959173202515
  timestamp: 1637978261
  timesteps_since_restore: 43000
  timesteps_this_iter: 500
  timesteps_total: 43000
  training_iteration: 86
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     86 |            18985 | 43000 | 0.492612 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_19-58-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.4995857973057634
  episode_reward_min: -0.2217741935483871
  episodes_this_iter: 500
  episodes_total: 43500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1675.622
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.47612613439559937
        entropy_coeff: 0.0
        kl: 0.006863275542855263
        model: {}
        policy_loss: -0.03120357356965542
        total_loss: -0.016705982387065887
        vf_explained_var: 0.5830304026603699
        vf_loss: 0.012760323472321033
    load_time_ms: 2.343
    num_steps_sampled: 43500
    num_steps_trained: 43500
    sample_time_ms: 79405.55
    update_time_ms: 5.838
  iterations_since_restore: 87
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.395238095238096
    ram_util_percent: 13.252380952380955
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 431.83402819363954
    mean_inference_ms: 1.5745098619734437
    mean_processing_ms: 1.150959319228268
  time_since_restore: 19058.668394327164
  time_this_iter_s: 73.70922112464905
  time_total_s: 19058.668394327164
  timestamp: 1637978335
  timesteps_since_restore: 43500
  timesteps_this_iter: 500
  timesteps_total: 43500
  training_iteration: 87
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     87 |          19058.7 | 43500 | 0.499586 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-00-02
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8650568181818182
  episode_reward_mean: 0.48749183515567907
  episode_reward_min: -0.17465753424657535
  episodes_this_iter: 500
  episodes_total: 44000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1664.934
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.5446092486381531
        entropy_coeff: 0.0
        kl: 0.010656132362782955
        model: {}
        policy_loss: -0.03206869587302208
        total_loss: -0.016299355775117874
        vf_explained_var: 0.5968872308731079
        vf_loss: 0.0130719980224967
    load_time_ms: 2.321
    num_steps_sampled: 44000
    num_steps_trained: 44000
    sample_time_ms: 78238.312
    update_time_ms: 5.659
  iterations_since_restore: 88
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.632291666666669
    ram_util_percent: 13.245833333333332
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 428.37930059425406
    mean_inference_ms: 1.5714598830154096
    mean_processing_ms: 1.1483577567797751
  time_since_restore: 19125.46824479103
  time_this_iter_s: 66.79985046386719
  time_total_s: 19125.46824479103
  timestamp: 1637978402
  timesteps_since_restore: 44000
  timesteps_this_iter: 500
  timesteps_total: 44000
  training_iteration: 88
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     88 |          19125.5 | 44000 | 0.487492 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-01-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8624161073825504
  episode_reward_mean: 0.4947024114949673
  episode_reward_min: 0.04018912529550828
  episodes_this_iter: 500
  episodes_total: 44500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1661.937
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.4909057319164276
        entropy_coeff: 0.0
        kl: 0.008264361880719662
        model: {}
        policy_loss: -0.026676950976252556
        total_loss: -0.01422007568180561
        vf_explained_var: 0.6587467193603516
        vf_loss: 0.010364955291152
    load_time_ms: 2.302
    num_steps_sampled: 44500
    num_steps_trained: 44500
    sample_time_ms: 76812.217
    update_time_ms: 5.661
  iterations_since_restore: 89
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.224000000000004
    ram_util_percent: 13.411
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 425.07311091878734
    mean_inference_ms: 1.5682215551422334
    mean_processing_ms: 1.1458903151290747
  time_since_restore: 19195.51134800911
  time_this_iter_s: 70.04310321807861
  time_total_s: 19195.51134800911
  timestamp: 1637978472
  timesteps_since_restore: 44500
  timesteps_this_iter: 500
  timesteps_total: 44500
  training_iteration: 89
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     89 |          19195.5 | 44500 | 0.494702 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-02-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8652931854199684
  episode_reward_mean: 0.4885930323655113
  episode_reward_min: 0.03
  episodes_this_iter: 500
  episodes_total: 45000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1652.096
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.4631294012069702
        entropy_coeff: 0.0
        kl: 0.0066321836784482
        model: {}
        policy_loss: -0.027754053473472595
        total_loss: -0.01599477417767048
        vf_explained_var: 0.666304349899292
        vf_loss: 0.010080504231154919
    load_time_ms: 2.305
    num_steps_sampled: 45000
    num_steps_trained: 45000
    sample_time_ms: 75096.007
    update_time_ms: 5.59
  iterations_since_restore: 90
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.242696629213482
    ram_util_percent: 13.237078651685392
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 421.6707903412574
    mean_inference_ms: 1.5649267261376534
    mean_processing_ms: 1.1432057860024716
  time_since_restore: 19257.737325906754
  time_this_iter_s: 62.22597789764404
  time_total_s: 19257.737325906754
  timestamp: 1637978534
  timesteps_since_restore: 45000
  timesteps_this_iter: 500
  timesteps_total: 45000
  training_iteration: 90
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     90 |          19257.7 | 45000 | 0.488593 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-03-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.4961612619267414
  episode_reward_min: -1.0628930817610063
  episodes_this_iter: 500
  episodes_total: 45500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1628.854
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.436664879322052
        entropy_coeff: 0.0
        kl: 0.004202745854854584
        model: {}
        policy_loss: -0.025677237659692764
        total_loss: -0.009359117597341537
        vf_explained_var: 0.5944774150848389
        vf_loss: 0.015254301019012928
    load_time_ms: 2.297
    num_steps_sampled: 45500
    num_steps_trained: 45500
    sample_time_ms: 71498.068
    update_time_ms: 5.61
  iterations_since_restore: 91
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.07872340425532
    ram_util_percent: 13.254255319148937
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 418.4219921078775
    mean_inference_ms: 1.5618458378118738
    mean_processing_ms: 1.1406596609609279
  time_since_restore: 19323.483082294464
  time_this_iter_s: 65.74575638771057
  time_total_s: 19323.483082294464
  timestamp: 1637978600
  timesteps_since_restore: 45500
  timesteps_this_iter: 500
  timesteps_total: 45500
  training_iteration: 91
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     91 |          19323.5 | 45500 | 0.496161 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-04-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8629441624365483
  episode_reward_mean: 0.5047932039619641
  episode_reward_min: 0.09777777777777778
  episodes_this_iter: 500
  episodes_total: 46000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1635.169
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.41820794343948364
        entropy_coeff: 0.0
        kl: 0.005941198673099279
        model: {}
        policy_loss: -0.022060664370656013
        total_loss: -0.01070638932287693
        vf_explained_var: 0.6132986545562744
        vf_loss: 0.010602346621453762
    load_time_ms: 2.457
    num_steps_sampled: 46000
    num_steps_trained: 46000
    sample_time_ms: 69467.673
    update_time_ms: 5.615
  iterations_since_restore: 92
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.253658536585368
    ram_util_percent: 13.247560975609755
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 415.0646721673284
    mean_inference_ms: 1.5586000564696931
    mean_processing_ms: 1.1378907449364506
  time_since_restore: 19381.082401752472
  time_this_iter_s: 57.59931945800781
  time_total_s: 19381.082401752472
  timestamp: 1637978658
  timesteps_since_restore: 46000
  timesteps_this_iter: 500
  timesteps_total: 46000
  training_iteration: 92
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     92 |          19381.1 | 46000 | 0.504793 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-05-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8737580362361193
  episode_reward_mean: 0.5065348917188511
  episode_reward_min: -2.6550632911392404
  episodes_this_iter: 500
  episodes_total: 46500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1628.468
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.3944171071052551
        entropy_coeff: 0.0
        kl: 0.002556802937760949
        model: {}
        policy_loss: -0.02124893106520176
        total_loss: 0.002709513297304511
        vf_explained_var: 0.6110241413116455
        vf_loss: 0.023634852841496468
    load_time_ms: 2.451
    num_steps_sampled: 46500
    num_steps_trained: 46500
    sample_time_ms: 66642.493
    update_time_ms: 5.63
  iterations_since_restore: 93
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.353731343283581
    ram_util_percent: 13.256716417910448
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 411.5524194627211
    mean_inference_ms: 1.5550002326570747
    mean_processing_ms: 1.1349930737301144
  time_since_restore: 19428.022525548935
  time_this_iter_s: 46.94012379646301
  time_total_s: 19428.022525548935
  timestamp: 1637978705
  timesteps_since_restore: 46500
  timesteps_this_iter: 500
  timesteps_total: 46500
  training_iteration: 93
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     93 |            19428 | 46500 | 0.506535 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-06-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8840399002493765
  episode_reward_mean: 0.48948946445068436
  episode_reward_min: -0.5447154471544715
  episodes_this_iter: 500
  episodes_total: 47000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1634.138
    learner:
      default_policy:
        cur_kl_coeff: 0.06328125298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.3857099115848541
        entropy_coeff: 0.0
        kl: 0.004075908102095127
        model: {}
        policy_loss: -0.022625137120485306
        total_loss: -0.005895907990634441
        vf_explained_var: 0.5171163082122803
        vf_loss: 0.01647130958735943
    load_time_ms: 2.449
    num_steps_sampled: 47000
    num_steps_trained: 47000
    sample_time_ms: 65193.731
    update_time_ms: 5.667
  iterations_since_restore: 94
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.626249999999999
    ram_util_percent: 13.321250000000001
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 408.29908563995315
    mean_inference_ms: 1.5519313899910865
    mean_processing_ms: 1.1324937849693488
  time_since_restore: 19483.630261421204
  time_this_iter_s: 55.60773587226868
  time_total_s: 19483.630261421204
  timestamp: 1637978761
  timesteps_since_restore: 47000
  timesteps_this_iter: 500
  timesteps_total: 47000
  training_iteration: 94
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     94 |          19483.6 | 47000 | 0.489489 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-06-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9664360370970116
  episode_reward_mean: 0.5134497784157683
  episode_reward_min: -2.5486725663716814
  episodes_this_iter: 500
  episodes_total: 47500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1638.801
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3590870201587677
        entropy_coeff: 0.0
        kl: 0.006006921641528606
        model: {}
        policy_loss: -0.03268267214298248
        total_loss: -0.005107172764837742
        vf_explained_var: 0.5205614566802979
        vf_loss: 0.027385439723730087
    load_time_ms: 2.431
    num_steps_sampled: 47500
    num_steps_trained: 47500
    sample_time_ms: 60522.916
    update_time_ms: 5.655
  iterations_since_restore: 95
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.116666666666667
    ram_util_percent: 13.261111111111111
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 404.73999925112554
    mean_inference_ms: 1.5481636475564073
    mean_processing_ms: 1.1294784527026123
  time_since_restore: 19521.57829761505
  time_this_iter_s: 37.948036193847656
  time_total_s: 19521.57829761505
  timestamp: 1637978799
  timesteps_since_restore: 47500
  timesteps_this_iter: 500
  timesteps_total: 47500
  training_iteration: 95
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     95 |          19521.6 | 47500 |  0.51345 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-07-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8855345911949686
  episode_reward_mean: 0.506511822632365
  episode_reward_min: 0.03832752613240418
  episodes_this_iter: 500
  episodes_total: 48000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1646.45
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3789384365081787
        entropy_coeff: 0.0
        kl: 0.00670416047796607
        model: {}
        policy_loss: -0.026823168620467186
        total_loss: -0.013053858652710915
        vf_explained_var: 0.5409704446792603
        vf_loss: 0.013557183556258678
    load_time_ms: 2.43
    num_steps_sampled: 48000
    num_steps_trained: 48000
    sample_time_ms: 56327.763
    update_time_ms: 5.609
  iterations_since_restore: 96
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.53709677419355
    ram_util_percent: 13.253225806451614
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 401.36757919369694
    mean_inference_ms: 1.5448313082648537
    mean_processing_ms: 1.126711926001618
  time_since_restore: 19564.867896080017
  time_this_iter_s: 43.28959846496582
  time_total_s: 19564.867896080017
  timestamp: 1637978842
  timesteps_since_restore: 48000
  timesteps_this_iter: 500
  timesteps_total: 48000
  training_iteration: 96
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     96 |          19564.9 | 48000 | 0.506512 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-07-59
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8959823885525592
  episode_reward_mean: 0.5087353453477526
  episode_reward_min: -0.2185792349726776
  episodes_this_iter: 500
  episodes_total: 48500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1643.323
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.351996511220932
        entropy_coeff: 0.0
        kl: 0.008269118145108223
        model: {}
        policy_loss: -0.023934150114655495
        total_loss: -0.010971537791192532
        vf_explained_var: 0.5965173244476318
        vf_loss: 0.012700971215963364
    load_time_ms: 2.418
    num_steps_sampled: 48500
    num_steps_trained: 48500
    sample_time_ms: 52623.147
    update_time_ms: 5.645
  iterations_since_restore: 97
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.092452830188677
    ram_util_percent: 13.252830188679248
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 397.926056572576
    mean_inference_ms: 1.54140685696481
    mean_processing_ms: 1.1239042183986212
  time_since_restore: 19601.499614477158
  time_this_iter_s: 36.6317183971405
  time_total_s: 19601.499614477158
  timestamp: 1637978879
  timesteps_since_restore: 48500
  timesteps_this_iter: 500
  timesteps_total: 48500
  training_iteration: 97
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     97 |          19601.5 | 48500 | 0.508735 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-08-42
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.50988404949878
  episode_reward_min: -0.27918781725888325
  episodes_this_iter: 500
  episodes_total: 49000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1630.69
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.34813326597213745
        entropy_coeff: 0.0
        kl: 0.005500266328454018
        model: {}
        policy_loss: -0.025364330038428307
        total_loss: -0.011561964638531208
        vf_explained_var: 0.5503365993499756
        vf_loss: 0.01362832635641098
    load_time_ms: 2.411
    num_steps_sampled: 49000
    num_steps_trained: 49000
    sample_time_ms: 50259.312
    update_time_ms: 5.648
  iterations_since_restore: 98
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.514754098360656
    ram_util_percent: 13.2672131147541
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 394.6887654787773
    mean_inference_ms: 1.538217711192253
    mean_processing_ms: 1.121343874166952
  time_since_restore: 19644.534613132477
  time_this_iter_s: 43.034998655319214
  time_total_s: 19644.534613132477
  timestamp: 1637978922
  timesteps_since_restore: 49000
  timesteps_this_iter: 500
  timesteps_total: 49000
  training_iteration: 98
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     98 |          19644.5 | 49000 | 0.509884 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-09-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595166163141994
  episode_reward_mean: 0.4979096544884761
  episode_reward_min: 0.08203125
  episodes_this_iter: 500
  episodes_total: 49500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1605.23
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.35609057545661926
        entropy_coeff: 0.0
        kl: 0.0068502952344715595
        model: {}
        policy_loss: -0.016292084008455276
        total_loss: -0.004378908779472113
        vf_explained_var: 0.5852680802345276
        vf_loss: 0.011696427129209042
    load_time_ms: 2.459
    num_steps_sampled: 49500
    num_steps_trained: 49500
    sample_time_ms: 46487.328
    update_time_ms: 5.842
  iterations_since_restore: 99
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.360869565217394
    ram_util_percent: 13.30434782608695
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 391.29695029035344
    mean_inference_ms: 1.5346808052167022
    mean_processing_ms: 1.1183990906909034
  time_since_restore: 19676.604145765305
  time_this_iter_s: 32.06953263282776
  time_total_s: 19676.604145765305
  timestamp: 1637978954
  timesteps_since_restore: 49500
  timesteps_this_iter: 500
  timesteps_total: 49500
  training_iteration: 99
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |     99 |          19676.6 | 49500 |  0.49791 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-09-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610634648370498
  episode_reward_mean: 0.48497510423170526
  episode_reward_min: -0.06970509383378017
  episodes_this_iter: 500
  episodes_total: 50000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1607.679
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4066236913204193
        entropy_coeff: 0.0
        kl: 0.017393164336681366
        model: {}
        policy_loss: -0.033864136785268784
        total_loss: -0.022684264928102493
        vf_explained_var: 0.6379417181015015
        vf_loss: 0.010629548691213131
    load_time_ms: 2.448
    num_steps_sampled: 50000
    num_steps_trained: 50000
    sample_time_ms: 43486.837
    update_time_ms: 5.932
  iterations_since_restore: 100
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.680434782608693
    ram_util_percent: 13.293478260869561
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 387.9737992903793
    mean_inference_ms: 1.5313179311136067
    mean_processing_ms: 1.1157804206739355
  time_since_restore: 19708.85106921196
  time_this_iter_s: 32.24692344665527
  time_total_s: 19708.85106921196
  timestamp: 1637978987
  timesteps_since_restore: 50000
  timesteps_this_iter: 500
  timesteps_total: 50000
  training_iteration: 100
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    100 |          19708.9 | 50000 | 0.484975 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-10-21
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8659476117103235
  episode_reward_mean: 0.4854704189010296
  episode_reward_min: 0.0145413870246085
  episodes_this_iter: 500
  episodes_total: 50500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1610.02
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.40303313732147217
        entropy_coeff: 0.0
        kl: 0.005441663321107626
        model: {}
        policy_loss: -0.025789592415094376
        total_loss: -0.014240176416933537
        vf_explained_var: 0.639148473739624
        vf_loss: 0.011377227492630482
    load_time_ms: 2.436
    num_steps_sampled: 50500
    num_steps_trained: 50500
    sample_time_ms: 40353.201
    update_time_ms: 5.889
  iterations_since_restore: 101
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.312000000000001
    ram_util_percent: 13.325999999999999
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 384.7611883399922
    mean_inference_ms: 1.5281049410344745
    mean_processing_ms: 1.113214010493698
  time_since_restore: 19743.28354549408
  time_this_iter_s: 34.43247628211975
  time_total_s: 19743.28354549408
  timestamp: 1637979021
  timesteps_since_restore: 50500
  timesteps_this_iter: 500
  timesteps_total: 50500
  training_iteration: 101
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    101 |          19743.3 | 50500 |  0.48547 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-10-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.5030429466250822
  episode_reward_min: 0.033582089552238806
  episodes_this_iter: 500
  episodes_total: 51000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1606.102
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.36697182059288025
        entropy_coeff: 0.0
        kl: 0.008410598151385784
        model: {}
        policy_loss: -0.024326292797923088
        total_loss: -0.012728828005492687
        vf_explained_var: 0.6192117929458618
        vf_loss: 0.011331344023346901
    load_time_ms: 2.265
    num_steps_sampled: 51000
    num_steps_trained: 51000
    sample_time_ms: 38183.386
    update_time_ms: 5.893
  iterations_since_restore: 102
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.76078431372549
    ram_util_percent: 13.282352941176473
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 381.63871330942936
    mean_inference_ms: 1.5248544089796636
    mean_processing_ms: 1.110658222842559
  time_since_restore: 19779.143944978714
  time_this_iter_s: 35.8603994846344
  time_total_s: 19779.143944978714
  timestamp: 1637979057
  timesteps_since_restore: 51000
  timesteps_this_iter: 500
  timesteps_total: 51000
  training_iteration: 102
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    102 |          19779.1 | 51000 | 0.503043 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-11-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8631578947368421
  episode_reward_mean: 0.4978989571125996
  episode_reward_min: -0.10784313725490197
  episodes_this_iter: 500
  episodes_total: 51500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1630.406
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.34522953629493713
        entropy_coeff: 0.0
        kl: 0.005981491878628731
        model: {}
        policy_loss: -0.031683120876550674
        total_loss: -0.016053564846515656
        vf_explained_var: 0.5053901076316833
        vf_loss: 0.015440297313034534
    load_time_ms: 2.279
    num_steps_sampled: 51500
    num_steps_trained: 51500
    sample_time_ms: 36941.45
    update_time_ms: 5.892
  iterations_since_restore: 103
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.327999999999998
    ram_util_percent: 13.297999999999996
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 378.55123203728164
    mean_inference_ms: 1.521730864618114
    mean_processing_ms: 1.108175430368959
  time_since_restore: 19813.907698869705
  time_this_iter_s: 34.76375389099121
  time_total_s: 19813.907698869705
  timestamp: 1637979092
  timesteps_since_restore: 51500
  timesteps_this_iter: 500
  timesteps_total: 51500
  training_iteration: 103
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    103 |          19813.9 | 51500 | 0.497899 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-12-00
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8650568181818182
  episode_reward_mean: 0.4870158522313718
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 52000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1631.838
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.38038188219070435
        entropy_coeff: 0.0
        kl: 0.010230831801891327
        model: {}
        policy_loss: -0.029205022379755974
        total_loss: -0.018483228981494904
        vf_explained_var: 0.6163274645805359
        vf_loss: 0.010398087091743946
    load_time_ms: 2.325
    num_steps_sampled: 52000
    num_steps_trained: 52000
    sample_time_ms: 34147.425
    update_time_ms: 5.907
  iterations_since_restore: 104
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.3475
    ram_util_percent: 13.3125
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 375.3923150049339
    mean_inference_ms: 1.5184062368257565
    mean_processing_ms: 1.1054940417267674
  time_since_restore: 19841.59009861946
  time_this_iter_s: 27.68239974975586
  time_total_s: 19841.59009861946
  timestamp: 1637979120
  timesteps_since_restore: 52000
  timesteps_this_iter: 500
  timesteps_total: 52000
  training_iteration: 104
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    104 |          19841.6 | 52000 | 0.487016 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-12-37
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8652931854199684
  episode_reward_mean: 0.4832803488367637
  episode_reward_min: 0.04018912529550828
  episodes_this_iter: 500
  episodes_total: 52500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1629.022
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3623191714286804
        entropy_coeff: 0.0
        kl: 0.00681573199108243
        model: {}
        policy_loss: -0.01988706737756729
        total_loss: -0.008277875371277332
        vf_explained_var: 0.6303379535675049
        vf_loss: 0.011393544264137745
    load_time_ms: 2.36
    num_steps_sampled: 52500
    num_steps_trained: 52500
    sample_time_ms: 34042.075
    update_time_ms: 5.907
  iterations_since_restore: 105
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.646153846153847
    ram_util_percent: 13.313461538461535
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 372.46538177653423
    mean_inference_ms: 1.5154517842906743
    mean_processing_ms: 1.1029941999663178
  time_since_restore: 19878.456161260605
  time_this_iter_s: 36.8660626411438
  time_total_s: 19878.456161260605
  timestamp: 1637979157
  timesteps_since_restore: 52500
  timesteps_this_iter: 500
  timesteps_total: 52500
  training_iteration: 105
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    105 |          19878.5 | 52500 |  0.48328 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-13-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647058823529412
  episode_reward_mean: 0.4991439596648368
  episode_reward_min: 0.03
  episodes_this_iter: 500
  episodes_total: 53000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1612.926
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.35433119535446167
        entropy_coeff: 0.0
        kl: 0.006078238599002361
        model: {}
        policy_loss: -0.022215964272618294
        total_loss: -0.012137046083807945
        vf_explained_var: 0.6631529331207275
        vf_loss: 0.009886595420539379
    load_time_ms: 2.354
    num_steps_sampled: 53000
    num_steps_trained: 53000
    sample_time_ms: 32898.813
    update_time_ms: 5.884
  iterations_since_restore: 106
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.576086956521738
    ram_util_percent: 13.369565217391305
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 369.4991433767326
    mean_inference_ms: 1.5130189272082597
    mean_processing_ms: 1.1012408196306465
  time_since_restore: 19910.152046442032
  time_this_iter_s: 31.695885181427002
  time_total_s: 19910.152046442032
  timestamp: 1637979189
  timesteps_since_restore: 53000
  timesteps_this_iter: 500
  timesteps_total: 53000
  training_iteration: 106
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    106 |          19910.2 | 53000 | 0.499144 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-13-40
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.849802371541502
  episode_reward_mean: 0.4980588974767099
  episode_reward_min: -0.08557046979865772
  episodes_this_iter: 500
  episodes_total: 53500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1599.572
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3162270486354828
        entropy_coeff: 0.0
        kl: 0.007155567407608032
        model: {}
        policy_loss: -0.03214279189705849
        total_loss: -0.021140966564416885
        vf_explained_var: 0.6230809092521667
        vf_loss: 0.010775425471365452
    load_time_ms: 2.395
    num_steps_sampled: 53500
    num_steps_trained: 53500
    sample_time_ms: 32379.363
    update_time_ms: 5.74
  iterations_since_restore: 107
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.391111111111114
    ram_util_percent: 13.359999999999994
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 366.58025180951915
    mean_inference_ms: 1.5099816441667413
    mean_processing_ms: 1.0988959102830618
  time_since_restore: 19941.45551776886
  time_this_iter_s: 31.303471326828003
  time_total_s: 19941.45551776886
  timestamp: 1637979220
  timesteps_since_restore: 53500
  timesteps_this_iter: 500
  timesteps_total: 53500
  training_iteration: 107
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    107 |          19941.5 | 53500 | 0.498059 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-14-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8629441624365483
  episode_reward_mean: 0.5000145564277357
  episode_reward_min: 0.07720588235294118
  episodes_this_iter: 500
  episodes_total: 54000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1602.671
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3540070354938507
        entropy_coeff: 0.0
        kl: 0.009022429585456848
        model: {}
        policy_loss: -0.024300871416926384
        total_loss: -0.013201255351305008
        vf_explained_var: 0.6037402749061584
        vf_loss: 0.010814135894179344
    load_time_ms: 2.409
    num_steps_sampled: 54000
    num_steps_trained: 54000
    sample_time_ms: 30646.585
    update_time_ms: 5.837
  iterations_since_restore: 108
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.02972972972973
    ram_util_percent: 13.335135135135136
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 363.612485486921
    mean_inference_ms: 1.5071584141670988
    mean_processing_ms: 1.0967298966046075
  time_since_restore: 19967.194981575012
  time_this_iter_s: 25.739463806152344
  time_total_s: 19967.194981575012
  timestamp: 1637979246
  timesteps_since_restore: 54000
  timesteps_this_iter: 500
  timesteps_total: 54000
  training_iteration: 108
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    108 |          19967.2 | 54000 | 0.500015 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-14-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8840399002493765
  episode_reward_mean: 0.5122658996976689
  episode_reward_min: 0.1206896551724138
  episodes_this_iter: 500
  episodes_total: 54500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1618.102
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3281767666339874
        entropy_coeff: 0.0
        kl: 0.0075474511831998825
        model: {}
        policy_loss: -0.023266203701496124
        total_loss: -0.010550246573984623
        vf_explained_var: 0.5761011242866516
        vf_loss: 0.0124771473929286
    load_time_ms: 2.385
    num_steps_sampled: 54500
    num_steps_trained: 54500
    sample_time_ms: 29414.444
    update_time_ms: 5.665
  iterations_since_restore: 109
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.49642857142857
    ram_util_percent: 13.310714285714285
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 360.5911776778067
    mean_inference_ms: 1.50392832479307
    mean_processing_ms: 1.0942855503963282
  time_since_restore: 19987.09680247307
  time_this_iter_s: 19.90182089805603
  time_total_s: 19987.09680247307
  timestamp: 1637979266
  timesteps_since_restore: 54500
  timesteps_this_iter: 500
  timesteps_total: 54500
  training_iteration: 109
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    109 |          19987.1 | 54500 | 0.512266 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-14-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8802507836990595
  episode_reward_mean: 0.4972935090910109
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 55000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1608.846
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3046407401561737
        entropy_coeff: 0.0
        kl: 0.005666609853506088
        model: {}
        policy_loss: -0.02065270207822323
        total_loss: -0.006554826628416777
        vf_explained_var: 0.5661046504974365
        vf_loss: 0.013918578624725342
    load_time_ms: 2.395
    num_steps_sampled: 55000
    num_steps_trained: 55000
    sample_time_ms: 28869.488
    update_time_ms: 5.642
  iterations_since_restore: 110
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.92564102564103
    ram_util_percent: 13.371794871794872
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 357.7506124330663
    mean_inference_ms: 1.501037919264061
    mean_processing_ms: 1.0918849351304183
  time_since_restore: 20013.800464868546
  time_this_iter_s: 26.703662395477295
  time_total_s: 20013.800464868546
  timestamp: 1637979293
  timesteps_since_restore: 55000
  timesteps_this_iter: 500
  timesteps_total: 55000
  training_iteration: 110
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    110 |          20013.8 | 55000 | 0.497294 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-15-17
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9664360370970116
  episode_reward_mean: 0.5131914514831
  episode_reward_min: 0.06097560975609756
  episodes_this_iter: 500
  episodes_total: 55500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1618.933
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.29508137702941895
        entropy_coeff: 0.0
        kl: 0.010014916770160198
        model: {}
        policy_loss: -0.019611012190580368
        total_loss: -0.007034013047814369
        vf_explained_var: 0.5722914338111877
        vf_loss: 0.01226012036204338
    load_time_ms: 2.385
    num_steps_sampled: 55500
    num_steps_trained: 55500
    sample_time_ms: 27805.464
    update_time_ms: 5.569
  iterations_since_restore: 111
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.223529411764707
    ram_util_percent: 13.305882352941177
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 354.90890731532465
    mean_inference_ms: 1.497952281388095
    mean_processing_ms: 1.0893493812901807
  time_since_restore: 20037.692578792572
  time_this_iter_s: 23.89211392402649
  time_total_s: 20037.692578792572
  timestamp: 1637979317
  timesteps_since_restore: 55500
  timesteps_this_iter: 500
  timesteps_total: 55500
  training_iteration: 111
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    111 |          20037.7 | 55500 | 0.513191 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-15-37
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8959823885525592
  episode_reward_mean: 0.5100369656649255
  episode_reward_min: -0.2185792349726776
  episodes_this_iter: 500
  episodes_total: 56000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1635.6
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3014141023159027
        entropy_coeff: 0.0
        kl: 0.006564741022884846
        model: {}
        policy_loss: -0.0193929485976696
        total_loss: -0.004378272220492363
        vf_explained_var: 0.5375894904136658
        vf_loss: 0.014806961640715599
    load_time_ms: 2.368
    num_steps_sampled: 56000
    num_steps_trained: 56000
    sample_time_ms: 26165.264
    update_time_ms: 5.687
  iterations_since_restore: 112
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.24642857142857
    ram_util_percent: 13.303571428571429
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 352.0395477546823
    mean_inference_ms: 1.494922611713878
    mean_processing_ms: 1.0869599238448637
  time_since_restore: 20057.318784952164
  time_this_iter_s: 19.626206159591675
  time_total_s: 20057.318784952164
  timestamp: 1637979337
  timesteps_since_restore: 56000
  timesteps_this_iter: 500
  timesteps_total: 56000
  training_iteration: 112
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    112 |          20057.3 | 56000 | 0.510037 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-16-02
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8801075268817204
  episode_reward_mean: 0.5075718720101549
  episode_reward_min: 0.012
  episodes_this_iter: 500
  episodes_total: 56500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1617.046
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.2955574691295624
        entropy_coeff: 0.0
        kl: 0.005657683592289686
        model: {}
        policy_loss: -0.019750285893678665
        total_loss: -0.008009079843759537
        vf_explained_var: 0.6041110157966614
        vf_loss: 0.011562193743884563
    load_time_ms: 2.362
    num_steps_sampled: 56500
    num_steps_trained: 56500
    sample_time_ms: 25224.567
    update_time_ms: 6.3
  iterations_since_restore: 113
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.816666666666666
    ram_util_percent: 13.311111111111112
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 349.31910722222494
    mean_inference_ms: 1.4941480817572168
    mean_processing_ms: 1.084784664235679
  time_since_restore: 20082.497344255447
  time_this_iter_s: 25.17855930328369
  time_total_s: 20082.497344255447
  timestamp: 1637979362
  timesteps_since_restore: 56500
  timesteps_this_iter: 500
  timesteps_total: 56500
  training_iteration: 113
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    113 |          20082.5 | 56500 | 0.507572 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-16-29
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5048764860557776
  episode_reward_min: -1.273015873015873
  episodes_this_iter: 500
  episodes_total: 57000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1624.223
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.31219232082366943
        entropy_coeff: 0.0
        kl: 0.004730880726128817
        model: {}
        policy_loss: -0.02597229555249214
        total_loss: -0.00889549870043993
        vf_explained_var: 0.5583451986312866
        vf_loss: 0.01692710816860199
    load_time_ms: 2.309
    num_steps_sampled: 57000
    num_steps_trained: 57000
    sample_time_ms: 25073.801
    update_time_ms: 6.246
  iterations_since_restore: 114
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.942105263157899
    ram_util_percent: 13.339473684210526
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 346.66755794589983
    mean_inference_ms: 1.4911887833985156
    mean_processing_ms: 1.0824908444936694
  time_since_restore: 20108.742965459824
  time_this_iter_s: 26.24562120437622
  time_total_s: 20108.742965459824
  timestamp: 1637979389
  timesteps_since_restore: 57000
  timesteps_this_iter: 500
  timesteps_total: 57000
  training_iteration: 114
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    114 |          20108.7 | 57000 | 0.504876 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-16-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595166163141994
  episode_reward_mean: 0.48872795955802856
  episode_reward_min: 0.08902691511387163
  episodes_this_iter: 500
  episodes_total: 57500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1621.578
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.27421754598617554
        entropy_coeff: 0.0
        kl: 0.007583958096802235
        model: {}
        policy_loss: -0.032901063561439514
        total_loss: -0.02208051271736622
        vf_explained_var: 0.6332710385322571
        vf_loss: 0.01070057600736618
    load_time_ms: 2.261
    num_steps_sampled: 57500
    num_steps_trained: 57500
    sample_time_ms: 23687.204
    update_time_ms: 6.266
  iterations_since_restore: 115
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.203030303030303
    ram_util_percent: 13.330303030303032
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 344.00472789264256
    mean_inference_ms: 1.4881930727164323
    mean_processing_ms: 1.0801149810683806
  time_since_restore: 20131.72020959854
  time_this_iter_s: 22.97724413871765
  time_total_s: 20131.72020959854
  timestamp: 1637979412
  timesteps_since_restore: 57500
  timesteps_this_iter: 500
  timesteps_total: 57500
  training_iteration: 115
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    115 |          20131.7 | 57500 | 0.488728 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-17-07
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610634648370498
  episode_reward_mean: 0.48770060067124327
  episode_reward_min: -0.2113095238095238
  episodes_this_iter: 500
  episodes_total: 58000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1634.087
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.32295775413513184
        entropy_coeff: 0.0
        kl: 0.02479914017021656
        model: {}
        policy_loss: -0.033423323184251785
        total_loss: -0.022268004715442657
        vf_explained_var: 0.665086030960083
        vf_loss: 0.010762989521026611
    load_time_ms: 2.265
    num_steps_sampled: 58000
    num_steps_trained: 58000
    sample_time_ms: 22005.228
    update_time_ms: 6.331
  iterations_since_restore: 116
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.004761904761903
    ram_util_percent: 13.380952380952381
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 341.2516053299524
    mean_inference_ms: 1.4852520285042232
    mean_processing_ms: 1.0777248337121628
  time_since_restore: 20146.722517728806
  time_this_iter_s: 15.002308130264282
  time_total_s: 20146.722517728806
  timestamp: 1637979427
  timesteps_since_restore: 58000
  timesteps_this_iter: 500
  timesteps_total: 58000
  training_iteration: 116
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    116 |          20146.7 | 58000 | 0.487701 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-17-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8659476117103235
  episode_reward_mean: 0.49814755330657573
  episode_reward_min: 0.0145413870246085
  episodes_this_iter: 500
  episodes_total: 58500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1625.4
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.33169806003570557
        entropy_coeff: 0.0
        kl: 0.013236919417977333
        model: {}
        policy_loss: -0.025840360671281815
        total_loss: -0.013224688358604908
        vf_explained_var: 0.6070334315299988
        vf_loss: 0.012301555834710598
    load_time_ms: 2.209
    num_steps_sampled: 58500
    num_steps_trained: 58500
    sample_time_ms: 21310.345
    update_time_ms: 6.503
  iterations_since_restore: 117
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.694285714285716
    ram_util_percent: 13.362857142857143
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 338.7052077651727
    mean_inference_ms: 1.482623411760141
    mean_processing_ms: 1.0755278021227088
  time_since_restore: 20170.991055965424
  time_this_iter_s: 24.268538236618042
  time_total_s: 20170.991055965424
  timestamp: 1637979451
  timesteps_since_restore: 58500
  timesteps_this_iter: 500
  timesteps_total: 58500
  training_iteration: 117
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    117 |            20171 | 58500 | 0.498148 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-17-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.4955138352925306
  episode_reward_min: 0.10894941634241245
  episodes_this_iter: 500
  episodes_total: 59000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1627.465
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.307543009519577
        entropy_coeff: 0.0
        kl: 0.006942854728549719
        model: {}
        policy_loss: -0.024523954838514328
        total_loss: -0.013290900737047195
        vf_explained_var: 0.5930231809616089
        vf_loss: 0.011068296618759632
    load_time_ms: 2.194
    num_steps_sampled: 59000
    num_steps_trained: 59000
    sample_time_ms: 21098.004
    update_time_ms: 6.39
  iterations_since_restore: 118
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.15294117647059
    ram_util_percent: 13.344117647058825
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 336.18996763663364
    mean_inference_ms: 1.4800112747854706
    mean_processing_ms: 1.07323848801757
  time_since_restore: 20194.626957416534
  time_this_iter_s: 23.63590145111084
  time_total_s: 20194.626957416534
  timestamp: 1637979475
  timesteps_since_restore: 59000
  timesteps_this_iter: 500
  timesteps_total: 59000
  training_iteration: 118
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    118 |          20194.6 | 59000 | 0.495514 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-18-13
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8631578947368421
  episode_reward_mean: 0.4954721893137332
  episode_reward_min: -0.2572145545796738
  episodes_this_iter: 500
  episodes_total: 59500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1607.042
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.3236471116542816
        entropy_coeff: 0.0
        kl: 0.010537445545196533
        model: {}
        policy_loss: -0.032747782766819
        total_loss: -0.017165102064609528
        vf_explained_var: 0.563561737537384
        vf_loss: 0.015332630835473537
    load_time_ms: 2.205
    num_steps_sampled: 59500
    num_steps_trained: 59500
    sample_time_ms: 20910.173
    update_time_ms: 6.37
  iterations_since_restore: 119
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.334615384615386
    ram_util_percent: 13.388461538461538
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 333.621765272539
    mean_inference_ms: 1.477171350103657
    mean_processing_ms: 1.0710186310065772
  time_since_restore: 20212.445030927658
  time_this_iter_s: 17.818073511123657
  time_total_s: 20212.445030927658
  timestamp: 1637979493
  timesteps_since_restore: 59500
  timesteps_this_iter: 500
  timesteps_total: 59500
  training_iteration: 119
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    119 |          20212.4 | 59500 | 0.495472 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-18-36
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8650568181818182
  episode_reward_mean: 0.4937935707228249
  episode_reward_min: -0.8931297709923665
  episodes_this_iter: 500
  episodes_total: 60000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1612.049
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.3245028555393219
        entropy_coeff: 0.0
        kl: 0.005369577556848526
        model: {}
        policy_loss: -0.023411685600876808
        total_loss: -0.00987473875284195
        vf_explained_var: 0.6275219917297363
        vf_loss: 0.01340951956808567
    load_time_ms: 2.192
    num_steps_sampled: 60000
    num_steps_trained: 60000
    sample_time_ms: 20533.089
    update_time_ms: 6.688
  iterations_since_restore: 120
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.215151515151517
    ram_util_percent: 13.393939393939393
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 331.1796605341637
    mean_inference_ms: 1.4747327865059165
    mean_processing_ms: 1.0691667341776299
  time_since_restore: 20235.431487321854
  time_this_iter_s: 22.986456394195557
  time_total_s: 20235.431487321854
  timestamp: 1637979516
  timesteps_since_restore: 60000
  timesteps_this_iter: 500
  timesteps_total: 60000
  training_iteration: 120
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    120 |          20235.4 | 60000 | 0.493794 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-18-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8652931854199684
  episode_reward_mean: 0.48036960634430464
  episode_reward_min: 0.03
  episodes_this_iter: 500
  episodes_total: 60500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1606.932
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.32281479239463806
        entropy_coeff: 0.0
        kl: 0.006011477671563625
        model: {}
        policy_loss: -0.024763142690062523
        total_loss: -0.01428950298577547
        vf_explained_var: 0.6668193340301514
        vf_loss: 0.010330984368920326
    load_time_ms: 2.199
    num_steps_sampled: 60500
    num_steps_trained: 60500
    sample_time_ms: 20195.736
    update_time_ms: 6.67
  iterations_since_restore: 121
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.720689655172412
    ram_util_percent: 13.36896551724138
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 328.73652451917263
    mean_inference_ms: 1.4723027391462564
    mean_processing_ms: 1.0669708992811837
  time_since_restore: 20255.8987596035
  time_this_iter_s: 20.46727228164673
  time_total_s: 20255.8987596035
  timestamp: 1637979537
  timesteps_since_restore: 60500
  timesteps_this_iter: 500
  timesteps_total: 60500
  training_iteration: 121
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    121 |          20255.9 | 60500 |  0.48037 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-19-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.5020233188125951
  episode_reward_min: 0.08044692737430167
  episodes_this_iter: 500
  episodes_total: 61000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1595.077
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.32495152950286865
        entropy_coeff: 0.0
        kl: 0.007064099423587322
        model: {}
        policy_loss: -0.024162864312529564
        total_loss: -0.013251936063170433
        vf_explained_var: 0.6189835071563721
        vf_loss: 0.010743306949734688
    load_time_ms: 2.244
    num_steps_sampled: 61000
    num_steps_trained: 61000
    sample_time_ms: 20493.634
    update_time_ms: 6.539
  iterations_since_restore: 122
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.46363636363636
    ram_util_percent: 13.369696969696971
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 326.36578981861646
    mean_inference_ms: 1.4697083473064863
    mean_processing_ms: 1.0649542349604015
  time_since_restore: 20278.384661912918
  time_this_iter_s: 22.485902309417725
  time_total_s: 20278.384661912918
  timestamp: 1637979560
  timesteps_since_restore: 61000
  timesteps_this_iter: 500
  timesteps_total: 61000
  training_iteration: 122
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    122 |          20278.4 | 61000 | 0.502023 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-19-33
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8629441624365483
  episode_reward_mean: 0.5006603846017229
  episode_reward_min: 0.09777777777777778
  episodes_this_iter: 500
  episodes_total: 61500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1600.324
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.339608758687973
        entropy_coeff: 0.0
        kl: 0.013294101692736149
        model: {}
        policy_loss: -0.02410825341939926
        total_loss: -0.012925723567605019
        vf_explained_var: 0.6269287467002869
        vf_loss: 0.010867051780223846
    load_time_ms: 2.256
    num_steps_sampled: 61500
    num_steps_trained: 61500
    sample_time_ms: 19332.38
    update_time_ms: 5.866
  iterations_since_restore: 123
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.173684210526318
    ram_util_percent: 13.410526315789477
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 323.88898994133314
    mean_inference_ms: 1.4671013860422932
    mean_processing_ms: 1.062780986465894
  time_since_restore: 20291.99542450905
  time_this_iter_s: 13.610762596130371
  time_total_s: 20291.99542450905
  timestamp: 1637979573
  timesteps_since_restore: 61500
  timesteps_this_iter: 500
  timesteps_total: 61500
  training_iteration: 123
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    123 |            20292 | 61500 |  0.50066 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-20-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8737580362361193
  episode_reward_mean: 0.5015309723377606
  episode_reward_min: -0.5850622406639004
  episodes_this_iter: 500
  episodes_total: 62000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1600.819
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.34238284826278687
        entropy_coeff: 0.0
        kl: 0.007169704418629408
        model: {}
        policy_loss: -0.03075876645743847
        total_loss: -0.01914915256202221
        vf_explained_var: 0.6421900391578674
        vf_loss: 0.011439475230872631
    load_time_ms: 2.274
    num_steps_sampled: 62000
    num_steps_trained: 62000
    sample_time_ms: 19629.067
    update_time_ms: 5.792
  iterations_since_restore: 124
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.088095238095237
    ram_util_percent: 13.378571428571425
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 321.70378571758243
    mean_inference_ms: 1.4648234501390447
    mean_processing_ms: 1.0610067875730869
  time_since_restore: 20321.212054252625
  time_this_iter_s: 29.21662974357605
  time_total_s: 20321.212054252625
  timestamp: 1637979603
  timesteps_since_restore: 62000
  timesteps_this_iter: 500
  timesteps_total: 62000
  training_iteration: 124
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    124 |          20321.2 | 62000 | 0.501531 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-20-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8840399002493765
  episode_reward_mean: 0.5010145173598045
  episode_reward_min: 0.04310344827586207
  episodes_this_iter: 500
  episodes_total: 62500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1603.94
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.31886380910873413
        entropy_coeff: 0.0
        kl: 0.009732547216117382
        model: {}
        policy_loss: -0.028641488403081894
        total_loss: -0.01513010822236538
        vf_explained_var: 0.5481246113777161
        vf_loss: 0.013280432671308517
    load_time_ms: 2.299
    num_steps_sampled: 62500
    num_steps_trained: 62500
    sample_time_ms: 20240.945
    update_time_ms: 5.8
  iterations_since_restore: 125
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.67619047619048
    ram_util_percent: 13.411904761904761
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 319.5508368707532
    mean_inference_ms: 1.4626294490335519
    mean_processing_ms: 1.0593066556772492
  time_since_restore: 20350.33579158783
  time_this_iter_s: 29.123737335205078
  time_total_s: 20350.33579158783
  timestamp: 1637979632
  timesteps_since_restore: 62500
  timesteps_this_iter: 500
  timesteps_total: 62500
  training_iteration: 125
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    125 |          20350.3 | 62500 | 0.501015 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-20-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8802507836990595
  episode_reward_mean: 0.5066226978008317
  episode_reward_min: -0.06837606837606838
  episodes_this_iter: 500
  episodes_total: 63000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1619.642
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.2975226044654846
        entropy_coeff: 0.0
        kl: 0.013641544617712498
        model: {}
        policy_loss: -0.03074326552450657
        total_loss: -0.018844252452254295
        vf_explained_var: 0.6285175085067749
        vf_loss: 0.011575289070606232
    load_time_ms: 2.335
    num_steps_sampled: 63000
    num_steps_trained: 63000
    sample_time_ms: 20604.598
    update_time_ms: 5.77
  iterations_since_restore: 126
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.455555555555556
    ram_util_percent: 13.392592592592596
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 317.2679476010546
    mean_inference_ms: 1.4601866500085994
    mean_processing_ms: 1.0572591983458928
  time_since_restore: 20369.131623506546
  time_this_iter_s: 18.79583191871643
  time_total_s: 20369.131623506546
  timestamp: 1637979651
  timesteps_since_restore: 63000
  timesteps_this_iter: 500
  timesteps_total: 63000
  training_iteration: 126
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    126 |          20369.1 | 63000 | 0.506623 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-21-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9664360370970116
  episode_reward_mean: 0.5118133176301359
  episode_reward_min: -1.853968253968254
  episodes_this_iter: 500
  episodes_total: 63500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1625.772
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.3004777431488037
        entropy_coeff: 0.0
        kl: 0.008781174197793007
        model: {}
        policy_loss: -0.024583758786320686
        total_loss: -0.0013649153988808393
        vf_explained_var: 0.5152860879898071
        vf_loss: 0.023010458797216415
    load_time_ms: 2.349
    num_steps_sampled: 63500
    num_steps_trained: 63500
    sample_time_ms: 19961.47
    update_time_ms: 5.775
  iterations_since_restore: 127
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.784615384615385
    ram_util_percent: 13.392307692307693
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 315.0096957198211
    mean_inference_ms: 1.4579351904884053
    mean_processing_ms: 1.055377349803054
  time_since_restore: 20387.030130386353
  time_this_iter_s: 17.89850687980652
  time_total_s: 20387.030130386353
  timestamp: 1637979669
  timesteps_since_restore: 63500
  timesteps_this_iter: 500
  timesteps_total: 63500
  training_iteration: 127
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    127 |            20387 | 63500 | 0.511813 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-21-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8959823885525592
  episode_reward_mean: 0.5054931468641425
  episode_reward_min: -0.3179916317991632
  episodes_this_iter: 500
  episodes_total: 64000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1631.378
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.28609469532966614
        entropy_coeff: 0.0
        kl: 0.005118134431540966
        model: {}
        policy_loss: -0.021770261228084564
        total_loss: -0.007307353429496288
        vf_explained_var: 0.5897453427314758
        vf_loss: 0.014341454952955246
    load_time_ms: 2.362
    num_steps_sampled: 64000
    num_steps_trained: 64000
    sample_time_ms: 20064.72
    update_time_ms: 5.859
  iterations_since_restore: 128
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.422857142857142
    ram_util_percent: 13.4
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 312.8921799848896
    mean_inference_ms: 1.455656966314329
    mean_processing_ms: 1.0534559655391795
  time_since_restore: 20411.755767822266
  time_this_iter_s: 24.725637435913086
  time_total_s: 20411.755767822266
  timestamp: 1637979694
  timesteps_since_restore: 64000
  timesteps_this_iter: 500
  timesteps_total: 64000
  training_iteration: 128
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    128 |          20411.8 | 64000 | 0.505493 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-21-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5182694524109404
  episode_reward_min: 0.1026252983293556
  episodes_this_iter: 500
  episodes_total: 64500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1651.436
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.2701255977153778
        entropy_coeff: 0.0
        kl: 0.006363833323121071
        model: {}
        policy_loss: -0.01569516211748123
        total_loss: -0.003948331810534
        vf_explained_var: 0.6044312715530396
        vf_loss: 0.011595807038247585
    load_time_ms: 2.34
    num_steps_sampled: 64500
    num_steps_trained: 64500
    sample_time_ms: 19595.288
    update_time_ms: 5.855
  iterations_since_restore: 129
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.835
    ram_util_percent: 13.385000000000002
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 310.6302516563657
    mean_inference_ms: 1.453619369530729
    mean_processing_ms: 1.0517794642972795
  time_since_restore: 20425.079897880554
  time_this_iter_s: 13.324130058288574
  time_total_s: 20425.079897880554
  timestamp: 1637979707
  timesteps_since_restore: 64500
  timesteps_this_iter: 500
  timesteps_total: 64500
  training_iteration: 129
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    129 |          20425.1 | 64500 | 0.518269 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-22-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595166163141994
  episode_reward_mean: 0.49202623900643533
  episode_reward_min: 0.08695652173913043
  episodes_this_iter: 500
  episodes_total: 65000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1659.4
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.30213800072669983
        entropy_coeff: 0.0
        kl: 0.013612586073577404
        model: {}
        policy_loss: -0.02773311920464039
        total_loss: -0.01682845503091812
        vf_explained_var: 0.6092116832733154
        vf_loss: 0.010581634007394314
    load_time_ms: 2.366
    num_steps_sampled: 65000
    num_steps_trained: 65000
    sample_time_ms: 19473.083
    update_time_ms: 5.536
  iterations_since_restore: 130
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.470967741935484
    ram_util_percent: 13.390322580645158
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 308.5346647145993
    mean_inference_ms: 1.4513105126986547
    mean_processing_ms: 1.0498810345568188
  time_since_restore: 20446.920770406723
  time_this_iter_s: 21.840872526168823
  time_total_s: 20446.920770406723
  timestamp: 1637979729
  timesteps_since_restore: 65000
  timesteps_this_iter: 500
  timesteps_total: 65000
  training_iteration: 130
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    130 |          20446.9 | 65000 | 0.492026 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-22-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610634648370498
  episode_reward_mean: 0.4912755350589098
  episode_reward_min: 0.0744920993227991
  episodes_this_iter: 500
  episodes_total: 65500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1663.156
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.27715247869491577
        entropy_coeff: 0.0
        kl: 0.00951344519853592
        model: {}
        policy_loss: -0.02632307820022106
        total_loss: -0.014936759136617184
        vf_explained_var: 0.5968813896179199
        vf_loss: 0.011160563677549362
    load_time_ms: 2.371
    num_steps_sampled: 65500
    num_steps_trained: 65500
    sample_time_ms: 19872.034
    update_time_ms: 5.57
  iterations_since_restore: 131
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.894285714285717
    ram_util_percent: 13.399999999999999
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 306.51182611924696
    mean_inference_ms: 1.4491166921574163
    mean_processing_ms: 1.0480762658211147
  time_since_restore: 20471.416426181793
  time_this_iter_s: 24.49565577507019
  time_total_s: 20471.416426181793
  timestamp: 1637979754
  timesteps_since_restore: 65500
  timesteps_this_iter: 500
  timesteps_total: 65500
  training_iteration: 131
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    131 |          20471.4 | 65500 | 0.491276 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-22-54
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8659476117103235
  episode_reward_mean: 0.4887335274258221
  episode_reward_min: -0.06970509383378017
  episodes_this_iter: 500
  episodes_total: 66000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1655.236
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.27861401438713074
        entropy_coeff: 0.0
        kl: 0.01442287303507328
        model: {}
        policy_loss: -0.024621153250336647
        total_loss: -0.0134350610896945
        vf_explained_var: 0.6656674146652222
        vf_loss: 0.01084382738918066
    load_time_ms: 2.33
    num_steps_sampled: 66000
    num_steps_trained: 66000
    sample_time_ms: 19587.666
    update_time_ms: 5.62
  iterations_since_restore: 132
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.942857142857145
    ram_util_percent: 13.335714285714289
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 304.4461572866176
    mean_inference_ms: 1.446888675505612
    mean_processing_ms: 1.0461544705525296
  time_since_restore: 20490.979234933853
  time_this_iter_s: 19.562808752059937
  time_total_s: 20490.979234933853
  timestamp: 1637979774
  timesteps_since_restore: 66000
  timesteps_this_iter: 500
  timesteps_total: 66000
  training_iteration: 132
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    132 |            20491 | 66000 | 0.488734 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-23-19
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8564437194127243
  episode_reward_mean: 0.499189664447541
  episode_reward_min: -0.5180722891566265
  episodes_this_iter: 500
  episodes_total: 66500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1648.24
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.26107028126716614
        entropy_coeff: 0.0
        kl: 0.005672601517289877
        model: {}
        policy_loss: -0.01796886697411537
        total_loss: -0.004349106457084417
        vf_explained_var: 0.5596689581871033
        vf_loss: 0.013485145755112171
    load_time_ms: 2.307
    num_steps_sampled: 66500
    num_steps_trained: 66500
    sample_time_ms: 20703.976
    update_time_ms: 5.8
  iterations_since_restore: 133
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.11388888888889
    ram_util_percent: 13.355555555555558
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 302.48785592909474
    mean_inference_ms: 1.4447499442979974
    mean_processing_ms: 1.0444945574606257
  time_since_restore: 20515.685215950012
  time_this_iter_s: 24.705981016159058
  time_total_s: 20515.685215950012
  timestamp: 1637979799
  timesteps_since_restore: 66500
  timesteps_this_iter: 500
  timesteps_total: 66500
  training_iteration: 133
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    133 |          20515.7 | 66500 |  0.49919 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-23-48
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.49545037764823907
  episode_reward_min: -1.46
  episodes_this_iter: 500
  episodes_total: 67000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1659.196
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.25704318284988403
        entropy_coeff: 0.0
        kl: 0.006581844296306372
        model: {}
        policy_loss: -0.02904224582016468
        total_loss: -0.011154992505908012
        vf_explained_var: 0.5471976399421692
        vf_loss: 0.017731063067913055
    load_time_ms: 2.283
    num_steps_sampled: 67000
    num_steps_trained: 67000
    sample_time_ms: 20712.988
    update_time_ms: 5.929
  iterations_since_restore: 134
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.628571428571428
    ram_util_percent: 13.357142857142858
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 300.62708605086794
    mean_inference_ms: 1.4427074668880748
    mean_processing_ms: 1.0428089246549042
  time_since_restore: 20545.10316514969
  time_this_iter_s: 29.417949199676514
  time_total_s: 20545.10316514969
  timestamp: 1637979828
  timesteps_since_restore: 67000
  timesteps_this_iter: 500
  timesteps_total: 67000
  training_iteration: 134
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    134 |          20545.1 | 67000 |  0.49545 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-24-21
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8650568181818182
  episode_reward_mean: 0.490724082316655
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 67500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1647.261
    learner:
      default_policy:
        cur_kl_coeff: 0.02373046800494194
        cur_lr: 4.999999873689376e-05
        entropy: 0.30750802159309387
        entropy_coeff: 0.0
        kl: 0.020675474777817726
        model: {}
        policy_loss: -0.033447347581386566
        total_loss: -0.02028212510049343
        vf_explained_var: 0.5858718156814575
        vf_loss: 0.012674583122134209
    load_time_ms: 2.331
    num_steps_sampled: 67500
    num_steps_trained: 67500
    sample_time_ms: 21089.706
    update_time_ms: 5.967
  iterations_since_restore: 135
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.642553191489363
    ram_util_percent: 13.355319148936166
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 298.8456505051107
    mean_inference_ms: 1.440810806844745
    mean_processing_ms: 1.041279377964655
  time_since_restore: 20577.87598466873
  time_this_iter_s: 32.77281951904297
  time_total_s: 20577.87598466873
  timestamp: 1637979861
  timesteps_since_restore: 67500
  timesteps_this_iter: 500
  timesteps_total: 67500
  training_iteration: 135
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    135 |          20577.9 | 67500 | 0.490724 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-24-42
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8624161073825504
  episode_reward_mean: 0.4937540336275009
  episode_reward_min: 0.04018912529550828
  episodes_this_iter: 500
  episodes_total: 68000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1630.177
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.3002531826496124
        entropy_coeff: 0.0
        kl: 0.01187710277736187
        model: {}
        policy_loss: -0.025529401376843452
        total_loss: -0.014612427912652493
        vf_explained_var: 0.6445305347442627
        vf_loss: 0.01049419492483139
    load_time_ms: 2.284
    num_steps_sampled: 68000
    num_steps_trained: 68000
    sample_time_ms: 21308.021
    update_time_ms: 6.037
  iterations_since_restore: 136
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.92666666666667
    ram_util_percent: 13.330000000000004
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 296.91481529966
    mean_inference_ms: 1.4388103246411859
    mean_processing_ms: 1.0395628731295743
  time_since_restore: 20598.684346437454
  time_this_iter_s: 20.808361768722534
  time_total_s: 20598.684346437454
  timestamp: 1637979882
  timesteps_since_restore: 68000
  timesteps_this_iter: 500
  timesteps_total: 68000
  training_iteration: 136
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    136 |          20598.7 | 68000 | 0.493754 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-25-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.4939768735157361
  episode_reward_min: 0.03
  episodes_this_iter: 500
  episodes_total: 68500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1649.425
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.3000362515449524
        entropy_coeff: 0.0
        kl: 0.012115415185689926
        model: {}
        policy_loss: -0.03457402437925339
        total_loss: -0.023863408714532852
        vf_explained_var: 0.6603057384490967
        vf_loss: 0.010279370471835136
    load_time_ms: 2.316
    num_steps_sampled: 68500
    num_steps_trained: 68500
    sample_time_ms: 22087.022
    update_time_ms: 6.063
  iterations_since_restore: 137
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.354054054054055
    ram_util_percent: 13.391891891891893
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 295.0835411980998
    mean_inference_ms: 1.43683975267507
    mean_processing_ms: 1.0380923310341925
  time_since_restore: 20624.566331624985
  time_this_iter_s: 25.881985187530518
  time_total_s: 20624.566331624985
  timestamp: 1637979908
  timesteps_since_restore: 68500
  timesteps_this_iter: 500
  timesteps_total: 68500
  training_iteration: 137
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    137 |          20624.6 | 68500 | 0.493977 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-25-24
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.4956966615224715
  episode_reward_min: 0.08044692737430167
  episodes_this_iter: 500
  episodes_total: 69000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1628.603
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.3036433756351471
        entropy_coeff: 0.0
        kl: 0.008682399056851864
        model: {}
        policy_loss: -0.022348307073116302
        total_loss: -0.011390320956707
        vf_explained_var: 0.608095645904541
        vf_loss: 0.010648936033248901
    load_time_ms: 2.321
    num_steps_sampled: 69000
    num_steps_trained: 69000
    sample_time_ms: 21181.901
    update_time_ms: 6.007
  iterations_since_restore: 138
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.278260869565216
    ram_util_percent: 13.569565217391307
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 293.13279062065106
    mean_inference_ms: 1.434826007454422
    mean_processing_ms: 1.0364507378375165
  time_since_restore: 20640.0317401886
  time_this_iter_s: 15.465408563613892
  time_total_s: 20640.0317401886
  timestamp: 1637979924
  timesteps_since_restore: 69000
  timesteps_this_iter: 500
  timesteps_total: 69000
  training_iteration: 138
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    138 |            20640 | 69000 | 0.495697 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-25-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8629441624365483
  episode_reward_mean: 0.4963869127915827
  episode_reward_min: -1.3211009174311927
  episodes_this_iter: 500
  episodes_total: 69500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1625.808
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.3315686881542206
        entropy_coeff: 0.0
        kl: 0.008752257563173771
        model: {}
        policy_loss: -0.027828631922602654
        total_loss: -0.010484082624316216
        vf_explained_var: 0.5545027852058411
        vf_loss: 0.017033005133271217
    load_time_ms: 2.328
    num_steps_sampled: 69500
    num_steps_trained: 69500
    sample_time_ms: 22760.23
    update_time_ms: 5.96
  iterations_since_restore: 139
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.53170731707317
    ram_util_percent: 13.341463414634147
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 291.4029546381647
    mean_inference_ms: 1.4329635555460372
    mean_processing_ms: 1.0349853157377937
  time_since_restore: 20669.111010074615
  time_this_iter_s: 29.079269886016846
  time_total_s: 20669.111010074615
  timestamp: 1637979953
  timesteps_since_restore: 69500
  timesteps_this_iter: 500
  timesteps_total: 69500
  training_iteration: 139
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    139 |          20669.1 | 69500 | 0.496387 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-26-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8737580362361193
  episode_reward_mean: 0.5138637692246629
  episode_reward_min: -0.057692307692307696
  episodes_this_iter: 500
  episodes_total: 70000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1631.912
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.28220969438552856
        entropy_coeff: 0.0
        kl: 0.007222014479339123
        model: {}
        policy_loss: -0.027887515723705292
        total_loss: -0.01568404957652092
        vf_explained_var: 0.6186128854751587
        vf_loss: 0.011946388520300388
    load_time_ms: 2.301
    num_steps_sampled: 70000
    num_steps_trained: 70000
    sample_time_ms: 23071.913
    update_time_ms: 5.997
  iterations_since_restore: 140
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.741666666666665
    ram_util_percent: 13.391666666666667
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 289.6385801987803
    mean_inference_ms: 1.431098861477446
    mean_processing_ms: 1.0335056923557708
  time_since_restore: 20694.130743980408
  time_this_iter_s: 25.019733905792236
  time_total_s: 20694.130743980408
  timestamp: 1637979978
  timesteps_since_restore: 70000
  timesteps_this_iter: 500
  timesteps_total: 70000
  training_iteration: 140
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    140 |          20694.1 | 70000 | 0.513864 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-26-43
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8840399002493765
  episode_reward_mean: 0.4933294014625419
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 70500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1628.495
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2995029091835022
        entropy_coeff: 0.0
        kl: 0.007011150009930134
        model: {}
        policy_loss: -0.01480386033654213
        total_loss: -0.0010109222494065762
        vf_explained_var: 0.5523975491523743
        vf_loss: 0.013543372973799706
    load_time_ms: 2.297
    num_steps_sampled: 70500
    num_steps_trained: 70500
    sample_time_ms: 23046.249
    update_time_ms: 6.037
  iterations_since_restore: 141
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.01142857142857
    ram_util_percent: 13.365714285714285
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 287.8895062111542
    mean_inference_ms: 1.4291943878967277
    mean_processing_ms: 1.0320471103501723
  time_since_restore: 20718.335092306137
  time_this_iter_s: 24.20434832572937
  time_total_s: 20718.335092306137
  timestamp: 1637980003
  timesteps_since_restore: 70500
  timesteps_this_iter: 500
  timesteps_total: 70500
  training_iteration: 141
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    141 |          20718.3 | 70500 | 0.493329 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-27-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9664360370970116
  episode_reward_mean: 0.5151975677179454
  episode_reward_min: 0.06097560975609756
  episodes_this_iter: 500
  episodes_total: 71000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1651.267
    learner:
      default_policy:
        cur_kl_coeff: 0.03559570387005806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2887364327907562
        entropy_coeff: 0.0
        kl: 0.004610301461070776
        model: {}
        policy_loss: -0.015434127300977707
        total_loss: -0.0034991740249097347
        vf_explained_var: 0.5992151498794556
        vf_loss: 0.011770840734243393
    load_time_ms: 2.326
    num_steps_sampled: 71000
    num_steps_trained: 71000
    sample_time_ms: 23249.733
    update_time_ms: 6.04
  iterations_since_restore: 142
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.832258064516129
    ram_util_percent: 13.387096774193546
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 286.1290878733185
    mean_inference_ms: 1.4272229664527294
    mean_processing_ms: 1.030454034410805
  time_since_restore: 20740.163093328476
  time_this_iter_s: 21.828001022338867
  time_total_s: 20740.163093328476
  timestamp: 1637980025
  timesteps_since_restore: 71000
  timesteps_this_iter: 500
  timesteps_total: 71000
  training_iteration: 142
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    142 |          20740.2 | 71000 | 0.515198 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-27-24
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8855345911949686
  episode_reward_mean: 0.511674508080978
  episode_reward_min: 0.055288461538461536
  episodes_this_iter: 500
  episodes_total: 71500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1639.038
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.29405608773231506
        entropy_coeff: 0.0
        kl: 0.010573145002126694
        model: {}
        policy_loss: -0.02409832738339901
        total_loss: -0.010960486717522144
        vf_explained_var: 0.5459968447685242
        vf_loss: 0.012949662283062935
    load_time_ms: 2.331
    num_steps_sampled: 71500
    num_steps_trained: 71500
    sample_time_ms: 22699.172
    update_time_ms: 5.957
  iterations_since_restore: 143
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.646428571428572
    ram_util_percent: 13.403571428571427
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 284.35899158272434
    mean_inference_ms: 1.4252728814753688
    mean_processing_ms: 1.0289662241197142
  time_since_restore: 20759.23943591118
  time_this_iter_s: 19.076342582702637
  time_total_s: 20759.23943591118
  timestamp: 1637980044
  timesteps_since_restore: 71500
  timesteps_this_iter: 500
  timesteps_total: 71500
  training_iteration: 143
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    143 |          20759.2 | 71500 | 0.511675 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-27-38
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8959823885525592
  episode_reward_mean: 0.5049935264775415
  episode_reward_min: -0.350597609561753
  episodes_this_iter: 500
  episodes_total: 72000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1616.311
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.2737118601799011
        entropy_coeff: 0.0
        kl: 0.005225720815360546
        model: {}
        policy_loss: -0.016085242852568626
        total_loss: -0.002181681804358959
        vf_explained_var: 0.5596207976341248
        vf_loss: 0.013810557313263416
    load_time_ms: 2.35
    num_steps_sampled: 72000
    num_steps_trained: 72000
    sample_time_ms: 21115.113
    update_time_ms: 5.859
  iterations_since_restore: 144
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.689473684210526
    ram_util_percent: 13.521052631578947
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 282.5339334467809
    mean_inference_ms: 1.423189152320377
    mean_processing_ms: 1.0272671491877468
  time_since_restore: 20772.588975667953
  time_this_iter_s: 13.349539756774902
  time_total_s: 20772.588975667953
  timestamp: 1637980058
  timesteps_since_restore: 72000
  timesteps_this_iter: 500
  timesteps_total: 72000
  training_iteration: 144
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    144 |          20772.6 | 72000 | 0.504994 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-27-59
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5127048359250377
  episode_reward_min: 0.12571428571428572
  episodes_this_iter: 500
  episodes_total: 72500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1630.05
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.2839151620864868
        entropy_coeff: 0.0
        kl: 0.007485153619199991
        model: {}
        policy_loss: -0.02432844415307045
        total_loss: -0.0130776921287179
        vf_explained_var: 0.6194871068000793
        vf_loss: 0.01111753098666668
    load_time_ms: 2.289
    num_steps_sampled: 72500
    num_steps_trained: 72500
    sample_time_ms: 19964.31
    update_time_ms: 5.872
  iterations_since_restore: 145
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.916129032258063
    ram_util_percent: 13.387096774193548
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 280.84181823414247
    mean_inference_ms: 1.4212919191479467
    mean_processing_ms: 1.0258071716995123
  time_since_restore: 20793.99085211754
  time_this_iter_s: 21.40187644958496
  time_total_s: 20793.99085211754
  timestamp: 1637980079
  timesteps_since_restore: 72500
  timesteps_this_iter: 500
  timesteps_total: 72500
  training_iteration: 145
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    145 |            20794 | 72500 | 0.512705 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-28-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595166163141994
  episode_reward_mean: 0.49374733007780996
  episode_reward_min: 0.08902691511387163
  episodes_this_iter: 500
  episodes_total: 73000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1647.034
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.32556626200675964
        entropy_coeff: 0.0
        kl: 0.019884755834937096
        model: {}
        policy_loss: -0.02829548344016075
        total_loss: -0.01659085787832737
        vf_explained_var: 0.605034589767456
        vf_loss: 0.011350717395544052
    load_time_ms: 2.276
    num_steps_sampled: 73000
    num_steps_trained: 73000
    sample_time_ms: 19694.515
    update_time_ms: 5.879
  iterations_since_restore: 146
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.857692307692306
    ram_util_percent: 13.392307692307694
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 279.12953345050977
    mean_inference_ms: 1.4195270116106358
    mean_processing_ms: 1.024381420164604
  time_since_restore: 20812.270836114883
  time_this_iter_s: 18.27998399734497
  time_total_s: 20812.270836114883
  timestamp: 1637980098
  timesteps_since_restore: 73000
  timesteps_this_iter: 500
  timesteps_total: 73000
  training_iteration: 146
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    146 |          20812.3 | 73000 | 0.493747 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-28-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610634648370498
  episode_reward_mean: 0.48482338411795595
  episode_reward_min: -1.7834224598930482
  episodes_this_iter: 500
  episodes_total: 73500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1638.842
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.270722895860672
        entropy_coeff: 0.0
        kl: 0.010046464391052723
        model: {}
        policy_loss: -0.023021258413791656
        total_loss: -0.003816789947450161
        vf_explained_var: 0.618899405002594
        vf_loss: 0.019025664776563644
    load_time_ms: 2.246
    num_steps_sampled: 73500
    num_steps_trained: 73500
    sample_time_ms: 20811.56
    update_time_ms: 5.87
  iterations_since_restore: 147
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.369811320754716
    ram_util_percent: 13.39622641509434
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 277.6958627478025
    mean_inference_ms: 1.4178712579406405
    mean_processing_ms: 1.022983208148457
  time_since_restore: 20849.240498542786
  time_this_iter_s: 36.96966242790222
  time_total_s: 20849.240498542786
  timestamp: 1637980135
  timesteps_since_restore: 73500
  timesteps_this_iter: 500
  timesteps_total: 73500
  training_iteration: 147
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    147 |          20849.2 | 73500 | 0.484823 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-29-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8659476117103235
  episode_reward_mean: 0.4904610668804062
  episode_reward_min: 0.07933194154488518
  episodes_this_iter: 500
  episodes_total: 74000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1667.565
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.2542575001716614
        entropy_coeff: 0.0
        kl: 0.005636684130877256
        model: {}
        policy_loss: -0.013800246641039848
        total_loss: -0.002146997721865773
        vf_explained_var: 0.6361841559410095
        vf_loss: 0.011552920565009117
    load_time_ms: 2.253
    num_steps_sampled: 74000
    num_steps_trained: 74000
    sample_time_ms: 21315.74
    update_time_ms: 5.844
  iterations_since_restore: 148
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.75
    ram_util_percent: 13.386666666666663
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 276.0626501789676
    mean_inference_ms: 1.4160207728386198
    mean_processing_ms: 1.0215184928304417
  time_since_restore: 20870.03498363495
  time_this_iter_s: 20.794485092163086
  time_total_s: 20870.03498363495
  timestamp: 1637980156
  timesteps_since_restore: 74000
  timesteps_this_iter: 500
  timesteps_total: 74000
  training_iteration: 148
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    148 |            20870 | 74000 | 0.490461 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-29-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.503232433710714
  episode_reward_min: 0.033582089552238806
  episodes_this_iter: 500
  episodes_total: 74500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1667.165
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.24398598074913025
        entropy_coeff: 0.0
        kl: 0.009097904898226261
        model: {}
        policy_loss: -0.01234816387295723
        total_loss: -0.0005773198790848255
        vf_explained_var: 0.5871884822845459
        vf_loss: 0.011608928442001343
    load_time_ms: 2.258
    num_steps_sampled: 74500
    num_steps_trained: 74500
    sample_time_ms: 20961.196
    update_time_ms: 5.833
  iterations_since_restore: 149
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.10810810810811
    ram_util_percent: 13.4027027027027
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 274.5163171983012
    mean_inference_ms: 1.4142217902493581
    mean_processing_ms: 1.0200086464774818
  time_since_restore: 20895.56558084488
  time_this_iter_s: 25.53059720993042
  time_total_s: 20895.56558084488
  timestamp: 1637980181
  timesteps_since_restore: 74500
  timesteps_this_iter: 500
  timesteps_total: 74500
  training_iteration: 149
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    149 |          20895.6 | 74500 | 0.503232 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-29-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8631578947368421
  episode_reward_mean: 0.4967779902370379
  episode_reward_min: 0.01282051282051282
  episodes_this_iter: 500
  episodes_total: 75000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1669.299
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.24554343521595
        entropy_coeff: 0.0
        kl: 0.007052668370306492
        model: {}
        policy_loss: -0.011512880213558674
        total_loss: 0.0019366752821952105
        vf_explained_var: 0.5813209414482117
        vf_loss: 0.01332403626292944
    load_time_ms: 2.273
    num_steps_sampled: 75000
    num_steps_trained: 75000
    sample_time_ms: 19884.112
    update_time_ms: 5.8
  iterations_since_restore: 150
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.904761904761905
    ram_util_percent: 13.41904761904762
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 272.83892542713073
    mean_inference_ms: 1.4123729390415583
    mean_processing_ms: 1.0186439053147427
  time_since_restore: 20909.836137771606
  time_this_iter_s: 14.270556926727295
  time_total_s: 20909.836137771606
  timestamp: 1637980196
  timesteps_since_restore: 75000
  timesteps_this_iter: 500
  timesteps_total: 75000
  training_iteration: 150
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    150 |          20909.8 | 75000 | 0.496778 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-30-15
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8650568181818182
  episode_reward_mean: 0.48899310847423255
  episode_reward_min: -0.9647577092511013
  episodes_this_iter: 500
  episodes_total: 75500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1663.793
    learner:
      default_policy:
        cur_kl_coeff: 0.01779785193502903
        cur_lr: 4.999999873689376e-05
        entropy: 0.24339771270751953
        entropy_coeff: 0.0
        kl: 0.0046109603717923164
        model: {}
        policy_loss: -0.0207551047205925
        total_loss: -0.0065228696912527084
        vf_explained_var: 0.6121944189071655
        vf_loss: 0.01415017619729042
    load_time_ms: 2.276
    num_steps_sampled: 75500
    num_steps_trained: 75500
    sample_time_ms: 19319.726
    update_time_ms: 5.831
  iterations_since_restore: 151
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.826923076923077
    ram_util_percent: 13.419230769230769
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 271.24267531629255
    mean_inference_ms: 1.4105206731060442
    mean_processing_ms: 1.0171289534030752
  time_since_restore: 20928.342151880264
  time_this_iter_s: 18.506014108657837
  time_total_s: 20928.342151880264
  timestamp: 1637980215
  timesteps_since_restore: 75500
  timesteps_this_iter: 500
  timesteps_total: 75500
  training_iteration: 151
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    151 |          20928.3 | 75500 | 0.488993 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-30-33
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.4840358195795768
  episode_reward_min: 0.03
  episodes_this_iter: 500
  episodes_total: 76000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1655.033
    learner:
      default_policy:
        cur_kl_coeff: 0.008898925967514515
        cur_lr: 4.999999873689376e-05
        entropy: 0.26310718059539795
        entropy_coeff: 0.0
        kl: 0.009570318274199963
        model: {}
        policy_loss: -0.014026757329702377
        total_loss: -0.002468622289597988
        vf_explained_var: 0.6587031483650208
        vf_loss: 0.011472971178591251
    load_time_ms: 2.277
    num_steps_sampled: 76000
    num_steps_trained: 76000
    sample_time_ms: 18939.583
    update_time_ms: 5.825
  iterations_since_restore: 152
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.257692307692306
    ram_util_percent: 13.403846153846153
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 269.65727391813107
    mean_inference_ms: 1.408910097582535
    mean_processing_ms: 1.0158876527558962
  time_since_restore: 20946.279750585556
  time_this_iter_s: 17.937598705291748
  time_total_s: 20946.279750585556
  timestamp: 1637980233
  timesteps_since_restore: 76000
  timesteps_this_iter: 500
  timesteps_total: 76000
  training_iteration: 152
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    152 |          20946.3 | 76000 | 0.484036 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-30-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647058823529412
  episode_reward_mean: 0.5015541924223854
  episode_reward_min: 0.10062893081761007
  episodes_this_iter: 500
  episodes_total: 76500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1671.244
    learner:
      default_policy:
        cur_kl_coeff: 0.008898925967514515
        cur_lr: 4.999999873689376e-05
        entropy: 0.2533953785896301
        entropy_coeff: 0.0
        kl: 0.007748561445623636
        model: {}
        policy_loss: -0.015401950106024742
        total_loss: -0.005410181358456612
        vf_explained_var: 0.6563786864280701
        vf_loss: 0.009922806173563004
    load_time_ms: 2.284
    num_steps_sampled: 76500
    num_steps_trained: 76500
    sample_time_ms: 18449.839
    update_time_ms: 5.814
  iterations_since_restore: 153
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.433333333333337
    ram_util_percent: 13.41904761904762
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 268.0466528214719
    mean_inference_ms: 1.4071917434456824
    mean_processing_ms: 1.0144900151186411
  time_since_restore: 20960.62075304985
  time_this_iter_s: 14.341002464294434
  time_total_s: 20960.62075304985
  timestamp: 1637980247
  timesteps_since_restore: 76500
  timesteps_this_iter: 500
  timesteps_total: 76500
  training_iteration: 153
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    153 |          20960.6 | 76500 | 0.501554 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-31-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8383333333333334
  episode_reward_mean: 0.4997477715282019
  episode_reward_min: 0.08044692737430167
  episodes_this_iter: 500
  episodes_total: 77000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1674.887
    learner:
      default_policy:
        cur_kl_coeff: 0.008898925967514515
        cur_lr: 4.999999873689376e-05
        entropy: 0.2582603394985199
        entropy_coeff: 0.0
        kl: 0.02416502684354782
        model: {}
        policy_loss: -0.03094419650733471
        total_loss: -0.020399723201990128
        vf_explained_var: 0.6348786354064941
        vf_loss: 0.010329424403607845
    load_time_ms: 2.276
    num_steps_sampled: 77000
    num_steps_trained: 77000
    sample_time_ms: 18466.018
    update_time_ms: 5.901
  iterations_since_restore: 154
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.71578947368421
    ram_util_percent: 13.421052631578949
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 266.4477751441774
    mean_inference_ms: 1.40557017453737
    mean_processing_ms: 1.0131584529921547
  time_since_restore: 20974.16863012314
  time_this_iter_s: 13.547877073287964
  time_total_s: 20974.16863012314
  timestamp: 1637980261
  timesteps_since_restore: 77000
  timesteps_this_iter: 500
  timesteps_total: 77000
  training_iteration: 154
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    154 |          20974.2 | 77000 | 0.499748 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-31-15
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8629441624365483
  episode_reward_mean: 0.5002794979172439
  episode_reward_min: 0.07720588235294118
  episodes_this_iter: 500
  episodes_total: 77500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1661.359
    learner:
      default_policy:
        cur_kl_coeff: 0.013348388485610485
        cur_lr: 4.999999873689376e-05
        entropy: 0.2877053916454315
        entropy_coeff: 0.0
        kl: 0.010941902175545692
        model: {}
        policy_loss: -0.018790218979120255
        total_loss: -0.007851582951843739
        vf_explained_var: 0.6142835021018982
        vf_loss: 0.010792583227157593
    load_time_ms: 2.286
    num_steps_sampled: 77500
    num_steps_trained: 77500
    sample_time_ms: 17749.656
    update_time_ms: 5.941
  iterations_since_restore: 155
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.64761904761905
    ram_util_percent: 13.414285714285715
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 264.8761737571376
    mean_inference_ms: 1.404005521878961
    mean_processing_ms: 1.0118635483300973
  time_since_restore: 20988.272120952606
  time_this_iter_s: 14.103490829467773
  time_total_s: 20988.272120952606
  timestamp: 1637980275
  timesteps_since_restore: 77500
  timesteps_this_iter: 500
  timesteps_total: 77500
  training_iteration: 155
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    155 |          20988.3 | 77500 | 0.500279 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-31-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8840399002493765
  episode_reward_mean: 0.5087257664729073
  episode_reward_min: 0.10739856801909307
  episodes_this_iter: 500
  episodes_total: 78000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1645.947
    learner:
      default_policy:
        cur_kl_coeff: 0.013348388485610485
        cur_lr: 4.999999873689376e-05
        entropy: 0.27728408575057983
        entropy_coeff: 0.0
        kl: 0.011224496178328991
        model: {}
        policy_loss: -0.024832211434841156
        total_loss: -0.011887026019394398
        vf_explained_var: 0.5513529777526855
        vf_loss: 0.012795351445674896
    load_time_ms: 2.299
    num_steps_sampled: 78000
    num_steps_trained: 78000
    sample_time_ms: 17536.38
    update_time_ms: 5.837
  iterations_since_restore: 156
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.330434782608695
    ram_util_percent: 13.443478260869563
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 263.34878447771035
    mean_inference_ms: 1.4023100085305003
    mean_processing_ms: 1.01064658788832
  time_since_restore: 21004.2639400959
  time_this_iter_s: 15.991819143295288
  time_total_s: 21004.2639400959
  timestamp: 1637980292
  timesteps_since_restore: 78000
  timesteps_this_iter: 500
  timesteps_total: 78000
  training_iteration: 156
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    156 |          21004.3 | 78000 | 0.508726 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-31-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8802507836990595
  episode_reward_mean: 0.499911554471278
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 78500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1618.03
    learner:
      default_policy:
        cur_kl_coeff: 0.013348388485610485
        cur_lr: 4.999999873689376e-05
        entropy: 0.27146416902542114
        entropy_coeff: 0.0
        kl: 0.00777885178104043
        model: {}
        policy_loss: -0.02066727913916111
        total_loss: -0.008314132690429688
        vf_explained_var: 0.606027364730835
        vf_loss: 0.012249317020177841
    load_time_ms: 2.347
    num_steps_sampled: 78500
    num_steps_trained: 78500
    sample_time_ms: 15325.522
    update_time_ms: 5.791
  iterations_since_restore: 157
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.48095238095238
    ram_util_percent: 13.714285714285712
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 261.8253539804304
    mean_inference_ms: 1.4007636263765917
    mean_processing_ms: 1.0095548010791475
  time_since_restore: 21018.845762729645
  time_this_iter_s: 14.581822633743286
  time_total_s: 21018.845762729645
  timestamp: 1637980306
  timesteps_since_restore: 78500
  timesteps_this_iter: 500
  timesteps_total: 78500
  training_iteration: 157
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    157 |          21018.8 | 78500 | 0.499912 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-32-02
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9664360370970116
  episode_reward_mean: 0.5146718872485758
  episode_reward_min: 0.06097560975609756
  episodes_this_iter: 500
  episodes_total: 79000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1628.357
    learner:
      default_policy:
        cur_kl_coeff: 0.013348388485610485
        cur_lr: 4.999999873689376e-05
        entropy: 0.2677280902862549
        entropy_coeff: 0.0
        kl: 0.0031726250890642405
        model: {}
        policy_loss: -0.010262914933264256
        total_loss: 0.0024633801076561213
        vf_explained_var: 0.5663586258888245
        vf_loss: 0.012683941051363945
    load_time_ms: 2.343
    num_steps_sampled: 79000
    num_steps_trained: 79000
    sample_time_ms: 14801.418
    update_time_ms: 5.829
  iterations_since_restore: 158
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.152173913043477
    ram_util_percent: 13.473913043478257
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 260.32941176108756
    mean_inference_ms: 1.3991986840144377
    mean_processing_ms: 1.0084169435886792
  time_since_restore: 21034.50262093544
  time_this_iter_s: 15.656858205795288
  time_total_s: 21034.50262093544
  timestamp: 1637980322
  timesteps_since_restore: 79000
  timesteps_this_iter: 500
  timesteps_total: 79000
  training_iteration: 158
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    158 |          21034.5 | 79000 | 0.514672 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-32-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8959823885525592
  episode_reward_mean: 0.5121045296149046
  episode_reward_min: -0.2185792349726776
  episodes_this_iter: 500
  episodes_total: 79500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1628.103
    learner:
      default_policy:
        cur_kl_coeff: 0.0066741942428052425
        cur_lr: 4.999999873689376e-05
        entropy: 0.2790793478488922
        entropy_coeff: 0.0
        kl: 0.010217026807367802
        model: {}
        policy_loss: -0.01760263368487358
        total_loss: -0.003295650240033865
        vf_explained_var: 0.5561246871948242
        vf_loss: 0.014238796196877956
    load_time_ms: 2.324
    num_steps_sampled: 79500
    num_steps_trained: 79500
    sample_time_ms: 13444.087
    update_time_ms: 5.903
  iterations_since_restore: 159
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.958823529411767
    ram_util_percent: 13.447058823529412
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 258.8086992318903
    mean_inference_ms: 1.3975589356721299
    mean_processing_ms: 1.0070615926704574
  time_since_restore: 21046.45693731308
  time_this_iter_s: 11.95431637763977
  time_total_s: 21046.45693731308
  timestamp: 1637980334
  timesteps_since_restore: 79500
  timesteps_this_iter: 500
  timesteps_total: 79500
  training_iteration: 159
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    159 |          21046.5 | 79500 | 0.512105 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-32-29
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8801075268817204
  episode_reward_mean: 0.5102619158810331
  episode_reward_min: -0.0947867298578199
  episodes_this_iter: 500
  episodes_total: 80000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1605.574
    learner:
      default_policy:
        cur_kl_coeff: 0.0066741942428052425
        cur_lr: 4.999999873689376e-05
        entropy: 0.2591947615146637
        entropy_coeff: 0.0
        kl: 0.006106427405029535
        model: {}
        policy_loss: -0.020864365622401237
        total_loss: -0.009298286400735378
        vf_explained_var: 0.5865414142608643
        vf_loss: 0.011525331996381283
    load_time_ms: 2.332
    num_steps_sampled: 80000
    num_steps_trained: 80000
    sample_time_ms: 13456.781
    update_time_ms: 6.033
  iterations_since_restore: 160
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.242857142857144
    ram_util_percent: 13.414285714285715
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 257.33554828608175
    mean_inference_ms: 1.3961189217949566
    mean_processing_ms: 1.0060066983165776
  time_since_restore: 21060.6291308403
  time_this_iter_s: 14.17219352722168
  time_total_s: 21060.6291308403
  timestamp: 1637980349
  timesteps_since_restore: 80000
  timesteps_this_iter: 500
  timesteps_total: 80000
  training_iteration: 160
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    160 |          21060.6 | 80000 | 0.510262 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-32-43
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5040957296529447
  episode_reward_min: 0.09836065573770492
  episodes_this_iter: 500
  episodes_total: 80500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1609.285
    learner:
      default_policy:
        cur_kl_coeff: 0.0066741942428052425
        cur_lr: 4.999999873689376e-05
        entropy: 0.3133237957954407
        entropy_coeff: 0.0
        kl: 0.004708778113126755
        model: {}
        policy_loss: -0.020852932706475258
        total_loss: -0.00915609486401081
        vf_explained_var: 0.5870069265365601
        vf_loss: 0.011665413156151772
    load_time_ms: 2.343
    num_steps_sampled: 80500
    num_steps_trained: 80500
    sample_time_ms: 13011.223
    update_time_ms: 5.955
  iterations_since_restore: 161
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.615000000000002
    ram_util_percent: 13.564999999999998
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 255.87933637570418
    mean_inference_ms: 1.394530476739668
    mean_processing_ms: 1.0046691038959776
  time_since_restore: 21074.715702295303
  time_this_iter_s: 14.086571455001831
  time_total_s: 21074.715702295303
  timestamp: 1637980363
  timesteps_since_restore: 80500
  timesteps_this_iter: 500
  timesteps_total: 80500
  training_iteration: 161
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    161 |          21074.7 | 80500 | 0.504096 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-32-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8571428571428571
  episode_reward_mean: 0.4919927082392187
  episode_reward_min: 0.07158836689038031
  episodes_this_iter: 500
  episodes_total: 81000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1598.747
    learner:
      default_policy:
        cur_kl_coeff: 0.0033370971214026213
        cur_lr: 4.999999873689376e-05
        entropy: 0.2826153635978699
        entropy_coeff: 0.0
        kl: 0.007546368055045605
        model: {}
        policy_loss: -0.009793516248464584
        total_loss: 0.0009635675232857466
        vf_explained_var: 0.6607638597488403
        vf_loss: 0.01073190663009882
    load_time_ms: 2.33
    num_steps_sampled: 81000
    num_steps_trained: 81000
    sample_time_ms: 12548.633
    update_time_ms: 5.921
  iterations_since_restore: 162
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.136842105263156
    ram_util_percent: 13.457894736842105
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 254.42971807767066
    mean_inference_ms: 1.3929530235913397
    mean_processing_ms: 1.0035962370068605
  time_since_restore: 21087.920475006104
  time_this_iter_s: 13.204772710800171
  time_total_s: 21087.920475006104
  timestamp: 1637980376
  timesteps_since_restore: 81000
  timesteps_this_iter: 500
  timesteps_total: 81000
  training_iteration: 162
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    162 |          21087.9 | 81000 | 0.491993 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-33-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610634648370498
  episode_reward_mean: 0.4851164082543718
  episode_reward_min: 0.064343163538874
  episodes_this_iter: 500
  episodes_total: 81500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1601.543
    learner:
      default_policy:
        cur_kl_coeff: 0.0033370971214026213
        cur_lr: 4.999999873689376e-05
        entropy: 0.2784753143787384
        entropy_coeff: 0.0
        kl: 0.010960062965750694
        model: {}
        policy_loss: -0.017940150573849678
        total_loss: -0.0077187311835587025
        vf_explained_var: 0.6642090082168579
        vf_loss: 0.010184845887124538
    load_time_ms: 2.307
    num_steps_sampled: 81500
    num_steps_trained: 81500
    sample_time_ms: 12252.443
    update_time_ms: 5.885
  iterations_since_restore: 163
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.735294117647058
    ram_util_percent: 13.411764705882355
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 252.9750965549628
    mean_inference_ms: 1.3913787424478798
    mean_processing_ms: 1.0023236478030744
  time_since_restore: 21099.327877759933
  time_this_iter_s: 11.407402753829956
  time_total_s: 21099.327877759933
  timestamp: 1637980388
  timesteps_since_restore: 81500
  timesteps_this_iter: 500
  timesteps_total: 81500
  training_iteration: 163
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    163 |          21099.3 | 81500 | 0.485116 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-33-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8659476117103235
  episode_reward_mean: 0.5034665360098826
  episode_reward_min: 0.0145413870246085
  episodes_this_iter: 500
  episodes_total: 82000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1603.127
    learner:
      default_policy:
        cur_kl_coeff: 0.0033370971214026213
        cur_lr: 4.999999873689376e-05
        entropy: 0.2285735160112381
        entropy_coeff: 0.0
        kl: 0.008893227204680443
        model: {}
        policy_loss: -0.017598647624254227
        total_loss: -0.005722701549530029
        vf_explained_var: 0.6039845943450928
        vf_loss: 0.011846273206174374
    load_time_ms: 2.296
    num_steps_sampled: 82000
    num_steps_trained: 82000
    sample_time_ms: 12263.728
    update_time_ms: 5.869
  iterations_since_restore: 164
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.56842105263158
    ram_util_percent: 13.61578947368421
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 251.56692997658925
    mean_inference_ms: 1.3899024618153013
    mean_processing_ms: 1.001271580378036
  time_since_restore: 21113.004937171936
  time_this_iter_s: 13.677059412002563
  time_total_s: 21113.004937171936
  timestamp: 1637980402
  timesteps_since_restore: 82000
  timesteps_this_iter: 500
  timesteps_total: 82000
  training_iteration: 164
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    164 |            21113 | 82000 | 0.503467 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-33-36
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.49487288190169404
  episode_reward_min: -1.1829085457271364
  episodes_this_iter: 500
  episodes_total: 82500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1609.879
    learner:
      default_policy:
        cur_kl_coeff: 0.0033370971214026213
        cur_lr: 4.999999873689376e-05
        entropy: 0.20217466354370117
        entropy_coeff: 0.0
        kl: 0.00348812248557806
        model: {}
        policy_loss: -0.01886587031185627
        total_loss: -0.0024545288179069757
        vf_explained_var: 0.5318308472633362
        vf_loss: 0.016399703919887543
    load_time_ms: 2.281
    num_steps_sampled: 82500
    num_steps_trained: 82500
    sample_time_ms: 12222.776
    update_time_ms: 5.804
  iterations_since_restore: 165
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.21
    ram_util_percent: 13.425
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 250.1760998303494
    mean_inference_ms: 1.3883168884535169
    mean_processing_ms: 1.0000728329471138
  time_since_restore: 21126.76493191719
  time_this_iter_s: 13.759994745254517
  time_total_s: 21126.76493191719
  timestamp: 1637980416
  timesteps_since_restore: 82500
  timesteps_this_iter: 500
  timesteps_total: 82500
  training_iteration: 165
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    165 |          21126.8 | 82500 | 0.494873 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-33-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8650568181818182
  episode_reward_mean: 0.49436352645926296
  episode_reward_min: 0.01282051282051282
  episodes_this_iter: 500
  episodes_total: 83000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1592.417
    learner:
      default_policy:
        cur_kl_coeff: 0.0016685485607013106
        cur_lr: 4.999999873689376e-05
        entropy: 0.2792954742908478
        entropy_coeff: 0.0
        kl: 0.02360609546303749
        model: {}
        policy_loss: -0.021163560450077057
        total_loss: -0.0086599076166749
        vf_explained_var: 0.6026103496551514
        vf_loss: 0.012464268133044243
    load_time_ms: 2.294
    num_steps_sampled: 83000
    num_steps_trained: 83000
    sample_time_ms: 11887.544
    update_time_ms: 5.796
  iterations_since_restore: 166
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.150000000000002
    ram_util_percent: 13.433333333333334
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 248.78889497717498
    mean_inference_ms: 1.3869468841872614
    mean_processing_ms: 0.9988589674071734
  time_since_restore: 21139.23002934456
  time_this_iter_s: 12.465097427368164
  time_total_s: 21139.23002934456
  timestamp: 1637980429
  timesteps_since_restore: 83000
  timesteps_this_iter: 500
  timesteps_total: 83000
  training_iteration: 166
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    166 |          21139.2 | 83000 | 0.494364 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-34-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8624161073825504
  episode_reward_mean: 0.4947199073315291
  episode_reward_min: -0.14009661835748793
  episodes_this_iter: 500
  episodes_total: 83500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1622.77
    learner:
      default_policy:
        cur_kl_coeff: 0.002502822782844305
        cur_lr: 4.999999873689376e-05
        entropy: 0.2862377166748047
        entropy_coeff: 0.0
        kl: 0.010975626297295094
        model: {}
        policy_loss: -0.020771875977516174
        total_loss: -0.00905173271894455
        vf_explained_var: 0.6219618320465088
        vf_loss: 0.011692664586007595
    load_time_ms: 2.234
    num_steps_sampled: 83500
    num_steps_trained: 83500
    sample_time_ms: 11812.186
    update_time_ms: 5.775
  iterations_since_restore: 167
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.314285714285717
    ram_util_percent: 13.428571428571429
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 247.43519414277986
    mean_inference_ms: 1.3854549915650278
    mean_processing_ms: 0.9976925489407136
  time_since_restore: 21153.3611638546
  time_this_iter_s: 14.131134510040283
  time_total_s: 21153.3611638546
  timestamp: 1637980443
  timesteps_since_restore: 83500
  timesteps_this_iter: 500
  timesteps_total: 83500
  training_iteration: 167
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    167 |          21153.4 | 83500 |  0.49472 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-34-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.4898524834419504
  episode_reward_min: 0.03
  episodes_this_iter: 500
  episodes_total: 84000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1603.318
    learner:
      default_policy:
        cur_kl_coeff: 0.002502822782844305
        cur_lr: 4.999999873689376e-05
        entropy: 0.2618762254714966
        entropy_coeff: 0.0
        kl: 0.013288009911775589
        model: {}
        policy_loss: -0.023321211338043213
        total_loss: -0.013651623390614986
        vf_explained_var: 0.6695745587348938
        vf_loss: 0.009636333212256432
    load_time_ms: 2.198
    num_steps_sampled: 84000
    num_steps_trained: 84000
    sample_time_ms: 11604.55
    update_time_ms: 5.845
  iterations_since_restore: 168
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.0
    ram_util_percent: 13.431578947368422
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 246.08939661088286
    mean_inference_ms: 1.3840555430886277
    mean_processing_ms: 0.9965795052692853
  time_since_restore: 21166.747799873352
  time_this_iter_s: 13.386636018753052
  time_total_s: 21166.747799873352
  timestamp: 1637980456
  timesteps_since_restore: 84000
  timesteps_this_iter: 500
  timesteps_total: 84000
  training_iteration: 168
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    168 |          21166.7 | 84000 | 0.489852 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-34-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.49868200243024663
  episode_reward_min: 0.08044692737430167
  episodes_this_iter: 500
  episodes_total: 84500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1592.52
    learner:
      default_policy:
        cur_kl_coeff: 0.002502822782844305
        cur_lr: 4.999999873689376e-05
        entropy: 0.2573481798171997
        entropy_coeff: 0.0
        kl: 0.00532898074015975
        model: {}
        policy_loss: -0.009860415011644363
        total_loss: 0.000620398495811969
        vf_explained_var: 0.6430132985115051
        vf_loss: 0.010467461310327053
    load_time_ms: 2.184
    num_steps_sampled: 84500
    num_steps_trained: 84500
    sample_time_ms: 11968.574
    update_time_ms: 5.841
  iterations_since_restore: 169
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.152173913043477
    ram_util_percent: 13.417391304347822
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 244.78604935441223
    mean_inference_ms: 1.3825553412764788
    mean_processing_ms: 0.9953452263203905
  time_since_restore: 21182.233993053436
  time_this_iter_s: 15.486193180084229
  time_total_s: 21182.233993053436
  timestamp: 1637980472
  timesteps_since_restore: 84500
  timesteps_this_iter: 500
  timesteps_total: 84500
  training_iteration: 169
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    169 |          21182.2 | 84500 | 0.498682 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-34-45
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8629441624365483
  episode_reward_mean: 0.4999862974055592
  episode_reward_min: 0.09777777777777778
  episodes_this_iter: 500
  episodes_total: 85000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1604.799
    learner:
      default_policy:
        cur_kl_coeff: 0.002502822782844305
        cur_lr: 4.999999873689376e-05
        entropy: 0.23492811620235443
        entropy_coeff: 0.0
        kl: 0.008147668093442917
        model: {}
        policy_loss: -0.01908194273710251
        total_loss: -0.008127832785248756
        vf_explained_var: 0.5978763103485107
        vf_loss: 0.010933717712759972
    load_time_ms: 2.177
    num_steps_sampled: 85000
    num_steps_trained: 85000
    sample_time_ms: 11819.044
    update_time_ms: 5.665
  iterations_since_restore: 170
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.294444444444444
    ram_util_percent: 13.433333333333334
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 243.4649316901688
    mean_inference_ms: 1.3810706625820486
    mean_processing_ms: 0.994161331471698
  time_since_restore: 21195.03222298622
  time_this_iter_s: 12.798229932785034
  time_total_s: 21195.03222298622
  timestamp: 1637980485
  timesteps_since_restore: 85000
  timesteps_this_iter: 500
  timesteps_total: 85000
  training_iteration: 170
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    170 |            21195 | 85000 | 0.499986 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-35-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8737580362361193
  episode_reward_mean: 0.5106887417799119
  episode_reward_min: -0.22105263157894736
  episodes_this_iter: 500
  episodes_total: 85500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1609.011
    learner:
      default_policy:
        cur_kl_coeff: 0.002502822782844305
        cur_lr: 4.999999873689376e-05
        entropy: 0.2313612401485443
        entropy_coeff: 0.0
        kl: 0.0047196391969919205
        model: {}
        policy_loss: -0.01863277703523636
        total_loss: -0.008475128561258316
        vf_explained_var: 0.6798007488250732
        vf_loss: 0.010145843029022217
    load_time_ms: 2.194
    num_steps_sampled: 85500
    num_steps_trained: 85500
    sample_time_ms: 11929.994
    update_time_ms: 5.686
  iterations_since_restore: 171
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.88181818181818
    ram_util_percent: 13.454545454545451
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 242.18780235862684
    mean_inference_ms: 1.3796904858334762
    mean_processing_ms: 0.9930814127187516
  time_since_restore: 21210.270634651184
  time_this_iter_s: 15.238411664962769
  time_total_s: 21210.270634651184
  timestamp: 1637980501
  timesteps_since_restore: 85500
  timesteps_this_iter: 500
  timesteps_total: 85500
  training_iteration: 171
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    171 |          21210.3 | 85500 | 0.510689 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-35-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8840399002493765
  episode_reward_mean: 0.4956908757777966
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 86000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1617.42
    learner:
      default_policy:
        cur_kl_coeff: 0.0012514113914221525
        cur_lr: 4.999999873689376e-05
        entropy: 0.23288829624652863
        entropy_coeff: 0.0
        kl: 0.005486202891916037
        model: {}
        policy_loss: -0.012951262295246124
        total_loss: 0.001574132707901299
        vf_explained_var: 0.5215333104133606
        vf_loss: 0.014518528245389462
    load_time_ms: 2.224
    num_steps_sampled: 86000
    num_steps_trained: 86000
    sample_time_ms: 11902.117
    update_time_ms: 5.689
  iterations_since_restore: 172
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.47368421052631
    ram_util_percent: 13.431578947368422
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 240.8990224357721
    mean_inference_ms: 1.3782598838114635
    mean_processing_ms: 0.9919607539926621
  time_since_restore: 21223.281239509583
  time_this_iter_s: 13.010604858398438
  time_total_s: 21223.281239509583
  timestamp: 1637980514
  timesteps_since_restore: 86000
  timesteps_this_iter: 500
  timesteps_total: 86000
  training_iteration: 172
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    172 |          21223.3 | 86000 | 0.495691 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-35-23
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8802507836990595
  episode_reward_mean: 0.5103785681104678
  episode_reward_min: 0.1440162271805274
  episodes_this_iter: 500
  episodes_total: 86500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1605.61
    learner:
      default_policy:
        cur_kl_coeff: 0.0012514113914221525
        cur_lr: 4.999999873689376e-05
        entropy: 0.20810121297836304
        entropy_coeff: 0.0
        kl: 0.005242747254669666
        model: {}
        policy_loss: -0.012133841402828693
        total_loss: -0.0011969577753916383
        vf_explained_var: 0.6136389374732971
        vf_loss: 0.010930326767265797
    load_time_ms: 2.234
    num_steps_sampled: 86500
    num_steps_trained: 86500
    sample_time_ms: 11669.894
    update_time_ms: 5.752
  iterations_since_restore: 173
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.22307692307692
    ram_util_percent: 13.461538461538463
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 239.57991738124852
    mean_inference_ms: 1.3767821123345847
    mean_processing_ms: 0.9908622180041154
  time_since_restore: 21232.24802517891
  time_this_iter_s: 8.966785669326782
  time_total_s: 21232.24802517891
  timestamp: 1637980523
  timesteps_since_restore: 86500
  timesteps_this_iter: 500
  timesteps_total: 86500
  training_iteration: 173
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    173 |          21232.2 | 86500 | 0.510379 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-35-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9664360370970116
  episode_reward_mean: 0.5121624283286563
  episode_reward_min: 0.06097560975609756
  episodes_this_iter: 500
  episodes_total: 87000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1615.509
    learner:
      default_policy:
        cur_kl_coeff: 0.0012514113914221525
        cur_lr: 4.999999873689376e-05
        entropy: 0.24019868671894073
        entropy_coeff: 0.0
        kl: 0.006480351556092501
        model: {}
        policy_loss: -0.014418073929846287
        total_loss: -0.0001912665320560336
        vf_explained_var: 0.5275346636772156
        vf_loss: 0.014218713156878948
    load_time_ms: 2.249
    num_steps_sampled: 87000
    num_steps_trained: 87000
    sample_time_ms: 11188.872
    update_time_ms: 5.763
  iterations_since_restore: 174
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.74615384615385
    ram_util_percent: 13.400000000000002
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 238.2746340509099
    mean_inference_ms: 1.3753432607986729
    mean_processing_ms: 0.989784732747177
  time_since_restore: 21241.213641166687
  time_this_iter_s: 8.96561598777771
  time_total_s: 21241.213641166687
  timestamp: 1637980532
  timesteps_since_restore: 87000
  timesteps_this_iter: 500
  timesteps_total: 87000
  training_iteration: 174
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    174 |          21241.2 | 87000 | 0.512162 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-35-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8959823885525592
  episode_reward_mean: 0.5126778689939633
  episode_reward_min: -0.2185792349726776
  episodes_this_iter: 500
  episodes_total: 87500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1620.064
    learner:
      default_policy:
        cur_kl_coeff: 0.0012514113914221525
        cur_lr: 4.999999873689376e-05
        entropy: 0.2737451493740082
        entropy_coeff: 0.0
        kl: 0.020588118582963943
        model: {}
        policy_loss: -0.016825292259454727
        total_loss: -0.004068620037287474
        vf_explained_var: 0.5625360608100891
        vf_loss: 0.012730909511446953
    load_time_ms: 2.255
    num_steps_sampled: 87500
    num_steps_trained: 87500
    sample_time_ms: 10663.74
    update_time_ms: 5.779
  iterations_since_restore: 175
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.376923076923074
    ram_util_percent: 13.423076923076925
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 236.97929415239236
    mean_inference_ms: 1.3739785115826006
    mean_processing_ms: 0.9885995333890172
  time_since_restore: 21249.768431663513
  time_this_iter_s: 8.554790496826172
  time_total_s: 21249.768431663513
  timestamp: 1637980541
  timesteps_since_restore: 87500
  timesteps_this_iter: 500
  timesteps_total: 87500
  training_iteration: 175
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    175 |          21249.8 | 87500 | 0.512678 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-35-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5121984316187767
  episode_reward_min: 0.1026252983293556
  episodes_this_iter: 500
  episodes_total: 88000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1638.922
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.2468462586402893
        entropy_coeff: 0.0
        kl: 0.00728485407307744
        model: {}
        policy_loss: -0.019911639392375946
        total_loss: -0.008121208287775517
        vf_explained_var: 0.615665078163147
        vf_loss: 0.011776749044656754
    load_time_ms: 2.292
    num_steps_sampled: 88000
    num_steps_trained: 88000
    sample_time_ms: 10886.721
    update_time_ms: 5.841
  iterations_since_restore: 176
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.7
    ram_util_percent: 13.442857142857141
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 235.77138711411285
    mean_inference_ms: 1.372688690441129
    mean_processing_ms: 0.9874692728673297
  time_since_restore: 21264.653048038483
  time_this_iter_s: 14.884616374969482
  time_total_s: 21264.653048038483
  timestamp: 1637980556
  timesteps_since_restore: 88000
  timesteps_this_iter: 500
  timesteps_total: 88000
  training_iteration: 176
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    176 |          21264.7 | 88000 | 0.512198 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-36-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595166163141994
  episode_reward_mean: 0.4992306096785827
  episode_reward_min: 0.08902691511387163
  episodes_this_iter: 500
  episodes_total: 88500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1627.584
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.2832162380218506
        entropy_coeff: 0.0
        kl: 0.006744369864463806
        model: {}
        policy_loss: -0.016557389870285988
        total_loss: -0.0050743152387440205
        vf_explained_var: 0.5803998112678528
        vf_loss: 0.011470424011349678
    load_time_ms: 2.305
    num_steps_sampled: 88500
    num_steps_trained: 88500
    sample_time_ms: 11846.709
    update_time_ms: 5.861
  iterations_since_restore: 177
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.958823529411765
    ram_util_percent: 13.467647058823527
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 234.67607868912378
    mean_inference_ms: 1.3713975867083286
    mean_processing_ms: 0.9864856223720833
  time_since_restore: 21288.27082157135
  time_this_iter_s: 23.61777353286743
  time_total_s: 21288.27082157135
  timestamp: 1637980580
  timesteps_since_restore: 88500
  timesteps_this_iter: 500
  timesteps_total: 88500
  training_iteration: 177
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    177 |          21288.3 | 88500 | 0.499231 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-36-38
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610634648370498
  episode_reward_mean: 0.48610420984785346
  episode_reward_min: -0.06970509383378017
  episodes_this_iter: 500
  episodes_total: 89000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1638.572
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.26585593819618225
        entropy_coeff: 0.0
        kl: 0.010184177197515965
        model: {}
        policy_loss: -0.02518305368721485
        total_loss: -0.013689353130757809
        vf_explained_var: 0.621073842048645
        vf_loss: 0.011474587954580784
    load_time_ms: 2.33
    num_steps_sampled: 89000
    num_steps_trained: 89000
    sample_time_ms: 12241.35
    update_time_ms: 5.776
  iterations_since_restore: 178
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.099999999999998
    ram_util_percent: 13.54230769230769
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 233.52126943611165
    mean_inference_ms: 1.3704272495535128
    mean_processing_ms: 0.9858452552230242
  time_since_restore: 21305.712157964706
  time_this_iter_s: 17.441336393356323
  time_total_s: 21305.712157964706
  timestamp: 1637980598
  timesteps_since_restore: 89000
  timesteps_this_iter: 500
  timesteps_total: 89000
  training_iteration: 178
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    178 |          21305.7 | 89000 | 0.486104 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-36-54
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8659476117103235
  episode_reward_mean: 0.4852657629917386
  episode_reward_min: -0.17725752508361203
  episodes_this_iter: 500
  episodes_total: 89500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1651.717
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.2670566141605377
        entropy_coeff: 0.0
        kl: 0.006342979148030281
        model: {}
        policy_loss: -0.01375595573335886
        total_loss: -0.0026410489808768034
        vf_explained_var: 0.656670331954956
        vf_loss: 0.011103005148470402
    load_time_ms: 2.368
    num_steps_sampled: 89500
    num_steps_trained: 89500
    sample_time_ms: 12274.268
    update_time_ms: 5.745
  iterations_since_restore: 179
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.29565217391304
    ram_util_percent: 13.49565217391304
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 232.3642828039861
    mean_inference_ms: 1.3692607157837815
    mean_processing_ms: 0.9848938389352764
  time_since_restore: 21321.659026622772
  time_this_iter_s: 15.946868658065796
  time_total_s: 21321.659026622772
  timestamp: 1637980614
  timesteps_since_restore: 89500
  timesteps_this_iter: 500
  timesteps_total: 89500
  training_iteration: 179
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    179 |          21321.7 | 89500 | 0.485266 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-37-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.5093264669729588
  episode_reward_min: 0.014925373134328358
  episodes_this_iter: 500
  episodes_total: 90000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1650.99
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.23414640128612518
        entropy_coeff: 0.0
        kl: 0.010378913022577763
        model: {}
        policy_loss: -0.02193445712327957
        total_loss: -0.010084517300128937
        vf_explained_var: 0.59400475025177
        vf_loss: 0.011830461211502552
    load_time_ms: 2.349
    num_steps_sampled: 90000
    num_steps_trained: 90000
    sample_time_ms: 13401.394
    update_time_ms: 5.838
  iterations_since_restore: 180
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.432352941176472
    ram_util_percent: 13.51470588235294
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 231.31026075799753
    mean_inference_ms: 1.3681988699118484
    mean_processing_ms: 0.9840863107121008
  time_since_restore: 21345.722291707993
  time_this_iter_s: 24.063265085220337
  time_total_s: 21345.722291707993
  timestamp: 1637980638
  timesteps_since_restore: 90000
  timesteps_this_iter: 500
  timesteps_total: 90000
  training_iteration: 180
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    180 |          21345.7 | 90000 | 0.509326 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-37-30
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8631578947368421
  episode_reward_mean: 0.4968871339064193
  episode_reward_min: -0.07088607594936709
  episodes_this_iter: 500
  episodes_total: 90500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1660.39
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.2227926403284073
        entropy_coeff: 0.0
        kl: 0.005481051746755838
        model: {}
        policy_loss: -0.016878750175237656
        total_loss: -0.003323433455079794
        vf_explained_var: 0.5473926067352295
        vf_loss: 0.013545025140047073
    load_time_ms: 2.317
    num_steps_sampled: 90500
    num_steps_trained: 90500
    sample_time_ms: 13062.899
    update_time_ms: 5.849
  iterations_since_restore: 181
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.133333333333336
    ram_util_percent: 13.450000000000001
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 230.1337324879191
    mean_inference_ms: 1.366838858436639
    mean_processing_ms: 0.9830073571819222
  time_since_restore: 21357.669840335846
  time_this_iter_s: 11.947548627853394
  time_total_s: 21357.669840335846
  timestamp: 1637980650
  timesteps_since_restore: 90500
  timesteps_this_iter: 500
  timesteps_total: 90500
  training_iteration: 181
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    181 |          21357.7 | 90500 | 0.496887 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-37-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8650568181818182
  episode_reward_mean: 0.49293244853922785
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 91000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1646.003
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.26232659816741943
        entropy_coeff: 0.0
        kl: 0.015539338812232018
        model: {}
        policy_loss: -0.018454870209097862
        total_loss: -0.007120666094124317
        vf_explained_var: 0.6232537031173706
        vf_loss: 0.011305022984743118
    load_time_ms: 2.274
    num_steps_sampled: 91000
    num_steps_trained: 91000
    sample_time_ms: 13337.618
    update_time_ms: 5.895
  iterations_since_restore: 182
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.654545454545458
    ram_util_percent: 13.486363636363636
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 229.01215045641086
    mean_inference_ms: 1.3655906648363707
    mean_processing_ms: 0.9820006475101621
  time_since_restore: 21373.28375172615
  time_this_iter_s: 15.613911390304565
  time_total_s: 21373.28375172615
  timestamp: 1637980666
  timesteps_since_restore: 91000
  timesteps_this_iter: 500
  timesteps_total: 91000
  training_iteration: 182
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    182 |          21373.3 | 91000 | 0.492932 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-38-02
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.861244019138756
  episode_reward_mean: 0.47953061600646607
  episode_reward_min: -0.3670103092783505
  episodes_this_iter: 500
  episodes_total: 91500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1648.753
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.24297897517681122
        entropy_coeff: 0.0
        kl: 0.005400866270065308
        model: {}
        policy_loss: -0.015412462875247002
        total_loss: -0.00442633219063282
        vf_explained_var: 0.638949990272522
        vf_loss: 0.010975983925163746
    load_time_ms: 2.319
    num_steps_sampled: 91500
    num_steps_trained: 91500
    sample_time_ms: 13976.379
    update_time_ms: 5.807
  iterations_since_restore: 183
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.922727272727272
    ram_util_percent: 13.45
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 227.89971334770266
    mean_inference_ms: 1.3643858298605416
    mean_processing_ms: 0.9809779664341645
  time_since_restore: 21388.665817022324
  time_this_iter_s: 15.382065296173096
  time_total_s: 21388.665817022324
  timestamp: 1637980682
  timesteps_since_restore: 91500
  timesteps_this_iter: 500
  timesteps_total: 91500
  training_iteration: 183
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    183 |          21388.7 | 91500 | 0.479531 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-38-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.5039095583704706
  episode_reward_min: 0.03
  episodes_this_iter: 500
  episodes_total: 92000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1638.556
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.2555069923400879
        entropy_coeff: 0.0
        kl: 0.011639713309705257
        model: {}
        policy_loss: -0.019499646499753
        total_loss: -0.009689846076071262
        vf_explained_var: 0.6707867383956909
        vf_loss: 0.009787950664758682
    load_time_ms: 2.365
    num_steps_sampled: 92000
    num_steps_trained: 92000
    sample_time_ms: 14267.757
    update_time_ms: 5.774
  iterations_since_restore: 184
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.544444444444444
    ram_util_percent: 13.444444444444445
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 226.76026969239453
    mean_inference_ms: 1.363286637641561
    mean_processing_ms: 0.9800429924720179
  time_since_restore: 21400.44329714775
  time_this_iter_s: 11.777480125427246
  time_total_s: 21400.44329714775
  timestamp: 1637980694
  timesteps_since_restore: 92000
  timesteps_this_iter: 500
  timesteps_total: 92000
  training_iteration: 184
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    184 |          21400.4 | 92000 |  0.50391 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-38-30
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.4964301243666704
  episode_reward_min: -0.1647940074906367
  episodes_this_iter: 500
  episodes_total: 92500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1632.191
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.23090116679668427
        entropy_coeff: 0.0
        kl: 0.005141828674823046
        model: {}
        policy_loss: -0.016623320057988167
        total_loss: -0.005494203418493271
        vf_explained_var: 0.5958564877510071
        vf_loss: 0.011119472794234753
    load_time_ms: 2.366
    num_steps_sampled: 92500
    num_steps_trained: 92500
    sample_time_ms: 15052.827
    update_time_ms: 5.7
  iterations_since_restore: 185
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.856521739130438
    ram_util_percent: 13.534782608695652
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 225.68174060402086
    mean_inference_ms: 1.362185618888777
    mean_processing_ms: 0.9791412847977524
  time_since_restore: 21416.784725904465
  time_this_iter_s: 16.341428756713867
  time_total_s: 21416.784725904465
  timestamp: 1637980710
  timesteps_since_restore: 92500
  timesteps_this_iter: 500
  timesteps_total: 92500
  training_iteration: 185
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    185 |          21416.8 | 92500 |  0.49643 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-38-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8629441624365483
  episode_reward_mean: 0.5019475558727269
  episode_reward_min: -0.1320754716981132
  episodes_this_iter: 500
  episodes_total: 93000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1635.716
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.2505890130996704
        entropy_coeff: 0.0
        kl: 0.0076403687708079815
        model: {}
        policy_loss: -0.014686299487948418
        total_loss: -0.0030505377799272537
        vf_explained_var: 0.6003335118293762
        vf_loss: 0.011621411889791489
    load_time_ms: 2.35
    num_steps_sampled: 93000
    num_steps_trained: 93000
    sample_time_ms: 15084.977
    update_time_ms: 5.716
  iterations_since_restore: 186
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.581818181818182
    ram_util_percent: 13.472727272727269
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 224.6027447095724
    mean_inference_ms: 1.3610916500908012
    mean_processing_ms: 0.9782583095367472
  time_since_restore: 21432.025520801544
  time_this_iter_s: 15.240794897079468
  time_total_s: 21432.025520801544
  timestamp: 1637980726
  timesteps_since_restore: 93000
  timesteps_this_iter: 500
  timesteps_total: 93000
  training_iteration: 186
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    186 |            21432 | 93000 | 0.501948 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-39-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8840399002493765
  episode_reward_mean: 0.5174493491830142
  episode_reward_min: 0.07327586206896551
  episodes_this_iter: 500
  episodes_total: 93500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1631.458
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.2500726580619812
        entropy_coeff: 0.0
        kl: 0.007178789004683495
        model: {}
        policy_loss: -0.014751550741493702
        total_loss: -0.0033459151163697243
        vf_explained_var: 0.6276010870933533
        vf_loss: 0.01139216497540474
    load_time_ms: 2.348
    num_steps_sampled: 93500
    num_steps_trained: 93500
    sample_time_ms: 14750.875
    update_time_ms: 5.715
  iterations_since_restore: 187
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.36551724137931
    ram_util_percent: 13.482758620689655
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 223.5899123327907
    mean_inference_ms: 1.3600223705799974
    mean_processing_ms: 0.9773834824091613
  time_since_restore: 21452.25974535942
  time_this_iter_s: 20.234224557876587
  time_total_s: 21452.25974535942
  timestamp: 1637980746
  timesteps_since_restore: 93500
  timesteps_this_iter: 500
  timesteps_total: 93500
  training_iteration: 187
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    187 |          21452.3 | 93500 | 0.517449 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-39-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8802507836990595
  episode_reward_mean: 0.49504790328832
  episode_reward_min: -0.1388888888888889
  episodes_this_iter: 500
  episodes_total: 94000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1632.931
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.23891280591487885
        entropy_coeff: 0.0
        kl: 0.008919789455831051
        model: {}
        policy_loss: -0.023681407794356346
        total_loss: -0.010241352021694183
        vf_explained_var: 0.5572254061698914
        vf_loss: 0.013423318043351173
    load_time_ms: 2.337
    num_steps_sampled: 94000
    num_steps_trained: 94000
    sample_time_ms: 15593.246
    update_time_ms: 5.708
  iterations_since_restore: 188
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.281578947368423
    ram_util_percent: 13.807894736842107
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 222.64517799194664
    mean_inference_ms: 1.3591583847404798
    mean_processing_ms: 0.9767264744379197
  time_since_restore: 21478.13973402977
  time_this_iter_s: 25.87998867034912
  time_total_s: 21478.13973402977
  timestamp: 1637980772
  timesteps_since_restore: 94000
  timesteps_this_iter: 500
  timesteps_total: 94000
  training_iteration: 188
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    188 |          21478.1 | 94000 | 0.495048 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-39-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9664360370970116
  episode_reward_mean: 0.5180308872579308
  episode_reward_min: 0.06097560975609756
  episodes_this_iter: 500
  episodes_total: 94500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1625.424
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.24146728217601776
        entropy_coeff: 0.0
        kl: 0.00896218977868557
        model: {}
        policy_loss: -0.019388001412153244
        total_loss: -0.007525136694312096
        vf_explained_var: 0.5856598615646362
        vf_loss: 0.011846041306853294
    load_time_ms: 2.296
    num_steps_sampled: 94500
    num_steps_trained: 94500
    sample_time_ms: 16454.019
    update_time_ms: 5.74
  iterations_since_restore: 189
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.860000000000001
    ram_util_percent: 13.571428571428571
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 221.697935675721
    mean_inference_ms: 1.3581401445180885
    mean_processing_ms: 0.9759277759083388
  time_since_restore: 21502.620025396347
  time_this_iter_s: 24.48029136657715
  time_total_s: 21502.620025396347
  timestamp: 1637980797
  timesteps_since_restore: 94500
  timesteps_this_iter: 500
  timesteps_total: 94500
  training_iteration: 189
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    189 |          21502.6 | 94500 | 0.518031 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-40-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8855345911949686
  episode_reward_mean: 0.5087332082931542
  episode_reward_min: 0.09606986899563319
  episodes_this_iter: 500
  episodes_total: 95000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1630.885
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.24323727190494537
        entropy_coeff: 0.0
        kl: 0.009778057225048542
        model: {}
        policy_loss: -0.011279764585196972
        total_loss: 0.0009791541378945112
        vf_explained_var: 0.5523504018783569
        vf_loss: 0.012240557931363583
    load_time_ms: 2.308
    num_steps_sampled: 95000
    num_steps_trained: 95000
    sample_time_ms: 16276.322
    update_time_ms: 5.532
  iterations_since_restore: 190
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.5125
    ram_util_percent: 13.49375
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 220.73707137765024
    mean_inference_ms: 1.3570913639727737
    mean_processing_ms: 0.9750427531550566
  time_since_restore: 21524.95896410942
  time_this_iter_s: 22.33893871307373
  time_total_s: 21524.95896410942
  timestamp: 1637980820
  timesteps_since_restore: 95000
  timesteps_this_iter: 500
  timesteps_total: 95000
  training_iteration: 190
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    190 |            21525 | 95000 | 0.508733 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-40-38
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8959823885525592
  episode_reward_mean: 0.49717263540041917
  episode_reward_min: -0.9190751445086706
  episodes_this_iter: 500
  episodes_total: 95500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1624.657
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.24302762746810913
        entropy_coeff: 0.0
        kl: 0.006348718423396349
        model: {}
        policy_loss: -0.02192039042711258
        total_loss: -0.006367808673530817
        vf_explained_var: 0.5874612927436829
        vf_loss: 0.015540664084255695
    load_time_ms: 2.317
    num_steps_sampled: 95500
    num_steps_trained: 95500
    sample_time_ms: 16921.995
    update_time_ms: 5.5
  iterations_since_restore: 191
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.925925925925924
    ram_util_percent: 13.56296296296296
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 219.74472442053596
    mean_inference_ms: 1.3560382068182784
    mean_processing_ms: 0.9742255805094224
  time_since_restore: 21543.30084824562
  time_this_iter_s: 18.34188413619995
  time_total_s: 21543.30084824562
  timestamp: 1637980838
  timesteps_since_restore: 95500
  timesteps_this_iter: 500
  timesteps_total: 95500
  training_iteration: 191
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    191 |          21543.3 | 95500 | 0.497173 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-40-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5234407656439339
  episode_reward_min: 0.12571428571428572
  episodes_this_iter: 500
  episodes_total: 96000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1637.507
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.263541579246521
        entropy_coeff: 0.0
        kl: 0.018309952691197395
        model: {}
        policy_loss: -0.01899160072207451
        total_loss: -0.007239785045385361
        vf_explained_var: 0.5850074887275696
        vf_loss: 0.011717444285750389
    load_time_ms: 2.303
    num_steps_sampled: 96000
    num_steps_trained: 96000
    sample_time_ms: 16995.181
    update_time_ms: 5.448
  iterations_since_restore: 192
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.22083333333333
    ram_util_percent: 13.541666666666666
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 218.74302963474352
    mean_inference_ms: 1.3550319189434306
    mean_processing_ms: 0.9734418096371591
  time_since_restore: 21559.774934768677
  time_this_iter_s: 16.47408652305603
  time_total_s: 21559.774934768677
  timestamp: 1637980855
  timesteps_since_restore: 96000
  timesteps_this_iter: 500
  timesteps_total: 96000
  training_iteration: 192
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    192 |          21559.8 | 96000 | 0.523441 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-41-17
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8595166163141994
  episode_reward_mean: 0.48528352645583134
  episode_reward_min: 0.08902691511387163
  episodes_this_iter: 500
  episodes_total: 96500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1644.548
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.29007866978645325
        entropy_coeff: 0.0
        kl: 0.01387119572609663
        model: {}
        policy_loss: -0.016510972753167152
        total_loss: -0.005851227790117264
        vf_explained_var: 0.6134755611419678
        vf_loss: 0.010633704252541065
    load_time_ms: 2.282
    num_steps_sampled: 96500
    num_steps_trained: 96500
    sample_time_ms: 17618.221
    update_time_ms: 5.58
  iterations_since_restore: 193
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.796774193548387
    ram_util_percent: 13.580645161290319
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 217.80552843173152
    mean_inference_ms: 1.3541520673983258
    mean_processing_ms: 0.9727927262587303
  time_since_restore: 21581.458639621735
  time_this_iter_s: 21.68370485305786
  time_total_s: 21581.458639621735
  timestamp: 1637980877
  timesteps_since_restore: 96500
  timesteps_this_iter: 500
  timesteps_total: 96500
  training_iteration: 193
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    193 |          21581.5 | 96500 | 0.485284 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-41-38
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610634648370498
  episode_reward_mean: 0.49191608881699983
  episode_reward_min: -1.0837696335078535
  episodes_this_iter: 500
  episodes_total: 97000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1643.114
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.27661144733428955
        entropy_coeff: 0.0
        kl: 0.01307439524680376
        model: {}
        policy_loss: -0.025986328721046448
        total_loss: -0.011907284148037434
        vf_explained_var: 0.6213952898979187
        vf_loss: 0.014054498635232449
    load_time_ms: 2.225
    num_steps_sampled: 97000
    num_steps_trained: 97000
    sample_time_ms: 18555.088
    update_time_ms: 5.625
  iterations_since_restore: 194
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.68
    ram_util_percent: 13.466666666666663
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 216.87351102820426
    mean_inference_ms: 1.3530767425674914
    mean_processing_ms: 0.9719548724995214
  time_since_restore: 21602.589869976044
  time_this_iter_s: 21.131230354309082
  time_total_s: 21602.589869976044
  timestamp: 1637980898
  timesteps_since_restore: 97000
  timesteps_this_iter: 500
  timesteps_total: 97000
  training_iteration: 194
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    194 |          21602.6 | 97000 | 0.491916 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-41-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8659476117103235
  episode_reward_mean: 0.49924478227607455
  episode_reward_min: 0.0145413870246085
  episodes_this_iter: 500
  episodes_total: 97500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1656.254
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.23742327094078064
        entropy_coeff: 0.0
        kl: 0.012033400125801563
        model: {}
        policy_loss: -0.02181573212146759
        total_loss: -0.010675103403627872
        vf_explained_var: 0.6248785257339478
        vf_loss: 0.011118040420114994
    load_time_ms: 2.304
    num_steps_sampled: 97500
    num_steps_trained: 97500
    sample_time_ms: 18755.022
    update_time_ms: 5.667
  iterations_since_restore: 195
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.35185185185185
    ram_util_percent: 13.451851851851849
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 215.92162100738454
    mean_inference_ms: 1.3519441642154402
    mean_processing_ms: 0.9711510210706946
  time_since_restore: 21621.06456065178
  time_this_iter_s: 18.474690675735474
  time_total_s: 21621.06456065178
  timestamp: 1637980917
  timesteps_since_restore: 97500
  timesteps_this_iter: 500
  timesteps_total: 97500
  training_iteration: 195
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    195 |          21621.1 | 97500 | 0.499245 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-42-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.4930695108466371
  episode_reward_min: 0.033582089552238806
  episodes_this_iter: 500
  episodes_total: 98000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1664.613
    learner:
      default_policy:
        cur_kl_coeff: 0.0018771172035485506
        cur_lr: 4.999999873689376e-05
        entropy: 0.21725322306156158
        entropy_coeff: 0.0
        kl: 0.0031109140254557133
        model: {}
        policy_loss: -0.006864302325993776
        total_loss: 0.00546919833868742
        vf_explained_var: 0.5711837410926819
        vf_loss: 0.01232765894383192
    load_time_ms: 2.323
    num_steps_sampled: 98000
    num_steps_trained: 98000
    sample_time_ms: 18483.134
    update_time_ms: 5.615
  iterations_since_restore: 196
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.833333333333332
    ram_util_percent: 13.494444444444447
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 214.91977571498379
    mean_inference_ms: 1.350931646342161
    mean_processing_ms: 0.970329294749566
  time_since_restore: 21633.67050385475
  time_this_iter_s: 12.605943202972412
  time_total_s: 21633.67050385475
  timestamp: 1637980930
  timesteps_since_restore: 98000
  timesteps_this_iter: 500
  timesteps_total: 98000
  training_iteration: 196
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    196 |          21633.7 | 98000 |  0.49307 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-42-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8631578947368421
  episode_reward_mean: 0.5004626264710891
  episode_reward_min: 0.01282051282051282
  episodes_this_iter: 500
  episodes_total: 98500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1665.956
    learner:
      default_policy:
        cur_kl_coeff: 0.0009385586017742753
        cur_lr: 4.999999873689376e-05
        entropy: 0.24171358346939087
        entropy_coeff: 0.0
        kl: 0.009384091943502426
        model: {}
        policy_loss: -0.013538260012865067
        total_loss: -0.0005601856391876936
        vf_explained_var: 0.5891952514648438
        vf_loss: 0.012969260104000568
    load_time_ms: 2.322
    num_steps_sampled: 98500
    num_steps_trained: 98500
    sample_time_ms: 17664.127
    update_time_ms: 5.632
  iterations_since_restore: 197
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.855555555555554
    ram_util_percent: 13.444444444444446
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 213.92442326844832
    mean_inference_ms: 1.3499052199909194
    mean_processing_ms: 0.9695542872728422
  time_since_restore: 21645.728140354156
  time_this_iter_s: 12.057636499404907
  time_total_s: 21645.728140354156
  timestamp: 1637980942
  timesteps_since_restore: 98500
  timesteps_this_iter: 500
  timesteps_total: 98500
  training_iteration: 197
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    197 |          21645.7 | 98500 | 0.500463 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


[2m[36m(pid=3420)[0m Program ./new_garbage_3420/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-42-36
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8650568181818182
  episode_reward_mean: 0.4967810150065832
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 99000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1630.69
    learner:
      default_policy:
        cur_kl_coeff: 0.0009385586017742753
        cur_lr: 4.999999873689376e-05
        entropy: 0.23397208750247955
        entropy_coeff: 0.0
        kl: 0.006947871297597885
        model: {}
        policy_loss: -0.010692800395190716
        total_loss: -0.0006723280530422926
        vf_explained_var: 0.6418328285217285
        vf_loss: 0.010013953782618046
    load_time_ms: 2.372
    num_steps_sampled: 99000
    num_steps_trained: 99000
    sample_time_ms: 16516.447
    update_time_ms: 5.614
  iterations_since_restore: 198
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.330000000000002
    ram_util_percent: 13.854999999999999
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 212.9605711629283
    mean_inference_ms: 1.3489843545526587
    mean_processing_ms: 0.968860735323796
  time_since_restore: 21659.77883386612
  time_this_iter_s: 14.05069351196289
  time_total_s: 21659.77883386612
  timestamp: 1637980956
  timesteps_since_restore: 99000
  timesteps_this_iter: 500
  timesteps_total: 99000
  training_iteration: 198
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    198 |          21659.8 | 99000 | 0.496781 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-42-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.48118880593237745
  episode_reward_min: 0.03
  episodes_this_iter: 500
  episodes_total: 99500
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1631.828
    learner:
      default_policy:
        cur_kl_coeff: 0.0009385586017742753
        cur_lr: 4.999999873689376e-05
        entropy: 0.25317639112472534
        entropy_coeff: 0.0
        kl: 0.005918382201343775
        model: {}
        policy_loss: -0.013021855615079403
        total_loss: -0.0023711181711405516
        vf_explained_var: 0.653578519821167
        vf_loss: 0.010645193047821522
    load_time_ms: 2.385
    num_steps_sampled: 99500
    num_steps_trained: 99500
    sample_time_ms: 15620.468
    update_time_ms: 5.576
  iterations_since_restore: 199
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.39130434782609
    ram_util_percent: 13.478260869565213
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 212.01985743600247
    mean_inference_ms: 1.3479323108282923
    mean_processing_ms: 0.9680213947966868
  time_since_restore: 21675.30963897705
  time_this_iter_s: 15.530805110931396
  time_total_s: 21675.30963897705
  timestamp: 1637980972
  timesteps_since_restore: 99500
  timesteps_this_iter: 500
  timesteps_total: 99500
  training_iteration: 199
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+--------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    199 |          21675.3 | 99500 | 0.481189 |
+-------------------+----------+--------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-26_20-43-13
  done: true
  episode_len_mean: 1.0
  episode_reward_max: 0.8595890410958904
  episode_reward_mean: 0.5069097085006454
  episode_reward_min: 0.10062893081761007
  episodes_this_iter: 500
  episodes_total: 100000
  experiment_id: 88e26ba8a21148cab5ec48c407e24c28
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1612.664
    learner:
      default_policy:
        cur_kl_coeff: 0.0009385586017742753
        cur_lr: 4.999999873689376e-05
        entropy: 0.26274374127388
        entropy_coeff: 0.0
        kl: 0.006908238399773836
        model: {}
        policy_loss: -0.012186126783490181
        total_loss: -0.002478024922311306
        vf_explained_var: 0.6249812245368958
        vf_loss: 0.009701620787382126
    load_time_ms: 2.379
    num_steps_sampled: 100000
    num_steps_trained: 100000
    sample_time_ms: 15519.109
    update_time_ms: 5.749
  iterations_since_restore: 200
  node_ip: 172.29.138.27
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.75
    ram_util_percent: 13.469999999999999
  pid: 3417
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 211.14523273159452
    mean_inference_ms: 1.3469848259357373
    mean_processing_ms: 0.9672791622570531
  time_since_restore: 21696.444448947906
  time_this_iter_s: 21.134809970855713
  time_total_s: 21696.444448947906
  timestamp: 1637980993
  timesteps_since_restore: 100000
  timesteps_this_iter: 500
  timesteps_total: 100000
  training_iteration: 200
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+--------------------+--------+------------------+--------+----------+
| Trial name        | status   | loc                |   iter |   total time (s) |     ts |   reward |
|-------------------+----------+--------------------+--------+------------------+--------+----------|
| PPO_autovec_00000 | RUNNING  | 172.29.138.27:3417 |    200 |          21696.4 | 100000 |  0.50691 |
+-------------------+----------+--------------------+--------+------------------+--------+----------+


== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 TERMINATED)
+-------------------+------------+-------+--------+------------------+--------+----------+
| Trial name        | status     | loc   |   iter |   total time (s) |     ts |   reward |
|-------------------+------------+-------+--------+------------------+--------+----------|
| PPO_autovec_00000 | TERMINATED |       |    200 |          21696.4 | 100000 |  0.50691 |
+-------------------+------------+-------+--------+------------------+--------+----------+


