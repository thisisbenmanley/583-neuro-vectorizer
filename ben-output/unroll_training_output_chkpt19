== Status ==
Memory usage on this node: 0.9/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+-------+
| Trial name        | status   | loc   |
|-------------------+----------+-------|
| PPO_autovec_00000 | RUNNING  |       |
+-------------------+----------+-------+


[2m[36m(pid=1479)[0m /home/bdmanley/anaconda3/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.
[2m[36m(pid=1479)[0m   for external in metadata.entry_points().get(self.group, []):
[2m[36m(pid=1479)[0m 2021-12-03 21:14:50,803	INFO trainer.py:428 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
[2m[36m(pid=1479)[0m 2021-12-03 21:14:50,811	WARNING deprecation.py:30 -- DeprecationWarning: `sample_batch_size` has been deprecated. Use `rollout_fragment_length` instead. This will raise an error in the future!
[2m[36m(pid=1479)[0m 2021-12-03 21:14:50,811	INFO trainer.py:585 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=1479)[0m cp: cannot stat './training_data/*': No such file or directory
[2m[36m(pid=1479)[0m creating ./new_unroll_garbage_1479 directory
[2m[36m(pid=1479)[0m running: cp -r ./training_data/* ./new_unroll_garbage_1479
[2m[36m(pid=1479)[0m Checking if local obs_encodings.pkl file exists.
[2m[36m(pid=1479)[0m Checking if local O3_runtimes.pkl file exists to avoid waste of compilation.
[2m[36m(pid=1479)[0m Did not find O3_runtimes.pkl... Compiling to get -O3 runtimes.
[2m[36m(pid=1482)[0m /home/bdmanley/anaconda3/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.
[2m[36m(pid=1482)[0m   for external in metadata.entry_points().get(self.group, []):
[2m[36m(pid=1482)[0m creating ./new_unroll_garbage_1482 directory
[2m[36m(pid=1482)[0m running: cp -r ./training_data/* ./new_unroll_garbage_1482
[2m[36m(pid=1479)[0m 2021-12-03 21:14:56,531	INFO trainable.py:217 -- Getting current IP.
[2m[36m(pid=1479)[0m 2021-12-03 21:14:56,531	WARNING util.py:37 -- Install gputil for GPU system monitoring.
== Status ==
Memory usage on this node: 1.5/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+-------+
| Trial name        | status   | loc   |
|-------------------+----------+-------|
| PPO_autovec_00000 | RUNNING  |       |
+-------------------+----------+-------+


[2m[36m(pid=1479)[0m 2021-12-03 21:14:56,601	INFO trainable.py:217 -- Getting current IP.
[2m[36m(pid=1479)[0m 2021-12-03 21:14:56,601	INFO trainable.py:423 -- Restored on 172.17.255.101 from checkpoint: /home/bdmanley/ray_results/neurovectorizer_train/PPO_autovec_0_2021-12-03_21-14-47yosib8zp/tmp0kdme814restore_from_object/checkpoint-19
[2m[36m(pid=1479)[0m 2021-12-03 21:14:56,601	INFO trainable.py:430 -- Current state after restoring: {'_iteration': 19, '_timesteps_total': 9500, '_time_total': 8504.005539655685, '_episodes_total': 9500}
[2m[36m(pid=1482)[0m Checking if local obs_encodings.pkl file exists.
[2m[36m(pid=1482)[0m found local obs_encodings.pkl.
[2m[36m(pid=1482)[0m Checking if local O3_runtimes.pkl file exists to avoid waste of compilation.
[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_21-23-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8600478468899522
  episode_reward_mean: 0.38502914646534375
  episode_reward_min: -1.4722222222222223
  episodes_this_iter: 500
  episodes_total: 10000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 2106.889
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 1.0887264013290405
        entropy_coeff: 0.0
        kl: 0.00940478965640068
        model: {}
        policy_loss: -0.027500800788402557
        total_loss: -0.004205720499157906
        vf_explained_var: 0.6402040719985962
        vf_loss: 0.021414127200841904
    load_time_ms: 58.348
    num_steps_sampled: 10000
    num_steps_trained: 10000
    sample_time_ms: 491144.275
    update_time_ms: 613.889
  iterations_since_restore: 1
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.399858156028365
    ram_util_percent: 13.11078014184397
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 965.1526267419085
    mean_inference_ms: 2.1566302476528882
    mean_processing_ms: 1.6587413475660984
  time_since_restore: 493.97525906562805
  time_this_iter_s: 493.97525906562805
  time_total_s: 8997.980798721313
  timestamp: 1638584590
  timesteps_since_restore: 500
  timesteps_this_iter: 500
  timesteps_total: 10000
  training_iteration: 20
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     20 |          8997.98 | 10000 | 0.385029 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_21-31-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9637862505520388
  episode_reward_mean: 0.4013115726023894
  episode_reward_min: -1.087463556851312
  episodes_this_iter: 500
  episodes_total: 10500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1880.381
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 1.069593906402588
        entropy_coeff: 0.0
        kl: 0.018439387902617455
        model: {}
        policy_loss: -0.03516675531864166
        total_loss: -0.0044416990131139755
        vf_explained_var: 0.504349410533905
        vf_loss: 0.027037180960178375
    load_time_ms: 30.193
    num_steps_sampled: 10500
    num_steps_trained: 10500
    sample_time_ms: 481057.531
    update_time_ms: 309.592
  iterations_since_restore: 2
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.302666666666665
    ram_util_percent: 13.346962962962964
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 951.6038727927042
    mean_inference_ms: 2.0787372932091097
    mean_processing_ms: 1.6637579663531052
  time_since_restore: 966.6165306568146
  time_this_iter_s: 472.6412715911865
  time_total_s: 9470.6220703125
  timestamp: 1638585063
  timesteps_since_restore: 1000
  timesteps_this_iter: 500
  timesteps_total: 10500
  training_iteration: 21
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     21 |          9470.62 | 10500 | 0.401312 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_21-39-07
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8657127132636213
  episode_reward_mean: 0.38950529004677165
  episode_reward_min: -1.2712933753943219
  episodes_this_iter: 500
  episodes_total: 11000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1797.129
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 1.0905591249465942
        entropy_coeff: 0.0
        kl: 0.015482191927731037
        model: {}
        policy_loss: -0.027599014341831207
        total_loss: 0.002567903371527791
        vf_explained_var: 0.5482833981513977
        vf_loss: 0.027070488780736923
    load_time_ms: 21.035
    num_steps_sampled: 11000
    num_steps_trained: 11000
    sample_time_ms: 481513.903
    update_time_ms: 207.683
  iterations_since_restore: 3
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.164057971014493
    ram_util_percent: 13.371159420289858
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 954.7000385617355
    mean_inference_ms: 2.0643619598348013
    mean_processing_ms: 1.6671658197615171
  time_since_restore: 1450.6893458366394
  time_this_iter_s: 484.07281517982483
  time_total_s: 9954.694885492325
  timestamp: 1638585547
  timesteps_since_restore: 1500
  timesteps_this_iter: 500
  timesteps_total: 11000
  training_iteration: 22
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     22 |          9954.69 | 11000 | 0.389505 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_21-47-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8831003811944091
  episode_reward_mean: 0.37367290433150574
  episode_reward_min: -1.8214285714285714
  episodes_this_iter: 500
  episodes_total: 11500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1806.667
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 1.107327938079834
        entropy_coeff: 0.0
        kl: 0.013478614389896393
        model: {}
        policy_loss: -0.04990609735250473
        total_loss: -0.011147608980536461
        vf_explained_var: 0.4816882014274597
        vf_loss: 0.03606276214122772
    load_time_ms: 16.472
    num_steps_sampled: 11500
    num_steps_trained: 11500
    sample_time_ms: 485543.821
    update_time_ms: 156.826
  iterations_since_restore: 4
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.369284712482468
    ram_util_percent: 13.38148667601683
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 963.8593519764622
    mean_inference_ms: 2.048298932503962
    mean_processing_ms: 1.6689230238777704
  time_since_restore: 1950.1763229370117
  time_this_iter_s: 499.4869771003723
  time_total_s: 10454.181862592697
  timestamp: 1638586046
  timesteps_since_restore: 2000
  timesteps_this_iter: 500
  timesteps_total: 11500
  training_iteration: 23
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     23 |          10454.2 | 11500 | 0.373673 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_21-55-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8513873052071456
  episode_reward_mean: 0.35307452282693536
  episode_reward_min: -1.3540983606557377
  episodes_this_iter: 500
  episodes_total: 12000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1780.312
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 1.08135187625885
        entropy_coeff: 0.0
        kl: 0.014271944761276245
        model: {}
        policy_loss: -0.02349958010017872
        total_loss: 0.0029106265865266323
        vf_explained_var: 0.568006157875061
        vf_loss: 0.023555822670459747
    load_time_ms: 13.744
    num_steps_sampled: 12000
    num_steps_trained: 12000
    sample_time_ms: 485245.731
    update_time_ms: 126.261
  iterations_since_restore: 5
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.152813852813852
    ram_util_percent: 13.444877344877346
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 963.8980238593036
    mean_inference_ms: 2.053718479191575
    mean_processing_ms: 1.6820026559383572
  time_since_restore: 2435.9220700263977
  time_this_iter_s: 485.745747089386
  time_total_s: 10939.927609682083
  timestamp: 1638586532
  timesteps_since_restore: 2500
  timesteps_this_iter: 500
  timesteps_total: 12000
  training_iteration: 24
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     24 |          10939.9 | 12000 | 0.353075 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_22-03-35
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8473413379073756
  episode_reward_mean: 0.3428473287577192
  episode_reward_min: -3.7711267605633805
  episodes_this_iter: 500
  episodes_total: 12500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1788.055
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 1.0841598510742188
        entropy_coeff: 0.0
        kl: 0.008119196631014347
        model: {}
        policy_loss: -0.024191798642277718
        total_loss: 0.0311010479927063
        vf_explained_var: 0.5966365933418274
        vf_loss: 0.05366900563240051
    load_time_ms: 11.843
    num_steps_sampled: 12500
    num_steps_trained: 12500
    sample_time_ms: 484528.114
    update_time_ms: 106.35
  iterations_since_restore: 6
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.317706821480407
    ram_util_percent: 13.469230769230771
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 962.8852185151135
    mean_inference_ms: 2.0572462307536896
    mean_processing_ms: 1.6915172149800564
  time_since_restore: 2918.7073802948
  time_this_iter_s: 482.7853102684021
  time_total_s: 11422.712919950485
  timestamp: 1638587015
  timesteps_since_restore: 3000
  timesteps_this_iter: 500
  timesteps_total: 12500
  training_iteration: 25
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     25 |          11422.7 | 12500 | 0.342847 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_22-11-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8542063189950514
  episode_reward_mean: 0.3453553079078629
  episode_reward_min: -1.5085324232081911
  episodes_this_iter: 500
  episodes_total: 13000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1785.922
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 1.1216840744018555
        entropy_coeff: 0.0
        kl: 0.01660953089594841
        model: {}
        policy_loss: -0.040197473019361496
        total_loss: -0.009639773517847061
        vf_explained_var: 0.6180245876312256
        vf_loss: 0.027235787361860275
    load_time_ms: 10.519
    num_steps_sampled: 13000
    num_steps_trained: 13000
    sample_time_ms: 485304.546
    update_time_ms: 91.787
  iterations_since_restore: 7
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.329529243937232
    ram_util_percent: 13.488159771754637
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 964.7457978957651
    mean_inference_ms: 2.05612734228296
    mean_processing_ms: 1.6959278081628604
  time_since_restore: 3410.461184501648
  time_this_iter_s: 491.75380420684814
  time_total_s: 11914.466724157333
  timestamp: 1638587507
  timesteps_since_restore: 3500
  timesteps_this_iter: 500
  timesteps_total: 13000
  training_iteration: 26
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     26 |          11914.5 | 13000 | 0.345355 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_22-19-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8551617873651772
  episode_reward_mean: 0.3487218355985342
  episode_reward_min: -1.4555160142348755
  episodes_this_iter: 500
  episodes_total: 13500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1770.678
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 1.0573704242706299
        entropy_coeff: 0.0
        kl: 0.010635809041559696
        model: {}
        policy_loss: -0.029981723055243492
        total_loss: 0.0012367451563477516
        vf_explained_var: 0.5710429549217224
        vf_loss: 0.02909129299223423
    load_time_ms: 9.502
    num_steps_sampled: 13500
    num_steps_trained: 13500
    sample_time_ms: 484876.499
    update_time_ms: 80.798
  iterations_since_restore: 8
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.124202898550722
    ram_util_percent: 13.505217391304349
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 964.1264682112857
    mean_inference_ms: 2.051837382927981
    mean_processing_ms: 1.6972357795942254
  time_since_restore: 3894.020996570587
  time_this_iter_s: 483.5598120689392
  time_total_s: 12398.026536226273
  timestamp: 1638587991
  timesteps_since_restore: 4000
  timesteps_this_iter: 500
  timesteps_total: 13500
  training_iteration: 27
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     27 |            12398 | 13500 | 0.348722 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_22-28-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8583333333333333
  episode_reward_mean: 0.361279351954792
  episode_reward_min: -0.38974358974358975
  episodes_this_iter: 500
  episodes_total: 14000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1755.774
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 1.027579426765442
        entropy_coeff: 0.0
        kl: 0.01414060965180397
        model: {}
        policy_loss: -0.034408941864967346
        total_loss: -0.012569352053105831
        vf_explained_var: 0.6104923486709595
        vf_loss: 0.019011463969945908
    load_time_ms: 8.694
    num_steps_sampled: 14000
    num_steps_trained: 14000
    sample_time_ms: 485285.214
    update_time_ms: 72.254
  iterations_since_restore: 9
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.300715307582262
    ram_util_percent: 13.522889842632331
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 965.1268237274345
    mean_inference_ms: 2.050370699669144
    mean_processing_ms: 1.6972703473935045
  time_since_restore: 4384.227557182312
  time_this_iter_s: 490.20656061172485
  time_total_s: 12888.233096837997
  timestamp: 1638588481
  timesteps_since_restore: 4500
  timesteps_this_iter: 500
  timesteps_total: 14000
  training_iteration: 28
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     28 |          12888.2 | 14000 | 0.361279 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_22-36-02
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8522727272727273
  episode_reward_mean: 0.3523517698281536
  episode_reward_min: -1.5645756457564575
  episodes_this_iter: 500
  episodes_total: 14500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1746.243
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.9720156788825989
        entropy_coeff: 0.0
        kl: 0.015421802178025246
        model: {}
        policy_loss: -0.035637374967336655
        total_loss: -0.003987753298133612
        vf_explained_var: 0.6006869673728943
        vf_loss: 0.028565263375639915
    load_time_ms: 8.036
    num_steps_sampled: 14500
    num_steps_trained: 14500
    sample_time_ms: 484673.321
    update_time_ms: 65.442
  iterations_since_restore: 10
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.33396501457726
    ram_util_percent: 13.560932944606414
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 964.0483803759574
    mean_inference_ms: 2.050687970697486
    mean_processing_ms: 1.6970712169364222
  time_since_restore: 4865.070872783661
  time_this_iter_s: 480.8433156013489
  time_total_s: 13369.076412439346
  timestamp: 1638588962
  timesteps_since_restore: 5000
  timesteps_this_iter: 500
  timesteps_total: 14500
  training_iteration: 29
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     29 |          13369.1 | 14500 | 0.352352 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_22-44-19
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8429133858267717
  episode_reward_mean: 0.3484694959041885
  episode_reward_min: -0.7789473684210526
  episodes_this_iter: 500
  episodes_total: 15000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1698.14
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.9650827050209045
        entropy_coeff: 0.0
        kl: 0.008385132066905499
        model: {}
        policy_loss: -0.023133045062422752
        total_loss: -0.005871244706213474
        vf_explained_var: 0.7023271322250366
        vf_loss: 0.015584767796099186
    load_time_ms: 2.476
    num_steps_sampled: 15000
    num_steps_trained: 15000
    sample_time_ms: 485076.542
    update_time_ms: 4.505
  iterations_since_restore: 11
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.297602256699577
    ram_util_percent: 13.587447108603667
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 966.0773689455169
    mean_inference_ms: 2.0495490840599118
    mean_processing_ms: 1.6971231265363647
  time_since_restore: 5361.88921380043
  time_this_iter_s: 496.8183410167694
  time_total_s: 13865.894753456116
  timestamp: 1638589459
  timesteps_since_restore: 5500
  timesteps_this_iter: 500
  timesteps_total: 15000
  training_iteration: 30
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     30 |          13865.9 | 15000 | 0.348469 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_22-52-29
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8397058823529412
  episode_reward_mean: 0.3533646435582914
  episode_reward_min: -0.6522988505747126
  episodes_this_iter: 500
  episodes_total: 15500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1696.685
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.8670949339866638
        entropy_coeff: 0.0
        kl: 0.01778716780245304
        model: {}
        policy_loss: -0.04819592088460922
        total_loss: -0.0272862259298563
        vf_explained_var: 0.7019541263580322
        vf_loss: 0.017352253198623657
    load_time_ms: 2.488
    num_steps_sampled: 15500
    num_steps_trained: 15500
    sample_time_ms: 486807.443
    update_time_ms: 4.502
  iterations_since_restore: 12
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.23519313304721
    ram_util_percent: 13.55321888412017
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 966.6140023081965
    mean_inference_ms: 2.052360207930026
    mean_processing_ms: 1.6980419514914626
  time_since_restore: 5851.824659109116
  time_this_iter_s: 489.9354453086853
  time_total_s: 14355.830198764801
  timestamp: 1638589949
  timesteps_since_restore: 6000
  timesteps_this_iter: 500
  timesteps_total: 15500
  training_iteration: 31
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     31 |          14355.8 | 15500 | 0.353365 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_23-00-40
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8455824863174355
  episode_reward_mean: 0.3527593397844378
  episode_reward_min: -0.2956521739130435
  episodes_this_iter: 500
  episodes_total: 16000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1709.621
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.8158528804779053
        entropy_coeff: 0.0
        kl: 0.009235217235982418
        model: {}
        policy_loss: -0.02673342637717724
        total_loss: -0.008544839918613434
        vf_explained_var: 0.6466672420501709
        vf_loss: 0.016341539099812508
    load_time_ms: 2.452
    num_steps_sampled: 16000
    num_steps_trained: 16000
    sample_time_ms: 487487.976
    update_time_ms: 4.52
  iterations_since_restore: 13
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.359486447931527
    ram_util_percent: 13.565905848787445
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 967.2140980148255
    mean_inference_ms: 2.0536367864979903
    mean_processing_ms: 1.7008280831105047
  time_since_restore: 6342.832855463028
  time_this_iter_s: 491.00819635391235
  time_total_s: 14846.838395118713
  timestamp: 1638590440
  timesteps_since_restore: 6500
  timesteps_this_iter: 500
  timesteps_total: 16000
  training_iteration: 32
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     32 |          14846.8 | 16000 | 0.352759 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_23-08-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.853641456582633
  episode_reward_mean: 0.3586758346410635
  episode_reward_min: -1.6865671641791045
  episodes_this_iter: 500
  episodes_total: 16500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1691.179
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.8330691456794739
        entropy_coeff: 0.0
        kl: 0.008273753337562084
        model: {}
        policy_loss: -0.030837655067443848
        total_loss: 0.003933236468583345
        vf_explained_var: 0.583955705165863
        vf_loss: 0.03311614692211151
    load_time_ms: 2.42
    num_steps_sampled: 16500
    num_steps_trained: 16500
    sample_time_ms: 487129.142
    update_time_ms: 4.541
  iterations_since_restore: 14
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.23210749646393
    ram_util_percent: 13.577652050919374
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 968.4222297589446
    mean_inference_ms: 2.053009273494726
    mean_processing_ms: 1.6990147255400456
  time_since_restore: 6838.544506072998
  time_this_iter_s: 495.7116506099701
  time_total_s: 15342.550045728683
  timestamp: 1638590935
  timesteps_since_restore: 7000
  timesteps_this_iter: 500
  timesteps_total: 16500
  training_iteration: 33
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     33 |          15342.6 | 16500 | 0.358676 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_23-16-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8556399766218585
  episode_reward_mean: 0.3916783787119225
  episode_reward_min: -1.105263157894737
  episodes_this_iter: 500
  episodes_total: 17000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1697.573
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.8073661923408508
        entropy_coeff: 0.0
        kl: 0.01106050331145525
        model: {}
        policy_loss: -0.02935086563229561
        total_loss: -0.009262547828257084
        vf_explained_var: 0.6461838483810425
        vf_loss: 0.017876219004392624
    load_time_ms: 2.365
    num_steps_sampled: 17000
    num_steps_trained: 17000
    sample_time_ms: 484941.509
    update_time_ms: 4.604
  iterations_since_restore: 15
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.17643504531722
    ram_util_percent: 13.620996978851961
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 965.219640553816
    mean_inference_ms: 2.052914506672955
    mean_processing_ms: 1.697575183029795
  time_since_restore: 7302.477138996124
  time_this_iter_s: 463.9326329231262
  time_total_s: 15806.48267865181
  timestamp: 1638591399
  timesteps_since_restore: 7500
  timesteps_this_iter: 500
  timesteps_total: 17000
  training_iteration: 34
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     34 |          15806.5 | 17000 | 0.391678 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_23-23-33
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8678304239401496
  episode_reward_mean: 0.3644721317320067
  episode_reward_min: -0.23008849557522124
  episodes_this_iter: 500
  episodes_total: 17500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1690.174
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.7430601716041565
        entropy_coeff: 0.0
        kl: 0.008746345527470112
        model: {}
        policy_loss: -0.01880677416920662
        total_loss: 0.0007257985998876393
        vf_explained_var: 0.5918697118759155
        vf_loss: 0.017783300951123238
    load_time_ms: 2.364
    num_steps_sampled: 17500
    num_steps_trained: 17500
    sample_time_ms: 478014.276
    update_time_ms: 4.338
  iterations_since_restore: 16
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.37728813559322
    ram_util_percent: 13.631186440677965
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 956.1172371401723
    mean_inference_ms: 2.045270100695955
    mean_processing_ms: 1.6911644262755574
  time_since_restore: 7715.91309094429
  time_this_iter_s: 413.4359519481659
  time_total_s: 16219.918630599976
  timestamp: 1638591813
  timesteps_since_restore: 8000
  timesteps_this_iter: 500
  timesteps_total: 17500
  training_iteration: 35
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     35 |          16219.9 | 17500 | 0.364472 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_23-28-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9636390401884293
  episode_reward_mean: 0.37936615961915576
  episode_reward_min: -0.38071065989847713
  episodes_this_iter: 500
  episodes_total: 18000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1692.256
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.7533568739891052
        entropy_coeff: 0.0
        kl: 0.011552759446203709
        model: {}
        policy_loss: -0.026206955313682556
        total_loss: -0.0064698876813054085
        vf_explained_var: 0.6703730821609497
        vf_loss: 0.017426518723368645
    load_time_ms: 2.377
    num_steps_sampled: 18000
    num_steps_trained: 18000
    sample_time_ms: 456729.278
    update_time_ms: 4.285
  iterations_since_restore: 17
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.438693467336684
    ram_util_percent: 13.633417085427137
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 932.2865978575721
    mean_inference_ms: 2.0234319493709174
    mean_processing_ms: 1.6727002981536148
  time_since_restore: 7994.836777687073
  time_this_iter_s: 278.9236867427826
  time_total_s: 16498.842317342758
  timestamp: 1638592092
  timesteps_since_restore: 8500
  timesteps_this_iter: 500
  timesteps_total: 18000
  training_iteration: 36
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     36 |          16498.8 | 18000 | 0.379366 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_23-32-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8628930817610063
  episode_reward_mean: 0.39346197721862447
  episode_reward_min: -0.8710526315789474
  episodes_this_iter: 500
  episodes_total: 18500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1696.846
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.7065082788467407
        entropy_coeff: 0.0
        kl: 0.0070680296048521996
        model: {}
        policy_loss: -0.024451041594147682
        total_loss: -0.00027276709442958236
        vf_explained_var: 0.5130507946014404
        vf_loss: 0.022764666005969048
    load_time_ms: 2.433
    num_steps_sampled: 18500
    num_steps_trained: 18500
    sample_time_ms: 434535.43
    update_time_ms: 4.436
  iterations_since_restore: 18
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.325201072386058
    ram_util_percent: 13.643163538873994
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 909.1953611707651
    mean_inference_ms: 2.004974485172085
    mean_processing_ms: 1.6559225071166541
  time_since_restore: 8256.505772590637
  time_this_iter_s: 261.66899490356445
  time_total_s: 16760.511312246323
  timestamp: 1638592354
  timesteps_since_restore: 9000
  timesteps_this_iter: 500
  timesteps_total: 18500
  training_iteration: 37
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     37 |          16760.5 | 18500 | 0.393462 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_23-37-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8657127132636213
  episode_reward_mean: 0.3840967318944139
  episode_reward_min: -0.47368421052631576
  episodes_this_iter: 500
  episodes_total: 19000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1697.256
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.6931824684143066
        entropy_coeff: 0.0
        kl: 0.00842362456023693
        model: {}
        policy_loss: -0.022262806072831154
        total_loss: -0.002803966635838151
        vf_explained_var: 0.6404566764831543
        vf_loss: 0.01777411252260208
    load_time_ms: 2.444
    num_steps_sampled: 19000
    num_steps_trained: 19000
    sample_time_ms: 413172.847
    update_time_ms: 4.553
  iterations_since_restore: 19
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.467088607594937
    ram_util_percent: 13.648860759493669
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 890.1109221407951
    mean_inference_ms: 1.9896163926377026
    mean_processing_ms: 1.6405409279026213
  time_since_restore: 8533.092176437378
  time_this_iter_s: 276.5864038467407
  time_total_s: 17037.097716093063
  timestamp: 1638592630
  timesteps_since_restore: 9500
  timesteps_this_iter: 500
  timesteps_total: 19000
  training_iteration: 38
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     38 |          17037.1 | 19000 | 0.384097 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_23-41-45
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8843710292249047
  episode_reward_mean: 0.3885148090542499
  episode_reward_min: -0.5792682926829268
  episodes_this_iter: 500
  episodes_total: 19500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1694.532
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.6572449207305908
        entropy_coeff: 0.0
        kl: 0.00640403525903821
        model: {}
        policy_loss: -0.018275892361998558
        total_loss: 0.00183130893856287
        vf_explained_var: 0.6026062369346619
        vf_loss: 0.018826397135853767
    load_time_ms: 2.47
    num_steps_sampled: 19500
    num_steps_trained: 19500
    sample_time_ms: 392577.589
    update_time_ms: 4.605
  iterations_since_restore: 20
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.420918367346939
    ram_util_percent: 13.667091836734691
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 872.764469516145
    mean_inference_ms: 1.9746421992856256
    mean_processing_ms: 1.6265394878129984
  time_since_restore: 8807.955351829529
  time_this_iter_s: 274.8631753921509
  time_total_s: 17311.960891485214
  timestamp: 1638592905
  timesteps_since_restore: 10000
  timesteps_this_iter: 500
  timesteps_total: 19500
  training_iteration: 39
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     39 |            17312 | 19500 | 0.388515 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_23-45-38
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8465608465608465
  episode_reward_mean: 0.3594429175850661
  episode_reward_min: -1.0546448087431695
  episodes_this_iter: 500
  episodes_total: 20000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1716.977
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.7006657123565674
        entropy_coeff: 0.0
        kl: 0.005771733354777098
        model: {}
        policy_loss: -0.023490481078624725
        total_loss: 0.0011496877996250987
        vf_explained_var: 0.6164867877960205
        vf_loss: 0.023485831916332245
    load_time_ms: 2.417
    num_steps_sampled: 20000
    num_steps_trained: 20000
    sample_time_ms: 366181.909
    update_time_ms: 4.65
  iterations_since_restore: 21
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.34084084084084
    ram_util_percent: 13.658558558558557
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 853.0756622572737
    mean_inference_ms: 1.9584642275323556
    mean_processing_ms: 1.6121266512811303
  time_since_restore: 9041.040763139725
  time_this_iter_s: 233.08541131019592
  time_total_s: 17545.04630279541
  timestamp: 1638593138
  timesteps_since_restore: 10500
  timesteps_this_iter: 500
  timesteps_total: 20000
  training_iteration: 40
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     40 |            17545 | 20000 | 0.359443 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_23-49-13
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8542063189950514
  episode_reward_mean: 0.3866531108816029
  episode_reward_min: -0.3872549019607843
  episodes_this_iter: 500
  episodes_total: 20500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1719.856
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.7420475482940674
        entropy_coeff: 0.0
        kl: 0.008648484013974667
        model: {}
        policy_loss: -0.023095212876796722
        total_loss: -0.005560233723372221
        vf_explained_var: 0.6657361388206482
        vf_loss: 0.015805285423994064
    load_time_ms: 2.442
    num_steps_sampled: 20500
    num_steps_trained: 20500
    sample_time_ms: 338648.735
    update_time_ms: 4.755
  iterations_since_restore: 22
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.341176470588238
    ram_util_percent: 13.65032679738562
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 833.5289776774929
    mean_inference_ms: 1.937007938728648
    mean_processing_ms: 1.5927460093724053
  time_since_restore: 9255.674807310104
  time_this_iter_s: 214.63404417037964
  time_total_s: 17759.68034696579
  timestamp: 1638593353
  timesteps_since_restore: 11000
  timesteps_this_iter: 500
  timesteps_total: 20500
  training_iteration: 41
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     41 |          17759.7 | 20500 | 0.386653 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_23-53-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8674884437596302
  episode_reward_mean: 0.38764926967282176
  episode_reward_min: -0.5078369905956113
  episodes_this_iter: 500
  episodes_total: 21000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1713.927
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.7439841628074646
        entropy_coeff: 0.0
        kl: 0.010073933750391006
        model: {}
        policy_loss: -0.02429247461259365
        total_loss: -0.00573125621303916
        vf_explained_var: 0.6586782932281494
        vf_loss: 0.016546443104743958
    load_time_ms: 2.459
    num_steps_sampled: 21000
    num_steps_trained: 21000
    sample_time_ms: 312611.846
    update_time_ms: 4.788
  iterations_since_restore: 23
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.188145896656534
    ram_util_percent: 13.610030395136777
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 817.065043984657
    mean_inference_ms: 1.9185314405670308
    mean_processing_ms: 1.5749025009018625
  time_since_restore: 9486.25428700447
  time_this_iter_s: 230.57947969436646
  time_total_s: 17990.259826660156
  timestamp: 1638593584
  timesteps_since_restore: 11500
  timesteps_this_iter: 500
  timesteps_total: 21000
  training_iteration: 42
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     42 |          17990.3 | 21000 | 0.387649 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-03_23-56-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8638888888888889
  episode_reward_mean: 0.3928900342603297
  episode_reward_min: -0.6380597014925373
  episodes_this_iter: 500
  episodes_total: 21500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1707.235
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.7082098126411438
        entropy_coeff: 0.0
        kl: 0.009553022682666779
        model: {}
        policy_loss: -0.024200348183512688
        total_loss: -0.003013928886502981
        vf_explained_var: 0.6162427067756653
        vf_loss: 0.019275814294815063
    load_time_ms: 2.454
    num_steps_sampled: 21500
    num_steps_trained: 21500
    sample_time_ms: 285690.73
    update_time_ms: 4.755
  iterations_since_restore: 24
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.326006191950468
    ram_util_percent: 13.62755417956656
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 801.6377782515709
    mean_inference_ms: 1.9012362288888338
    mean_processing_ms: 1.5582563121977793
  time_since_restore: 9712.687915563583
  time_this_iter_s: 226.43362855911255
  time_total_s: 18216.69345521927
  timestamp: 1638593810
  timesteps_since_restore: 12000
  timesteps_this_iter: 500
  timesteps_total: 21500
  training_iteration: 43
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     43 |          18216.7 | 21500 |  0.39289 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_00-00-38
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8575851393188855
  episode_reward_mean: 0.38611795198825855
  episode_reward_min: -0.44623655913978494
  episodes_this_iter: 500
  episodes_total: 22000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1706.648
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.71728515625
        entropy_coeff: 0.0
        kl: 0.009085548110306263
        model: {}
        policy_loss: -0.030401434749364853
        total_loss: -0.006225242745131254
        vf_explained_var: 0.561215341091156
        vf_loss: 0.022359095513820648
    load_time_ms: 2.468
    num_steps_sampled: 22000
    num_steps_trained: 22000
    sample_time_ms: 262124.569
    update_time_ms: 4.833
  iterations_since_restore: 25
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.585582822085888
    ram_util_percent: 13.6260736196319
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 787.5717316958514
    mean_inference_ms: 1.8888158174946101
    mean_processing_ms: 1.546529414853843
  time_since_restore: 9940.955825805664
  time_this_iter_s: 228.2679102420807
  time_total_s: 18444.96136546135
  timestamp: 1638594038
  timesteps_since_restore: 12500
  timesteps_this_iter: 500
  timesteps_total: 22000
  training_iteration: 44
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     44 |            18445 | 22000 | 0.386118 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_00-04-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.860738255033557
  episode_reward_mean: 0.3811887956337813
  episode_reward_min: -0.49473684210526314
  episodes_this_iter: 500
  episodes_total: 22500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1691.162
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.7351257801055908
        entropy_coeff: 0.0
        kl: 0.00817091204226017
        model: {}
        policy_loss: -0.019231503829360008
        total_loss: -0.001338430680334568
        vf_explained_var: 0.6704979538917542
        vf_loss: 0.016258884221315384
    load_time_ms: 2.475
    num_steps_sampled: 22500
    num_steps_trained: 22500
    sample_time_ms: 241416.783
    update_time_ms: 4.944
  iterations_since_restore: 26
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.523469387755101
    ram_util_percent: 13.736394557823129
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 772.9070341024992
    mean_inference_ms: 1.874019894065531
    mean_processing_ms: 1.5334060087395436
  time_since_restore: 10147.159627199173
  time_this_iter_s: 206.2038013935089
  time_total_s: 18651.16516685486
  timestamp: 1638594245
  timesteps_since_restore: 13000
  timesteps_this_iter: 500
  timesteps_total: 22500
  training_iteration: 45
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     45 |          18651.2 | 22500 | 0.381189 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_00-07-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.849703184025904
  episode_reward_mean: 0.36969979467858627
  episode_reward_min: -1.474074074074074
  episodes_this_iter: 500
  episodes_total: 23000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1671.806
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.7675755023956299
        entropy_coeff: 0.0
        kl: 0.01101866364479065
        model: {}
        policy_loss: -0.020043127238750458
        total_loss: 0.0019504871452227235
        vf_explained_var: 0.6766747832298279
        vf_loss: 0.01978987827897072
    load_time_ms: 2.447
    num_steps_sampled: 23000
    num_steps_trained: 23000
    sample_time_ms: 233920.099
    update_time_ms: 5.014
  iterations_since_restore: 27
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.153951890034365
    ram_util_percent: 13.628178694158073
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 759.1511611805679
    mean_inference_ms: 1.8586857602663567
    mean_processing_ms: 1.5193895449171102
  time_since_restore: 10350.921876192093
  time_this_iter_s: 203.76224899291992
  time_total_s: 18854.92741584778
  timestamp: 1638594448
  timesteps_since_restore: 13500
  timesteps_this_iter: 500
  timesteps_total: 23000
  training_iteration: 46
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     46 |          18854.9 | 23000 |   0.3697 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_00-11-13
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647058823529412
  episode_reward_mean: 0.3923824899460902
  episode_reward_min: -0.8753993610223643
  episodes_this_iter: 500
  episodes_total: 23500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1661.039
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.7360478043556213
        entropy_coeff: 0.0
        kl: 0.012718976475298405
        model: {}
        policy_loss: -0.03382815048098564
        total_loss: -0.016918709501624107
        vf_explained_var: 0.7088624835014343
        vf_loss: 0.014365637674927711
    load_time_ms: 2.352
    num_steps_sampled: 23500
    num_steps_trained: 23500
    sample_time_ms: 230223.316
    update_time_ms: 4.988
  iterations_since_restore: 28
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.286562499999999
    ram_util_percent: 13.655937499999999
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 747.8630434793286
    mean_inference_ms: 1.8460273095585857
    mean_processing_ms: 1.5069645529567801
  time_since_restore: 10575.514073610306
  time_this_iter_s: 224.5921974182129
  time_total_s: 19079.51961326599
  timestamp: 1638594673
  timesteps_since_restore: 14000
  timesteps_this_iter: 500
  timesteps_total: 23500
  training_iteration: 47
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     47 |          19079.5 | 23500 | 0.392382 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_00-14-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8566666666666667
  episode_reward_mean: 0.3849838002735493
  episode_reward_min: -1.2268370607028753
  episodes_this_iter: 500
  episodes_total: 24000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1683.988
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.7559802532196045
        entropy_coeff: 0.0
        kl: 0.008191566914319992
        model: {}
        policy_loss: -0.023775625973939896
        total_loss: -0.0024921733420342207
        vf_explained_var: 0.6513216495513916
        vf_loss: 0.01964513771235943
    load_time_ms: 2.326
    num_steps_sampled: 24000
    num_steps_trained: 24000
    sample_time_ms: 220826.715
    update_time_ms: 4.961
  iterations_since_restore: 29
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.465134099616858
    ram_util_percent: 13.677777777777777
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 734.460497303639
    mean_inference_ms: 1.8309480477576336
    mean_processing_ms: 1.4945805364621525
  time_since_restore: 10758.362560987473
  time_this_iter_s: 182.84848737716675
  time_total_s: 19262.368100643158
  timestamp: 1638594856
  timesteps_since_restore: 14500
  timesteps_this_iter: 500
  timesteps_total: 24000
  training_iteration: 48
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     48 |          19262.4 | 24000 | 0.384984 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_00-17-45
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8609077598828697
  episode_reward_mean: 0.3924509391692883
  episode_reward_min: -1.6865671641791045
  episodes_this_iter: 500
  episodes_total: 24500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1692.12
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.8136740922927856
        entropy_coeff: 0.0
        kl: 0.009196863509714603
        model: {}
        policy_loss: -0.028348682448267937
        total_loss: -0.0002617657301016152
        vf_explained_var: 0.5756305456161499
        vf_loss: 0.026247534900903702
    load_time_ms: 2.311
    num_steps_sampled: 24500
    num_steps_trained: 24500
    sample_time_ms: 214243.955
    update_time_ms: 5.093
  iterations_since_restore: 30
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.500668896321073
    ram_util_percent: 13.682943143812706
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 723.713761861702
    mean_inference_ms: 1.8169678065722943
    mean_processing_ms: 1.4821209833467968
  time_since_restore: 10967.480174303055
  time_this_iter_s: 209.11761331558228
  time_total_s: 19471.48571395874
  timestamp: 1638595065
  timesteps_since_restore: 15000
  timesteps_this_iter: 500
  timesteps_total: 24500
  training_iteration: 49
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     49 |          19471.5 | 24500 | 0.392451 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_00-21-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8877805486284289
  episode_reward_mean: 0.4094101505277401
  episode_reward_min: -1.5511811023622046
  episodes_this_iter: 500
  episodes_total: 25000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1671.399
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.867255687713623
        entropy_coeff: 0.0
        kl: 0.013930623419582844
        model: {}
        policy_loss: -0.043159183114767075
        total_loss: -0.014348587952554226
        vf_explained_var: 0.5839261412620544
        vf_loss: 0.026024485006928444
    load_time_ms: 2.346
    num_steps_sampled: 25000
    num_steps_trained: 25000
    sample_time_ms: 212999.091
    update_time_ms: 5.079
  iterations_since_restore: 31
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.146178343949044
    ram_util_percent: 13.730254777070062
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 714.3926498205631
    mean_inference_ms: 1.8052313144910985
    mean_processing_ms: 1.4709859853805656
  time_since_restore: 11187.910315275192
  time_this_iter_s: 220.43014097213745
  time_total_s: 19691.915854930878
  timestamp: 1638595286
  timesteps_since_restore: 15500
  timesteps_this_iter: 500
  timesteps_total: 25000
  training_iteration: 50
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     50 |          19691.9 | 25000 |  0.40941 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_00-24-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8744019138755981
  episode_reward_mean: 0.4001986515008405
  episode_reward_min: -0.38071065989847713
  episodes_this_iter: 500
  episodes_total: 25500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1680.373
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.8922255039215088
        entropy_coeff: 0.0
        kl: 0.027239806950092316
        model: {}
        policy_loss: -0.038930896669626236
        total_loss: -0.01706855371594429
        vf_explained_var: 0.6701443195343018
        vf_loss: 0.016414381563663483
    load_time_ms: 2.316
    num_steps_sampled: 25500
    num_steps_trained: 25500
    sample_time_ms: 208700.785
    update_time_ms: 4.973
  iterations_since_restore: 32
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.314285714285713
    ram_util_percent: 13.667346938775507
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 702.6113237666232
    mean_inference_ms: 1.7904621103049654
    mean_processing_ms: 1.4574182055144151
  time_since_restore: 11359.64903974533
  time_this_iter_s: 171.73872447013855
  time_total_s: 19863.654579401016
  timestamp: 1638595458
  timesteps_since_restore: 16000
  timesteps_this_iter: 500
  timesteps_total: 25500
  training_iteration: 51
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     51 |          19863.7 | 25500 | 0.400199 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_00-26-48
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9636390401884293
  episode_reward_mean: 0.4086966553559592
  episode_reward_min: -1.087463556851312
  episodes_this_iter: 500
  episodes_total: 26000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1672.129
    learner:
      default_policy:
        cur_kl_coeff: 0.30000001192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.9239653944969177
        entropy_coeff: 0.0
        kl: 0.010471886023879051
        model: {}
        policy_loss: -0.02465285360813141
        total_loss: -0.001357132219709456
        vf_explained_var: 0.6567443013191223
        vf_loss: 0.020154159516096115
    load_time_ms: 2.27
    num_steps_sampled: 26000
    num_steps_trained: 26000
    sample_time_ms: 200663.163
    update_time_ms: 5.058
  iterations_since_restore: 33
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.606976744186046
    ram_util_percent: 13.758604651162788
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 690.2423787641493
    mean_inference_ms: 1.7769411689375008
    mean_processing_ms: 1.4441614837026922
  time_since_restore: 11509.770166158676
  time_this_iter_s: 150.12112641334534
  time_total_s: 20013.77570581436
  timestamp: 1638595608
  timesteps_since_restore: 16500
  timesteps_this_iter: 500
  timesteps_total: 26000
  training_iteration: 52
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     52 |          20013.8 | 26000 | 0.408697 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_00-29-33
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8970831040176115
  episode_reward_mean: 0.43159403946621344
  episode_reward_min: -0.40703517587939697
  episodes_this_iter: 500
  episodes_total: 26500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1667.399
    learner:
      default_policy:
        cur_kl_coeff: 0.30000001192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.9130398631095886
        entropy_coeff: 0.0
        kl: 0.01632457785308361
        model: {}
        policy_loss: -0.04105354845523834
        total_loss: -0.016656341031193733
        vf_explained_var: 0.5933204293251038
        vf_loss: 0.019499830901622772
    load_time_ms: 2.303
    num_steps_sampled: 26500
    num_steps_trained: 26500
    sample_time_ms: 194596.648
    update_time_ms: 5.151
  iterations_since_restore: 34
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.109322033898305
    ram_util_percent: 13.674999999999997
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 679.5213196840111
    mean_inference_ms: 1.7653043379075983
    mean_processing_ms: 1.432672513736626
  time_since_restore: 11675.491714715958
  time_this_iter_s: 165.7215485572815
  time_total_s: 20179.497254371643
  timestamp: 1638595773
  timesteps_since_restore: 17000
  timesteps_this_iter: 500
  timesteps_total: 26500
  training_iteration: 53
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     53 |          20179.5 | 26500 | 0.431594 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_00-32-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8879781420765027
  episode_reward_mean: 0.41729168160614777
  episode_reward_min: -0.2796208530805687
  episodes_this_iter: 500
  episodes_total: 27000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1653.879
    learner:
      default_policy:
        cur_kl_coeff: 0.30000001192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.8931775093078613
        entropy_coeff: 0.0
        kl: 0.017029399052262306
        model: {}
        policy_loss: -0.0454062856733799
        total_loss: -0.024864381179213524
        vf_explained_var: 0.6417297124862671
        vf_loss: 0.015433077700436115
    load_time_ms: 2.292
    num_steps_sampled: 27000
    num_steps_trained: 27000
    sample_time_ms: 191147.667
    update_time_ms: 5.173
  iterations_since_restore: 35
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.205797101449276
    ram_util_percent: 13.699637681159418
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 671.0028693332828
    mean_inference_ms: 1.7547889693342855
    mean_processing_ms: 1.423024850588895
  time_since_restore: 11869.131754875183
  time_this_iter_s: 193.64004015922546
  time_total_s: 20373.13729453087
  timestamp: 1638595967
  timesteps_since_restore: 17500
  timesteps_this_iter: 500
  timesteps_total: 27000
  training_iteration: 54
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     54 |          20373.1 | 27000 | 0.417292 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_00-36-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8919949174078781
  episode_reward_mean: 0.4033654108353751
  episode_reward_min: -1.1841269841269841
  episodes_this_iter: 500
  episodes_total: 27500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1668.65
    learner:
      default_policy:
        cur_kl_coeff: 0.30000001192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.8438777923583984
        entropy_coeff: 0.0
        kl: 0.011899607256054878
        model: {}
        policy_loss: -0.03444192558526993
        total_loss: -0.007518363650888205
        vf_explained_var: 0.5585792660713196
        vf_loss: 0.023353684693574905
    load_time_ms: 2.25
    num_steps_sampled: 27500
    num_steps_trained: 27500
    sample_time_ms: 190943.427
    update_time_ms: 5.115
  iterations_since_restore: 36
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.265753424657536
    ram_util_percent: 13.710273972602737
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 663.540937630218
    mean_inference_ms: 1.7453017853861432
    mean_processing_ms: 1.4147195847297631
  time_since_restore: 12073.440394163132
  time_this_iter_s: 204.3086392879486
  time_total_s: 20577.445933818817
  timestamp: 1638596172
  timesteps_since_restore: 18000
  timesteps_this_iter: 500
  timesteps_total: 27500
  training_iteration: 55
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     55 |          20577.4 | 27500 | 0.403365 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_00-39-58
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8577832110839446
  episode_reward_mean: 0.4023848193069447
  episode_reward_min: -0.42441860465116277
  episodes_this_iter: 500
  episodes_total: 28000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1668.315
    learner:
      default_policy:
        cur_kl_coeff: 0.30000001192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.7649291753768921
        entropy_coeff: 0.0
        kl: 0.013746439479291439
        model: {}
        policy_loss: -0.043228134512901306
        total_loss: -0.0226590633392334
        vf_explained_var: 0.6604331731796265
        vf_loss: 0.016445137560367584
    load_time_ms: 2.218
    num_steps_sampled: 28000
    num_steps_trained: 28000
    sample_time_ms: 193177.424
    update_time_ms: 5.112
  iterations_since_restore: 37
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.390092879256965
    ram_util_percent: 13.735603715170276
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 657.6672752678932
    mean_inference_ms: 1.7372133615732028
    mean_processing_ms: 1.406639719336724
  time_since_restore: 12299.539183139801
  time_this_iter_s: 226.0987889766693
  time_total_s: 20803.544722795486
  timestamp: 1638596398
  timesteps_since_restore: 18500
  timesteps_this_iter: 500
  timesteps_total: 28000
  training_iteration: 56
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     56 |          20803.5 | 28000 | 0.402385 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_00-43-54
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.4090773026305975
  episode_reward_min: -0.5078369905956113
  episodes_this_iter: 500
  episodes_total: 28500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1659.874
    learner:
      default_policy:
        cur_kl_coeff: 0.30000001192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.7453764081001282
        entropy_coeff: 0.0
        kl: 0.010447490029036999
        model: {}
        policy_loss: -0.03163354471325874
        total_loss: -0.013242101296782494
        vf_explained_var: 0.6939554810523987
        vf_loss: 0.015257187187671661
    load_time_ms: 2.231
    num_steps_sampled: 28500
    num_steps_trained: 28500
    sample_time_ms: 194327.574
    update_time_ms: 5.165
  iterations_since_restore: 38
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.035416666666666
    ram_util_percent: 13.67797619047619
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 652.6268201340852
    mean_inference_ms: 1.7302025745344272
    mean_processing_ms: 1.4000262444185325
  time_since_restore: 12535.54849100113
  time_this_iter_s: 236.00930786132812
  time_total_s: 21039.554030656815
  timestamp: 1638596634
  timesteps_since_restore: 19000
  timesteps_this_iter: 500
  timesteps_total: 28500
  training_iteration: 57
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     57 |          21039.6 | 28500 | 0.409077 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_01-22-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8617977528089887
  episode_reward_mean: 0.39105277310521974
  episode_reward_min: -1.5073068893528183
  episodes_this_iter: 500
  episodes_total: 29000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1633.957
    learner:
      default_policy:
        cur_kl_coeff: 0.30000001192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.7596124410629272
        entropy_coeff: 0.0
        kl: 0.004804951138794422
        model: {}
        policy_loss: -0.018537908792495728
        total_loss: 0.014219838194549084
        vf_explained_var: 0.5870991349220276
        vf_loss: 0.03131626918911934
    load_time_ms: 2.233
    num_steps_sampled: 29000
    num_steps_trained: 29000
    sample_time_ms: 409374.737
    update_time_ms: 5.147
  iterations_since_restore: 39
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.36742209631728
    ram_util_percent: 13.741643059490084
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 755.3704043399565
    mean_inference_ms: 1.7261494123582979
    mean_processing_ms: 1.3962748062793402
  time_since_restore: 14868.60977602005
  time_this_iter_s: 2333.061285018921
  time_total_s: 23372.615315675735
  timestamp: 1638598967
  timesteps_since_restore: 19500
  timesteps_this_iter: 500
  timesteps_total: 29000
  training_iteration: 58
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     58 |          23372.6 | 29000 | 0.391053 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_01-27-15
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8611111111111112
  episode_reward_mean: 0.40518470017891345
  episode_reward_min: -0.38974358974358975
  episodes_this_iter: 500
  episodes_total: 29500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1616.163
    learner:
      default_policy:
        cur_kl_coeff: 0.15000000596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.8053327798843384
        entropy_coeff: 0.0
        kl: 0.035559188574552536
        model: {}
        policy_loss: -0.034908879548311234
        total_loss: -0.013246512040495872
        vf_explained_var: 0.6343850493431091
        vf_loss: 0.016328489407896996
    load_time_ms: 2.267
    num_steps_sampled: 29500
    num_steps_trained: 29500
    sample_time_ms: 415266.822
    update_time_ms: 5.08
  iterations_since_restore: 40
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.330548302872062
    ram_util_percent: 13.774412532637077
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 749.7288309140871
    mean_inference_ms: 1.7206586841869151
    mean_processing_ms: 1.3912670684214814
  time_since_restore: 15136.469631195068
  time_this_iter_s: 267.8598551750183
  time_total_s: 23640.475170850754
  timestamp: 1638599235
  timesteps_since_restore: 20000
  timesteps_this_iter: 500
  timesteps_total: 29500
  training_iteration: 59
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     59 |          23640.5 | 29500 | 0.405185 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_01-31-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8597285067873304
  episode_reward_mean: 0.41865433165423377
  episode_reward_min: -0.4479166666666667
  episodes_this_iter: 500
  episodes_total: 30000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1628.075
    learner:
      default_policy:
        cur_kl_coeff: 0.22499999403953552
        cur_lr: 4.999999873689376e-05
        entropy: 0.7816902995109558
        entropy_coeff: 0.0
        kl: 0.010656941682100296
        model: {}
        policy_loss: -0.028095955029129982
        total_loss: -0.006434042938053608
        vf_explained_var: 0.6148668527603149
        vf_loss: 0.019264094531536102
    load_time_ms: 2.232
    num_steps_sampled: 30000
    num_steps_trained: 30000
    sample_time_ms: 416666.37
    update_time_ms: 5.066
  iterations_since_restore: 41
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.184431137724552
    ram_util_percent: 13.777245508982038
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 742.7285896453105
    mean_inference_ms: 1.7144808065169646
    mean_processing_ms: 1.3854342910419013
  time_since_restore: 15371.013663768768
  time_this_iter_s: 234.54403257369995
  time_total_s: 23875.019203424454
  timestamp: 1638599470
  timesteps_since_restore: 20500
  timesteps_this_iter: 500
  timesteps_total: 30000
  training_iteration: 60
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     60 |            23875 | 30000 | 0.418654 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_01-35-24
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.854320987654321
  episode_reward_mean: 0.41373221264348875
  episode_reward_min: -0.49473684210526314
  episodes_this_iter: 500
  episodes_total: 30500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1615.456
    learner:
      default_policy:
        cur_kl_coeff: 0.22499999403953552
        cur_lr: 4.999999873689376e-05
        entropy: 0.8004443645477295
        entropy_coeff: 0.0
        kl: 0.014382611960172653
        model: {}
        policy_loss: -0.027476636692881584
        total_loss: -0.0090635996311903
        vf_explained_var: 0.6851582527160645
        vf_loss: 0.015176949091255665
    load_time_ms: 2.221
    num_steps_sampled: 30500
    num_steps_trained: 30500
    sample_time_ms: 424964.945
    update_time_ms: 5.06
  iterations_since_restore: 42
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.262912087912087
    ram_util_percent: 13.823351648351649
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 737.0221077286114
    mean_inference_ms: 1.7089197439362018
    mean_processing_ms: 1.3802844418508031
  time_since_restore: 15625.611865282059
  time_this_iter_s: 254.5982015132904
  time_total_s: 24129.617404937744
  timestamp: 1638599724
  timesteps_since_restore: 21000
  timesteps_this_iter: 500
  timesteps_total: 30500
  training_iteration: 61
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     61 |          24129.6 | 30500 | 0.413732 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_01-39-45
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8663663663663663
  episode_reward_mean: 0.40597370260500826
  episode_reward_min: -1.2993197278911566
  episodes_this_iter: 500
  episodes_total: 31000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1621.457
    learner:
      default_policy:
        cur_kl_coeff: 0.22499999403953552
        cur_lr: 4.999999873689376e-05
        entropy: 0.7688454389572144
        entropy_coeff: 0.0
        kl: 0.010616450570523739
        model: {}
        policy_loss: -0.03897542878985405
        total_loss: -0.012467031367123127
        vf_explained_var: 0.6298616528511047
        vf_loss: 0.02411969006061554
    load_time_ms: 2.207
    num_steps_sampled: 31000
    num_steps_trained: 31000
    sample_time_ms: 435995.113
    update_time_ms: 5.051
  iterations_since_restore: 43
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.044743935309974
    ram_util_percent: 13.774932614555256
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 731.8512686939719
    mean_inference_ms: 1.7043066426191953
    mean_processing_ms: 1.3759606694361255
  time_since_restore: 15886.093964099884
  time_this_iter_s: 260.4820988178253
  time_total_s: 24390.09950375557
  timestamp: 1638599985
  timesteps_since_restore: 21500
  timesteps_this_iter: 500
  timesteps_total: 31000
  training_iteration: 62
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     62 |          24390.1 | 31000 | 0.405974 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_01-44-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8561643835616438
  episode_reward_mean: 0.3923932530628442
  episode_reward_min: -0.2956521739130435
  episodes_this_iter: 500
  episodes_total: 31500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1638.742
    learner:
      default_policy:
        cur_kl_coeff: 0.22499999403953552
        cur_lr: 4.999999873689376e-05
        entropy: 0.7734600901603699
        entropy_coeff: 0.0
        kl: 0.00852176919579506
        model: {}
        policy_loss: -0.024258708581328392
        total_loss: -0.008991831913590431
        vf_explained_var: 0.6967544555664062
        vf_loss: 0.013349476270377636
    load_time_ms: 2.166
    num_steps_sampled: 31500
    num_steps_trained: 31500
    sample_time_ms: 445498.197
    update_time_ms: 5.043
  iterations_since_restore: 44
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.256836461126003
    ram_util_percent: 13.788471849865953
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 726.9296156406988
    mean_inference_ms: 1.702009203824004
    mean_processing_ms: 1.3741034008438962
  time_since_restore: 16147.01933670044
  time_this_iter_s: 260.9253726005554
  time_total_s: 24651.024876356125
  timestamp: 1638600246
  timesteps_since_restore: 22000
  timesteps_this_iter: 500
  timesteps_total: 31500
  training_iteration: 63
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     63 |            24651 | 31500 | 0.392393 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_01-48-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8683473389355743
  episode_reward_mean: 0.3996981569786163
  episode_reward_min: -1.6865671641791045
  episodes_this_iter: 500
  episodes_total: 32000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1640.582
    learner:
      default_policy:
        cur_kl_coeff: 0.22499999403953552
        cur_lr: 4.999999873689376e-05
        entropy: 0.7749249935150146
        entropy_coeff: 0.0
        kl: 0.0049667214043438435
        model: {}
        policy_loss: -0.02380046434700489
        total_loss: 0.002481070812791586
        vf_explained_var: 0.6194060444831848
        vf_loss: 0.02516402304172516
    load_time_ms: 2.149
    num_steps_sampled: 32000
    num_steps_trained: 32000
    sample_time_ms: 454134.326
    update_time_ms: 4.95
  iterations_since_restore: 45
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.289724310776942
    ram_util_percent: 13.727318295739346
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 723.0791875422941
    mean_inference_ms: 1.6999804471885942
    mean_processing_ms: 1.37224148010753
  time_since_restore: 16427.037865400314
  time_this_iter_s: 280.0185286998749
  time_total_s: 24931.043405056
  timestamp: 1638600526
  timesteps_since_restore: 22500
  timesteps_this_iter: 500
  timesteps_total: 32000
  training_iteration: 64
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     64 |            24931 | 32000 | 0.399698 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_01-53-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8541033434650456
  episode_reward_mean: 0.4183022684936219
  episode_reward_min: -0.49683544303797467
  episodes_this_iter: 500
  episodes_total: 32500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1622.917
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.7518142461776733
        entropy_coeff: 0.0
        kl: 0.0091165192425251
        model: {}
        policy_loss: -0.01696092076599598
        total_loss: 0.0005438156658783555
        vf_explained_var: 0.6670825481414795
        vf_loss: 0.016479123383760452
    load_time_ms: 2.164
    num_steps_sampled: 32500
    num_steps_trained: 32500
    sample_time_ms: 459471.358
    update_time_ms: 4.908
  iterations_since_restore: 46
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.20054347826087
    ram_util_percent: 13.720108695652174
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 718.4196523643411
    mean_inference_ms: 1.6977962817965808
    mean_processing_ms: 1.3704736006477076
  time_since_restore: 16684.539501667023
  time_this_iter_s: 257.5016362667084
  time_total_s: 25188.545041322708
  timestamp: 1638600783
  timesteps_since_restore: 23000
  timesteps_this_iter: 500
  timesteps_total: 32500
  training_iteration: 65
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     65 |          25188.5 | 32500 | 0.418302 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_01-57-21
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8698830409356725
  episode_reward_mean: 0.40607962110950735
  episode_reward_min: -1.5511811023622046
  episodes_this_iter: 500
  episodes_total: 33000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1626.343
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.6684929132461548
        entropy_coeff: 0.0
        kl: 0.011232125572860241
        model: {}
        policy_loss: -0.027421174570918083
        total_loss: -0.00255155679769814
        vf_explained_var: 0.5430924892425537
        vf_loss: 0.023606007918715477
    load_time_ms: 2.229
    num_steps_sampled: 33000
    num_steps_trained: 33000
    sample_time_ms: 462603.846
    update_time_ms: 5.053
  iterations_since_restore: 47
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.197275204359675
    ram_util_percent: 13.749318801089919
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 713.9549127949394
    mean_inference_ms: 1.695084483576533
    mean_processing_ms: 1.3682386336552423
  time_since_restore: 16942.00014233589
  time_this_iter_s: 257.460640668869
  time_total_s: 25446.005681991577
  timestamp: 1638601041
  timesteps_since_restore: 23500
  timesteps_this_iter: 500
  timesteps_total: 33000
  training_iteration: 66
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     66 |            25446 | 33000 |  0.40608 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-00-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8752351097178683
  episode_reward_mean: 0.40485330033292743
  episode_reward_min: -0.38071065989847713
  episodes_this_iter: 500
  episodes_total: 33500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1630.902
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.6490390300750732
        entropy_coeff: 0.0
        kl: 0.014413535594940186
        model: {}
        policy_loss: -0.02862272970378399
        total_loss: -0.012130851857364178
        vf_explained_var: 0.7168257832527161
        vf_loss: 0.01487035397440195
    load_time_ms: 2.217
    num_steps_sampled: 33500
    num_steps_trained: 33500
    sample_time_ms: 460147.339
    update_time_ms: 4.898
  iterations_since_restore: 48
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.316887417218545
    ram_util_percent: 13.750993377483441
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 707.7658336056575
    mean_inference_ms: 1.6913808667109929
    mean_processing_ms: 1.3652936671506437
  time_since_restore: 17153.48890399933
  time_this_iter_s: 211.4887616634369
  time_total_s: 25657.494443655014
  timestamp: 1638601253
  timesteps_since_restore: 24000
  timesteps_this_iter: 500
  timesteps_total: 33500
  training_iteration: 67
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     67 |          25657.5 | 33500 | 0.404853 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-04-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9658471956425733
  episode_reward_mean: 0.4266742771393964
  episode_reward_min: -0.5625
  episodes_this_iter: 500
  episodes_total: 34000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1629.3
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.665668249130249
        entropy_coeff: 0.0
        kl: 0.00715857557952404
        model: {}
        policy_loss: -0.017283260822296143
        total_loss: 0.004190654959529638
        vf_explained_var: 0.5869715213775635
        vf_loss: 0.020668573677539825
    load_time_ms: 2.216
    num_steps_sampled: 34000
    num_steps_trained: 34000
    sample_time_ms: 246988.782
    update_time_ms: 5.012
  iterations_since_restore: 49
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.317770034843205
    ram_util_percent: 13.736236933797908
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 701.4187546701976
    mean_inference_ms: 1.6876933166072943
    mean_processing_ms: 1.3624183071238143
  time_since_restore: 17354.949959278107
  time_this_iter_s: 201.46105527877808
  time_total_s: 25858.955498933792
  timestamp: 1638601454
  timesteps_since_restore: 24500
  timesteps_this_iter: 500
  timesteps_total: 34000
  training_iteration: 68
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     68 |            25859 | 34000 | 0.426674 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-07-35
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8970831040176115
  episode_reward_mean: 0.4270112449896555
  episode_reward_min: -0.39067055393586003
  episodes_this_iter: 500
  episodes_total: 34500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1636.831
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.6057155728340149
        entropy_coeff: 0.0
        kl: 0.008187752217054367
        model: {}
        policy_loss: -0.025814272463321686
        total_loss: -0.006270299665629864
        vf_explained_var: 0.5927028059959412
        vf_loss: 0.018622852861881256
    load_time_ms: 2.171
    num_steps_sampled: 34500
    num_steps_trained: 34500
    sample_time_ms: 240248.119
    update_time_ms: 5.008
  iterations_since_restore: 50
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.368641114982577
    ram_util_percent: 13.757491289198606
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 695.288331197465
    mean_inference_ms: 1.6836643619521328
    mean_processing_ms: 1.3595421950028734
  time_since_restore: 17555.47773885727
  time_this_iter_s: 200.5277795791626
  time_total_s: 26059.483278512955
  timestamp: 1638601655
  timesteps_since_restore: 25000
  timesteps_this_iter: 500
  timesteps_total: 34500
  training_iteration: 69
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     69 |          26059.5 | 34500 | 0.427011 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-10-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8945362134688691
  episode_reward_mean: 0.43141144078239446
  episode_reward_min: -0.5792682926829268
  episodes_this_iter: 500
  episodes_total: 35000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1623.783
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.6327282190322876
        entropy_coeff: 0.0
        kl: 0.007796409074217081
        model: {}
        policy_loss: -0.019504563882946968
        total_loss: -0.0031251346226781607
        vf_explained_var: 0.6521018743515015
        vf_loss: 0.015502332709729671
    load_time_ms: 2.168
    num_steps_sampled: 35000
    num_steps_trained: 35000
    sample_time_ms: 234083.417
    update_time_ms: 5.136
  iterations_since_restore: 51
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.46788617886179
    ram_util_percent: 13.758130081300811
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 688.3152957748118
    mean_inference_ms: 1.6770527870588399
    mean_processing_ms: 1.353362593799099
  time_since_restore: 17728.245542049408
  time_this_iter_s: 172.76780319213867
  time_total_s: 26232.251081705093
  timestamp: 1638601828
  timesteps_since_restore: 25500
  timesteps_this_iter: 500
  timesteps_total: 35000
  training_iteration: 70
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     70 |          26232.3 | 35000 | 0.431411 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-13-02
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610271903323263
  episode_reward_mean: 0.41033443536087433
  episode_reward_min: -0.5573770491803278
  episodes_this_iter: 500
  episodes_total: 35500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1621.468
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.5844641327857971
        entropy_coeff: 0.0
        kl: 0.012085297144949436
        model: {}
        policy_loss: -0.024739963933825493
        total_loss: -0.005752940196543932
        vf_explained_var: 0.6112265586853027
        vf_loss: 0.017627418041229248
    load_time_ms: 2.266
    num_steps_sampled: 35500
    num_steps_trained: 35500
    sample_time_ms: 224059.693
    update_time_ms: 5.172
  iterations_since_restore: 52
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.597737556561084
    ram_util_percent: 13.750678733031673
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 680.9037506092071
    mean_inference_ms: 1.6700447644138736
    mean_processing_ms: 1.3470258085935203
  time_since_restore: 17882.58433318138
  time_this_iter_s: 154.33879113197327
  time_total_s: 26386.589872837067
  timestamp: 1638601982
  timesteps_since_restore: 26000
  timesteps_this_iter: 500
  timesteps_total: 35500
  training_iteration: 71
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     71 |          26386.6 | 35500 | 0.410334 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-15-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8660068519223448
  episode_reward_mean: 0.42207144877765074
  episode_reward_min: -0.3872549019607843
  episodes_this_iter: 500
  episodes_total: 36000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1614.264
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.6220064163208008
        entropy_coeff: 0.0
        kl: 0.009773444384336472
        model: {}
        policy_loss: -0.021586552262306213
        total_loss: -0.007380119990557432
        vf_explained_var: 0.6936939358711243
        vf_loss: 0.013106917031109333
    load_time_ms: 2.277
    num_steps_sampled: 36000
    num_steps_trained: 36000
    sample_time_ms: 211805.634
    update_time_ms: 5.198
  iterations_since_restore: 53
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.173979591836737
    ram_util_percent: 13.754591836734694
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 673.1508467396333
    mean_inference_ms: 1.66314573343023
    mean_processing_ms: 1.3407445629562211
  time_since_restore: 18020.454438447952
  time_this_iter_s: 137.87010526657104
  time_total_s: 26524.459978103638
  timestamp: 1638602120
  timesteps_since_restore: 26500
  timesteps_this_iter: 500
  timesteps_total: 36000
  training_iteration: 72
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     72 |          26524.5 | 36000 | 0.422071 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-17-27
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.875
  episode_reward_mean: 0.409510660236088
  episode_reward_min: -0.5078369905956113
  episodes_this_iter: 500
  episodes_total: 36500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1598.414
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.6304638385772705
        entropy_coeff: 0.0
        kl: 0.010368993505835533
        model: {}
        policy_loss: -0.025988630950450897
        total_loss: -0.011018607765436172
        vf_explained_var: 0.7022727727890015
        vf_loss: 0.013803519308567047
    load_time_ms: 2.257
    num_steps_sampled: 36500
    num_steps_trained: 36500
    sample_time_ms: 198406.206
    update_time_ms: 5.265
  iterations_since_restore: 54
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.404419889502762
    ram_util_percent: 13.717127071823203
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 665.2778438680998
    mean_inference_ms: 1.65586179108325
    mean_processing_ms: 1.3336447458665266
  time_since_restore: 18147.228265047073
  time_this_iter_s: 126.7738265991211
  time_total_s: 26651.23380470276
  timestamp: 1638602247
  timesteps_since_restore: 27000
  timesteps_this_iter: 500
  timesteps_total: 36500
  training_iteration: 73
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     73 |          26651.2 | 36500 | 0.409511 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-19-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8611111111111112
  episode_reward_mean: 0.39986894357362257
  episode_reward_min: -3.735408560311284
  episodes_this_iter: 500
  episodes_total: 37000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1611.799
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.6290563344955444
        entropy_coeff: 0.0
        kl: 0.01248070690780878
        model: {}
        policy_loss: -0.02352004498243332
        total_loss: 0.026353152468800545
        vf_explained_var: 0.5418766736984253
        vf_loss: 0.048469118773937225
    load_time_ms: 2.259
    num_steps_sampled: 37000
    num_steps_trained: 37000
    sample_time_ms: 185379.544
    update_time_ms: 5.311
  iterations_since_restore: 55
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.513084112149533
    ram_util_percent: 13.734579439252336
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 658.5230965869375
    mean_inference_ms: 1.6491640082689067
    mean_processing_ms: 1.3276463374021397
  time_since_restore: 18297.114580869675
  time_this_iter_s: 149.88631582260132
  time_total_s: 26801.12012052536
  timestamp: 1638602397
  timesteps_since_restore: 27500
  timesteps_this_iter: 500
  timesteps_total: 37000
  training_iteration: 74
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     74 |          26801.1 | 37000 | 0.399869 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-22-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8605341246290801
  episode_reward_mean: 0.4200193677029848
  episode_reward_min: -0.44623655913978494
  episodes_this_iter: 500
  episodes_total: 37500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1613.585
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.5971058011054993
        entropy_coeff: 0.0
        kl: 0.01984119415283203
        model: {}
        policy_loss: -0.027720851823687553
        total_loss: -0.005322732497006655
        vf_explained_var: 0.5663822293281555
        vf_loss: 0.020165974274277687
    load_time_ms: 2.25
    num_steps_sampled: 37500
    num_steps_trained: 37500
    sample_time_ms: 173905.66
    update_time_ms: 5.482
  iterations_since_restore: 56
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.592156862745096
    ram_util_percent: 13.775490196078433
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 651.7618112038563
    mean_inference_ms: 1.6429449233798992
    mean_processing_ms: 1.3216318886116836
  time_since_restore: 18439.89644551277
  time_this_iter_s: 142.78186464309692
  time_total_s: 26943.901985168457
  timestamp: 1638602540
  timesteps_since_restore: 28000
  timesteps_this_iter: 500
  timesteps_total: 37500
  training_iteration: 75
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     75 |          26943.9 | 37500 | 0.420019 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-24-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8693181818181818
  episode_reward_mean: 0.41653287081617
  episode_reward_min: -0.49473684210526314
  episodes_this_iter: 500
  episodes_total: 38000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1637.79
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.6112953424453735
        entropy_coeff: 0.0
        kl: 0.009501416236162186
        model: {}
        policy_loss: -0.0191341582685709
        total_loss: 0.00023542762210126966
        vf_explained_var: 0.6077210903167725
        vf_loss: 0.018300671130418777
    load_time_ms: 2.174
    num_steps_sampled: 38000
    num_steps_trained: 38000
    sample_time_ms: 161236.481
    update_time_ms: 5.476
  iterations_since_restore: 57
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.547593582887702
    ram_util_percent: 13.772192513368985
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 644.8154697660472
    mean_inference_ms: 1.6362508143597683
    mean_processing_ms: 1.3156480268195516
  time_since_restore: 18570.905512332916
  time_this_iter_s: 131.00906682014465
  time_total_s: 27074.9110519886
  timestamp: 1638602671
  timesteps_since_restore: 28500
  timesteps_this_iter: 500
  timesteps_total: 38000
  training_iteration: 76
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     76 |          27074.9 | 38000 | 0.416533 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-26-48
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.40407299159105103
  episode_reward_min: -0.4308510638297872
  episodes_this_iter: 500
  episodes_total: 38500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1646.892
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.6354977488517761
        entropy_coeff: 0.0
        kl: 0.012983964756131172
        model: {}
        policy_loss: -0.025573406368494034
        total_loss: -0.011070745065808296
        vf_explained_var: 0.7227332592010498
        vf_loss: 0.013041947968304157
    load_time_ms: 2.172
    num_steps_sampled: 38500
    num_steps_trained: 38500
    sample_time_ms: 153745.204
    update_time_ms: 5.629
  iterations_since_restore: 58
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.27076923076923
    ram_util_percent: 13.776410256410257
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 638.3111457578733
    mean_inference_ms: 1.6299769827499164
    mean_processing_ms: 1.3098819087872866
  time_since_restore: 18707.57328248024
  time_this_iter_s: 136.6677701473236
  time_total_s: 27211.578822135925
  timestamp: 1638602808
  timesteps_since_restore: 29000
  timesteps_this_iter: 500
  timesteps_total: 38500
  training_iteration: 77
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     77 |          27211.6 | 38500 | 0.404073 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-29-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8661764705882353
  episode_reward_mean: 0.4272990644836585
  episode_reward_min: -0.1377245508982036
  episodes_this_iter: 500
  episodes_total: 39000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1649.109
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.6242275238037109
        entropy_coeff: 0.0
        kl: 0.012717295438051224
        model: {}
        policy_loss: -0.03629850223660469
        total_loss: -0.021017618477344513
        vf_explained_var: 0.6967200636863708
        vf_loss: 0.0138501962646842
    load_time_ms: 2.174
    num_steps_sampled: 39000
    num_steps_trained: 39000
    sample_time_ms: 148827.795
    update_time_ms: 5.561
  iterations_since_restore: 59
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.238073394495414
    ram_util_percent: 13.756880733944953
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 632.5578849754722
    mean_inference_ms: 1.6241168487694684
    mean_processing_ms: 1.3049128241371066
  time_since_restore: 18859.88138604164
  time_this_iter_s: 152.30810356140137
  time_total_s: 27363.886925697327
  timestamp: 1638602960
  timesteps_since_restore: 29500
  timesteps_this_iter: 500
  timesteps_total: 39000
  training_iteration: 78
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     78 |          27363.9 | 39000 | 0.427299 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-31-38
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8521809369951535
  episode_reward_mean: 0.3971624524413188
  episode_reward_min: -0.29901960784313725
  episodes_this_iter: 500
  episodes_total: 39500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1655.807
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.5839186906814575
        entropy_coeff: 0.0
        kl: 0.01738077588379383
        model: {}
        policy_loss: -0.025044012814760208
        total_loss: -0.007104371674358845
        vf_explained_var: 0.6632649302482605
        vf_loss: 0.015984298661351204
    load_time_ms: 2.192
    num_steps_sampled: 39500
    num_steps_trained: 39500
    sample_time_ms: 142599.982
    update_time_ms: 5.551
  iterations_since_restore: 60
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.532487309644672
    ram_util_percent: 13.741624365482233
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 626.5217919043073
    mean_inference_ms: 1.619649813145877
    mean_processing_ms: 1.3040766740321303
  time_since_restore: 18998.198268175125
  time_this_iter_s: 138.3168821334839
  time_total_s: 27502.20380783081
  timestamp: 1638603098
  timesteps_since_restore: 30000
  timesteps_this_iter: 500
  timesteps_total: 39500
  training_iteration: 79
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     79 |          27502.2 | 39500 | 0.397162 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-34-07
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8683473389355743
  episode_reward_mean: 0.42222039880586965
  episode_reward_min: -0.49683544303797467
  episodes_this_iter: 500
  episodes_total: 40000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1659.186
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.6170918941497803
        entropy_coeff: 0.0
        kl: 0.01002498995512724
        model: {}
        policy_loss: -0.015274308621883392
        total_loss: 0.0026123388670384884
        vf_explained_var: 0.6181619167327881
        vf_loss: 0.016758831217885017
    load_time_ms: 2.174
    num_steps_sampled: 40000
    num_steps_trained: 40000
    sample_time_ms: 140214.474
    update_time_ms: 5.502
  iterations_since_restore: 61
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.738028169014084
    ram_util_percent: 13.753521126760564
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 621.0386610035818
    mean_inference_ms: 1.6143100620711393
    mean_processing_ms: 1.2991012133503306
  time_since_restore: 19147.144055128098
  time_this_iter_s: 148.9457869529724
  time_total_s: 27651.149594783783
  timestamp: 1638603247
  timesteps_since_restore: 30500
  timesteps_this_iter: 500
  timesteps_total: 40000
  training_iteration: 80
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     80 |          27651.1 | 40000 |  0.42222 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-36-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8654970760233918
  episode_reward_mean: 0.4221623108740059
  episode_reward_min: -2.3984168865435356
  episodes_this_iter: 500
  episodes_total: 40500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1667.88
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.6170380115509033
        entropy_coeff: 0.0
        kl: 0.005055854097008705
        model: {}
        policy_loss: -0.02803698554635048
        total_loss: 0.010770273394882679
        vf_explained_var: 0.5226944088935852
        vf_loss: 0.03823847696185112
    load_time_ms: 2.082
    num_steps_sampled: 40500
    num_steps_trained: 40500
    sample_time_ms: 141642.865
    update_time_ms: 5.519
  iterations_since_restore: 62
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.558091286307054
    ram_util_percent: 13.812863070539418
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 616.3674170177009
    mean_inference_ms: 1.6099038014415468
    mean_processing_ms: 1.2949967337425266
  time_since_restore: 19315.85293364525
  time_this_iter_s: 168.70887851715088
  time_total_s: 27819.858473300934
  timestamp: 1638603416
  timesteps_since_restore: 31000
  timesteps_this_iter: 500
  timesteps_total: 40500
  training_iteration: 81
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     81 |          27819.9 | 40500 | 0.422162 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-40-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8877805486284289
  episode_reward_mean: 0.41605346148973216
  episode_reward_min: -1.330935251798561
  episodes_this_iter: 500
  episodes_total: 41000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1660.095
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.5762070417404175
        entropy_coeff: 0.0
        kl: 0.014536874368786812
        model: {}
        policy_loss: -0.031601086258888245
        total_loss: -0.010594507679343224
        vf_explained_var: 0.6108376383781433
        vf_loss: 0.01937117986381054
    load_time_ms: 2.074
    num_steps_sampled: 41000
    num_steps_trained: 41000
    sample_time_ms: 146374.513
    update_time_ms: 5.51
  iterations_since_restore: 63
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.48560606060606
    ram_util_percent: 13.764015151515151
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 612.3699368244088
    mean_inference_ms: 1.6056897545545041
    mean_processing_ms: 1.2914287503199107
  time_since_restore: 19500.9615585804
  time_this_iter_s: 185.10862493515015
  time_total_s: 28004.967098236084
  timestamp: 1638603601
  timesteps_since_restore: 31500
  timesteps_this_iter: 500
  timesteps_total: 41000
  training_iteration: 82
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     82 |            28005 | 41000 | 0.416053 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-42-36
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9658471956425733
  episode_reward_mean: 0.4287183133111076
  episode_reward_min: -0.3412322274881517
  episodes_this_iter: 500
  episodes_total: 41500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1653.762
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.5831347703933716
        entropy_coeff: 0.0
        kl: 0.01648183912038803
        model: {}
        policy_loss: -0.02644973248243332
        total_loss: -0.006800186820328236
        vf_explained_var: 0.6233202219009399
        vf_loss: 0.017795339226722717
    load_time_ms: 2.063
    num_steps_sampled: 41500
    num_steps_trained: 41500
    sample_time_ms: 149119.121
    update_time_ms: 5.493
  iterations_since_restore: 64
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.29818181818182
    ram_util_percent: 13.75727272727273
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 607.5334760391067
    mean_inference_ms: 1.6006636644154022
    mean_processing_ms: 1.2869212944870205
  time_since_restore: 19655.11706638336
  time_this_iter_s: 154.15550780296326
  time_total_s: 28159.122606039047
  timestamp: 1638603756
  timesteps_since_restore: 32000
  timesteps_this_iter: 500
  timesteps_total: 41500
  training_iteration: 83
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     83 |          28159.1 | 41500 | 0.428718 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-45-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8814285714285715
  episode_reward_mean: 0.42970272820220784
  episode_reward_min: -0.5625
  episodes_this_iter: 500
  episodes_total: 42000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1653.852
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.5446287393569946
        entropy_coeff: 0.0
        kl: 0.012739642523229122
        model: {}
        policy_loss: -0.0219785887748003
        total_loss: -0.0013124197721481323
        vf_explained_var: 0.564598798751831
        vf_loss: 0.01923295296728611
    load_time_ms: 2.065
    num_steps_sampled: 42000
    num_steps_trained: 42000
    sample_time_ms: 149540.443
    update_time_ms: 5.487
  iterations_since_restore: 65
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.651363636363637
    ram_util_percent: 13.798636363636362
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 602.8358928387225
    mean_inference_ms: 1.5959228457995496
    mean_processing_ms: 1.2825095232829788
  time_since_restore: 19809.216938257217
  time_this_iter_s: 154.0998718738556
  time_total_s: 28313.222477912903
  timestamp: 1638603910
  timesteps_since_restore: 32500
  timesteps_this_iter: 500
  timesteps_total: 42000
  training_iteration: 84
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     84 |          28313.2 | 42000 | 0.429703 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-48-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8970831040176115
  episode_reward_mean: 0.4258130993965324
  episode_reward_min: -0.2796208530805687
  episodes_this_iter: 500
  episodes_total: 42500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1656.859
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.5897255539894104
        entropy_coeff: 0.0
        kl: 0.009747780859470367
        model: {}
        policy_loss: -0.015126220881938934
        total_loss: 0.0011279898462817073
        vf_explained_var: 0.6118453145027161
        vf_loss: 0.015157587826251984
    load_time_ms: 2.082
    num_steps_sampled: 42500
    num_steps_trained: 42500
    sample_time_ms: 152576.77
    update_time_ms: 5.451
  iterations_since_restore: 66
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.41417004048583
    ram_util_percent: 13.740485829959512
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 598.861883128832
    mean_inference_ms: 1.5919337918955552
    mean_processing_ms: 1.2784056589677912
  time_since_restore: 19982.39204120636
  time_this_iter_s: 173.17510294914246
  time_total_s: 28486.397580862045
  timestamp: 1638604083
  timesteps_since_restore: 33000
  timesteps_this_iter: 500
  timesteps_total: 42500
  training_iteration: 85
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     85 |          28486.4 | 42500 | 0.425813 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-51-02
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8919949174078781
  episode_reward_mean: 0.4463282342422249
  episode_reward_min: -0.5792682926829268
  episodes_this_iter: 500
  episodes_total: 43000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1639.739
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.5567730069160461
        entropy_coeff: 0.0
        kl: 0.01003421563655138
        model: {}
        policy_loss: -0.02402529865503311
        total_loss: -0.005719393026083708
        vf_explained_var: 0.6019807457923889
        vf_loss: 0.01717706397175789
    load_time_ms: 2.111
    num_steps_sampled: 43000
    num_steps_trained: 43000
    sample_time_ms: 157334.474
    update_time_ms: 5.333
  iterations_since_restore: 67
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.512941176470589
    ram_util_percent: 13.745882352941177
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 595.1601348169945
    mean_inference_ms: 1.5879417938216933
    mean_processing_ms: 1.2747277388241478
  time_since_restore: 20160.80618071556
  time_this_iter_s: 178.41413950920105
  time_total_s: 28664.811720371246
  timestamp: 1638604262
  timesteps_since_restore: 33500
  timesteps_this_iter: 500
  timesteps_total: 43000
  training_iteration: 86
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     86 |          28664.8 | 43000 | 0.446328 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-53-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610271903323263
  episode_reward_mean: 0.40279500557372927
  episode_reward_min: -0.8955223880597015
  episodes_this_iter: 500
  episodes_total: 43500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1628.412
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.5026569962501526
        entropy_coeff: 0.0
        kl: 0.009335881099104881
        model: {}
        policy_loss: -0.026049144566059113
        total_loss: -0.006232861895114183
        vf_explained_var: 0.6130267381668091
        vf_loss: 0.018765993416309357
    load_time_ms: 2.134
    num_steps_sampled: 43500
    num_steps_trained: 43500
    sample_time_ms: 159430.551
    update_time_ms: 5.316
  iterations_since_restore: 68
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.575555555555555
    ram_util_percent: 13.71511111111111
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 590.9587939147868
    mean_inference_ms: 1.583208522671535
    mean_processing_ms: 1.2706534406240644
  time_since_restore: 20318.32161617279
  time_this_iter_s: 157.51543545722961
  time_total_s: 28822.327155828476
  timestamp: 1638604419
  timesteps_since_restore: 34000
  timesteps_this_iter: 500
  timesteps_total: 43500
  training_iteration: 87
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     87 |          28822.3 | 43500 | 0.402795 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-56-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8577832110839446
  episode_reward_mean: 0.43121719186323515
  episode_reward_min: -0.33157894736842103
  episodes_this_iter: 500
  episodes_total: 44000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1621.542
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.5307718515396118
        entropy_coeff: 0.0
        kl: 0.008206445723772049
        model: {}
        policy_loss: -0.01791144534945488
        total_loss: -0.003949813079088926
        vf_explained_var: 0.6980487108230591
        vf_loss: 0.013038401491940022
    load_time_ms: 2.119
    num_steps_sampled: 44000
    num_steps_trained: 44000
    sample_time_ms: 158553.934
    update_time_ms: 5.338
  iterations_since_restore: 69
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.808292682926828
    ram_util_percent: 13.774146341463414
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 586.4722450651407
    mean_inference_ms: 1.5787437084374134
    mean_processing_ms: 1.2663592774226513
  time_since_restore: 20461.79445695877
  time_this_iter_s: 143.47284078598022
  time_total_s: 28965.799996614456
  timestamp: 1638604563
  timesteps_since_restore: 34500
  timesteps_this_iter: 500
  timesteps_total: 44000
  training_iteration: 88
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     88 |          28965.8 | 44000 | 0.431217 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_02-58-17
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.4116695696251391
  episode_reward_min: -0.5078369905956113
  episodes_this_iter: 500
  episodes_total: 44500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1612.06
    learner:
      default_policy:
        cur_kl_coeff: 0.11249999701976776
        cur_lr: 4.999999873689376e-05
        entropy: 0.4853760600090027
        entropy_coeff: 0.0
        kl: 0.004125815816223621
        model: {}
        policy_loss: -0.008535023778676987
        total_loss: 0.007122381124645472
        vf_explained_var: 0.6742647290229797
        vf_loss: 0.015193250961601734
    load_time_ms: 2.146
    num_steps_sampled: 44500
    num_steps_trained: 44500
    sample_time_ms: 158129.915
    update_time_ms: 5.402
  iterations_since_restore: 70
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.637172774869109
    ram_util_percent: 13.715706806282721
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 581.8418280430743
    mean_inference_ms: 1.5743882624558942
    mean_processing_ms: 1.262033167220787
  time_since_restore: 20595.777067899704
  time_this_iter_s: 133.98261094093323
  time_total_s: 29099.78260755539
  timestamp: 1638604697
  timesteps_since_restore: 35000
  timesteps_this_iter: 500
  timesteps_total: 44500
  training_iteration: 89
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     89 |          29099.8 | 44500 |  0.41167 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-00-40
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8611111111111112
  episode_reward_mean: 0.4105594001240652
  episode_reward_min: -0.38974358974358975
  episodes_this_iter: 500
  episodes_total: 45000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1614.0
    learner:
      default_policy:
        cur_kl_coeff: 0.05624999850988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.4756007492542267
        entropy_coeff: 0.0
        kl: 0.010456383228302002
        model: {}
        policy_loss: -0.014577844180166721
        total_loss: 0.004263303242623806
        vf_explained_var: 0.6199434399604797
        vf_loss: 0.01825297623872757
    load_time_ms: 2.162
    num_steps_sampled: 45000
    num_steps_trained: 45000
    sample_time_ms: 157495.774
    update_time_ms: 5.417
  iterations_since_restore: 71
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.529064039408865
    ram_util_percent: 13.737931034482756
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 577.5823945250465
    mean_inference_ms: 1.5701311634801167
    mean_processing_ms: 1.257900130476422
  time_since_restore: 20738.40112400055
  time_this_iter_s: 142.62405610084534
  time_total_s: 29242.406663656235
  timestamp: 1638604840
  timesteps_since_restore: 35500
  timesteps_this_iter: 500
  timesteps_total: 45000
  training_iteration: 90
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     90 |          29242.4 | 45000 | 0.410559 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-02-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8606811145510835
  episode_reward_mean: 0.42907538619314334
  episode_reward_min: -0.44623655913978494
  episodes_this_iter: 500
  episodes_total: 45500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1620.393
    learner:
      default_policy:
        cur_kl_coeff: 0.05624999850988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.4920268952846527
        entropy_coeff: 0.0
        kl: 0.009086860343813896
        model: {}
        policy_loss: -0.016472460702061653
        total_loss: 0.0038177743554115295
        vf_explained_var: 0.6011035442352295
        vf_loss: 0.01977909728884697
    load_time_ms: 2.163
    num_steps_sampled: 45500
    num_steps_trained: 45500
    sample_time_ms: 154291.28
    update_time_ms: 5.424
  iterations_since_restore: 72
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.85357142857143
    ram_util_percent: 13.766836734693877
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 573.2748296001826
    mean_inference_ms: 1.5662034542467005
    mean_processing_ms: 1.2542307666598327
  time_since_restore: 20875.12898850441
  time_this_iter_s: 136.72786450386047
  time_total_s: 29379.134528160095
  timestamp: 1638604976
  timesteps_since_restore: 36000
  timesteps_this_iter: 500
  timesteps_total: 45500
  training_iteration: 91
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     91 |          29379.1 | 45500 | 0.429075 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-05-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721590909090909
  episode_reward_mean: 0.4223855105144661
  episode_reward_min: -1.3333333333333333
  episodes_this_iter: 500
  episodes_total: 46000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1634.581
    learner:
      default_policy:
        cur_kl_coeff: 0.05624999850988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.5171067118644714
        entropy_coeff: 0.0
        kl: 0.011449214071035385
        model: {}
        policy_loss: -0.023775620386004448
        total_loss: -0.005109512712806463
        vf_explained_var: 0.6274376511573792
        vf_loss: 0.0180220827460289
    load_time_ms: 2.18
    num_steps_sampled: 46000
    num_steps_trained: 46000
    sample_time_ms: 150711.399
    update_time_ms: 5.39
  iterations_since_restore: 73
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.459154929577462
    ram_util_percent: 13.810328638497651
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 569.4364896098483
    mean_inference_ms: 1.5623981124887543
    mean_processing_ms: 1.2505212674966943
  time_since_restore: 21024.58071064949
  time_this_iter_s: 149.45172214508057
  time_total_s: 29528.586250305176
  timestamp: 1638605126
  timesteps_since_restore: 36500
  timesteps_this_iter: 500
  timesteps_total: 46000
  training_iteration: 92
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     92 |          29528.6 | 46000 | 0.422386 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-07-33
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8663663663663663
  episode_reward_mean: 0.40775337565093583
  episode_reward_min: -0.4308510638297872
  episodes_this_iter: 500
  episodes_total: 46500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1650.737
    learner:
      default_policy:
        cur_kl_coeff: 0.05624999850988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.5103844404220581
        entropy_coeff: 0.0
        kl: 0.00972664263099432
        model: {}
        policy_loss: -0.02179694175720215
        total_loss: -0.007218898739665747
        vf_explained_var: 0.6797277331352234
        vf_loss: 0.01403091475367546
    load_time_ms: 2.187
    num_steps_sampled: 46500
    num_steps_trained: 46500
    sample_time_ms: 147982.038
    update_time_ms: 5.423
  iterations_since_restore: 74
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.660220994475138
    ram_util_percent: 13.73867403314917
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 565.097290123963
    mean_inference_ms: 1.5580463930064385
    mean_processing_ms: 1.2465926531936566
  time_since_restore: 21151.604433774948
  time_this_iter_s: 127.02372312545776
  time_total_s: 29655.609973430634
  timestamp: 1638605253
  timesteps_since_restore: 37000
  timesteps_this_iter: 500
  timesteps_total: 46500
  training_iteration: 93
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     93 |          29655.6 | 46500 | 0.407753 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-09-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8527397260273972
  episode_reward_mean: 0.42059346792619906
  episode_reward_min: -0.2956521739130435
  episodes_this_iter: 500
  episodes_total: 47000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1635.722
    learner:
      default_policy:
        cur_kl_coeff: 0.05624999850988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.5121859908103943
        entropy_coeff: 0.0
        kl: 0.011124231852591038
        model: {}
        policy_loss: -0.015021017752587795
        total_loss: -0.0013379252050071955
        vf_explained_var: 0.7114096283912659
        vf_loss: 0.013057348318397999
    load_time_ms: 2.189
    num_steps_sampled: 47000
    num_steps_trained: 47000
    sample_time_ms: 144334.609
    update_time_ms: 5.452
  iterations_since_restore: 75
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.735119047619047
    ram_util_percent: 13.797023809523807
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 560.6209292246122
    mean_inference_ms: 1.553566722036257
    mean_processing_ms: 1.242580784088433
  time_since_restore: 21269.081077098846
  time_this_iter_s: 117.47664332389832
  time_total_s: 29773.086616754532
  timestamp: 1638605371
  timesteps_since_restore: 37500
  timesteps_this_iter: 500
  timesteps_total: 47000
  training_iteration: 94
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     94 |          29773.1 | 47000 | 0.420593 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-11-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8629441624365483
  episode_reward_mean: 0.41616198832121215
  episode_reward_min: -0.3417085427135678
  episodes_this_iter: 500
  episodes_total: 47500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1629.6
    learner:
      default_policy:
        cur_kl_coeff: 0.05624999850988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.45981839299201965
        entropy_coeff: 0.0
        kl: 0.015852099284529686
        model: {}
        policy_loss: -0.022958166897296906
        total_loss: -0.00787653960287571
        vf_explained_var: 0.6956239342689514
        vf_loss: 0.014189938083291054
    load_time_ms: 2.204
    num_steps_sampled: 47500
    num_steps_trained: 47500
    sample_time_ms: 137497.782
    update_time_ms: 5.463
  iterations_since_restore: 76
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.843999999999996
    ram_util_percent: 13.780666666666667
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 555.9286218151155
    mean_inference_ms: 1.5492439019059212
    mean_processing_ms: 1.2385705211207052
  time_since_restore: 21373.827425956726
  time_this_iter_s: 104.74634885787964
  time_total_s: 29877.83296561241
  timestamp: 1638605476
  timesteps_since_restore: 38000
  timesteps_this_iter: 500
  timesteps_total: 47500
  training_iteration: 95
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     95 |          29877.8 | 47500 | 0.416162 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-13-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8743424897720631
  episode_reward_mean: 0.41978916069745414
  episode_reward_min: -0.49683544303797467
  episodes_this_iter: 500
  episodes_total: 48000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1624.214
    learner:
      default_policy:
        cur_kl_coeff: 0.05624999850988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.494627982378006
        entropy_coeff: 0.0
        kl: 0.012077247723937035
        model: {}
        policy_loss: -0.025333870202302933
        total_loss: -0.00859946757555008
        vf_explained_var: 0.6442617177963257
        vf_loss: 0.016055045649409294
    load_time_ms: 2.228
    num_steps_sampled: 48000
    num_steps_trained: 48000
    sample_time_ms: 130359.592
    update_time_ms: 5.55
  iterations_since_restore: 77
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.585620915032683
    ram_util_percent: 13.757516339869282
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 551.4132870515878
    mean_inference_ms: 1.5453545911780076
    mean_processing_ms: 1.234851537786556
  time_since_restore: 21480.807458400726
  time_this_iter_s: 106.98003244400024
  time_total_s: 29984.81299805641
  timestamp: 1638605583
  timesteps_since_restore: 38500
  timesteps_this_iter: 500
  timesteps_total: 48000
  training_iteration: 96
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     96 |          29984.8 | 48000 | 0.419789 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-14-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8877805486284289
  episode_reward_mean: 0.4301370401103007
  episode_reward_min: -0.41578947368421054
  episodes_this_iter: 500
  episodes_total: 48500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1624.709
    learner:
      default_policy:
        cur_kl_coeff: 0.05624999850988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.49532926082611084
        entropy_coeff: 0.0
        kl: 0.008267376571893692
        model: {}
        policy_loss: -0.020692238584160805
        total_loss: -0.002141401870176196
        vf_explained_var: 0.5886647701263428
        vf_loss: 0.018085790798068047
    load_time_ms: 2.234
    num_steps_sampled: 48500
    num_steps_trained: 48500
    sample_time_ms: 124458.957
    update_time_ms: 5.592
  iterations_since_restore: 78
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.654285714285717
    ram_util_percent: 13.97357142857143
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 546.7990333583246
    mean_inference_ms: 1.5414980465850905
    mean_processing_ms: 1.2315548107240823
  time_since_restore: 21579.322196483612
  time_this_iter_s: 98.51473808288574
  time_total_s: 30083.327736139297
  timestamp: 1638605681
  timesteps_since_restore: 39000
  timesteps_this_iter: 500
  timesteps_total: 48500
  training_iteration: 97
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     97 |          30083.3 | 48500 | 0.430137 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-15-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8752351097178683
  episode_reward_mean: 0.4192029768351874
  episode_reward_min: -0.38071065989847713
  episodes_this_iter: 500
  episodes_total: 49000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1634.068
    learner:
      default_policy:
        cur_kl_coeff: 0.05624999850988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.4335610866546631
        entropy_coeff: 0.0
        kl: 0.014596998691558838
        model: {}
        policy_loss: -0.02427997998893261
        total_loss: -0.007702948525547981
        vf_explained_var: 0.6495110392570496
        vf_loss: 0.015755951404571533
    load_time_ms: 2.233
    num_steps_sampled: 49000
    num_steps_trained: 49000
    sample_time_ms: 117193.071
    update_time_ms: 5.596
  iterations_since_restore: 79
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.854901960784312
    ram_util_percent: 13.923529411764708
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 541.6016926756629
    mean_inference_ms: 1.5370893778974437
    mean_processing_ms: 1.2276300837494405
  time_since_restore: 21650.229656934738
  time_this_iter_s: 70.9074604511261
  time_total_s: 30154.235196590424
  timestamp: 1638605752
  timesteps_since_restore: 39500
  timesteps_this_iter: 500
  timesteps_total: 49000
  training_iteration: 98
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     98 |          30154.2 | 49000 | 0.419203 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-17-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9673192992786692
  episode_reward_mean: 0.4291819270489971
  episode_reward_min: -1.3333333333333333
  episodes_this_iter: 500
  episodes_total: 49500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1646.27
    learner:
      default_policy:
        cur_kl_coeff: 0.05624999850988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.43772339820861816
        entropy_coeff: 0.0
        kl: 0.007219924125820398
        model: {}
        policy_loss: -0.02327059768140316
        total_loss: 0.004342094529420137
        vf_explained_var: 0.5639132261276245
        vf_loss: 0.027206575497984886
    load_time_ms: 2.176
    num_steps_sampled: 49500
    num_steps_trained: 49500
    sample_time_ms: 112151.166
    update_time_ms: 5.538
  iterations_since_restore: 80
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.510084033613447
    ram_util_percent: 13.808403361344538
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 536.851917105059
    mean_inference_ms: 1.5328949664384763
    mean_processing_ms: 1.2238361529059918
  time_since_restore: 21733.914813756943
  time_this_iter_s: 83.68515682220459
  time_total_s: 30237.920353412628
  timestamp: 1638605836
  timesteps_since_restore: 40000
  timesteps_this_iter: 500
  timesteps_total: 49500
  training_iteration: 99
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |     99 |          30237.9 | 49500 | 0.429182 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-18-27
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8970831040176115
  episode_reward_mean: 0.437559841057889
  episode_reward_min: -0.39067055393586003
  episodes_this_iter: 500
  episodes_total: 50000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1639.341
    learner:
      default_policy:
        cur_kl_coeff: 0.05624999850988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.4493867754936218
        entropy_coeff: 0.0
        kl: 0.005220485385507345
        model: {}
        policy_loss: -0.015590445138514042
        total_loss: 0.0037789822090417147
        vf_explained_var: 0.5784817934036255
        vf_loss: 0.019075771793723106
    load_time_ms: 2.2
    num_steps_sampled: 50000
    num_steps_trained: 50000
    sample_time_ms: 105013.785
    update_time_ms: 5.559
  iterations_since_restore: 81
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.648039215686277
    ram_util_percent: 13.788235294117648
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 531.9135748708115
    mean_inference_ms: 1.5284815958018882
    mean_processing_ms: 1.2198688807256377
  time_since_restore: 21805.0965385437
  time_this_iter_s: 71.18172478675842
  time_total_s: 30309.102078199387
  timestamp: 1638605907
  timesteps_since_restore: 40500
  timesteps_this_iter: 500
  timesteps_total: 50000
  training_iteration: 100
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    100 |          30309.1 | 50000 |  0.43756 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-19-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8831003811944091
  episode_reward_mean: 0.4435420168604959
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 50500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1624.905
    learner:
      default_policy:
        cur_kl_coeff: 0.05624999850988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.4773646891117096
        entropy_coeff: 0.0
        kl: 0.008542483672499657
        model: {}
        policy_loss: -0.02271064929664135
        total_loss: -0.007778172381222248
        vf_explained_var: 0.626731812953949
        vf_loss: 0.014451964758336544
    load_time_ms: 2.21
    num_steps_sampled: 50500
    num_steps_trained: 50500
    sample_time_ms: 99288.684
    update_time_ms: 5.55
  iterations_since_restore: 82
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.437168141592919
    ram_util_percent: 13.791150442477875
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 527.294118085555
    mean_inference_ms: 1.5244762483641785
    mean_processing_ms: 1.2160498544485472
  time_since_restore: 21884.430154561996
  time_this_iter_s: 79.33361601829529
  time_total_s: 30388.435694217682
  timestamp: 1638605987
  timesteps_since_restore: 41000
  timesteps_this_iter: 500
  timesteps_total: 50500
  training_iteration: 101
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    101 |          30388.4 | 50500 | 0.443542 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-20-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8588957055214724
  episode_reward_mean: 0.4195653020815372
  episode_reward_min: -0.5792682926829268
  episodes_this_iter: 500
  episodes_total: 51000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1608.858
    learner:
      default_policy:
        cur_kl_coeff: 0.05624999850988388
        cur_lr: 4.999999873689376e-05
        entropy: 0.5059259533882141
        entropy_coeff: 0.0
        kl: 0.020900359377264977
        model: {}
        policy_loss: -0.029529213905334473
        total_loss: -0.01119787897914648
        vf_explained_var: 0.6224015951156616
        vf_loss: 0.017155690118670464
    load_time_ms: 2.228
    num_steps_sampled: 51000
    num_steps_trained: 51000
    sample_time_ms: 90641.857
    update_time_ms: 5.537
  iterations_since_restore: 83
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.508888888888889
    ram_util_percent: 13.947777777777777
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 522.3908843869132
    mean_inference_ms: 1.520258332300737
    mean_processing_ms: 1.212519613082936
  time_since_restore: 21947.253002405167
  time_this_iter_s: 62.822847843170166
  time_total_s: 30451.258542060852
  timestamp: 1638606050
  timesteps_since_restore: 41500
  timesteps_this_iter: 500
  timesteps_total: 51000
  training_iteration: 102
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    102 |          30451.3 | 51000 | 0.419565 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-21-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8577832110839446
  episode_reward_mean: 0.3800128851173063
  episode_reward_min: -3.9618320610687023
  episodes_this_iter: 500
  episodes_total: 51500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1614.099
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4702799618244171
        entropy_coeff: 0.0
        kl: 0.009687098674476147
        model: {}
        policy_loss: -0.03856859728693962
        total_loss: 0.044028107076883316
        vf_explained_var: 0.38505271077156067
        vf_loss: 0.08177933841943741
    load_time_ms: 2.234
    num_steps_sampled: 51500
    num_steps_trained: 51500
    sample_time_ms: 83836.777
    update_time_ms: 5.521
  iterations_since_restore: 84
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.395238095238096
    ram_util_percent: 13.891666666666667
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 517.5098284508869
    mean_inference_ms: 1.5160905977382062
    mean_processing_ms: 1.2087096958165398
  time_since_restore: 22006.27827644348
  time_this_iter_s: 59.02527403831482
  time_total_s: 30510.283816099167
  timestamp: 1638606109
  timesteps_since_restore: 42000
  timesteps_this_iter: 500
  timesteps_total: 51500
  training_iteration: 103
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    103 |          30510.3 | 51500 | 0.380013 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-22-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8708333333333333
  episode_reward_mean: 0.4243158840578518
  episode_reward_min: -0.5078369905956113
  episodes_this_iter: 500
  episodes_total: 52000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1627.828
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4983786344528198
        entropy_coeff: 0.0
        kl: 0.011188472621142864
        model: {}
        policy_loss: -0.027129190042614937
        total_loss: -0.011728210374712944
        vf_explained_var: 0.6755333542823792
        vf_loss: 0.014456945471465588
    load_time_ms: 2.224
    num_steps_sampled: 52000
    num_steps_trained: 52000
    sample_time_ms: 78090.518
    update_time_ms: 5.488
  iterations_since_restore: 85
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.747674418604651
    ram_util_percent: 13.802325581395351
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 512.7686304343858
    mean_inference_ms: 1.5123291847658216
    mean_processing_ms: 1.2052449273299068
  time_since_restore: 22066.42874979973
  time_this_iter_s: 60.15047335624695
  time_total_s: 30570.434289455414
  timestamp: 1638606169
  timesteps_since_restore: 42500
  timesteps_this_iter: 500
  timesteps_total: 52000
  training_iteration: 104
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    104 |          30570.4 | 52000 | 0.424316 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-23-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.40867387724841786
  episode_reward_min: -0.3056872037914692
  episodes_this_iter: 500
  episodes_total: 52500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1627.396
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.5225209593772888
        entropy_coeff: 0.0
        kl: 0.007649310864508152
        model: {}
        policy_loss: -0.018334560096263885
        total_loss: 0.00043122886563651264
        vf_explained_var: 0.5862505435943604
        vf_loss: 0.01812037266790867
    load_time_ms: 2.212
    num_steps_sampled: 52500
    num_steps_trained: 52500
    sample_time_ms: 73737.861
    update_time_ms: 5.481
  iterations_since_restore: 86
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.525
    ram_util_percent: 13.835227272727273
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 508.16705412583144
    mean_inference_ms: 1.5084026486415487
    mean_processing_ms: 1.2018461398852598
  time_since_restore: 22127.717179059982
  time_this_iter_s: 61.288429260253906
  time_total_s: 30631.722718715668
  timestamp: 1638606231
  timesteps_since_restore: 43000
  timesteps_this_iter: 500
  timesteps_total: 52500
  training_iteration: 105
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    105 |          30631.7 | 52500 | 0.408674 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-24-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8603628367234745
  episode_reward_mean: 0.42361510546514075
  episode_reward_min: -0.38974358974358975
  episodes_this_iter: 500
  episodes_total: 53000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1622.796
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.43822625279426575
        entropy_coeff: 0.0
        kl: 0.008481785655021667
        model: {}
        policy_loss: -0.012076497077941895
        total_loss: 0.005083420313894749
        vf_explained_var: 0.626422643661499
        vf_loss: 0.016444267705082893
    load_time_ms: 2.184
    num_steps_sampled: 53000
    num_steps_trained: 53000
    sample_time_ms: 69064.751
    update_time_ms: 5.514
  iterations_since_restore: 87
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.588372093023255
    ram_util_percent: 13.890697674418606
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 503.6468808561797
    mean_inference_ms: 1.5045653671805186
    mean_processing_ms: 1.1984574400428545
  time_since_restore: 22187.919939756393
  time_this_iter_s: 60.20276069641113
  time_total_s: 30691.92547941208
  timestamp: 1638606291
  timesteps_since_restore: 43500
  timesteps_this_iter: 500
  timesteps_total: 53000
  training_iteration: 106
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    106 |          30691.9 | 53000 | 0.423615 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-25-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721590909090909
  episode_reward_mean: 0.42152501946402493
  episode_reward_min: -0.8121546961325967
  episodes_this_iter: 500
  episodes_total: 53500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1628.248
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4207991063594818
        entropy_coeff: 0.0
        kl: 0.007606044411659241
        model: {}
        policy_loss: -0.023424344137310982
        total_loss: -0.0004326677299104631
        vf_explained_var: 0.560880184173584
        vf_loss: 0.022349918261170387
    load_time_ms: 2.206
    num_steps_sampled: 53500
    num_steps_trained: 53500
    sample_time_ms: 65089.932
    update_time_ms: 5.49
  iterations_since_restore: 88
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.31190476190476
    ram_util_percent: 14.004761904761907
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 499.197818688871
    mean_inference_ms: 1.5009133908583958
    mean_processing_ms: 1.1953638915606426
  time_since_restore: 22246.74133014679
  time_this_iter_s: 58.82139039039612
  time_total_s: 30750.746869802475
  timestamp: 1638606350
  timesteps_since_restore: 44000
  timesteps_this_iter: 500
  timesteps_total: 53500
  training_iteration: 107
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    107 |          30750.7 | 53500 | 0.421525 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-26-54
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8732193732193733
  episode_reward_mean: 0.42264773294197966
  episode_reward_min: -0.39285714285714285
  episodes_this_iter: 500
  episodes_total: 54000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1636.899
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.47049838304519653
        entropy_coeff: 0.0
        kl: 0.013217481784522533
        model: {}
        policy_loss: -0.024063946679234505
        total_loss: -0.00875302217900753
        vf_explained_var: 0.6750063300132751
        vf_loss: 0.014195705763995647
    load_time_ms: 2.246
    num_steps_sampled: 54000
    num_steps_trained: 54000
    sample_time_ms: 64381.284
    update_time_ms: 5.514
  iterations_since_restore: 89
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.569565217391302
    ram_util_percent: 13.833695652173914
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 494.9596835876811
    mean_inference_ms: 1.4976252947187736
    mean_processing_ms: 1.1924926314374624
  time_since_restore: 22310.650042533875
  time_this_iter_s: 63.90871238708496
  time_total_s: 30814.65558218956
  timestamp: 1638606414
  timesteps_since_restore: 44500
  timesteps_this_iter: 500
  timesteps_total: 54000
  training_iteration: 108
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    108 |          30814.7 | 54000 | 0.422648 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-27-58
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647058823529412
  episode_reward_mean: 0.41608468071615423
  episode_reward_min: -0.4088397790055249
  episodes_this_iter: 500
  episodes_total: 54500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1634.593
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4631625711917877
        entropy_coeff: 0.0
        kl: 0.013496404513716698
        model: {}
        policy_loss: -0.024630971252918243
        total_loss: -0.010821822099387646
        vf_explained_var: 0.7125868797302246
        vf_loss: 0.012670386582612991
    load_time_ms: 2.251
    num_steps_sampled: 54500
    num_steps_trained: 54500
    sample_time_ms: 62364.103
    update_time_ms: 5.547
  iterations_since_restore: 90
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.18666666666667
    ram_util_percent: 13.826666666666668
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 490.8080955274461
    mean_inference_ms: 1.4941045139708027
    mean_processing_ms: 1.1893314392428243
  time_since_restore: 22374.14078760147
  time_this_iter_s: 63.490745067596436
  time_total_s: 30878.146327257156
  timestamp: 1638606478
  timesteps_since_restore: 45000
  timesteps_this_iter: 500
  timesteps_total: 54500
  training_iteration: 109
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    109 |          30878.1 | 54500 | 0.416085 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-28-58
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8578767123287672
  episode_reward_mean: 0.4106391257834457
  episode_reward_min: -0.2956521739130435
  episodes_this_iter: 500
  episodes_total: 55000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1630.7
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4076988101005554
        entropy_coeff: 0.0
        kl: 0.019582994282245636
        model: {}
        policy_loss: -0.02735453099012375
        total_loss: -0.01091772597283125
        vf_explained_var: 0.6927550435066223
        vf_loss: 0.014784487895667553
    load_time_ms: 2.23
    num_steps_sampled: 55000
    num_steps_trained: 55000
    sample_time_ms: 61242.297
    update_time_ms: 5.523
  iterations_since_restore: 91
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.861627906976743
    ram_util_percent: 13.870930232558141
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 486.6718753835993
    mean_inference_ms: 1.490637123269046
    mean_processing_ms: 1.1861011333846618
  time_since_restore: 22434.064975500107
  time_this_iter_s: 59.924187898635864
  time_total_s: 30938.070515155792
  timestamp: 1638606538
  timesteps_since_restore: 45500
  timesteps_this_iter: 500
  timesteps_total: 55000
  training_iteration: 110
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    110 |          30938.1 | 55000 | 0.410639 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-29-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8683473389355743
  episode_reward_mean: 0.41825113520009966
  episode_reward_min: -1.0340557275541795
  episodes_this_iter: 500
  episodes_total: 55500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1640.485
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4598516523838043
        entropy_coeff: 0.0
        kl: 0.009047762490808964
        model: {}
        policy_loss: -0.023439381271600723
        total_loss: -0.005233317147940397
        vf_explained_var: 0.6507684588432312
        vf_loss: 0.01744265854358673
    load_time_ms: 2.242
    num_steps_sampled: 55500
    num_steps_trained: 55500
    sample_time_ms: 59250.807
    update_time_ms: 5.537
  iterations_since_restore: 92
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.563529411764707
    ram_util_percent: 13.821176470588238
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 482.6139365094415
    mean_inference_ms: 1.4870753275519104
    mean_processing_ms: 1.1829500734690739
  time_since_restore: 22493.580889463425
  time_this_iter_s: 59.51591396331787
  time_total_s: 30997.58642911911
  timestamp: 1638606597
  timesteps_since_restore: 46000
  timesteps_this_iter: 500
  timesteps_total: 55500
  training_iteration: 111
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    111 |          30997.6 | 55500 | 0.418251 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-30-42
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8743424897720631
  episode_reward_mean: 0.43752654883400155
  episode_reward_min: -1.3028169014084507
  episodes_this_iter: 500
  episodes_total: 56000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1654.647
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4353926479816437
        entropy_coeff: 0.0
        kl: 0.010542374104261398
        model: {}
        policy_loss: -0.02480345033109188
        total_loss: -0.004597301594913006
        vf_explained_var: 0.6308649182319641
        vf_loss: 0.01931663788855076
    load_time_ms: 2.216
    num_steps_sampled: 56000
    num_steps_trained: 56000
    sample_time_ms: 57410.479
    update_time_ms: 5.591
  iterations_since_restore: 93
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.1265625
    ram_util_percent: 13.935937500000001
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 478.3230513229809
    mean_inference_ms: 1.4835557758991438
    mean_processing_ms: 1.179857799149142
  time_since_restore: 22538.142698526382
  time_this_iter_s: 44.561809062957764
  time_total_s: 31042.148238182068
  timestamp: 1638606642
  timesteps_since_restore: 46500
  timesteps_this_iter: 500
  timesteps_total: 56000
  training_iteration: 112
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    112 |          31042.1 | 56000 | 0.437527 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-31-29
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8877805486284289
  episode_reward_mean: 0.41999531292879294
  episode_reward_min: -0.23008849557522124
  episodes_this_iter: 500
  episodes_total: 56500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1650.682
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4045116901397705
        entropy_coeff: 0.0
        kl: 0.008757148869335651
        model: {}
        policy_loss: -0.018603753298521042
        total_loss: -0.0011928192107006907
        vf_explained_var: 0.6060731410980225
        vf_loss: 0.016672056168317795
    load_time_ms: 2.195
    num_steps_sampled: 56500
    num_steps_trained: 56500
    sample_time_ms: 56230.822
    update_time_ms: 5.512
  iterations_since_restore: 94
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.898507462686569
    ram_util_percent: 13.870149253731347
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 474.1785620727963
    mean_inference_ms: 1.4804651507879634
    mean_processing_ms: 1.1769963290822711
  time_since_restore: 22585.33024096489
  time_this_iter_s: 47.18754243850708
  time_total_s: 31089.335780620575
  timestamp: 1638606689
  timesteps_since_restore: 47000
  timesteps_this_iter: 500
  timesteps_total: 56500
  training_iteration: 113
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    113 |          31089.3 | 56500 | 0.419995 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-32-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9661416163697925
  episode_reward_mean: 0.42687394231447395
  episode_reward_min: -0.38071065989847713
  episodes_this_iter: 500
  episodes_total: 57000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1635.056
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4747384786605835
        entropy_coeff: 0.0
        kl: 0.015600377693772316
        model: {}
        policy_loss: -0.03384271264076233
        total_loss: -0.016420939937233925
        vf_explained_var: 0.6902509331703186
        vf_loss: 0.016105489805340767
    load_time_ms: 2.207
    num_steps_sampled: 57000
    num_steps_trained: 57000
    sample_time_ms: 54916.259
    update_time_ms: 5.547
  iterations_since_restore: 95
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.865671641791042
    ram_util_percent: 13.970149253731343
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 470.11525122853993
    mean_inference_ms: 1.4776629459601707
    mean_processing_ms: 1.1745898618850905
  time_since_restore: 22632.179952144623
  time_this_iter_s: 46.849711179733276
  time_total_s: 31136.18549180031
  timestamp: 1638606736
  timesteps_since_restore: 47500
  timesteps_this_iter: 500
  timesteps_total: 57000
  training_iteration: 114
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    114 |          31136.2 | 57000 | 0.426874 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-33-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8842767295597485
  episode_reward_mean: 0.42519467983217507
  episode_reward_min: -1.4803921568627452
  episodes_this_iter: 500
  episodes_total: 57500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1640.378
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3643510043621063
        entropy_coeff: 0.0
        kl: 0.009570902213454247
        model: {}
        policy_loss: -0.02959728054702282
        total_loss: 0.002435217145830393
        vf_explained_var: 0.49287405610084534
        vf_loss: 0.031224951148033142
    load_time_ms: 2.185
    num_steps_sampled: 57500
    num_steps_trained: 57500
    sample_time_ms: 54189.14
    update_time_ms: 5.422
  iterations_since_restore: 96
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.042307692307691
    ram_util_percent: 13.962820512820514
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 466.2849995094609
    mean_inference_ms: 1.4750344418343926
    mean_processing_ms: 1.1721836005927886
  time_since_restore: 22686.17532992363
  time_this_iter_s: 53.99537777900696
  time_total_s: 31190.180869579315
  timestamp: 1638606790
  timesteps_since_restore: 48000
  timesteps_this_iter: 500
  timesteps_total: 57500
  training_iteration: 115
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    115 |          31190.2 | 57500 | 0.425195 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-33-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8970831040176115
  episode_reward_mean: 0.43046053180359106
  episode_reward_min: -1.1533333333333333
  episodes_this_iter: 500
  episodes_total: 58000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1647.587
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.42607882618904114
        entropy_coeff: 0.0
        kl: 0.008121985010802746
        model: {}
        policy_loss: -0.023310314863920212
        total_loss: 0.00046237825881689787
        vf_explained_var: 0.5512926578521729
        vf_loss: 0.023087400943040848
    load_time_ms: 2.185
    num_steps_sampled: 58000
    num_steps_trained: 58000
    sample_time_ms: 52662.208
    update_time_ms: 5.353
  iterations_since_restore: 97
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.6984375
    ram_util_percent: 13.9109375
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 462.34848604937457
    mean_inference_ms: 1.4715729387801288
    mean_processing_ms: 1.1691376709750758
  time_since_restore: 22731.17955994606
  time_this_iter_s: 45.00423002243042
  time_total_s: 31235.185099601746
  timestamp: 1638606836
  timesteps_since_restore: 48500
  timesteps_this_iter: 500
  timesteps_total: 58000
  training_iteration: 116
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    116 |          31235.2 | 58000 | 0.430461 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-34-48
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8879781420765027
  episode_reward_mean: 0.4386353396033602
  episode_reward_min: -0.5792682926829268
  episodes_this_iter: 500
  episodes_total: 58500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1663.309
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4066435992717743
        entropy_coeff: 0.0
        kl: 0.008443182334303856
        model: {}
        policy_loss: -0.01668880134820938
        total_loss: 0.0002856528735719621
        vf_explained_var: 0.6269410252571106
        vf_loss: 0.01626206561923027
    load_time_ms: 2.136
    num_steps_sampled: 58500
    num_steps_trained: 58500
    sample_time_ms: 52032.277
    update_time_ms: 5.369
  iterations_since_restore: 98
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.759999999999996
    ram_util_percent: 13.793333333333337
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 458.6469868743097
    mean_inference_ms: 1.4683189655999231
    mean_processing_ms: 1.166217894104655
  time_since_restore: 22783.858394622803
  time_this_iter_s: 52.678834676742554
  time_total_s: 31287.863934278488
  timestamp: 1638606888
  timesteps_since_restore: 49000
  timesteps_this_iter: 500
  timesteps_total: 58500
  training_iteration: 117
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    117 |          31287.9 | 58500 | 0.438635 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-35-30
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8588957055214724
  episode_reward_mean: 0.4194124311943794
  episode_reward_min: -0.5573770491803278
  episodes_this_iter: 500
  episodes_total: 59000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1664.096
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3783048987388611
        entropy_coeff: 0.0
        kl: 0.013541702181100845
        model: {}
        policy_loss: -0.02395845577120781
        total_loss: -0.005370864644646645
        vf_explained_var: 0.5999876856803894
        vf_loss: 0.017445001751184464
    load_time_ms: 2.118
    num_steps_sampled: 59000
    num_steps_trained: 59000
    sample_time_ms: 49767.391
    update_time_ms: 5.425
  iterations_since_restore: 99
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.084745762711865
    ram_util_percent: 14.184745762711866
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 454.79050149041205
    mean_inference_ms: 1.4649816783822491
    mean_processing_ms: 1.1631999795397028
  time_since_restore: 22825.126560926437
  time_this_iter_s: 41.268166303634644
  time_total_s: 31329.132100582123
  timestamp: 1638606930
  timesteps_since_restore: 49500
  timesteps_this_iter: 500
  timesteps_total: 59000
  training_iteration: 118
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    118 |          31329.1 | 59000 | 0.419412 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-36-24
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8660068519223448
  episode_reward_mean: 0.41249628566077473
  episode_reward_min: -1.6107142857142858
  episodes_this_iter: 500
  episodes_total: 59500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1658.732
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.41902607679367065
        entropy_coeff: 0.0
        kl: 0.008751719258725643
        model: {}
        policy_loss: -0.0345463789999485
        total_loss: -0.012089473195374012
        vf_explained_var: 0.6542984247207642
        vf_loss: 0.021718479692935944
    load_time_ms: 2.121
    num_steps_sampled: 59500
    num_steps_trained: 59500
    sample_time_ms: 48841.239
    update_time_ms: 5.385
  iterations_since_restore: 100
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.594871794871793
    ram_util_percent: 13.82179487179487
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 451.27092042719534
    mean_inference_ms: 1.4618942469173075
    mean_processing_ms: 1.1605080913365864
  time_since_restore: 22879.301584005356
  time_this_iter_s: 54.17502307891846
  time_total_s: 31383.30712366104
  timestamp: 1638606984
  timesteps_since_restore: 50000
  timesteps_this_iter: 500
  timesteps_total: 59500
  training_iteration: 119
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    119 |          31383.3 | 59500 | 0.412496 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-37-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8736517719568567
  episode_reward_mean: 0.4103580822484912
  episode_reward_min: -0.7154811715481172
  episodes_this_iter: 500
  episodes_total: 60000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1665.694
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.40517449378967285
        entropy_coeff: 0.0
        kl: 0.006267013493925333
        model: {}
        policy_loss: -0.017877018079161644
        total_loss: -0.0001956638734554872
        vf_explained_var: 0.6630827188491821
        vf_loss: 0.0171525701880455
    load_time_ms: 2.111
    num_steps_sampled: 60000
    num_steps_trained: 60000
    sample_time_ms: 46771.382
    update_time_ms: 5.373
  iterations_since_restore: 101
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.45892857142857
    ram_util_percent: 13.81607142857143
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 447.5265759736821
    mean_inference_ms: 1.4586256805291207
    mean_processing_ms: 1.1576612511095852
  time_since_restore: 22918.596383333206
  time_this_iter_s: 39.29479932785034
  time_total_s: 31422.60192298889
  timestamp: 1638607024
  timesteps_since_restore: 50500
  timesteps_this_iter: 500
  timesteps_total: 60000
  training_iteration: 120
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    120 |          31422.6 | 60000 | 0.410358 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-37-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8583333333333333
  episode_reward_mean: 0.42084246973289724
  episode_reward_min: -1.132686084142395
  episodes_this_iter: 500
  episodes_total: 60500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1650.155
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4486742913722992
        entropy_coeff: 0.0
        kl: 0.015385356731712818
        model: {}
        policy_loss: -0.022588694468140602
        total_loss: -0.0015395426889881492
        vf_explained_var: 0.6341614723205566
        vf_loss: 0.019751012325286865
    load_time_ms: 2.109
    num_steps_sampled: 60500
    num_steps_trained: 60500
    sample_time_ms: 45364.084
    update_time_ms: 5.326
  iterations_since_restore: 102
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.68769230769231
    ram_util_percent: 13.872307692307693
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 443.97459717624866
    mean_inference_ms: 1.4555951417262634
    mean_processing_ms: 1.1548948288898824
  time_since_restore: 22963.88326525688
  time_this_iter_s: 45.28688192367554
  time_total_s: 31467.888804912567
  timestamp: 1638607069
  timesteps_since_restore: 51000
  timesteps_this_iter: 500
  timesteps_total: 60500
  training_iteration: 121
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    121 |          31467.9 | 60500 | 0.420842 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-38-36
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8605341246290801
  episode_reward_mean: 0.4300560336345281
  episode_reward_min: -0.44623655913978494
  episodes_this_iter: 500
  episodes_total: 61000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1643.827
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4218810796737671
        entropy_coeff: 0.0
        kl: 0.009804298169910908
        model: {}
        policy_loss: -0.015421225689351559
        total_loss: 0.005637196358293295
        vf_explained_var: 0.5966710448265076
        vf_loss: 0.02023118920624256
    load_time_ms: 2.136
    num_steps_sampled: 61000
    num_steps_trained: 61000
    sample_time_ms: 45560.844
    update_time_ms: 5.344
  iterations_since_restore: 103
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.577272727272728
    ram_util_percent: 13.896969696969698
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 440.5138416013999
    mean_inference_ms: 1.4526539178860376
    mean_processing_ms: 1.1522496654668788
  time_since_restore: 23010.34920167923
  time_this_iter_s: 46.46593642234802
  time_total_s: 31514.354741334915
  timestamp: 1638607116
  timesteps_since_restore: 51500
  timesteps_this_iter: 500
  timesteps_total: 61000
  training_iteration: 122
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    122 |          31514.4 | 61000 | 0.430056 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-39-21
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721590909090909
  episode_reward_mean: 0.41860892286235585
  episode_reward_min: -0.49473684210526314
  episodes_this_iter: 500
  episodes_total: 61500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1658.984
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.42817801237106323
        entropy_coeff: 0.0
        kl: 0.010289035737514496
        model: {}
        policy_loss: -0.020656026899814606
        total_loss: -0.004031448159366846
        vf_explained_var: 0.5795084238052368
        vf_loss: 0.015756450593471527
    load_time_ms: 2.133
    num_steps_sampled: 61500
    num_steps_trained: 61500
    sample_time_ms: 45322.461
    update_time_ms: 5.363
  iterations_since_restore: 104
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.066153846153846
    ram_util_percent: 14.06
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 437.0860014165177
    mean_inference_ms: 1.4499811132981988
    mean_processing_ms: 1.1497304012279292
  time_since_restore: 23055.30755996704
  time_this_iter_s: 44.95835828781128
  time_total_s: 31559.313099622726
  timestamp: 1638607161
  timesteps_since_restore: 52000
  timesteps_this_iter: 500
  timesteps_total: 61500
  training_iteration: 123
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    123 |          31559.3 | 61500 | 0.418609 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-40-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8732193732193733
  episode_reward_mean: 0.4069513198203647
  episode_reward_min: -0.4308510638297872
  episodes_this_iter: 500
  episodes_total: 62000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1652.08
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.464839905500412
        entropy_coeff: 0.0
        kl: 0.01103212870657444
        model: {}
        policy_loss: -0.029823075979948044
        total_loss: -0.01493832003325224
        vf_explained_var: 0.7170522212982178
        vf_loss: 0.013953916728496552
    load_time_ms: 2.142
    num_steps_sampled: 62000
    num_steps_trained: 62000
    sample_time_ms: 46757.063
    update_time_ms: 5.295
  iterations_since_restore: 105
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.394252873563218
    ram_util_percent: 13.817241379310346
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 434.0368122312559
    mean_inference_ms: 1.447415933597928
    mean_processing_ms: 1.1474912192616649
  time_since_restore: 23116.432940721512
  time_this_iter_s: 61.125380754470825
  time_total_s: 31620.438480377197
  timestamp: 1638607222
  timesteps_since_restore: 52500
  timesteps_this_iter: 500
  timesteps_total: 62000
  training_iteration: 124
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    124 |          31620.4 | 62000 | 0.406951 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-41-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8632352941176471
  episode_reward_mean: 0.4310830513792995
  episode_reward_min: -0.2956521739130435
  episodes_this_iter: 500
  episodes_total: 62500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1649.164
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.47667407989501953
        entropy_coeff: 0.0
        kl: 0.013647913932800293
        model: {}
        policy_loss: -0.024540381506085396
        total_loss: -0.011615417897701263
        vf_explained_var: 0.7219973206520081
        vf_loss: 0.01177341677248478
    load_time_ms: 2.173
    num_steps_sampled: 62500
    num_steps_trained: 62500
    sample_time_ms: 46560.454
    update_time_ms: 5.418
  iterations_since_restore: 106
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.088
    ram_util_percent: 13.82666666666667
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 430.87239602910273
    mean_inference_ms: 1.44468594743599
    mean_processing_ms: 1.1449358678804684
  time_since_restore: 23168.43460559845
  time_this_iter_s: 52.001664876937866
  time_total_s: 31672.440145254135
  timestamp: 1638607274
  timesteps_since_restore: 53000
  timesteps_this_iter: 500
  timesteps_total: 62500
  training_iteration: 125
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    125 |          31672.4 | 62500 | 0.431083 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-41-59
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8517786561264822
  episode_reward_mean: 0.41218038961984427
  episode_reward_min: -0.29901960784313725
  episodes_this_iter: 500
  episodes_total: 63000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1658.87
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.44557636976242065
        entropy_coeff: 0.0
        kl: 0.016513144597411156
        model: {}
        policy_loss: -0.024645263329148293
        total_loss: -0.008687479421496391
        vf_explained_var: 0.6886227130889893
        vf_loss: 0.014564498327672482
    load_time_ms: 2.169
    num_steps_sampled: 63000
    num_steps_trained: 63000
    sample_time_ms: 46551.41
    update_time_ms: 5.437
  iterations_since_restore: 107
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.8046875
    ram_util_percent: 13.8640625
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 427.6329403968506
    mean_inference_ms: 1.4418479413692622
    mean_processing_ms: 1.1424904896725856
  time_since_restore: 23213.445992708206
  time_this_iter_s: 45.01138710975647
  time_total_s: 31717.45153236389
  timestamp: 1638607319
  timesteps_since_restore: 53500
  timesteps_this_iter: 500
  timesteps_total: 63000
  training_iteration: 126
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    126 |          31717.5 | 63000 |  0.41218 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-43-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8683473389355743
  episode_reward_mean: 0.40251658005370233
  episode_reward_min: -3.9808429118773945
  episodes_this_iter: 500
  episodes_total: 63500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1640.174
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.48138076066970825
        entropy_coeff: 0.0
        kl: 0.013191916048526764
        model: {}
        policy_loss: -0.029105519875884056
        total_loss: 0.041518259793519974
        vf_explained_var: 0.3906562328338623
        vf_loss: 0.06951072067022324
    load_time_ms: 2.168
    num_steps_sampled: 63500
    num_steps_trained: 63500
    sample_time_ms: 47712.879
    update_time_ms: 5.422
  iterations_since_restore: 108
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.633695652173913
    ram_util_percent: 13.845652173913045
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 424.8101058106686
    mean_inference_ms: 1.4393970689557922
    mean_processing_ms: 1.1403434676277744
  time_since_restore: 23277.552842378616
  time_this_iter_s: 64.10684967041016
  time_total_s: 31781.5583820343
  timestamp: 1638607384
  timesteps_since_restore: 54000
  timesteps_this_iter: 500
  timesteps_total: 63500
  training_iteration: 127
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    127 |          31781.6 | 63500 | 0.402517 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-43-59
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.885286783042394
  episode_reward_mean: 0.42885189037425214
  episode_reward_min: -1.330935251798561
  episodes_this_iter: 500
  episodes_total: 64000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1648.17
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.5089089870452881
        entropy_coeff: 0.0
        kl: 0.011662482284009457
        model: {}
        policy_loss: -0.018013665452599525
        total_loss: 0.004148353822529316
        vf_explained_var: 0.5978109240531921
        vf_loss: 0.021177995949983597
    load_time_ms: 2.167
    num_steps_sampled: 64000
    num_steps_trained: 64000
    sample_time_ms: 49109.086
    update_time_ms: 5.352
  iterations_since_restore: 109
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.672151898734178
    ram_util_percent: 13.896202531645573
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 421.87323017043025
    mean_inference_ms: 1.4369392353023636
    mean_processing_ms: 1.1382751759164993
  time_since_restore: 23332.861840963364
  time_this_iter_s: 55.308998584747314
  time_total_s: 31836.86738061905
  timestamp: 1638607439
  timesteps_since_restore: 54500
  timesteps_this_iter: 500
  timesteps_total: 64000
  training_iteration: 128
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    128 |          31836.9 | 64000 | 0.428852 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-44-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8752351097178683
  episode_reward_mean: 0.423896472151417
  episode_reward_min: -0.38071065989847713
  episodes_this_iter: 500
  episodes_total: 64500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1647.433
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.45220479369163513
        entropy_coeff: 0.0
        kl: 0.01519886963069439
        model: {}
        policy_loss: -0.019212689250707626
        total_loss: -0.0011465830029919744
        vf_explained_var: 0.6455855369567871
        vf_loss: 0.016783704981207848
    load_time_ms: 2.182
    num_steps_sampled: 64500
    num_steps_trained: 64500
    sample_time_ms: 48824.113
    update_time_ms: 5.4
  iterations_since_restore: 110
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.865753424657532
    ram_util_percent: 14.067123287671235
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 418.92100643221704
    mean_inference_ms: 1.4343848868011635
    mean_processing_ms: 1.136125593809116
  time_since_restore: 23384.180258750916
  time_this_iter_s: 51.31841778755188
  time_total_s: 31888.1857984066
  timestamp: 1638607490
  timesteps_since_restore: 55000
  timesteps_this_iter: 500
  timesteps_total: 64500
  training_iteration: 129
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    129 |          31888.2 | 64500 | 0.423896 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-45-29
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9673192992786692
  episode_reward_mean: 0.4267314767448161
  episode_reward_min: -0.5625
  episodes_this_iter: 500
  episodes_total: 65000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1645.163
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4539612829685211
        entropy_coeff: 0.0
        kl: 0.00875522755086422
        model: {}
        policy_loss: -0.016614828258752823
        total_loss: 0.0026470625307410955
        vf_explained_var: 0.6298113465309143
        vf_loss: 0.01852315478026867
    load_time_ms: 2.166
    num_steps_sampled: 65000
    num_steps_trained: 65000
    sample_time_ms: 48715.789
    update_time_ms: 5.368
  iterations_since_restore: 111
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.943636363636363
    ram_util_percent: 13.96727272727273
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 415.78601474613845
    mean_inference_ms: 1.431545810277104
    mean_processing_ms: 1.1337535733268171
  time_since_restore: 23422.368910074234
  time_this_iter_s: 38.18865132331848
  time_total_s: 31926.37444972992
  timestamp: 1638607529
  timesteps_since_restore: 55500
  timesteps_this_iter: 500
  timesteps_total: 65000
  training_iteration: 130
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    130 |          31926.4 | 65000 | 0.426731 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-46-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8970831040176115
  episode_reward_mean: 0.4477230872502615
  episode_reward_min: -0.40703517587939697
  episodes_this_iter: 500
  episodes_total: 65500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1651.162
    learner:
      default_policy:
        cur_kl_coeff: 0.08437500149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.48697081208229065
        entropy_coeff: 0.0
        kl: 0.021642891690135002
        model: {}
        policy_loss: -0.027224378660321236
        total_loss: -0.006962792482227087
        vf_explained_var: 0.6002769470214844
        vf_loss: 0.018435463309288025
    load_time_ms: 2.145
    num_steps_sampled: 65500
    num_steps_trained: 65500
    sample_time_ms: 47809.178
    update_time_ms: 5.356
  iterations_since_restore: 112
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.349999999999998
    ram_util_percent: 13.79423076923077
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 412.67322434291015
    mean_inference_ms: 1.428703008316489
    mean_processing_ms: 1.1312982652492223
  time_since_restore: 23458.6495115757
  time_this_iter_s: 36.280601501464844
  time_total_s: 31962.655051231384
  timestamp: 1638607565
  timesteps_since_restore: 56000
  timesteps_this_iter: 500
  timesteps_total: 65500
  training_iteration: 131
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    131 |          31962.7 | 65500 | 0.447723 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-46-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8888888888888888
  episode_reward_mean: 0.4277568823203746
  episode_reward_min: -0.3955431754874652
  episodes_this_iter: 500
  episodes_total: 66000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1659.284
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.4986023008823395
        entropy_coeff: 0.0
        kl: 0.010234161280095577
        model: {}
        policy_loss: -0.017630919814109802
        total_loss: -0.0006091153481975198
        vf_explained_var: 0.6238352656364441
        vf_loss: 0.015726549550890923
    load_time_ms: 2.11
    num_steps_sampled: 66000
    num_steps_trained: 66000
    sample_time_ms: 48162.175
    update_time_ms: 5.466
  iterations_since_restore: 113
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.726388888888891
    ram_util_percent: 13.830555555555556
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 409.858263449737
    mean_inference_ms: 1.426253449007278
    mean_processing_ms: 1.129030512509326
  time_since_restore: 23508.727911949158
  time_this_iter_s: 50.07840037345886
  time_total_s: 32012.733451604843
  timestamp: 1638607615
  timesteps_since_restore: 56500
  timesteps_this_iter: 500
  timesteps_total: 66000
  training_iteration: 132
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    132 |          32012.7 | 66000 | 0.427757 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-47-43
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8919949174078781
  episode_reward_mean: 0.44002750308823513
  episode_reward_min: -0.5792682926829268
  episodes_this_iter: 500
  episodes_total: 66500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1654.523
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.5036755800247192
        entropy_coeff: 0.0
        kl: 0.009855668991804123
        model: {}
        policy_loss: -0.018272312358021736
        total_loss: -0.0004261550202500075
        vf_explained_var: 0.6204473972320557
        vf_loss: 0.01659880019724369
    load_time_ms: 2.134
    num_steps_sampled: 66500
    num_steps_trained: 66500
    sample_time_ms: 48394.773
    update_time_ms: 5.49
  iterations_since_restore: 114
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.119402985074625
    ram_util_percent: 13.979104477611942
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 407.0408844813549
    mean_inference_ms: 1.4239124443587048
    mean_processing_ms: 1.1269790586974584
  time_since_restore: 23555.963596343994
  time_this_iter_s: 47.235684394836426
  time_total_s: 32059.96913599968
  timestamp: 1638607663
  timesteps_since_restore: 57000
  timesteps_this_iter: 500
  timesteps_total: 66500
  training_iteration: 133
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    133 |            32060 | 66500 | 0.440028 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-48-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8589065255731922
  episode_reward_mean: 0.4119610279702533
  episode_reward_min: -0.8220338983050848
  episodes_this_iter: 500
  episodes_total: 67000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1683.006
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.5011435151100159
        entropy_coeff: 0.0
        kl: 0.013587163761258125
        model: {}
        policy_loss: -0.023131798952817917
        total_loss: -0.005238620564341545
        vf_explained_var: 0.657818615436554
        vf_loss: 0.016173560172319412
    load_time_ms: 2.107
    num_steps_sampled: 67000
    num_steps_trained: 67000
    sample_time_ms: 47137.281
    update_time_ms: 5.659
  iterations_since_restore: 115
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.771428571428572
    ram_util_percent: 13.985714285714282
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 404.29997687128247
    mean_inference_ms: 1.4215589421713566
    mean_processing_ms: 1.1248055135633022
  time_since_restore: 23604.800407409668
  time_this_iter_s: 48.83681106567383
  time_total_s: 32108.805947065353
  timestamp: 1638607712
  timesteps_since_restore: 57500
  timesteps_this_iter: 500
  timesteps_total: 67000
  training_iteration: 134
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    134 |          32108.8 | 67000 | 0.411961 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-49-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8708333333333333
  episode_reward_mean: 0.41876932317081805
  episode_reward_min: -1.3462783171521036
  episodes_this_iter: 500
  episodes_total: 67500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1697.27
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.476814866065979
        entropy_coeff: 0.0
        kl: 0.009275918826460838
        model: {}
        policy_loss: -0.024395443499088287
        total_loss: -0.005662727169692516
        vf_explained_var: 0.6488486528396606
        vf_loss: 0.017558734863996506
    load_time_ms: 2.075
    num_steps_sampled: 67500
    num_steps_trained: 67500
    sample_time_ms: 47477.563
    update_time_ms: 5.665
  iterations_since_restore: 116
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.884810126582279
    ram_util_percent: 13.845569620253164
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 401.72292584766694
    mean_inference_ms: 1.419436888243338
    mean_processing_ms: 1.1229855227360643
  time_since_restore: 23660.34791827202
  time_this_iter_s: 55.547510862350464
  time_total_s: 32164.353457927704
  timestamp: 1638607768
  timesteps_since_restore: 58000
  timesteps_this_iter: 500
  timesteps_total: 67500
  training_iteration: 135
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    135 |          32164.4 | 67500 | 0.418769 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-50-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8674884437596302
  episode_reward_mean: 0.4192411638006303
  episode_reward_min: -0.5078369905956113
  episodes_this_iter: 500
  episodes_total: 68000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1679.316
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.4917321503162384
        entropy_coeff: 0.0
        kl: 0.0164214875549078
        model: {}
        policy_loss: -0.020158914849162102
        total_loss: -0.0010362439788877964
        vf_explained_var: 0.657264769077301
        vf_loss: 0.017044320702552795
    load_time_ms: 2.058
    num_steps_sampled: 68000
    num_steps_trained: 68000
    sample_time_ms: 48448.053
    update_time_ms: 5.66
  iterations_since_restore: 117
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.048717948717945
    ram_util_percent: 13.84230769230769
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 399.17491042339503
    mean_inference_ms: 1.4174492737649491
    mean_processing_ms: 1.1209973889382174
  time_since_restore: 23714.884171962738
  time_this_iter_s: 54.536253690719604
  time_total_s: 32218.889711618423
  timestamp: 1638607822
  timesteps_since_restore: 58500
  timesteps_this_iter: 500
  timesteps_total: 68000
  training_iteration: 136
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    136 |          32218.9 | 68000 | 0.419241 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-51-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8680555555555556
  episode_reward_mean: 0.41291325497812115
  episode_reward_min: -0.38974358974358975
  episodes_this_iter: 500
  episodes_total: 68500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1685.533
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.4486629068851471
        entropy_coeff: 0.0
        kl: 0.008609755896031857
        model: {}
        policy_loss: -0.01377295982092619
        total_loss: 0.004282774403691292
        vf_explained_var: 0.6172441244125366
        vf_loss: 0.016966063529253006
    load_time_ms: 2.062
    num_steps_sampled: 68500
    num_steps_trained: 68500
    sample_time_ms: 46990.758
    update_time_ms: 5.661
  iterations_since_restore: 118
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.756338028169015
    ram_util_percent: 13.946478873239432
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 396.58593927403047
    mean_inference_ms: 1.4151682948822093
    mean_processing_ms: 1.1190451985062086
  time_since_restore: 23764.480651140213
  time_this_iter_s: 49.596479177474976
  time_total_s: 32268.4861907959
  timestamp: 1638607872
  timesteps_since_restore: 59000
  timesteps_this_iter: 500
  timesteps_total: 68500
  training_iteration: 137
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    137 |          32268.5 | 68500 | 0.412913 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-51-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647845468053492
  episode_reward_mean: 0.4315989922520308
  episode_reward_min: -0.4479166666666667
  episodes_this_iter: 500
  episodes_total: 69000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1665.12
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.43835800886154175
        entropy_coeff: 0.0
        kl: 0.012839016504585743
        model: {}
        policy_loss: -0.02461792528629303
        total_loss: -0.004338194150477648
        vf_explained_var: 0.6281601190567017
        vf_loss: 0.01865479163825512
    load_time_ms: 2.057
    num_steps_sampled: 69000
    num_steps_trained: 69000
    sample_time_ms: 45303.102
    update_time_ms: 5.623
  iterations_since_restore: 119
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.976363636363637
    ram_util_percent: 13.83636363636363
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 393.8502300022226
    mean_inference_ms: 1.4128399340838473
    mean_processing_ms: 1.1168308886028604
  time_since_restore: 23802.708975076675
  time_this_iter_s: 38.2283239364624
  time_total_s: 32306.71451473236
  timestamp: 1638607910
  timesteps_since_restore: 59500
  timesteps_this_iter: 500
  timesteps_total: 69000
  training_iteration: 138
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    138 |          32306.7 | 69000 | 0.431599 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-52-35
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721590909090909
  episode_reward_mean: 0.42375960960487796
  episode_reward_min: -0.49473684210526314
  episodes_this_iter: 500
  episodes_total: 69500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1666.906
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.4324571192264557
        entropy_coeff: 0.0
        kl: 0.010828724130988121
        model: {}
        policy_loss: -0.01855282671749592
        total_loss: -0.002375122392550111
        vf_explained_var: 0.6435672044754028
        vf_loss: 0.01480720192193985
    load_time_ms: 2.016
    num_steps_sampled: 69500
    num_steps_trained: 69500
    sample_time_ms: 44620.282
    update_time_ms: 5.621
  iterations_since_restore: 120
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.912500000000001
    ram_util_percent: 14.6140625
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 391.2634474720844
    mean_inference_ms: 1.41086462897
    mean_processing_ms: 1.1151642587267914
  time_since_restore: 23847.21649456024
  time_this_iter_s: 44.507519483566284
  time_total_s: 32351.222034215927
  timestamp: 1638607955
  timesteps_since_restore: 60000
  timesteps_this_iter: 500
  timesteps_total: 69500
  training_iteration: 139
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    139 |          32351.2 | 69500 |  0.42376 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-53-29
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8647058823529412
  episode_reward_mean: 0.41188117296209886
  episode_reward_min: -0.4308510638297872
  episodes_this_iter: 500
  episodes_total: 70000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1656.176
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.44402217864990234
        entropy_coeff: 0.0
        kl: 0.012387496419250965
        model: {}
        policy_loss: -0.02394629456102848
        total_loss: -0.009335899725556374
        vf_explained_var: 0.6903781294822693
        vf_loss: 0.01304260641336441
    load_time_ms: 2.013
    num_steps_sampled: 70000
    num_steps_trained: 70000
    sample_time_ms: 46215.503
    update_time_ms: 5.716
  iterations_since_restore: 121
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.485714285714288
    ram_util_percent: 13.841558441558439
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 388.8791772728567
    mean_inference_ms: 1.4088521391728188
    mean_processing_ms: 1.1133138618123084
  time_since_restore: 23901.250869512558
  time_this_iter_s: 54.034374952316284
  time_total_s: 32405.256409168243
  timestamp: 1638608009
  timesteps_since_restore: 60500
  timesteps_this_iter: 500
  timesteps_total: 70000
  training_iteration: 140
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    140 |          32405.3 | 70000 | 0.411881 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-54-17
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8578767123287672
  episode_reward_mean: 0.41345051473626204
  episode_reward_min: -0.6522988505747126
  episodes_this_iter: 500
  episodes_total: 70500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1650.58
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.3981727957725525
        entropy_coeff: 0.0
        kl: 0.008052960969507694
        model: {}
        policy_loss: -0.026988573372364044
        total_loss: -0.01202168595045805
        vf_explained_var: 0.698088526725769
        vf_loss: 0.013947687111794949
    load_time_ms: 2.007
    num_steps_sampled: 70500
    num_steps_trained: 70500
    sample_time_ms: 47382.157
    update_time_ms: 5.715
  iterations_since_restore: 122
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.792753623188402
    ram_util_percent: 13.879710144927534
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 386.43277744174327
    mean_inference_ms: 1.406749692761064
    mean_processing_ms: 1.111410908639549
  time_since_restore: 23949.1418569088
  time_this_iter_s: 47.890987396240234
  time_total_s: 32453.147396564484
  timestamp: 1638608057
  timesteps_since_restore: 61000
  timesteps_this_iter: 500
  timesteps_total: 70500
  training_iteration: 141
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    141 |          32453.1 | 70500 | 0.413451 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-55-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8683473389355743
  episode_reward_mean: 0.42049706237662565
  episode_reward_min: -0.3417085427135678
  episodes_this_iter: 500
  episodes_total: 71000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1651.011
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.3987761437892914
        entropy_coeff: 0.0
        kl: 0.007089830003678799
        model: {}
        policy_loss: -0.0195463914424181
        total_loss: -0.004296374972909689
        vf_explained_var: 0.678356409072876
        vf_loss: 0.014352714642882347
    load_time_ms: 2.016
    num_steps_sampled: 71000
    num_steps_trained: 71000
    sample_time_ms: 46884.275
    update_time_ms: 5.624
  iterations_since_restore: 123
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.264062500000001
    ram_util_percent: 13.912500000000001
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 383.97924659042866
    mean_inference_ms: 1.4045253497554318
    mean_processing_ms: 1.109445229388588
  time_since_restore: 23994.24445271492
  time_this_iter_s: 45.102595806121826
  time_total_s: 32498.249992370605
  timestamp: 1638608103
  timesteps_since_restore: 61500
  timesteps_this_iter: 500
  timesteps_total: 71000
  training_iteration: 142
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    142 |          32498.2 | 71000 | 0.420497 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-55-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8743424897720631
  episode_reward_mean: 0.4245142482259809
  episode_reward_min: -0.49683544303797467
  episodes_this_iter: 500
  episodes_total: 71500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1656.362
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.41138556599617004
        entropy_coeff: 0.0
        kl: 0.00657243886962533
        model: {}
        policy_loss: -0.022230392321944237
        total_loss: -0.002734619425609708
        vf_explained_var: 0.6192948818206787
        vf_loss: 0.01866394467651844
    load_time_ms: 2.0
    num_steps_sampled: 71500
    num_steps_trained: 71500
    sample_time_ms: 46544.029
    update_time_ms: 5.64
  iterations_since_restore: 124
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.931746031746034
    ram_util_percent: 13.866666666666664
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 381.5432132512312
    mean_inference_ms: 1.4024370130140036
    mean_processing_ms: 1.1074969684732927
  time_since_restore: 24038.129870176315
  time_this_iter_s: 43.885417461395264
  time_total_s: 32542.135409832
  timestamp: 1638608147
  timesteps_since_restore: 62000
  timesteps_this_iter: 500
  timesteps_total: 71500
  training_iteration: 143
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    143 |          32542.1 | 71500 | 0.424514 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-56-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8877805486284289
  episode_reward_mean: 0.42888121814190977
  episode_reward_min: -0.23553719008264462
  episodes_this_iter: 500
  episodes_total: 72000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1633.24
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.41531237959861755
        entropy_coeff: 0.0
        kl: 0.019040720537304878
        model: {}
        policy_loss: -0.018955308943986893
        total_loss: -0.00036750256549566984
        vf_explained_var: 0.5929023623466492
        vf_loss: 0.01617797091603279
    load_time_ms: 1.993
    num_steps_sampled: 72000
    num_steps_trained: 72000
    sample_time_ms: 45183.481
    update_time_ms: 5.581
  iterations_since_restore: 125
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.58
    ram_util_percent: 13.827999999999998
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 379.00844364688413
    mean_inference_ms: 1.4001017782116363
    mean_processing_ms: 1.1055015571227909
  time_since_restore: 24073.129227161407
  time_this_iter_s: 34.99935698509216
  time_total_s: 32577.134766817093
  timestamp: 1638608182
  timesteps_since_restore: 62500
  timesteps_this_iter: 500
  timesteps_total: 72000
  training_iteration: 144
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    144 |          32577.1 | 72000 | 0.428881 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-57-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8752351097178683
  episode_reward_mean: 0.4218173309974789
  episode_reward_min: -0.9921259842519685
  episodes_this_iter: 500
  episodes_total: 72500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1614.142
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.3759106695652008
        entropy_coeff: 0.0
        kl: 0.010463730432093143
        model: {}
        policy_loss: -0.021901406347751617
        total_loss: -0.00290884543210268
        vf_explained_var: 0.6614800095558167
        vf_loss: 0.01766824908554554
    load_time_ms: 1.994
    num_steps_sampled: 72500
    num_steps_trained: 72500
    sample_time_ms: 44412.669
    update_time_ms: 5.553
  iterations_since_restore: 126
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.273913043478263
    ram_util_percent: 14.088405797101446
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 376.7143903093712
    mean_inference_ms: 1.398266925673411
    mean_processing_ms: 1.1039146803531974
  time_since_restore: 24120.77713751793
  time_this_iter_s: 47.647910356521606
  time_total_s: 32624.782677173615
  timestamp: 1638608230
  timesteps_since_restore: 63000
  timesteps_this_iter: 500
  timesteps_total: 72500
  training_iteration: 145
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    145 |          32624.8 | 72500 | 0.421817 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-57-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9661416163697925
  episode_reward_mean: 0.43846428954037137
  episode_reward_min: -0.5625
  episodes_this_iter: 500
  episodes_total: 73000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1636.272
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.34623461961746216
        entropy_coeff: 0.0
        kl: 0.008060447871685028
        model: {}
        policy_loss: -0.017487239092588425
        total_loss: 0.004463532939553261
        vf_explained_var: 0.5674207210540771
        vf_loss: 0.020930614322423935
    load_time_ms: 1.984
    num_steps_sampled: 73000
    num_steps_trained: 73000
    sample_time_ms: 43098.277
    update_time_ms: 5.58
  iterations_since_restore: 127
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.5864406779661
    ram_util_percent: 13.901694915254236
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 374.3573375255922
    mean_inference_ms: 1.396187365395811
    mean_processing_ms: 1.1022443615622985
  time_since_restore: 24162.39084792137
  time_this_iter_s: 41.61371040344238
  time_total_s: 32666.396387577057
  timestamp: 1638608271
  timesteps_since_restore: 63500
  timesteps_this_iter: 500
  timesteps_total: 73000
  training_iteration: 146
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    146 |          32666.4 | 73000 | 0.438464 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-58-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8970831040176115
  episode_reward_mean: 0.4410330032651951
  episode_reward_min: -0.39067055393586003
  episodes_this_iter: 500
  episodes_total: 73500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1639.31
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.356324702501297
        entropy_coeff: 0.0
        kl: 0.009669456630945206
        model: {}
        policy_loss: -0.012872420251369476
        total_loss: 0.006164678372442722
        vf_explained_var: 0.6033079028129578
        vf_loss: 0.017813310027122498
    load_time_ms: 2.001
    num_steps_sampled: 73500
    num_steps_trained: 73500
    sample_time_ms: 43628.041
    update_time_ms: 5.542
  iterations_since_restore: 128
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.964556962025314
    ram_util_percent: 13.93291139240506
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 372.2469953259025
    mean_inference_ms: 1.394480292222397
    mean_processing_ms: 1.1006290786976096
  time_since_restore: 24217.31432747841
  time_this_iter_s: 54.92347955703735
  time_total_s: 32721.319867134094
  timestamp: 1638608326
  timesteps_since_restore: 64000
  timesteps_this_iter: 500
  timesteps_total: 73500
  training_iteration: 147
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    147 |          32721.3 | 73500 | 0.441033 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_03-59-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8907242693773825
  episode_reward_mean: 0.45017771146884855
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 74000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1644.314
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.32094985246658325
        entropy_coeff: 0.0
        kl: 0.007235884200781584
        model: {}
        policy_loss: -0.014543256722390652
        total_loss: 0.0007712602382525802
        vf_explained_var: 0.6403271555900574
        vf_loss: 0.014398724772036076
    load_time_ms: 1.977
    num_steps_sampled: 74000
    num_steps_trained: 74000
    sample_time_ms: 44303.838
    update_time_ms: 5.616
  iterations_since_restore: 129
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.646875
    ram_util_percent: 13.946875
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 370.01652524714535
    mean_inference_ms: 1.3926070530568604
    mean_processing_ms: 1.0988743618915928
  time_since_restore: 24262.350821495056
  time_this_iter_s: 45.03649401664734
  time_total_s: 32766.35636115074
  timestamp: 1638608372
  timesteps_since_restore: 64500
  timesteps_this_iter: 500
  timesteps_total: 74000
  training_iteration: 148
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    148 |          32766.4 | 74000 | 0.450178 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-00-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8588957055214724
  episode_reward_mean: 0.4136110146841326
  episode_reward_min: -0.5792682926829268
  episodes_this_iter: 500
  episodes_total: 74500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1646.302
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.31529009342193604
        entropy_coeff: 0.0
        kl: 0.00445714732632041
        model: {}
        policy_loss: -0.008305591531097889
        total_loss: 0.010032543912529945
        vf_explained_var: 0.6201850771903992
        vf_loss: 0.017774036154150963
    load_time_ms: 2.018
    num_steps_sampled: 74500
    num_steps_trained: 74500
    sample_time_ms: 45445.409
    update_time_ms: 5.624
  iterations_since_restore: 130
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.11375
    ram_util_percent: 14.030000000000001
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 367.9873340836038
    mean_inference_ms: 1.3911117086212312
    mean_processing_ms: 1.0976222340461776
  time_since_restore: 24318.294706583023
  time_this_iter_s: 55.94388508796692
  time_total_s: 32822.30024623871
  timestamp: 1638608428
  timesteps_since_restore: 65000
  timesteps_this_iter: 500
  timesteps_total: 74500
  training_iteration: 149
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    149 |          32822.3 | 74500 | 0.413611 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-01-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8577832110839446
  episode_reward_mean: 0.4192044619682069
  episode_reward_min: -0.4171907756813417
  episodes_this_iter: 500
  episodes_total: 75000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1657.99
    learner:
      default_policy:
        cur_kl_coeff: 0.06328125298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.2999076247215271
        entropy_coeff: 0.0
        kl: 0.0057379440404474735
        model: {}
        policy_loss: -0.018221698701381683
        total_loss: -0.003267144551500678
        vf_explained_var: 0.6864443421363831
        vf_loss: 0.014591449871659279
    load_time_ms: 2.017
    num_steps_sampled: 75000
    num_steps_trained: 75000
    sample_time_ms: 44078.98
    update_time_ms: 5.465
  iterations_since_restore: 131
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.456896551724139
    ram_util_percent: 13.970689655172412
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 365.7543777580494
    mean_inference_ms: 1.389268318155653
    mean_processing_ms: 1.0959565847881427
  time_since_restore: 24358.77988743782
  time_this_iter_s: 40.48518085479736
  time_total_s: 32862.785427093506
  timestamp: 1638608468
  timesteps_since_restore: 65500
  timesteps_this_iter: 500
  timesteps_total: 75000
  training_iteration: 150
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    150 |          32862.8 | 75000 | 0.419204 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-01-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8708333333333333
  episode_reward_mean: 0.4267196088121584
  episode_reward_min: -0.5078369905956113
  episodes_this_iter: 500
  episodes_total: 75500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1660.902
    learner:
      default_policy:
        cur_kl_coeff: 0.06328125298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.2823706865310669
        entropy_coeff: 0.0
        kl: 0.011513003148138523
        model: {}
        policy_loss: -0.016950661316514015
        total_loss: -0.002930463757365942
        vf_explained_var: 0.7091348171234131
        vf_loss: 0.013291638344526291
    load_time_ms: 2.02
    num_steps_sampled: 75500
    num_steps_trained: 75500
    sample_time_ms: 43042.344
    update_time_ms: 5.462
  iterations_since_restore: 132
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.742592592592594
    ram_util_percent: 14.035185185185183
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 363.5115369923415
    mean_inference_ms: 1.3873811017451698
    mean_processing_ms: 1.0943255354636705
  time_since_restore: 24396.333999156952
  time_this_iter_s: 37.55411171913147
  time_total_s: 32900.33953881264
  timestamp: 1638608506
  timesteps_since_restore: 66000
  timesteps_this_iter: 500
  timesteps_total: 75500
  training_iteration: 151
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    151 |          32900.3 | 75500 |  0.42672 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-02-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8488813845504433
  episode_reward_mean: 0.4166287290923528
  episode_reward_min: -1.3235294117647058
  episodes_this_iter: 500
  episodes_total: 76000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1655.944
    learner:
      default_policy:
        cur_kl_coeff: 0.06328125298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.25528183579444885
        entropy_coeff: 0.0
        kl: 0.0022349869832396507
        model: {}
        policy_loss: -0.013351142406463623
        total_loss: 0.009004320949316025
        vf_explained_var: 0.608973503112793
        vf_loss: 0.022214028984308243
    load_time_ms: 2.014
    num_steps_sampled: 76000
    num_steps_trained: 76000
    sample_time_ms: 42108.171
    update_time_ms: 5.453
  iterations_since_restore: 133
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.598039215686274
    ram_util_percent: 13.874509803921564
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 361.27434842229906
    mean_inference_ms: 1.38547789023171
    mean_processing_ms: 1.0926468931885243
  time_since_restore: 24432.0456969738
  time_this_iter_s: 35.711697816848755
  time_total_s: 32936.051236629486
  timestamp: 1638608542
  timesteps_since_restore: 66500
  timesteps_this_iter: 500
  timesteps_total: 76000
  training_iteration: 152
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    152 |          32936.1 | 76000 | 0.416629 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-03-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8680555555555556
  episode_reward_mean: 0.42041456920511083
  episode_reward_min: -0.38974358974358975
  episodes_this_iter: 500
  episodes_total: 76500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1635.203
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.28428974747657776
        entropy_coeff: 0.0
        kl: 0.017202412709593773
        model: {}
        policy_loss: -0.017365867272019386
        total_loss: -0.00040910960524342954
        vf_explained_var: 0.6164803504943848
        vf_loss: 0.016412444412708282
    load_time_ms: 2.005
    num_steps_sampled: 76500
    num_steps_trained: 76500
    sample_time_ms: 42437.594
    update_time_ms: 5.448
  iterations_since_restore: 134
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.930882352941174
    ram_util_percent: 13.929411764705879
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 359.2385816544917
    mean_inference_ms: 1.3837228150362826
    mean_processing_ms: 1.0910425963176689
  time_since_restore: 24479.017986297607
  time_this_iter_s: 46.97228932380676
  time_total_s: 32983.02352595329
  timestamp: 1638608589
  timesteps_since_restore: 67000
  timesteps_this_iter: 500
  timesteps_total: 76500
  training_iteration: 153
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    153 |            32983 | 76500 | 0.420415 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-03-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721590909090909
  episode_reward_mean: 0.4266061311191907
  episode_reward_min: -0.49473684210526314
  episodes_this_iter: 500
  episodes_total: 77000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1648.798
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.2509109675884247
        entropy_coeff: 0.0
        kl: 0.00552276149392128
        model: {}
        policy_loss: -0.011198852211236954
        total_loss: 0.007936723530292511
        vf_explained_var: 0.55335533618927
        vf_loss: 0.018960826098918915
    load_time_ms: 2.037
    num_steps_sampled: 77000
    num_steps_trained: 77000
    sample_time_ms: 43555.305
    update_time_ms: 5.363
  iterations_since_restore: 135
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.709090909090909
    ram_util_percent: 14.06212121212121
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 357.2216506315227
    mean_inference_ms: 1.3821666038410216
    mean_processing_ms: 1.0895145071698809
  time_since_restore: 24525.33013033867
  time_this_iter_s: 46.3121440410614
  time_total_s: 33029.335669994354
  timestamp: 1638608636
  timesteps_since_restore: 67500
  timesteps_this_iter: 500
  timesteps_total: 77000
  training_iteration: 154
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    154 |          33029.3 | 77000 | 0.426606 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-04-45
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8732193732193733
  episode_reward_mean: 0.4202303522090986
  episode_reward_min: -0.4308510638297872
  episodes_this_iter: 500
  episodes_total: 77500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1654.113
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.2969050109386444
        entropy_coeff: 0.0
        kl: 0.00754119036719203
        model: {}
        policy_loss: -0.014853538013994694
        total_loss: -0.0022053576540201902
        vf_explained_var: 0.7209853529930115
        vf_loss: 0.012409563176333904
    load_time_ms: 2.033
    num_steps_sampled: 77500
    num_steps_trained: 77500
    sample_time_ms: 43708.226
    update_time_ms: 5.341
  iterations_since_restore: 136
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.48142857142857
    ram_util_percent: 14.165714285714282
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 355.27914674581376
    mean_inference_ms: 1.3804525381060129
    mean_processing_ms: 1.0881171335401056
  time_since_restore: 24574.56026983261
  time_this_iter_s: 49.23013949394226
  time_total_s: 33078.5658094883
  timestamp: 1638608685
  timesteps_since_restore: 68000
  timesteps_this_iter: 500
  timesteps_total: 77500
  training_iteration: 155
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    155 |          33078.6 | 77500 |  0.42023 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-05-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8632352941176471
  episode_reward_mean: 0.42046699410173694
  episode_reward_min: -0.3285024154589372
  episodes_this_iter: 500
  episodes_total: 78000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1644.897
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.2932446599006653
        entropy_coeff: 0.0
        kl: 0.009478586725890636
        model: {}
        policy_loss: -0.01731698587536812
        total_loss: -0.003829255932942033
        vf_explained_var: 0.7148532271385193
        vf_loss: 0.013187824748456478
    load_time_ms: 2.034
    num_steps_sampled: 78000
    num_steps_trained: 78000
    sample_time_ms: 43610.569
    update_time_ms: 5.268
  iterations_since_restore: 137
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.18305084745763
    ram_util_percent: 13.91186440677966
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 353.23645090166167
    mean_inference_ms: 1.3787139462887985
    mean_processing_ms: 1.0865302669279948
  time_since_restore: 24615.10496354103
  time_this_iter_s: 40.5446937084198
  time_total_s: 33119.110503196716
  timestamp: 1638608726
  timesteps_since_restore: 68500
  timesteps_this_iter: 500
  timesteps_total: 78000
  training_iteration: 156
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    156 |          33119.1 | 78000 | 0.420467 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-06-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8544520547945206
  episode_reward_mean: 0.40611682484450606
  episode_reward_min: -1.2268370607028753
  episodes_this_iter: 500
  episodes_total: 78500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1649.066
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.24721099436283112
        entropy_coeff: 0.0
        kl: 0.005156862083822489
        model: {}
        policy_loss: -0.01291410718113184
        total_loss: 0.0049489946104586124
        vf_explained_var: 0.6876291036605835
        vf_loss: 0.017699938267469406
    load_time_ms: 2.01
    num_steps_sampled: 78500
    num_steps_trained: 78500
    sample_time_ms: 42077.867
    update_time_ms: 5.291
  iterations_since_restore: 138
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.528571428571427
    ram_util_percent: 13.87857142857143
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 351.2101330823967
    mean_inference_ms: 1.3770801160900858
    mean_processing_ms: 1.0851806226763987
  time_since_restore: 24654.742794036865
  time_this_iter_s: 39.63783049583435
  time_total_s: 33158.74833369255
  timestamp: 1638608766
  timesteps_since_restore: 69000
  timesteps_this_iter: 500
  timesteps_total: 78500
  training_iteration: 157
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    157 |          33158.7 | 78500 | 0.406117 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-06-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8683473389355743
  episode_reward_mean: 0.4191800011761545
  episode_reward_min: -2.0
  episodes_this_iter: 500
  episodes_total: 79000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1654.159
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.24378499388694763
        entropy_coeff: 0.0
        kl: 0.006538376212120056
        model: {}
        policy_loss: -0.02679893933236599
        total_loss: 0.007693484891206026
        vf_explained_var: 0.5846743583679199
        vf_loss: 0.03428555279970169
    load_time_ms: 2.044
    num_steps_sampled: 79000
    num_steps_trained: 79000
    sample_time_ms: 42551.401
    update_time_ms: 5.303
  iterations_since_restore: 139
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.0
    ram_util_percent: 14.044444444444444
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 349.35916886720923
    mean_inference_ms: 1.3756518264401445
    mean_processing_ms: 1.083919273736853
  time_since_restore: 24704.5663292408
  time_this_iter_s: 49.823535203933716
  time_total_s: 33208.571868896484
  timestamp: 1638608816
  timesteps_since_restore: 69500
  timesteps_this_iter: 500
  timesteps_total: 79000
  training_iteration: 158
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    158 |          33208.6 | 79000 |  0.41918 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-07-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8620689655172413
  episode_reward_mean: 0.44301921256145466
  episode_reward_min: -0.41578947368421054
  episodes_this_iter: 500
  episodes_total: 79500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1653.181
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.2355581521987915
        entropy_coeff: 0.0
        kl: 0.004778817296028137
        model: {}
        policy_loss: -0.011833501979708672
        total_loss: 0.005003167316317558
        vf_explained_var: 0.6521298289299011
        vf_loss: 0.016685454174876213
    load_time_ms: 2.017
    num_steps_sampled: 79500
    num_steps_trained: 79500
    sample_time_ms: 42572.143
    update_time_ms: 5.289
  iterations_since_restore: 140
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.105
    ram_util_percent: 14.06875
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 347.62590157403434
    mean_inference_ms: 1.3742018944178225
    mean_processing_ms: 1.0825932954877115
  time_since_restore: 24760.707397460938
  time_this_iter_s: 56.14106822013855
  time_total_s: 33264.71293711662
  timestamp: 1638608872
  timesteps_since_restore: 70000
  timesteps_this_iter: 500
  timesteps_total: 79500
  training_iteration: 159
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    159 |          33264.7 | 79500 | 0.443019 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-08-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8802992518703242
  episode_reward_mean: 0.416812495026262
  episode_reward_min: -1.330935251798561
  episodes_this_iter: 500
  episodes_total: 80000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1637.843
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.22678570449352264
        entropy_coeff: 0.0
        kl: 0.005373750813305378
        model: {}
        policy_loss: -0.020033154636621475
        total_loss: -0.00044376254663802683
        vf_explained_var: 0.5854332447052002
        vf_loss: 0.019504379481077194
    load_time_ms: 2.008
    num_steps_sampled: 80000
    num_steps_trained: 80000
    sample_time_ms: 42169.188
    update_time_ms: 5.422
  iterations_since_restore: 141
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.971153846153847
    ram_util_percent: 14.082692307692305
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 345.6383539892066
    mean_inference_ms: 1.3726221037439248
    mean_processing_ms: 1.081392309553777
  time_since_restore: 24797.01143169403
  time_this_iter_s: 36.30403423309326
  time_total_s: 33301.016971349716
  timestamp: 1638608908
  timesteps_since_restore: 70500
  timesteps_this_iter: 500
  timesteps_total: 80000
  training_iteration: 160
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    160 |            33301 | 80000 | 0.416812 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-09-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9661416163697925
  episode_reward_mean: 0.43142535212669547
  episode_reward_min: -1.5634517766497462
  episodes_this_iter: 500
  episodes_total: 80500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1645.363
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2426992803812027
        entropy_coeff: 0.0
        kl: 0.00884749460965395
        model: {}
        policy_loss: -0.025339528918266296
        total_loss: 5.2663683163700625e-05
        vf_explained_var: 0.5793144106864929
        vf_loss: 0.02525223046541214
    load_time_ms: 1.995
    num_steps_sampled: 80500
    num_steps_trained: 80500
    sample_time_ms: 42522.994
    update_time_ms: 5.455
  iterations_since_restore: 142
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.745762711864408
    ram_util_percent: 13.908474576271187
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 343.744975013049
    mean_inference_ms: 1.3710852618002627
    mean_processing_ms: 1.0798735775811037
  time_since_restore: 24838.17889213562
  time_this_iter_s: 41.167460441589355
  time_total_s: 33342.184431791306
  timestamp: 1638608950
  timesteps_since_restore: 71000
  timesteps_this_iter: 500
  timesteps_total: 80500
  training_iteration: 161
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    161 |          33342.2 | 80500 | 0.431425 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-09-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8867924528301887
  episode_reward_mean: 0.4439824069754727
  episode_reward_min: -1.087463556851312
  episodes_this_iter: 500
  episodes_total: 81000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1641.74
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.23942990601062775
        entropy_coeff: 0.0
        kl: 0.01177106611430645
        model: {}
        policy_loss: -0.014157390221953392
        total_loss: 0.008475718088448048
        vf_explained_var: 0.548424243927002
        vf_loss: 0.0224468894302845
    load_time_ms: 1.981
    num_steps_sampled: 81000
    num_steps_trained: 81000
    sample_time_ms: 41898.979
    update_time_ms: 5.413
  iterations_since_restore: 143
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.326190476190478
    ram_util_percent: 14.133333333333335
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 341.71542405958786
    mean_inference_ms: 1.3693073736491086
    mean_processing_ms: 1.0782879760463049
  time_since_restore: 24867.613341093063
  time_this_iter_s: 29.434448957443237
  time_total_s: 33371.61888074875
  timestamp: 1638608979
  timesteps_since_restore: 71500
  timesteps_this_iter: 500
  timesteps_total: 81000
  training_iteration: 162
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    162 |          33371.6 | 81000 | 0.443982 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-10-11
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8970831040176115
  episode_reward_mean: 0.425469383455723
  episode_reward_min: -1.8214285714285714
  episodes_this_iter: 500
  episodes_total: 81500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1638.041
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.24242287874221802
        entropy_coeff: 0.0
        kl: 0.00558866374194622
        model: {}
        policy_loss: -0.021899061277508736
        total_loss: 0.0067489431239664555
        vf_explained_var: 0.5233563780784607
        vf_loss: 0.028559597209095955
    load_time_ms: 1.998
    num_steps_sampled: 81500
    num_steps_trained: 81500
    sample_time_ms: 40351.25
    update_time_ms: 5.511
  iterations_since_restore: 144
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.619565217391305
    ram_util_percent: 13.939130434782605
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 339.74223263328173
    mean_inference_ms: 1.3675802514045814
    mean_processing_ms: 1.076836392021224
  time_since_restore: 24899.072302103043
  time_this_iter_s: 31.458961009979248
  time_total_s: 33403.07784175873
  timestamp: 1638609011
  timesteps_since_restore: 72000
  timesteps_this_iter: 500
  timesteps_total: 81500
  training_iteration: 163
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    163 |          33403.1 | 81500 | 0.425469 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-10-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8907242693773825
  episode_reward_mean: 0.4478863458228028
  episode_reward_min: -0.5792682926829268
  episodes_this_iter: 500
  episodes_total: 82000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1618.423
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2339709997177124
        entropy_coeff: 0.0
        kl: 0.009411260485649109
        model: {}
        policy_loss: -0.014568599872291088
        total_loss: 0.0012236010516062379
        vf_explained_var: 0.6271000504493713
        vf_loss: 0.015643304213881493
    load_time_ms: 1.957
    num_steps_sampled: 82000
    num_steps_trained: 82000
    sample_time_ms: 37460.904
    update_time_ms: 5.6
  iterations_since_restore: 145
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.995833333333332
    ram_util_percent: 13.891666666666666
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 337.6013237670942
    mean_inference_ms: 1.3656953675449541
    mean_processing_ms: 1.0750750831350078
  time_since_restore: 24916.284503221512
  time_this_iter_s: 17.21220111846924
  time_total_s: 33420.2900428772
  timestamp: 1638609028
  timesteps_since_restore: 72500
  timesteps_this_iter: 500
  timesteps_total: 82000
  training_iteration: 164
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    164 |          33420.3 | 82000 | 0.447886 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-11-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8542944785276073
  episode_reward_mean: 0.41782934671446487
  episode_reward_min: -0.5573770491803278
  episodes_this_iter: 500
  episodes_total: 82500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1626.316
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2610611915588379
        entropy_coeff: 0.0
        kl: 0.01310421247035265
        model: {}
        policy_loss: -0.0172012597322464
        total_loss: 0.0004036614263895899
        vf_explained_var: 0.6148096323013306
        vf_loss: 0.017397603020071983
    load_time_ms: 1.952
    num_steps_sampled: 82500
    num_steps_trained: 82500
    sample_time_ms: 35784.466
    update_time_ms: 5.693
  iterations_since_restore: 146
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.41489361702128
    ram_util_percent: 14.008510638297869
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 335.6975258393633
    mean_inference_ms: 1.3638285959853358
    mean_processing_ms: 1.0734119832803939
  time_since_restore: 24948.829627513885
  time_this_iter_s: 32.54512429237366
  time_total_s: 33452.83516716957
  timestamp: 1638609061
  timesteps_since_restore: 73000
  timesteps_this_iter: 500
  timesteps_total: 82500
  training_iteration: 165
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    165 |          33452.8 | 82500 | 0.417829 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-11-23
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8577832110839446
  episode_reward_mean: 0.41702810343509217
  episode_reward_min: -1.6107142857142858
  episodes_this_iter: 500
  episodes_total: 83000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1618.035
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.23014278709888458
        entropy_coeff: 0.0
        kl: 0.00922058243304491
        model: {}
        policy_loss: -0.016861524432897568
        total_loss: 0.002984990132972598
        vf_explained_var: 0.6404356956481934
        vf_loss: 0.019700653851032257
    load_time_ms: 1.954
    num_steps_sampled: 83000
    num_steps_trained: 83000
    sample_time_ms: 33864.364
    update_time_ms: 5.706
  iterations_since_restore: 147
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.838709677419354
    ram_util_percent: 14.006451612903225
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 333.6663761131909
    mean_inference_ms: 1.3620345972438759
    mean_processing_ms: 1.0717399681401567
  time_since_restore: 24970.090499162674
  time_this_iter_s: 21.260871648788452
  time_total_s: 33474.09603881836
  timestamp: 1638609083
  timesteps_since_restore: 73500
  timesteps_this_iter: 500
  timesteps_total: 83000
  training_iteration: 166
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    166 |          33474.1 | 83000 | 0.417028 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-11-38
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8708333333333333
  episode_reward_mean: 0.4224857367650184
  episode_reward_min: -0.5078369905956113
  episodes_this_iter: 500
  episodes_total: 83500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1617.455
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.19452163577079773
        entropy_coeff: 0.0
        kl: 0.00511978380382061
        model: {}
        policy_loss: -0.006947434972971678
        total_loss: 0.007759890519082546
        vf_explained_var: 0.6889721751213074
        vf_loss: 0.014626331627368927
    load_time_ms: 1.957
    num_steps_sampled: 83500
    num_steps_trained: 83500
    sample_time_ms: 31379.214
    update_time_ms: 5.679
  iterations_since_restore: 148
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.40952380952381
    ram_util_percent: 13.885714285714286
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 331.57472298536135
    mean_inference_ms: 1.3600169635315518
    mean_processing_ms: 1.0699401041815126
  time_since_restore: 24984.870640277863
  time_this_iter_s: 14.780141115188599
  time_total_s: 33488.87617993355
  timestamp: 1638609098
  timesteps_since_restore: 74000
  timesteps_this_iter: 500
  timesteps_total: 83500
  training_iteration: 167
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    167 |          33488.9 | 83500 | 0.422486 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-11-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8680555555555556
  episode_reward_mean: 0.41851332078927456
  episode_reward_min: -0.5714285714285714
  episodes_this_iter: 500
  episodes_total: 84000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1600.918
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.18848423659801483
        entropy_coeff: 0.0
        kl: 0.008671877905726433
        model: {}
        policy_loss: -0.010604205541312695
        total_loss: 0.007986393757164478
        vf_explained_var: 0.6083938479423523
        vf_loss: 0.018453408032655716
    load_time_ms: 1.912
    num_steps_sampled: 84000
    num_steps_trained: 84000
    sample_time_ms: 28238.95
    update_time_ms: 5.758
  iterations_since_restore: 149
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.926923076923076
    ram_util_percent: 13.938461538461537
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 329.5589730674982
    mean_inference_ms: 1.3585138032264228
    mean_processing_ms: 1.0684902377644536
  time_since_restore: 25003.126065015793
  time_this_iter_s: 18.255424737930298
  time_total_s: 33507.13160467148
  timestamp: 1638609116
  timesteps_since_restore: 74500
  timesteps_this_iter: 500
  timesteps_total: 84000
  training_iteration: 168
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    168 |          33507.1 | 84000 | 0.418513 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-12-13
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8590504451038575
  episode_reward_mean: 0.43311299190385943
  episode_reward_min: -0.44623655913978494
  episodes_this_iter: 500
  episodes_total: 84500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1606.521
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.21724605560302734
        entropy_coeff: 0.0
        kl: 0.010559458285570145
        model: {}
        policy_loss: -0.01554714422672987
        total_loss: 0.0026965164579451084
        vf_explained_var: 0.5731165409088135
        vf_loss: 0.01807660609483719
    load_time_ms: 1.912
    num_steps_sampled: 84500
    num_steps_trained: 84500
    sample_time_ms: 24254.337
    update_time_ms: 5.712
  iterations_since_restore: 150
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.616666666666667
    ram_util_percent: 13.920833333333334
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 327.5433824109426
    mean_inference_ms: 1.3566309956779108
    mean_processing_ms: 1.0666987735146445
  time_since_restore: 25019.476484537125
  time_this_iter_s: 16.350419521331787
  time_total_s: 33523.48202419281
  timestamp: 1638609133
  timesteps_since_restore: 75000
  timesteps_this_iter: 500
  timesteps_total: 84500
  training_iteration: 169
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    169 |          33523.5 | 84500 | 0.433113 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-12-38
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8732193732193733
  episode_reward_mean: 0.4194125665733349
  episode_reward_min: -1.5555555555555556
  episodes_this_iter: 500
  episodes_total: 85000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1626.296
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.23095081746578217
        entropy_coeff: 0.0
        kl: 0.005939381197094917
        model: {}
        policy_loss: -0.017680294811725616
        total_loss: 0.006595007609575987
        vf_explained_var: 0.5744205713272095
        vf_loss: 0.024181338027119637
    load_time_ms: 1.939
    num_steps_sampled: 85000
    num_steps_trained: 85000
    sample_time_ms: 23123.425
    update_time_ms: 5.714
  iterations_since_restore: 151
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.650000000000002
    ram_util_percent: 14.119444444444444
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 325.6713695282087
    mean_inference_ms: 1.3549179685420385
    mean_processing_ms: 1.0653417083064818
  time_since_restore: 25044.669286727905
  time_this_iter_s: 25.19280219078064
  time_total_s: 33548.67482638359
  timestamp: 1638609158
  timesteps_since_restore: 75500
  timesteps_this_iter: 500
  timesteps_total: 85000
  training_iteration: 170
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    170 |          33548.7 | 85000 | 0.419413 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-12-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8559093362115489
  episode_reward_mean: 0.4101360588531354
  episode_reward_min: -0.4308510638297872
  episodes_this_iter: 500
  episodes_total: 85500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1627.196
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2665117383003235
        entropy_coeff: 0.0
        kl: 0.011302996426820755
        model: {}
        policy_loss: -0.013463244773447514
        total_loss: 0.00033322811941616237
        vf_explained_var: 0.7153527140617371
        vf_loss: 0.01361765619367361
    load_time_ms: 1.952
    num_steps_sampled: 85500
    num_steps_trained: 85500
    sample_time_ms: 20859.524
    update_time_ms: 5.787
  iterations_since_restore: 152
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.76296296296296
    ram_util_percent: 13.911111111111108
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 323.7364146774097
    mean_inference_ms: 1.3532729492747646
    mean_processing_ms: 1.0639254280558426
  time_since_restore: 25063.206976890564
  time_this_iter_s: 18.53769016265869
  time_total_s: 33567.21251654625
  timestamp: 1638609177
  timesteps_since_restore: 76000
  timesteps_this_iter: 500
  timesteps_total: 85500
  training_iteration: 171
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    171 |          33567.2 | 85500 | 0.410136 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-13-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8632352941176471
  episode_reward_mean: 0.424695325069981
  episode_reward_min: -0.8881789137380192
  episodes_this_iter: 500
  episodes_total: 86000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1638.393
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2376558482646942
        entropy_coeff: 0.0
        kl: 0.007166280876845121
        model: {}
        policy_loss: -0.016817253082990646
        total_loss: -0.0021176489535719156
        vf_explained_var: 0.6962282061576843
        vf_loss: 0.014586234465241432
    load_time_ms: 1.957
    num_steps_sampled: 86000
    num_steps_trained: 86000
    sample_time_ms: 20442.634
    update_time_ms: 5.75
  iterations_since_restore: 153
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.56666666666667
    ram_util_percent: 13.952777777777776
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 321.9160275625028
    mean_inference_ms: 1.3516747426837725
    mean_processing_ms: 1.0624213620161902
  time_since_restore: 25088.583991527557
  time_this_iter_s: 25.377014636993408
  time_total_s: 33592.58953118324
  timestamp: 1638609202
  timesteps_since_restore: 76500
  timesteps_this_iter: 500
  timesteps_total: 86000
  training_iteration: 172
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    172 |          33592.6 | 86000 | 0.424695 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-13-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8566666666666667
  episode_reward_mean: 0.42360325400380106
  episode_reward_min: -0.3417085427135678
  episodes_this_iter: 500
  episodes_total: 86500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1651.964
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2223917543888092
        entropy_coeff: 0.0
        kl: 0.007653957232832909
        model: {}
        policy_loss: -0.0181100033223629
        total_loss: -0.004118403885513544
        vf_explained_var: 0.693093478679657
        vf_loss: 0.013870520517230034
    load_time_ms: 1.939
    num_steps_sampled: 86500
    num_steps_trained: 86500
    sample_time_ms: 18912.476
    update_time_ms: 5.664
  iterations_since_restore: 154
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.258333333333336
    ram_util_percent: 13.908333333333333
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 320.00173022054366
    mean_inference_ms: 1.349874549765947
    mean_processing_ms: 1.060632242431712
  time_since_restore: 25104.87636446953
  time_this_iter_s: 16.292372941970825
  time_total_s: 33608.88190412521
  timestamp: 1638609219
  timesteps_since_restore: 77000
  timesteps_this_iter: 500
  timesteps_total: 86500
  training_iteration: 173
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    173 |          33608.9 | 86500 | 0.423603 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-13-59
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8683473389355743
  episode_reward_mean: 0.4116563556611312
  episode_reward_min: -1.6865671641791045
  episodes_this_iter: 500
  episodes_total: 87000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1684.35
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.22919879853725433
        entropy_coeff: 0.0
        kl: 0.007010437082499266
        model: {}
        policy_loss: -0.02148045040667057
        total_loss: 0.0003053414693567902
        vf_explained_var: 0.6342702507972717
        vf_loss: 0.02167489565908909
    load_time_ms: 1.958
    num_steps_sampled: 87000
    num_steps_trained: 87000
    sample_time_ms: 19135.812
    update_time_ms: 5.625
  iterations_since_restore: 155
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.514285714285714
    ram_util_percent: 13.921428571428567
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 318.1550481642718
    mean_inference_ms: 1.3481567488047568
    mean_processing_ms: 1.059188622631329
  time_since_restore: 25124.647446155548
  time_this_iter_s: 19.771081686019897
  time_total_s: 33628.65298581123
  timestamp: 1638609239
  timesteps_since_restore: 77500
  timesteps_this_iter: 500
  timesteps_total: 87000
  training_iteration: 174
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    174 |          33628.7 | 87000 | 0.411656 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-14-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8802992518703242
  episode_reward_mean: 0.4252308269302711
  episode_reward_min: -3.8181818181818183
  episodes_this_iter: 500
  episodes_total: 87500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1668.782
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2266063094139099
        entropy_coeff: 0.0
        kl: 0.006190621294081211
        model: {}
        policy_loss: -0.025030024349689484
        total_loss: 0.025540485978126526
        vf_explained_var: 0.516309916973114
        vf_loss: 0.05047256872057915
    load_time_ms: 1.963
    num_steps_sampled: 87500
    num_steps_trained: 87500
    sample_time_ms: 17810.891
    update_time_ms: 5.559
  iterations_since_restore: 156
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.389285714285716
    ram_util_percent: 14.167857142857141
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 316.3284242716348
    mean_inference_ms: 1.3462820520272742
    mean_processing_ms: 1.0576719650924087
  time_since_restore: 25143.790030002594
  time_this_iter_s: 19.1425838470459
  time_total_s: 33647.79556965828
  timestamp: 1638609258
  timesteps_since_restore: 78000
  timesteps_this_iter: 500
  timesteps_total: 87500
  training_iteration: 175
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    175 |          33647.8 | 87500 | 0.425231 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-14-35
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8779904306220095
  episode_reward_mean: 0.4228881840941311
  episode_reward_min: -1.4722222222222223
  episodes_this_iter: 500
  episodes_total: 88000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1672.979
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.20850494503974915
        entropy_coeff: 0.0
        kl: 0.0050105438567698
        model: {}
        policy_loss: -0.01058140117675066
        total_loss: 0.008827551268041134
        vf_explained_var: 0.6626831293106079
        vf_loss: 0.019329678267240524
    load_time_ms: 2.002
    num_steps_sampled: 88000
    num_steps_trained: 88000
    sample_time_ms: 17320.161
    update_time_ms: 5.611
  iterations_since_restore: 157
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.791666666666668
    ram_util_percent: 13.920833333333334
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 314.48779592568593
    mean_inference_ms: 1.344632702121853
    mean_processing_ms: 1.0560418743672406
  time_since_restore: 25160.187440633774
  time_this_iter_s: 16.39741063117981
  time_total_s: 33664.19298028946
  timestamp: 1638609275
  timesteps_since_restore: 78500
  timesteps_this_iter: 500
  timesteps_total: 88000
  training_iteration: 176
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    176 |          33664.2 | 88000 | 0.422888 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-14-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9661416163697925
  episode_reward_mean: 0.4315912005705818
  episode_reward_min: -0.5625
  episodes_this_iter: 500
  episodes_total: 88500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1655.423
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.21288008987903595
        entropy_coeff: 0.0
        kl: 0.004654052667319775
        model: {}
        policy_loss: -0.008600210770964622
        total_loss: 0.010463354177772999
        vf_explained_var: 0.6058253645896912
        vf_loss: 0.018989931792020798
    load_time_ms: 1.998
    num_steps_sampled: 88500
    num_steps_trained: 88500
    sample_time_ms: 17428.657
    update_time_ms: 5.59
  iterations_since_restore: 158
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.868181818181817
    ram_util_percent: 13.909090909090907
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 312.6637412572794
    mean_inference_ms: 1.3427972368052594
    mean_processing_ms: 1.0544387761949687
  time_since_restore: 25175.87707066536
  time_this_iter_s: 15.689630031585693
  time_total_s: 33679.882610321045
  timestamp: 1638609291
  timesteps_since_restore: 79000
  timesteps_this_iter: 500
  timesteps_total: 88500
  training_iteration: 177
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    177 |          33679.9 | 88500 | 0.431591 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-15-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8970831040176115
  episode_reward_mean: 0.4499968124129419
  episode_reward_min: -0.40703517587939697
  episodes_this_iter: 500
  episodes_total: 89000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1668.822
    learner:
      default_policy:
        cur_kl_coeff: 0.00791015662252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.22807060182094574
        entropy_coeff: 0.0
        kl: 0.007619503885507584
        model: {}
        policy_loss: -0.011542346328496933
        total_loss: 0.007504182402044535
        vf_explained_var: 0.5810927748680115
        vf_loss: 0.018986260518431664
    load_time_ms: 2.023
    num_steps_sampled: 89000
    num_steps_trained: 89000
    sample_time_ms: 17527.329
    update_time_ms: 5.428
  iterations_since_restore: 159
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.228571428571428
    ram_util_percent: 13.903571428571427
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 310.9069933218155
    mean_inference_ms: 1.3410438209345883
    mean_processing_ms: 1.0527686184108567
  time_since_restore: 25195.251994609833
  time_this_iter_s: 19.374923944473267
  time_total_s: 33699.25753426552
  timestamp: 1638609310
  timesteps_since_restore: 79500
  timesteps_this_iter: 500
  timesteps_total: 89000
  training_iteration: 178
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    178 |          33699.3 | 89000 | 0.449997 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-15-30
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8897996357012751
  episode_reward_mean: 0.4417532021674025
  episode_reward_min: -0.2796208530805687
  episodes_this_iter: 500
  episodes_total: 89500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1665.184
    learner:
      default_policy:
        cur_kl_coeff: 0.00791015662252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.21212266385555267
        entropy_coeff: 0.0
        kl: 0.007024523802101612
        model: {}
        policy_loss: -0.01483684778213501
        total_loss: 0.000572848308365792
        vf_explained_var: 0.6225625872612
        vf_loss: 0.015354132279753685
    load_time_ms: 2.01
    num_steps_sampled: 89500
    num_steps_trained: 89500
    sample_time_ms: 17826.782
    update_time_ms: 5.423
  iterations_since_restore: 160
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.107142857142858
    ram_util_percent: 13.932142857142853
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 309.1712528549953
    mean_inference_ms: 1.339394885810235
    mean_processing_ms: 1.0512947396942027
  time_since_restore: 25214.56008696556
  time_this_iter_s: 19.30809235572815
  time_total_s: 33718.565626621246
  timestamp: 1638609330
  timesteps_since_restore: 80000
  timesteps_this_iter: 500
  timesteps_total: 89500
  training_iteration: 179
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    179 |          33718.6 | 89500 | 0.441753 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-15-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8907242693773825
  episode_reward_mean: 0.4348562079771009
  episode_reward_min: -0.5792682926829268
  episodes_this_iter: 500
  episodes_total: 90000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1667.014
    learner:
      default_policy:
        cur_kl_coeff: 0.00791015662252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.23113374412059784
        entropy_coeff: 0.0
        kl: 0.006781997159123421
        model: {}
        policy_loss: -0.007356662768870592
        total_loss: 0.010088915005326271
        vf_explained_var: 0.6046959161758423
        vf_loss: 0.017391933128237724
    load_time_ms: 1.998
    num_steps_sampled: 90000
    num_steps_trained: 90000
    sample_time_ms: 16749.109
    update_time_ms: 5.401
  iterations_since_restore: 161
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.414285714285715
    ram_util_percent: 13.914285714285711
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 307.39611127290937
    mean_inference_ms: 1.3377410850383211
    mean_processing_ms: 1.049888866871562
  time_since_restore: 25228.99430823326
  time_this_iter_s: 14.434221267700195
  time_total_s: 33732.99984788895
  timestamp: 1638609344
  timesteps_since_restore: 80500
  timesteps_this_iter: 500
  timesteps_total: 90000
  training_iteration: 180
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    180 |            33733 | 90000 | 0.434856 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-16-01
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8517350157728707
  episode_reward_mean: 0.42189255474413007
  episode_reward_min: -0.42441860465116277
  episodes_this_iter: 500
  episodes_total: 90500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1656.109
    learner:
      default_policy:
        cur_kl_coeff: 0.00791015662252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.2045300304889679
        entropy_coeff: 0.0
        kl: 0.007742913905531168
        model: {}
        policy_loss: -0.02040785364806652
        total_loss: -0.00577325327321887
        vf_explained_var: 0.6874116659164429
        vf_loss: 0.01457334402948618
    load_time_ms: 1.992
    num_steps_sampled: 90500
    num_steps_trained: 90500
    sample_time_ms: 16522.27
    update_time_ms: 5.315
  iterations_since_restore: 162
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.986956521739133
    ram_util_percent: 13.917391304347822
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 305.666199004323
    mean_inference_ms: 1.3359672097435362
    mean_processing_ms: 1.0483259418932267
  time_since_restore: 25245.153883218765
  time_this_iter_s: 16.15957498550415
  time_total_s: 33749.15942287445
  timestamp: 1638609361
  timesteps_since_restore: 81000
  timesteps_this_iter: 500
  timesteps_total: 90500
  training_iteration: 181
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    181 |          33749.2 | 90500 | 0.421893 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-16-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8708333333333333
  episode_reward_mean: 0.4193102981313627
  episode_reward_min: -0.5078369905956113
  episodes_this_iter: 500
  episodes_total: 91000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1652.515
    learner:
      default_policy:
        cur_kl_coeff: 0.00791015662252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.20658110082149506
        entropy_coeff: 0.0
        kl: 0.009327619336545467
        model: {}
        policy_loss: -0.018654773011803627
        total_loss: -0.00511753698810935
        vf_explained_var: 0.671795666217804
        vf_loss: 0.013463451527059078
    load_time_ms: 1.994
    num_steps_sampled: 91000
    num_steps_trained: 91000
    sample_time_ms: 16068.021
    update_time_ms: 5.348
  iterations_since_restore: 163
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.12333333333333
    ram_util_percent: 13.913333333333329
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 304.01308605772465
    mean_inference_ms: 1.3342476732442632
    mean_processing_ms: 1.0469042566372246
  time_since_restore: 25265.953258752823
  time_this_iter_s: 20.799375534057617
  time_total_s: 33769.95879840851
  timestamp: 1638609382
  timesteps_since_restore: 81500
  timesteps_this_iter: 500
  timesteps_total: 91000
  training_iteration: 182
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    182 |            33770 | 91000 |  0.41931 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-16-35
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8674884437596302
  episode_reward_mean: 0.4239933643107671
  episode_reward_min: -0.2702702702702703
  episodes_this_iter: 500
  episodes_total: 91500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1641.61
    learner:
      default_policy:
        cur_kl_coeff: 0.00791015662252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.18763042986392975
        entropy_coeff: 0.0
        kl: 0.005214918404817581
        model: {}
        policy_loss: -0.009141738526523113
        total_loss: 0.007590594235807657
        vf_explained_var: 0.6571124196052551
        vf_loss: 0.016691086813807487
    load_time_ms: 2.025
    num_steps_sampled: 91500
    num_steps_trained: 91500
    sample_time_ms: 15729.506
    update_time_ms: 5.349
  iterations_since_restore: 164
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.952631578947365
    ram_util_percent: 13.915789473684212
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 302.28328967091227
    mean_inference_ms: 1.3325733608798929
    mean_processing_ms: 1.0454930034629124
  time_since_restore: 25278.75147819519
  time_this_iter_s: 12.798219442367554
  time_total_s: 33782.757017850876
  timestamp: 1638609395
  timesteps_since_restore: 82000
  timesteps_this_iter: 500
  timesteps_total: 91500
  training_iteration: 183
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    183 |          33782.8 | 91500 | 0.423993 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-16-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8680555555555556
  episode_reward_mean: 0.41980437072730353
  episode_reward_min: -0.38974358974358975
  episodes_this_iter: 500
  episodes_total: 92000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1630.035
    learner:
      default_policy:
        cur_kl_coeff: 0.00791015662252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.17844997346401215
        entropy_coeff: 0.0
        kl: 0.008876967243850231
        model: {}
        policy_loss: -0.008481759577989578
        total_loss: 0.007317530922591686
        vf_explained_var: 0.6384149789810181
        vf_loss: 0.015729064121842384
    load_time_ms: 2.02
    num_steps_sampled: 92000
    num_steps_trained: 92000
    sample_time_ms: 15007.801
    update_time_ms: 5.35
  iterations_since_restore: 165
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.883333333333333
    ram_util_percent: 13.9
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 300.56908489251845
    mean_inference_ms: 1.3307650518903438
    mean_processing_ms: 1.0439343088963609
  time_since_restore: 25291.188161611557
  time_this_iter_s: 12.436683416366577
  time_total_s: 33795.19370126724
  timestamp: 1638609407
  timesteps_since_restore: 82500
  timesteps_this_iter: 500
  timesteps_total: 92000
  training_iteration: 184
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    184 |          33795.2 | 92000 | 0.419804 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-16-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8678977272727273
  episode_reward_mean: 0.43219632036402045
  episode_reward_min: -0.4479166666666667
  episodes_this_iter: 500
  episodes_total: 92500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1640.164
    learner:
      default_policy:
        cur_kl_coeff: 0.00791015662252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.17120224237442017
        entropy_coeff: 0.0
        kl: 0.004807338584214449
        model: {}
        policy_loss: -0.008915583603084087
        total_loss: 0.009075183421373367
        vf_explained_var: 0.6161811351776123
        vf_loss: 0.017952734604477882
    load_time_ms: 2.028
    num_steps_sampled: 92500
    num_steps_trained: 92500
    sample_time_ms: 13982.569
    update_time_ms: 5.303
  iterations_since_restore: 166
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.96153846153846
    ram_util_percent: 13.900000000000002
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 298.83531333409144
    mean_inference_ms: 1.3290226048020644
    mean_processing_ms: 1.0423607625791365
  time_since_restore: 25300.176792621613
  time_this_iter_s: 8.988631010055542
  time_total_s: 33804.1823322773
  timestamp: 1638609417
  timesteps_since_restore: 83000
  timesteps_this_iter: 500
  timesteps_total: 92500
  training_iteration: 185
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    185 |          33804.2 | 92500 | 0.432196 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-17-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8732193732193733
  episode_reward_mean: 0.42285902530036257
  episode_reward_min: -0.49473684210526314
  episodes_this_iter: 500
  episodes_total: 93000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1645.785
    learner:
      default_policy:
        cur_kl_coeff: 0.003955078311264515
        cur_lr: 4.999999873689376e-05
        entropy: 0.16817981004714966
        entropy_coeff: 0.0
        kl: 0.008157139644026756
        model: {}
        policy_loss: -0.010282330214977264
        total_loss: 0.004038277082145214
        vf_explained_var: 0.6749334931373596
        vf_loss: 0.014288345351815224
    load_time_ms: 2.034
    num_steps_sampled: 93000
    num_steps_trained: 93000
    sample_time_ms: 13186.372
    update_time_ms: 5.304
  iterations_since_restore: 167
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.925
    ram_util_percent: 13.941666666666668
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 297.1148034261131
    mean_inference_ms: 1.3272472002456546
    mean_processing_ms: 1.0408195406703526
  time_since_restore: 25308.667214632034
  time_this_iter_s: 8.490422010421753
  time_total_s: 33812.67275428772
  timestamp: 1638609425
  timesteps_since_restore: 83500
  timesteps_this_iter: 500
  timesteps_total: 93000
  training_iteration: 186
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    186 |          33812.7 | 93000 | 0.422859 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-17-19
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8632352941176471
  episode_reward_mean: 0.4197579579871529
  episode_reward_min: -0.3285024154589372
  episodes_this_iter: 500
  episodes_total: 93500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1657.314
    learner:
      default_policy:
        cur_kl_coeff: 0.003955078311264515
        cur_lr: 4.999999873689376e-05
        entropy: 0.21441501379013062
        entropy_coeff: 0.0
        kl: 0.00940699502825737
        model: {}
        policy_loss: -0.008798169903457165
        total_loss: 0.004338163882493973
        vf_explained_var: 0.6733812689781189
        vf_loss: 0.013099128380417824
    load_time_ms: 2.026
    num_steps_sampled: 93500
    num_steps_trained: 93500
    sample_time_ms: 12921.987
    update_time_ms: 5.321
  iterations_since_restore: 168
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.43684210526316
    ram_util_percent: 13.910526315789474
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 295.471319035305
    mean_inference_ms: 1.3256709681606167
    mean_processing_ms: 1.039309052688403
  time_since_restore: 25321.82830119133
  time_this_iter_s: 13.161086559295654
  time_total_s: 33825.833840847015
  timestamp: 1638609439
  timesteps_since_restore: 84000
  timesteps_this_iter: 500
  timesteps_total: 93500
  training_iteration: 187
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    187 |          33825.8 | 93500 | 0.419758 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-17-33
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8544520547945206
  episode_reward_mean: 0.4149778330037532
  episode_reward_min: -0.2857142857142857
  episodes_this_iter: 500
  episodes_total: 94000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1660.031
    learner:
      default_policy:
        cur_kl_coeff: 0.003955078311264515
        cur_lr: 4.999999873689376e-05
        entropy: 0.18814849853515625
        entropy_coeff: 0.0
        kl: 0.004546680022031069
        model: {}
        policy_loss: -0.015892749652266502
        total_loss: -0.0030081833247095346
        vf_explained_var: 0.7056095600128174
        vf_loss: 0.012866580858826637
    load_time_ms: 2.037
    num_steps_sampled: 94000
    num_steps_trained: 94000
    sample_time_ms: 12429.421
    update_time_ms: 5.377
  iterations_since_restore: 169
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.209523809523812
    ram_util_percent: 13.899999999999999
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 293.8621300970797
    mean_inference_ms: 1.3240190276357446
    mean_processing_ms: 1.0378104162149033
  time_since_restore: 25336.305526018143
  time_this_iter_s: 14.477224826812744
  time_total_s: 33840.31106567383
  timestamp: 1638609453
  timesteps_since_restore: 84500
  timesteps_this_iter: 500
  timesteps_total: 94000
  training_iteration: 188
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    188 |          33840.3 | 94000 | 0.414978 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-17-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8683473389355743
  episode_reward_mean: 0.4144523916027342
  episode_reward_min: -1.6865671641791045
  episodes_this_iter: 500
  episodes_total: 94500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1655.464
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.18827538192272186
        entropy_coeff: 0.0
        kl: 0.005602148827165365
        model: {}
        policy_loss: -0.012914332561194897
        total_loss: 0.007294736336916685
        vf_explained_var: 0.6427809000015259
        vf_loss: 0.02019798941910267
    load_time_ms: 2.045
    num_steps_sampled: 94500
    num_steps_trained: 94500
    sample_time_ms: 11716.714
    update_time_ms: 5.448
  iterations_since_restore: 170
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.583333333333332
    ram_util_percent: 13.9
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 292.24531122185806
    mean_inference_ms: 1.322402641187871
    mean_processing_ms: 1.0363511484601433
  time_since_restore: 25348.44132590294
  time_this_iter_s: 12.135799884796143
  time_total_s: 33852.446865558624
  timestamp: 1638609466
  timesteps_since_restore: 85000
  timesteps_this_iter: 500
  timesteps_total: 94500
  training_iteration: 189
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    189 |          33852.4 | 94500 | 0.414452 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-17-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8620689655172413
  episode_reward_mean: 0.430445556960822
  episode_reward_min: -1.5105633802816902
  episodes_this_iter: 500
  episodes_total: 95000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1643.828
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.1769941747188568
        entropy_coeff: 0.0
        kl: 0.006308804731816053
        model: {}
        policy_loss: -0.01928853988647461
        total_loss: 0.0012617006432265043
        vf_explained_var: 0.675402045249939
        vf_loss: 0.020537767559289932
    load_time_ms: 2.037
    num_steps_sampled: 95000
    num_steps_trained: 95000
    sample_time_ms: 11266.907
    update_time_ms: 5.418
  iterations_since_restore: 171
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.142857142857142
    ram_util_percent: 13.907142857142858
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 290.6209800153059
    mean_inference_ms: 1.3207309997644612
    mean_processing_ms: 1.034807996305616
  time_since_restore: 25358.260064840317
  time_this_iter_s: 9.81873893737793
  time_total_s: 33862.265604496
  timestamp: 1638609476
  timesteps_since_restore: 85500
  timesteps_this_iter: 500
  timesteps_total: 95000
  training_iteration: 190
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    190 |          33862.3 | 95000 | 0.430446 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=1482)[0m Program ./new_unroll_garbage_1482/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-18-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8802992518703242
  episode_reward_mean: 0.42175568706328304
  episode_reward_min: -1.330935251798561
  episodes_this_iter: 500
  episodes_total: 95500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1653.081
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.15458030998706818
        entropy_coeff: 0.0
        kl: 0.0032198873814195395
        model: {}
        policy_loss: -0.009648916311562061
        total_loss: 0.013280529528856277
        vf_explained_var: 0.5290065407752991
        vf_loss: 0.022923080250620842
    load_time_ms: 2.048
    num_steps_sampled: 95500
    num_steps_trained: 95500
    sample_time_ms: 10938.231
    update_time_ms: 5.485
  iterations_since_restore: 172
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.53684210526316
    ram_util_percent: 13.905263157894737
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 289.05087375298217
    mean_inference_ms: 1.3191854841072819
    mean_processing_ms: 1.0334973784319512
  time_since_restore: 25371.225838184357
  time_this_iter_s: 12.965773344039917
  time_total_s: 33875.23137784004
  timestamp: 1638609489
  timesteps_since_restore: 86000
  timesteps_this_iter: 500
  timesteps_total: 95500
  training_iteration: 191
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    191 |          33875.2 | 95500 | 0.421756 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-18-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8779904306220095
  episode_reward_mean: 0.42279418869688934
  episode_reward_min: -0.38071065989847713
  episodes_this_iter: 500
  episodes_total: 96000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1642.546
    learner:
      default_policy:
        cur_kl_coeff: 0.0009887695778161287
        cur_lr: 4.999999873689376e-05
        entropy: 0.1575545221567154
        entropy_coeff: 0.0
        kl: 0.002638879930600524
        model: {}
        policy_loss: -0.007976578548550606
        total_loss: 0.006093224976211786
        vf_explained_var: 0.661220908164978
        vf_loss: 0.01406719908118248
    load_time_ms: 2.076
    num_steps_sampled: 96000
    num_steps_trained: 96000
    sample_time_ms: 9554.189
    update_time_ms: 5.478
  iterations_since_restore: 173
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.8
    ram_util_percent: 13.88
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 287.4296102133408
    mean_inference_ms: 1.3177017839192986
    mean_processing_ms: 1.0320194729396965
  time_since_restore: 25378.07939338684
  time_this_iter_s: 6.853555202484131
  time_total_s: 33882.084933042526
  timestamp: 1638609496
  timesteps_since_restore: 86500
  timesteps_this_iter: 500
  timesteps_total: 96000
  training_iteration: 192
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    192 |          33882.1 | 96000 | 0.422794 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-18-21
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9661416163697925
  episode_reward_mean: 0.4453558805948541
  episode_reward_min: -0.5625
  episodes_this_iter: 500
  episodes_total: 96500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1642.474
    learner:
      default_policy:
        cur_kl_coeff: 0.0004943847889080644
        cur_lr: 4.999999873689376e-05
        entropy: 0.16575045883655548
        entropy_coeff: 0.0
        kl: 0.0042670294642448425
        model: {}
        policy_loss: -0.009183713234961033
        total_loss: 0.010719762183725834
        vf_explained_var: 0.5681997537612915
        vf_loss: 0.019901365041732788
    load_time_ms: 2.04
    num_steps_sampled: 96500
    num_steps_trained: 96500
    sample_time_ms: 8800.366
    update_time_ms: 5.456
  iterations_since_restore: 174
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.4875
    ram_util_percent: 13.9
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 285.8084326353505
    mean_inference_ms: 1.315990657190133
    mean_processing_ms: 1.0305448224674119
  time_since_restore: 25383.338713645935
  time_this_iter_s: 5.259320259094238
  time_total_s: 33887.34425330162
  timestamp: 1638609501
  timesteps_since_restore: 87000
  timesteps_this_iter: 500
  timesteps_total: 96500
  training_iteration: 193
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    193 |          33887.3 | 96500 | 0.445356 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-18-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8970831040176115
  episode_reward_mean: 0.439808210260748
  episode_reward_min: -1.1533333333333333
  episodes_this_iter: 500
  episodes_total: 97000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1630.234
    learner:
      default_policy:
        cur_kl_coeff: 0.0002471923944540322
        cur_lr: 4.999999873689376e-05
        entropy: 0.16154199838638306
        entropy_coeff: 0.0
        kl: 0.005482306703925133
        model: {}
        policy_loss: -0.01628878153860569
        total_loss: 0.004598485771566629
        vf_explained_var: 0.5628069043159485
        vf_loss: 0.020885903388261795
    load_time_ms: 2.024
    num_steps_sampled: 97000
    num_steps_trained: 97000
    sample_time_ms: 8245.195
    update_time_ms: 5.558
  iterations_since_restore: 175
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.029999999999998
    ram_util_percent: 13.9
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 284.222979091704
    mean_inference_ms: 1.3143526791308278
    mean_processing_ms: 1.0290989239454729
  time_since_restore: 25390.102018117905
  time_this_iter_s: 6.7633044719696045
  time_total_s: 33894.10755777359
  timestamp: 1638609508
  timesteps_since_restore: 87500
  timesteps_this_iter: 500
  timesteps_total: 97000
  training_iteration: 194
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    194 |          33894.1 | 97000 | 0.439808 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-18-37
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8907242693773825
  episode_reward_mean: 0.44388431416677215
  episode_reward_min: -0.5792682926829268
  episodes_this_iter: 500
  episodes_total: 97500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1643.047
    learner:
      default_policy:
        cur_kl_coeff: 0.0002471923944540322
        cur_lr: 4.999999873689376e-05
        entropy: 0.14593282341957092
        entropy_coeff: 0.0
        kl: 0.0025969885755330324
        model: {}
        policy_loss: -0.004971749614924192
        total_loss: 0.010143425315618515
        vf_explained_var: 0.6573191285133362
        vf_loss: 0.01511454675346613
    load_time_ms: 2.048
    num_steps_sampled: 97500
    num_steps_trained: 97500
    sample_time_ms: 8143.928
    update_time_ms: 5.605
  iterations_since_restore: 176
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.391666666666666
    ram_util_percent: 13.908333333333337
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 282.66913914869855
    mean_inference_ms: 1.312795654578466
    mean_processing_ms: 1.0276506833613686
  time_since_restore: 25398.20640063286
  time_this_iter_s: 8.104382514953613
  time_total_s: 33902.211940288544
  timestamp: 1638609517
  timesteps_since_restore: 88000
  timesteps_this_iter: 500
  timesteps_total: 97500
  training_iteration: 195
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    195 |          33902.2 | 97500 | 0.443884 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-18-45
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8542944785276073
  episode_reward_mean: 0.42094616660341616
  episode_reward_min: -0.5573770491803278
  episodes_this_iter: 500
  episodes_total: 98000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1634.265
    learner:
      default_policy:
        cur_kl_coeff: 0.0001235961972270161
        cur_lr: 4.999999873689376e-05
        entropy: 0.15337294340133667
        entropy_coeff: 0.0
        kl: 0.005771941971033812
        model: {}
        policy_loss: -0.012757563963532448
        total_loss: 0.004801424685865641
        vf_explained_var: 0.5901819467544556
        vf_loss: 0.017558278515934944
    load_time_ms: 2.0
    num_steps_sampled: 98000
    num_steps_trained: 98000
    sample_time_ms: 8134.617
    update_time_ms: 5.626
  iterations_since_restore: 177
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.75
    ram_util_percent: 13.91666666666667
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 281.1359621341875
    mean_inference_ms: 1.311329986775369
    mean_processing_ms: 1.0263162745393453
  time_since_restore: 25406.51564002037
  time_this_iter_s: 8.309239387512207
  time_total_s: 33910.521179676056
  timestamp: 1638609525
  timesteps_since_restore: 88500
  timesteps_this_iter: 500
  timesteps_total: 98000
  training_iteration: 196
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    196 |          33910.5 | 98000 | 0.420946 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-18-58
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8660068519223448
  episode_reward_mean: 0.429331128523098
  episode_reward_min: -0.3872549019607843
  episodes_this_iter: 500
  episodes_total: 98500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1625.657
    learner:
      default_policy:
        cur_kl_coeff: 0.0001235961972270161
        cur_lr: 4.999999873689376e-05
        entropy: 0.15980814397335052
        entropy_coeff: 0.0
        kl: 0.006173461675643921
        model: {}
        policy_loss: -0.011293893679976463
        total_loss: 0.002036452293395996
        vf_explained_var: 0.6925289630889893
        vf_loss: 0.013329590670764446
    load_time_ms: 1.998
    num_steps_sampled: 98500
    num_steps_trained: 98500
    sample_time_ms: 8095.942
    update_time_ms: 5.707
  iterations_since_restore: 178
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.566666666666666
    ram_util_percent: 13.933333333333334
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 279.6703144932899
    mean_inference_ms: 1.309866985630889
    mean_processing_ms: 1.0249388354412436
  time_since_restore: 25419.2047457695
  time_this_iter_s: 12.689105749130249
  time_total_s: 33923.210285425186
  timestamp: 1638609538
  timesteps_since_restore: 89000
  timesteps_this_iter: 500
  timesteps_total: 98500
  training_iteration: 197
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    197 |          33923.2 | 98500 | 0.429331 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-19-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8708333333333333
  episode_reward_mean: 0.4135523728645306
  episode_reward_min: -1.4555160142348755
  episodes_this_iter: 500
  episodes_total: 99000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1615.315
    learner:
      default_policy:
        cur_kl_coeff: 0.0001235961972270161
        cur_lr: 4.999999873689376e-05
        entropy: 0.13862888514995575
        entropy_coeff: 0.0
        kl: 0.0033252805005759
        model: {}
        policy_loss: -0.011904561892151833
        total_loss: 0.006222680676728487
        vf_explained_var: 0.6873738169670105
        vf_loss: 0.018126841634511948
    load_time_ms: 1.98
    num_steps_sampled: 99000
    num_steps_trained: 99000
    sample_time_ms: 7426.979
    update_time_ms: 5.704
  iterations_since_restore: 179
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.441666666666666
    ram_util_percent: 13.925000000000002
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 278.16468518738844
    mean_inference_ms: 1.3083580521860292
    mean_processing_ms: 1.0235161756323983
  time_since_restore: 25426.88925766945
  time_this_iter_s: 7.68451189994812
  time_total_s: 33930.894797325134
  timestamp: 1638609546
  timesteps_since_restore: 89500
  timesteps_this_iter: 500
  timesteps_total: 99000
  training_iteration: 198
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    198 |          33930.9 | 99000 | 0.413552 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-19-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8680555555555556
  episode_reward_mean: 0.42565575922639776
  episode_reward_min: -0.38974358974358975
  episodes_this_iter: 500
  episodes_total: 99500
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1617.471
    learner:
      default_policy:
        cur_kl_coeff: 6.179809861350805e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.13339152932167053
        entropy_coeff: 0.0
        kl: 0.001832071808166802
        model: {}
        policy_loss: -0.007905060425400734
        total_loss: 0.008708545938134193
        vf_explained_var: 0.649441659450531
        vf_loss: 0.016613494604825974
    load_time_ms: 1.992
    num_steps_sampled: 99500
    num_steps_trained: 99500
    sample_time_ms: 7360.819
    update_time_ms: 5.655
  iterations_since_restore: 180
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.68125
    ram_util_percent: 13.9625
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 276.7173647065966
    mean_inference_ms: 1.3069658310889847
    mean_processing_ms: 1.0223183263305946
  time_since_restore: 25438.38542199135
  time_this_iter_s: 11.496164321899414
  time_total_s: 33942.390961647034
  timestamp: 1638609558
  timesteps_since_restore: 90000
  timesteps_this_iter: 500
  timesteps_total: 99500
  training_iteration: 199
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    199 |          33942.4 | 99500 | 0.425656 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-12-04_04-19-24
  done: true
  episode_len_mean: 1.0
  episode_reward_max: 0.8603628367234745
  episode_reward_mean: 0.4250773175436243
  episode_reward_min: -0.44623655913978494
  episodes_this_iter: 500
  episodes_total: 100000
  experiment_id: 4ce322bef21948ed909a866986aa4d76
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1638.441
    learner:
      default_policy:
        cur_kl_coeff: 3.089904930675402e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.13362988829612732
        entropy_coeff: 0.0
        kl: 0.0077781821601092815
        model: {}
        policy_loss: -0.011251842603087425
        total_loss: 0.006594948936253786
        vf_explained_var: 0.5837121605873108
        vf_loss: 0.01784655638039112
    load_time_ms: 1.993
    num_steps_sampled: 100000
    num_steps_trained: 100000
    sample_time_ms: 6960.766
    update_time_ms: 5.604
  iterations_since_restore: 181
  node_ip: 172.17.255.101
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.833333333333332
    ram_util_percent: 13.933333333333334
  pid: 1479
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 275.2242790841406
    mean_inference_ms: 1.3055200056534928
    mean_processing_ms: 1.0210471928255989
  time_since_restore: 25444.413058280945
  time_this_iter_s: 6.027636289596558
  time_total_s: 33948.41859793663
  timestamp: 1638609564
  timesteps_since_restore: 90500
  timesteps_this_iter: 500
  timesteps_total: 100000
  training_iteration: 200
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+--------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |     ts |   reward |
|-------------------+----------+---------------------+--------+------------------+--------+----------|
| PPO_autovec_00000 | RUNNING  | 172.17.255.101:1479 |    200 |          33948.4 | 100000 | 0.425077 |
+-------------------+----------+---------------------+--------+------------------+--------+----------+


== Status ==
Memory usage on this node: 1.7/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 TERMINATED)
+-------------------+------------+-------+--------+------------------+--------+----------+
| Trial name        | status     | loc   |   iter |   total time (s) |     ts |   reward |
|-------------------+------------+-------+--------+------------------+--------+----------|
| PPO_autovec_00000 | TERMINATED |       |    200 |          33948.4 | 100000 | 0.425077 |
+-------------------+------------+-------+--------+------------------+--------+----------+


