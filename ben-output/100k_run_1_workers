== Status ==
Memory usage on this node: 2.6/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+-------+
| Trial name        | status   | loc   |
|-------------------+----------+-------|
| PPO_autovec_00000 | RUNNING  |       |
+-------------------+----------+-------+


[2m[36m(pid=22795)[0m /home/bdmanley/anaconda3/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.
[2m[36m(pid=22795)[0m   for external in metadata.entry_points().get(self.group, []):
[2m[36m(pid=22795)[0m 2021-11-25 11:51:26,515	INFO trainer.py:428 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
[2m[36m(pid=22795)[0m 2021-11-25 11:51:26,528	WARNING deprecation.py:30 -- DeprecationWarning: `sample_batch_size` has been deprecated. Use `rollout_fragment_length` instead. This will raise an error in the future!
[2m[36m(pid=22795)[0m 2021-11-25 11:51:26,528	INFO trainer.py:585 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=22795)[0m creating ./new_garbage_22795 directory
[2m[36m(pid=22795)[0m running: cp -r ./training_data/* ./new_garbage_22795
[2m[36m(pid=22795)[0m cp: cannot stat './training_data/*': No such file or directory
[2m[36m(pid=22795)[0m =-=-=-=-=-=-=-=-= BEAN BEAN BEAN BEAN BEAN =-=-=-=-=-=-=-=-=
[2m[36m(pid=22795)[0m Low for all Boxes is 0.
[2m[36m(pid=22795)[0m High for first and third is 134, second is 4239, last is 1
[2m[36m(pid=22795)[0m =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
[2m[36m(pid=22795)[0m Checking if local obs_encodings.pkl file exists.
[2m[36m(pid=22795)[0m Checking if local O3_runtimes.pkl file exists to avoid waste of compilation.
[2m[36m(pid=22795)[0m Did not find O3_runtimes.pkl... Compiling to get -O3 runtimes.
[2m[36m(pid=22800)[0m /home/bdmanley/anaconda3/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.
[2m[36m(pid=22800)[0m   for external in metadata.entry_points().get(self.group, []):
[2m[36m(pid=22800)[0m creating ./new_garbage_22800 directory
[2m[36m(pid=22800)[0m running: cp -r ./training_data/* ./new_garbage_22800
[2m[36m(pid=22795)[0m 2021-11-25 11:51:32,063	INFO trainable.py:217 -- Getting current IP.
[2m[36m(pid=22795)[0m 2021-11-25 11:51:32,063	WARNING util.py:37 -- Install gputil for GPU system monitoring.
[2m[36m(pid=22800)[0m =-=-=-=-=-=-=-=-= BEAN BEAN BEAN BEAN BEAN =-=-=-=-=-=-=-=-=
[2m[36m(pid=22800)[0m Low for all Boxes is 0.
[2m[36m(pid=22800)[0m High for first and third is 134, second is 4239, last is 1
[2m[36m(pid=22800)[0m =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
[2m[36m(pid=22800)[0m Checking if local obs_encodings.pkl file exists.
[2m[36m(pid=22800)[0m found local obs_encodings.pkl.
[2m[36m(pid=22800)[0m Checking if local O3_runtimes.pkl file exists to avoid waste of compilation.
[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_12-00-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8514285714285714
  episode_reward_mean: 0.2762540238160288
  episode_reward_min: -5.496794871794871
  episodes_this_iter: 500
  episodes_total: 500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 2016.631
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 3.5405542850494385
        entropy_coeff: 0.0
        kl: 0.014955195598304272
        model: {}
        policy_loss: -0.06602558493614197
        total_loss: 0.11968637257814407
        vf_explained_var: 0.026819413527846336
        vf_loss: 0.18272092938423157
    load_time_ms: 88.22
    num_steps_sampled: 500
    num_steps_trained: 500
    sample_time_ms: 538882.464
    update_time_ms: 929.266
  iterations_since_restore: 1
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.599095607235142
    ram_util_percent: 25.52441860465116
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 1067.8523605217238
    mean_inference_ms: 2.0949878616485296
    mean_processing_ms: 1.4957734448705127
  time_since_restore: 541.9976851940155
  time_this_iter_s: 541.9976851940155
  time_total_s: 541.9976851940155
  timestamp: 1637863234
  timesteps_since_restore: 500
  timesteps_this_iter: 500
  timesteps_total: 500
  training_iteration: 1
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |      1 |          541.998 |  500 | 0.276254 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_12-08-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9210709318497914
  episode_reward_mean: 0.29832295193398856
  episode_reward_min: -3.0245398773006134
  episodes_this_iter: 500
  episodes_total: 1000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1836.273
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 3.5122177600860596
        entropy_coeff: 0.0
        kl: 0.0157918818295002
        model: {}
        policy_loss: -0.0883914977312088
        total_loss: 0.07426779717206955
        vf_explained_var: 0.06359590590000153
        vf_loss: 0.15950089693069458
    load_time_ms: 45.688
    num_steps_sampled: 1000
    num_steps_trained: 1000
    sample_time_ms: 517832.454
    update_time_ms: 467.616
  iterations_since_restore: 2
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.464416315049228
    ram_util_percent: 25.73670886075949
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 1028.9516768136345
    mean_inference_ms: 2.0096952264959156
    mean_processing_ms: 1.4680163129107222
  time_since_restore: 1040.4541985988617
  time_this_iter_s: 498.4565134048462
  time_total_s: 1040.4541985988617
  timestamp: 1637863732
  timesteps_since_restore: 1000
  timesteps_this_iter: 500
  timesteps_total: 1000
  training_iteration: 2
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |      2 |          1040.45 | 1000 | 0.298323 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_12-16-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8642117376294591
  episode_reward_mean: 0.33347679088405285
  episode_reward_min: -2.688888888888889
  episodes_this_iter: 500
  episodes_total: 1500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1798.498
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 3.4685862064361572
        entropy_coeff: 0.0
        kl: 0.018890835344791412
        model: {}
        policy_loss: -0.08973851054906845
        total_loss: 0.041717223823070526
        vf_explained_var: 0.09085825830698013
        vf_loss: 0.1276775598526001
    load_time_ms: 31.294
    num_steps_sampled: 1500
    num_steps_trained: 1500
    sample_time_ms: 501768.727
    update_time_ms: 313.744
  iterations_since_restore: 3
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.445022288261516
    ram_util_percent: 25.721396731054977
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 997.8983468964924
    mean_inference_ms: 1.977850642703042
    mean_processing_ms: 1.448133482605834
  time_since_restore: 1511.8360223770142
  time_this_iter_s: 471.38182377815247
  time_total_s: 1511.8360223770142
  timestamp: 1637864204
  timesteps_since_restore: 1500
  timesteps_this_iter: 500
  timesteps_total: 1500
  training_iteration: 3
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |      3 |          1511.84 | 1500 | 0.333477 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_12-24-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8674698795180723
  episode_reward_mean: 0.35810229206018557
  episode_reward_min: -3.658711217183771
  episodes_this_iter: 500
  episodes_total: 2000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1745.412
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 3.3870339393615723
        entropy_coeff: 0.0
        kl: 0.02309172786772251
        model: {}
        policy_loss: -0.09755261242389679
        total_loss: 0.0081282714381814
        vf_explained_var: 0.23601703345775604
        vf_loss: 0.10106252878904343
    load_time_ms: 24.078
    num_steps_sampled: 2000
    num_steps_trained: 2000
    sample_time_ms: 493475.166
    update_time_ms: 236.442
  iterations_since_restore: 4
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.286567164179104
    ram_util_percent: 25.75283582089552
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 981.852944286867
    mean_inference_ms: 1.9522624752153346
    mean_processing_ms: 1.4365153095830623
  time_since_restore: 1982.0324614048004
  time_this_iter_s: 470.19643902778625
  time_total_s: 1982.0324614048004
  timestamp: 1637864674
  timesteps_since_restore: 2000
  timesteps_this_iter: 500
  timesteps_total: 2000
  training_iteration: 4
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |      4 |          1982.03 | 2000 | 0.358102 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_12-32-13
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8640483383685801
  episode_reward_mean: 0.34079527545363547
  episode_reward_min: -2.2649006622516556
  episodes_this_iter: 500
  episodes_total: 2500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1724.657
    learner:
      default_policy:
        cur_kl_coeff: 0.30000001192092896
        cur_lr: 4.999999873689376e-05
        entropy: 3.2731752395629883
        entropy_coeff: 0.0
        kl: 0.02927483804523945
        model: {}
        policy_loss: -0.10761690884828568
        total_loss: -0.021807271987199783
        vf_explained_var: 0.13223141431808472
        vf_loss: 0.07702717930078506
    load_time_ms: 19.841
    num_steps_sampled: 2500
    num_steps_trained: 2500
    sample_time_ms: 486234.29
    update_time_ms: 189.968
  iterations_since_restore: 5
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.35145038167939
    ram_util_percent: 25.816030534351146
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 967.6907335172313
    mean_inference_ms: 1.9396784209289917
    mean_processing_ms: 1.4318327387062755
  time_since_restore: 2440.9604127407074
  time_this_iter_s: 458.927951335907
  time_total_s: 2440.9604127407074
  timestamp: 1637865133
  timesteps_since_restore: 2500
  timesteps_this_iter: 500
  timesteps_total: 2500
  training_iteration: 5
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |      5 |          2440.96 | 2500 | 0.340795 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_12-39-42
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.850828729281768
  episode_reward_mean: 0.3490279784176675
  episode_reward_min: -3.0604982206405693
  episodes_this_iter: 500
  episodes_total: 3000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1724.697
    learner:
      default_policy:
        cur_kl_coeff: 0.44999998807907104
        cur_lr: 4.999999873689376e-05
        entropy: 3.1715407371520996
        entropy_coeff: 0.0
        kl: 0.01975221373140812
        model: {}
        policy_loss: -0.09000074118375778
        total_loss: 0.015852048993110657
        vf_explained_var: 0.17354929447174072
        vf_loss: 0.0969642847776413
    load_time_ms: 16.953
    num_steps_sampled: 3000
    num_steps_trained: 3000
    sample_time_ms: 479715.19
    update_time_ms: 159.29
  iterations_since_restore: 6
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.398283931357254
    ram_util_percent: 25.85163806552262
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 954.8611818890059
    mean_inference_ms: 1.9322239292021477
    mean_processing_ms: 1.431943018886893
  time_since_restore: 2889.8222210407257
  time_this_iter_s: 448.8618083000183
  time_total_s: 2889.8222210407257
  timestamp: 1637865582
  timesteps_since_restore: 3000
  timesteps_this_iter: 500
  timesteps_total: 3000
  training_iteration: 6
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |      6 |          2889.82 | 3000 | 0.349028 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_12-46-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8736111111111111
  episode_reward_mean: 0.36042276309805893
  episode_reward_min: -2.774193548387097
  episodes_this_iter: 500
  episodes_total: 3500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1736.979
    learner:
      default_policy:
        cur_kl_coeff: 0.44999998807907104
        cur_lr: 4.999999873689376e-05
        entropy: 3.022934913635254
        entropy_coeff: 0.0
        kl: 0.020713770762085915
        model: {}
        policy_loss: -0.10469408333301544
        total_loss: -0.010302559472620487
        vf_explained_var: 0.21550439298152924
        vf_loss: 0.08507032692432404
    load_time_ms: 14.848
    num_steps_sampled: 3500
    num_steps_trained: 3500
    sample_time_ms: 471627.985
    update_time_ms: 137.279
  iterations_since_restore: 7
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.321122112211222
    ram_util_percent: 25.81584158415842
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 938.8428671432882
    mean_inference_ms: 1.9241806712364409
    mean_processing_ms: 1.4282427866504517
  time_since_restore: 3314.753764152527
  time_this_iter_s: 424.93154311180115
  time_total_s: 3314.753764152527
  timestamp: 1637866007
  timesteps_since_restore: 3500
  timesteps_this_iter: 500
  timesteps_total: 3500
  training_iteration: 7
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |      7 |          3314.75 | 3500 | 0.360423 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_12-53-35
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8499184339314845
  episode_reward_mean: 0.4069449102879078
  episode_reward_min: -1.8802395209580838
  episodes_this_iter: 500
  episodes_total: 4000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1718.11
    learner:
      default_policy:
        cur_kl_coeff: 0.675000011920929
        cur_lr: 4.999999873689376e-05
        entropy: 2.8672144412994385
        entropy_coeff: 0.0
        kl: 0.02299734763801098
        model: {}
        policy_loss: -0.10085062682628632
        total_loss: -0.02330990508198738
        vf_explained_var: 0.10902179777622223
        vf_loss: 0.062017496675252914
    load_time_ms: 13.278
    num_steps_sampled: 4000
    num_steps_trained: 4000
    sample_time_ms: 463447.012
    update_time_ms: 120.734
  iterations_since_restore: 8
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.260652920962201
    ram_util_percent: 25.838144329896913
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 922.5972675436947
    mean_inference_ms: 1.9197649909269503
    mean_processing_ms: 1.4251600173496364
  time_since_restore: 3722.535686969757
  time_this_iter_s: 407.7819228172302
  time_total_s: 3722.535686969757
  timestamp: 1637866415
  timesteps_since_restore: 4000
  timesteps_this_iter: 500
  timesteps_total: 4000
  training_iteration: 8
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |      8 |          3722.54 | 4000 | 0.406945 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_13-00-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8691588785046729
  episode_reward_mean: 0.39702120899724247
  episode_reward_min: -1.7099697885196374
  episodes_this_iter: 500
  episodes_total: 4500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1714.537
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 2.714214563369751
        entropy_coeff: 0.0
        kl: 0.01892535574734211
        model: {}
        policy_loss: -0.1105140745639801
        total_loss: -0.03544177860021591
        vf_explained_var: 0.240895077586174
        vf_loss: 0.0559103824198246
    load_time_ms: 12.144
    num_steps_sampled: 4500
    num_steps_trained: 4500
    sample_time_ms: 458314.454
    update_time_ms: 107.887
  iterations_since_restore: 9
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.15351170568562
    ram_util_percent: 25.84698996655519
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 912.4219147954032
    mean_inference_ms: 1.9165301052789314
    mean_processing_ms: 1.4211452952810615
  time_since_restore: 4141.4923260211945
  time_this_iter_s: 418.9566390514374
  time_total_s: 4141.4923260211945
  timestamp: 1637866834
  timesteps_since_restore: 4500
  timesteps_this_iter: 500
  timesteps_total: 4500
  training_iteration: 9
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |      9 |          4141.49 | 4500 | 0.397021 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_13-08-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8735795454545454
  episode_reward_mean: 0.33161886489117787
  episode_reward_min: -5.510158013544018
  episodes_this_iter: 500
  episodes_total: 5000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1724.21
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 2.599992275238037
        entropy_coeff: 0.0
        kl: 0.011252014897763729
        model: {}
        policy_loss: -0.0619356743991375
        total_loss: 0.1717909276485443
        vf_explained_var: 0.06785004585981369
        vf_loss: 0.22233395278453827
    load_time_ms: 11.167
    num_steps_sampled: 5000
    num_steps_trained: 5000
    sample_time_ms: 460866.918
    update_time_ms: 97.598
  iterations_since_restore: 10
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.197254335260116
    ram_util_percent: 25.867919075144517
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 917.5447917084674
    mean_inference_ms: 1.9391544626560526
    mean_processing_ms: 1.4428515549636658
  time_since_restore: 4627.159126758575
  time_this_iter_s: 485.666800737381
  time_total_s: 4627.159126758575
  timestamp: 1637867319
  timesteps_since_restore: 5000
  timesteps_this_iter: 500
  timesteps_total: 5000
  training_iteration: 10
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     10 |          4627.16 | 5000 | 0.331619 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_13-15-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.4365071263725939
  episode_reward_min: -1.4044117647058822
  episodes_this_iter: 500
  episodes_total: 5500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1686.581
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 2.4685447216033936
        entropy_coeff: 0.0
        kl: 0.013192513957619667
        model: {}
        policy_loss: -0.07542607188224792
        total_loss: -0.020538799464702606
        vf_explained_var: 0.35890284180641174
        vf_loss: 0.041529856622219086
    load_time_ms: 2.577
    num_steps_sampled: 5500
    num_steps_trained: 5500
    sample_time_ms: 447511.897
    update_time_ms: 5.155
  iterations_since_restore: 11
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.922891566265061
    ram_util_percent: 25.877969018932877
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 907.5106653901059
    mean_inference_ms: 1.9347361706967914
    mean_processing_ms: 1.4387068586378964
  time_since_restore: 5034.147535800934
  time_this_iter_s: 406.9884090423584
  time_total_s: 5034.147535800934
  timestamp: 1637867726
  timesteps_since_restore: 5500
  timesteps_this_iter: 500
  timesteps_total: 5500
  training_iteration: 11
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     11 |          5034.15 | 5500 | 0.436507 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_13-22-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8633633633633634
  episode_reward_mean: 0.44424157281342436
  episode_reward_min: -0.4540229885057471
  episodes_this_iter: 500
  episodes_total: 6000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1700.104
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 2.3347997665405273
        entropy_coeff: 0.0
        kl: 0.014602027833461761
        model: {}
        policy_loss: -0.07972344756126404
        total_loss: -0.04323423281311989
        vf_explained_var: 0.47486793994903564
        vf_loss: 0.02170466259121895
    load_time_ms: 2.489
    num_steps_sampled: 6000
    num_steps_trained: 6000
    sample_time_ms: 437963.799
    update_time_ms: 5.124
  iterations_since_restore: 12
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.85791304347826
    ram_util_percent: 25.84539130434783
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 898.4754292135773
    mean_inference_ms: 1.9312578327475822
    mean_processing_ms: 1.4366363013035015
  time_since_restore: 5437.257617712021
  time_this_iter_s: 403.11008191108704
  time_total_s: 5437.257617712021
  timestamp: 1637868129
  timesteps_since_restore: 6000
  timesteps_this_iter: 500
  timesteps_total: 6000
  training_iteration: 12
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     12 |          5437.26 | 6000 | 0.444242 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_13-28-45
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8541147132169576
  episode_reward_mean: 0.4579942489642243
  episode_reward_min: -1.125
  episodes_this_iter: 500
  episodes_total: 6500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1679.643
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 2.3087055683135986
        entropy_coeff: 0.0
        kl: 0.014425789937376976
        model: {}
        policy_loss: -0.08142220228910446
        total_loss: -0.03519156575202942
        vf_explained_var: 0.38092759251594543
        vf_loss: 0.03162452578544617
    load_time_ms: 2.489
    num_steps_sampled: 6500
    num_steps_trained: 6500
    sample_time_ms: 430431.378
    update_time_ms: 5.104
  iterations_since_restore: 13
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.791681415929203
    ram_util_percent: 25.852566371681416
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 889.7564873257487
    mean_inference_ms: 1.9283811049614668
    mean_processing_ms: 1.434060357713897
  time_since_restore: 5833.110099554062
  time_this_iter_s: 395.852481842041
  time_total_s: 5833.110099554062
  timestamp: 1637868525
  timesteps_since_restore: 6500
  timesteps_this_iter: 500
  timesteps_total: 6500
  training_iteration: 13
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     13 |          5833.11 | 6500 | 0.457994 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_13-35-38
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8753501400560224
  episode_reward_mean: 0.4469738981666519
  episode_reward_min: -2.6666666666666665
  episodes_this_iter: 500
  episodes_total: 7000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1670.241
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 2.1563053131103516
        entropy_coeff: 0.0
        kl: 0.010343058034777641
        model: {}
        policy_loss: -0.06545273959636688
        total_loss: -0.0008452129550278187
        vf_explained_var: 0.34375685453414917
        vf_loss: 0.05413518473505974
    load_time_ms: 2.486
    num_steps_sampled: 7000
    num_steps_trained: 7000
    sample_time_ms: 424685.517
    update_time_ms: 5.224
  iterations_since_restore: 14
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.9509337860781
    ram_util_percent: 25.850933786078105
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 884.6840970159648
    mean_inference_ms: 1.9266602312253378
    mean_processing_ms: 1.4322486166919302
  time_since_restore: 6245.7546145915985
  time_this_iter_s: 412.6445150375366
  time_total_s: 6245.7546145915985
  timestamp: 1637868938
  timesteps_since_restore: 7000
  timesteps_this_iter: 500
  timesteps_total: 7000
  training_iteration: 14
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     14 |          6245.75 | 7000 | 0.446974 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_13-41-54
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8731735827001753
  episode_reward_mean: 0.4990165316061375
  episode_reward_min: -0.29473684210526313
  episodes_this_iter: 500
  episodes_total: 7500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1672.155
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 2.0342159271240234
        entropy_coeff: 0.0
        kl: 0.011429193429648876
        model: {}
        policy_loss: -0.06687980890274048
        total_loss: -0.03785582259297371
        vf_explained_var: 0.4729035198688507
        vf_loss: 0.01745191402733326
    load_time_ms: 2.417
    num_steps_sampled: 7500
    num_steps_trained: 7500
    sample_time_ms: 416413.032
    update_time_ms: 5.276
  iterations_since_restore: 15
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.723463687150838
    ram_util_percent: 25.900558659217882
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 875.4099454423326
    mean_inference_ms: 1.9249187884466148
    mean_processing_ms: 1.4307691548414474
  time_since_restore: 6621.9767162799835
  time_this_iter_s: 376.222101688385
  time_total_s: 6621.9767162799835
  timestamp: 1637869314
  timesteps_since_restore: 7500
  timesteps_this_iter: 500
  timesteps_total: 7500
  training_iteration: 15
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     15 |          6621.98 | 7500 | 0.499017 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_13-48-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.4737364673199295
  episode_reward_min: -1.1628664495114007
  episodes_this_iter: 500
  episodes_total: 8000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1668.618
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.9964606761932373
        entropy_coeff: 0.0
        kl: 0.011223205365240574
        model: {}
        policy_loss: -0.07365450263023376
        total_loss: -0.02267618663609028
        vf_explained_var: 0.3986146152019501
        vf_loss: 0.03961481899023056
    load_time_ms: 2.42
    num_steps_sampled: 8000
    num_steps_trained: 8000
    sample_time_ms: 410919.396
    update_time_ms: 5.177
  iterations_since_restore: 16
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.792170818505339
    ram_util_percent: 25.895907473309617
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 869.5010845995802
    mean_inference_ms: 1.9222161066918024
    mean_processing_ms: 1.429197833234408
  time_since_restore: 7015.865578651428
  time_this_iter_s: 393.8888623714447
  time_total_s: 7015.865578651428
  timestamp: 1637869708
  timesteps_since_restore: 8000
  timesteps_this_iter: 500
  timesteps_total: 8000
  training_iteration: 16
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     16 |          7015.87 | 8000 | 0.473736 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_13-54-45
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9674665096422789
  episode_reward_mean: 0.4667270815680571
  episode_reward_min: -2.158904109589041
  episodes_this_iter: 500
  episodes_total: 8500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1668.838
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.8135370016098022
        entropy_coeff: 0.0
        kl: 0.010986482724547386
        model: {}
        policy_loss: -0.07517939805984497
        total_loss: -0.004907654598355293
        vf_explained_var: 0.3674216866493225
        vf_loss: 0.059147924184799194
    load_time_ms: 2.49
    num_steps_sampled: 8500
    num_steps_trained: 8500
    sample_time_ms: 406135.202
    update_time_ms: 5.198
  iterations_since_restore: 17
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.962825278810408
    ram_util_percent: 25.90018587360595
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 862.2999302346125
    mean_inference_ms: 1.9183460087961848
    mean_processing_ms: 1.426460574394309
  time_since_restore: 7392.958251476288
  time_this_iter_s: 377.0926728248596
  time_total_s: 7392.958251476288
  timestamp: 1637870085
  timesteps_since_restore: 8500
  timesteps_this_iter: 500
  timesteps_total: 8500
  training_iteration: 17
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     17 |          7392.96 | 8500 | 0.466727 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_14-00-58
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8918238993710692
  episode_reward_mean: 0.4989457984302974
  episode_reward_min: -1.0885416666666667
  episodes_this_iter: 500
  episodes_total: 9000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1684.889
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.88395357131958
        entropy_coeff: 0.0
        kl: 0.007968650199472904
        model: {}
        policy_loss: -0.05891936272382736
        total_loss: -0.02575443498790264
        vf_explained_var: 0.504875898361206
        vf_loss: 0.025096673518419266
    load_time_ms: 2.475
    num_steps_sampled: 9000
    num_steps_trained: 9000
    sample_time_ms: 402567.091
    update_time_ms: 5.352
  iterations_since_restore: 18
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.795856873822975
    ram_util_percent: 25.898870056497174
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 855.3698693841127
    mean_inference_ms: 1.914509586884755
    mean_processing_ms: 1.423764448671285
  time_since_restore: 7765.221111536026
  time_this_iter_s: 372.26286005973816
  time_total_s: 7765.221111536026
  timestamp: 1637870458
  timesteps_since_restore: 9000
  timesteps_this_iter: 500
  timesteps_total: 9000
  training_iteration: 18
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     18 |          7765.22 | 9000 | 0.498946 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_14-07-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9036873968079252
  episode_reward_mean: 0.5005224202931258
  episode_reward_min: -1.7616438356164383
  episodes_this_iter: 500
  episodes_total: 9500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1694.883
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.8044183254241943
        entropy_coeff: 0.0
        kl: 0.007564326748251915
        model: {}
        policy_loss: -0.06027083098888397
        total_loss: -0.026421699672937393
        vf_explained_var: 0.47000378370285034
        vf_loss: 0.026190239936113358
    load_time_ms: 2.465
    num_steps_sampled: 9500
    num_steps_trained: 9500
    sample_time_ms: 397888.47
    update_time_ms: 5.276
  iterations_since_restore: 19
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.793973634651602
    ram_util_percent: 25.89039548022599
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 849.1655683131011
    mean_inference_ms: 1.911681070539552
    mean_processing_ms: 1.4209371656508787
  time_since_restore: 8137.491264343262
  time_this_iter_s: 372.2701528072357
  time_total_s: 8137.491264343262
  timestamp: 1637870830
  timesteps_since_restore: 9500
  timesteps_this_iter: 500
  timesteps_total: 9500
  training_iteration: 19
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |   ts |   reward |
|-------------------+----------+---------------------+--------+------------------+------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     19 |          8137.49 | 9500 | 0.500522 |
+-------------------+----------+---------------------+--------+------------------+------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_14-13-24
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8970775095298602
  episode_reward_mean: 0.5117230027732368
  episode_reward_min: -0.8891013384321224
  episodes_this_iter: 500
  episodes_total: 10000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1658.209
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.7022360563278198
        entropy_coeff: 0.0
        kl: 0.008787503466010094
        model: {}
        policy_loss: -0.06125379726290703
        total_loss: -0.03240368887782097
        vf_explained_var: 0.5181787014007568
        vf_loss: 0.01995275355875492
    load_time_ms: 2.519
    num_steps_sampled: 10000
    num_steps_trained: 10000
    sample_time_ms: 386762.213
    update_time_ms: 5.291
  iterations_since_restore: 20
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.635580524344569
    ram_util_percent: 25.88614232209738
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 843.7912678697111
    mean_inference_ms: 1.9089861424395276
    mean_processing_ms: 1.4199442463437986
  time_since_restore: 8511.528736829758
  time_this_iter_s: 374.037472486496
  time_total_s: 8511.528736829758
  timestamp: 1637871204
  timesteps_since_restore: 10000
  timesteps_this_iter: 500
  timesteps_total: 10000
  training_iteration: 20
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     20 |          8511.53 | 10000 | 0.511723 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_14-19-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610271903323263
  episode_reward_mean: 0.4715109559522156
  episode_reward_min: -0.9204545454545454
  episodes_this_iter: 500
  episodes_total: 10500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1673.091
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.7413573265075684
        entropy_coeff: 0.0
        kl: 0.009327968582510948
        model: {}
        policy_loss: -0.07321510463953018
        total_loss: -0.0366801880300045
        vf_explained_var: 0.45864197611808777
        vf_loss: 0.027090342715382576
    load_time_ms: 2.536
    num_steps_sampled: 10500
    num_steps_trained: 10500
    sample_time_ms: 382765.607
    update_time_ms: 5.289
  iterations_since_restore: 21
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.004770992366412
    ram_util_percent: 25.890648854961835
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 838.2447560552575
    mean_inference_ms: 1.9059526773875424
    mean_processing_ms: 1.4172512830387878
  time_since_restore: 8878.700248479843
  time_this_iter_s: 367.17151165008545
  time_total_s: 8878.700248479843
  timestamp: 1637871571
  timesteps_since_restore: 10500
  timesteps_this_iter: 500
  timesteps_total: 10500
  training_iteration: 21
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     21 |           8878.7 | 10500 | 0.471511 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_14-25-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8596214511041009
  episode_reward_mean: 0.4842111031958204
  episode_reward_min: -1.0712074303405572
  episodes_this_iter: 500
  episodes_total: 11000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1679.07
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.6669869422912598
        entropy_coeff: 0.0
        kl: 0.00737615954130888
        model: {}
        policy_loss: -0.058993224054574966
        total_loss: -0.03200564533472061
        vf_explained_var: 0.5149083733558655
        vf_loss: 0.019519217312335968
    load_time_ms: 2.536
    num_steps_sampled: 11000
    num_steps_trained: 11000
    sample_time_ms: 375949.986
    update_time_ms: 5.334
  iterations_since_restore: 22
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.878242677824266
    ram_util_percent: 25.88347280334728
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 830.2763302904206
    mean_inference_ms: 1.901568569775961
    mean_processing_ms: 1.4135549528123508
  time_since_restore: 9213.713527441025
  time_this_iter_s: 335.01327896118164
  time_total_s: 9213.713527441025
  timestamp: 1637871906
  timesteps_since_restore: 11000
  timesteps_this_iter: 500
  timesteps_total: 11000
  training_iteration: 22
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     22 |          9213.71 | 11000 | 0.484211 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_14-30-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8736111111111111
  episode_reward_mean: 0.4892243321118422
  episode_reward_min: -1.135135135135135
  episodes_this_iter: 500
  episodes_total: 11500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1702.093
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.5887531042099
        entropy_coeff: 0.0
        kl: 0.005593662150204182
        model: {}
        policy_loss: -0.05547802150249481
        total_loss: -0.028997158631682396
        vf_explained_var: 0.5525901317596436
        vf_loss: 0.02081727795302868
    load_time_ms: 2.54
    num_steps_sampled: 11500
    num_steps_trained: 11500
    sample_time_ms: 371319.899
    update_time_ms: 5.406
  iterations_since_restore: 23
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.815430861723446
    ram_util_percent: 25.864328657314626
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 824.292932693963
    mean_inference_ms: 1.8977852098196133
    mean_processing_ms: 1.4107191669413361
  time_since_restore: 9563.495654821396
  time_this_iter_s: 349.7821273803711
  time_total_s: 9563.495654821396
  timestamp: 1637872256
  timesteps_since_restore: 11500
  timesteps_this_iter: 500
  timesteps_total: 11500
  training_iteration: 23
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     23 |           9563.5 | 11500 | 0.489224 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_14-36-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.4940000042719281
  episode_reward_min: -1.3827751196172249
  episodes_this_iter: 500
  episodes_total: 12000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1725.038
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.538564920425415
        entropy_coeff: 0.0
        kl: 0.007896831259131432
        model: {}
        policy_loss: -0.05400414392352104
        total_loss: -0.022874880582094193
        vf_explained_var: 0.48183396458625793
        vf_loss: 0.023133736103773117
    load_time_ms: 2.542
    num_steps_sampled: 12000
    num_steps_trained: 12000
    sample_time_ms: 364461.507
    update_time_ms: 5.359
  iterations_since_restore: 24
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.834623217922607
    ram_util_percent: 25.869042769857437
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 818.3534383157942
    mean_inference_ms: 1.8938355580557091
    mean_processing_ms: 1.4079250839191437
  time_since_restore: 9907.785892486572
  time_this_iter_s: 344.2902376651764
  time_total_s: 9907.785892486572
  timestamp: 1637872601
  timesteps_since_restore: 12000
  timesteps_this_iter: 500
  timesteps_total: 12000
  training_iteration: 24
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     24 |          9907.79 | 12000 |    0.494 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_14-42-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8702064896755162
  episode_reward_mean: 0.4901287883360189
  episode_reward_min: -0.982089552238806
  episodes_this_iter: 500
  episodes_total: 12500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1741.872
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.557993769645691
        entropy_coeff: 0.0
        kl: 0.006211295258253813
        model: {}
        policy_loss: -0.047863226383924484
        total_loss: -0.0156850703060627
        vf_explained_var: 0.4971715211868286
        vf_loss: 0.025889219716191292
    load_time_ms: 2.566
    num_steps_sampled: 12500
    num_steps_trained: 12500
    sample_time_ms: 359291.147
    update_time_ms: 5.483
  iterations_since_restore: 25
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.768682505399568
    ram_util_percent: 25.881209503239745
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 811.3144052647543
    mean_inference_ms: 1.8891023355582726
    mean_processing_ms: 1.4047764576050707
  time_since_restore: 10232.474584817886
  time_this_iter_s: 324.6886923313141
  time_total_s: 10232.474584817886
  timestamp: 1637872925
  timesteps_since_restore: 12500
  timesteps_this_iter: 500
  timesteps_total: 12500
  training_iteration: 25
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     25 |          10232.5 | 12500 | 0.490129 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_14-47-13
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8707386363636364
  episode_reward_mean: 0.48980300465967785
  episode_reward_min: -1.0069605568445477
  episodes_this_iter: 500
  episodes_total: 13000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1750.671
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.4873127937316895
        entropy_coeff: 0.0
        kl: 0.00718854833394289
        model: {}
        policy_loss: -0.0485939159989357
        total_loss: -0.024618737399578094
        vf_explained_var: 0.5459791421890259
        vf_loss: 0.016696779057383537
    load_time_ms: 2.533
    num_steps_sampled: 13000
    num_steps_trained: 13000
    sample_time_ms: 350652.578
    update_time_ms: 5.584
  iterations_since_restore: 26
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.85876993166287
    ram_util_percent: 25.946241457858772
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 803.5072238342035
    mean_inference_ms: 1.8839713252789143
    mean_processing_ms: 1.4009039802337075
  time_since_restore: 10540.066878080368
  time_this_iter_s: 307.5922932624817
  time_total_s: 10540.066878080368
  timestamp: 1637873233
  timesteps_since_restore: 13000
  timesteps_this_iter: 500
  timesteps_total: 13000
  training_iteration: 26
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     26 |          10540.1 | 13000 | 0.489803 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_14-52-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8684627575277337
  episode_reward_mean: 0.4738824841589834
  episode_reward_min: -0.35911602209944754
  episodes_this_iter: 500
  episodes_total: 13500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1726.735
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.559015154838562
        entropy_coeff: 0.0
        kl: 0.008429267443716526
        model: {}
        policy_loss: -0.06152212619781494
        total_loss: -0.037099625915288925
        vf_explained_var: 0.6052998304367065
        vf_loss: 0.015887875109910965
    load_time_ms: 2.464
    num_steps_sampled: 13500
    num_steps_trained: 13500
    sample_time_ms: 343097.847
    update_time_ms: 5.605
  iterations_since_restore: 27
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.642325581395351
    ram_util_percent: 25.87325581395349
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 795.8304064599295
    mean_inference_ms: 1.8780831009994996
    mean_processing_ms: 1.396016962978012
  time_since_restore: 10841.373507261276
  time_this_iter_s: 301.3066291809082
  time_total_s: 10841.373507261276
  timestamp: 1637873534
  timesteps_since_restore: 13500
  timesteps_this_iter: 500
  timesteps_total: 13500
  training_iteration: 27
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     27 |          10841.4 | 13500 | 0.473882 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_14-57-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8632352941176471
  episode_reward_mean: 0.49709896906078627
  episode_reward_min: -1.5704225352112675
  episodes_this_iter: 500
  episodes_total: 14000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1718.416
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.4329396486282349
        entropy_coeff: 0.0
        kl: 0.005354313645511866
        model: {}
        policy_loss: -0.046598710119724274
        total_loss: -0.02008916437625885
        vf_explained_var: 0.5202375650405884
        vf_loss: 0.021088313311338425
    load_time_ms: 2.476
    num_steps_sampled: 14000
    num_steps_trained: 14000
    sample_time_ms: 335455.722
    update_time_ms: 5.371
  iterations_since_restore: 28
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.824407582938388
    ram_util_percent: 25.872274881516592
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 788.3010142854721
    mean_inference_ms: 1.871602704342617
    mean_processing_ms: 1.390872806423469
  time_since_restore: 11137.12959432602
  time_this_iter_s: 295.75608706474304
  time_total_s: 11137.12959432602
  timestamp: 1637873830
  timesteps_since_restore: 14000
  timesteps_this_iter: 500
  timesteps_total: 14000
  training_iteration: 28
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     28 |          11137.1 | 14000 | 0.497099 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-01-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8439490445859873
  episode_reward_mean: 0.49309204274082497
  episode_reward_min: -1.1384615384615384
  episodes_this_iter: 500
  episodes_total: 14500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1687.183
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.501367211341858
        entropy_coeff: 0.0
        kl: 0.007243323139846325
        model: {}
        policy_loss: -0.051253221929073334
        total_loss: -0.0263525303453207
        vf_explained_var: 0.5641958713531494
        vf_loss: 0.017566824331879616
    load_time_ms: 2.403
    num_steps_sampled: 14500
    num_steps_trained: 14500
    sample_time_ms: 326351.408
    update_time_ms: 5.459
  iterations_since_restore: 29
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.87506234413965
    ram_util_percent: 25.8638403990025
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 780.2799441355539
    mean_inference_ms: 1.8654714394549605
    mean_processing_ms: 1.3864598235757781
  time_since_restore: 11418.043971300125
  time_this_iter_s: 280.91437697410583
  time_total_s: 11418.043971300125
  timestamp: 1637874111
  timesteps_since_restore: 14500
  timesteps_this_iter: 500
  timesteps_total: 14500
  training_iteration: 29
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     29 |            11418 | 14500 | 0.493092 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-06-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8753501400560224
  episode_reward_mean: 0.49003822348814846
  episode_reward_min: -0.8626666666666667
  episodes_this_iter: 500
  episodes_total: 15000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1728.643
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.4113720655441284
        entropy_coeff: 0.0
        kl: 0.006331874523311853
        model: {}
        policy_loss: -0.051153916865587234
        total_loss: -0.02243804931640625
        vf_explained_var: 0.5137240290641785
        vf_loss: 0.022304847836494446
    load_time_ms: 2.335
    num_steps_sampled: 15000
    num_steps_trained: 15000
    sample_time_ms: 315349.057
    update_time_ms: 5.423
  iterations_since_restore: 30
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.756233421750665
    ram_util_percent: 25.882758620689653
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 771.6724488125049
    mean_inference_ms: 1.858113487675447
    mean_processing_ms: 1.3805756162988385
  time_since_restore: 11682.472528457642
  time_this_iter_s: 264.4285571575165
  time_total_s: 11682.472528457642
  timestamp: 1637874376
  timesteps_since_restore: 15000
  timesteps_this_iter: 500
  timesteps_total: 15000
  training_iteration: 30
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     30 |          11682.5 | 15000 | 0.490038 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-10-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8890274314214464
  episode_reward_mean: 0.5185815549538603
  episode_reward_min: -0.3159722222222222
  episodes_this_iter: 500
  episodes_total: 15500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1708.771
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.3592088222503662
        entropy_coeff: 0.0
        kl: 0.009606916457414627
        model: {}
        policy_loss: -0.053795814514160156
        total_loss: -0.03025931306183338
        vf_explained_var: 0.5485991835594177
        vf_loss: 0.013809499330818653
    load_time_ms: 2.315
    num_steps_sampled: 15500
    num_steps_trained: 15500
    sample_time_ms: 302883.749
    update_time_ms: 5.605
  iterations_since_restore: 31
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.670809248554912
    ram_util_percent: 25.909826589595383
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 762.2127134133505
    mean_inference_ms: 1.850552008572059
    mean_processing_ms: 1.3743137038220863
  time_since_restore: 11924.793629407883
  time_this_iter_s: 242.3211009502411
  time_total_s: 11924.793629407883
  timestamp: 1637874618
  timesteps_since_restore: 15500
  timesteps_this_iter: 500
  timesteps_total: 15500
  training_iteration: 31
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     31 |          11924.8 | 15500 | 0.518582 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-14-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.883385579937304
  episode_reward_mean: 0.5113361992856491
  episode_reward_min: -1.6422764227642277
  episodes_this_iter: 500
  episodes_total: 16000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1698.197
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.2982258796691895
        entropy_coeff: 0.0
        kl: 0.0069654942490160465
        model: {}
        policy_loss: -0.0445801243185997
        total_loss: -0.016479436308145523
        vf_explained_var: 0.5311475396156311
        vf_loss: 0.02104812301695347
    load_time_ms: 2.308
    num_steps_sampled: 16000
    num_steps_trained: 16000
    sample_time_ms: 291841.233
    update_time_ms: 5.612
  iterations_since_restore: 32
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.890654205607476
    ram_util_percent: 25.96323987538941
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 752.2223422649641
    mean_inference_ms: 1.8419973269588288
    mean_processing_ms: 1.3674774972150252
  time_since_restore: 12149.276863574982
  time_this_iter_s: 224.483234167099
  time_total_s: 12149.276863574982
  timestamp: 1637874843
  timesteps_since_restore: 16000
  timesteps_this_iter: 500
  timesteps_total: 16000
  training_iteration: 32
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     32 |          12149.3 | 16000 | 0.511336 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-17-45
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9674665096422789
  episode_reward_mean: 0.5089384690402852
  episode_reward_min: -0.9376199616122841
  episodes_this_iter: 500
  episodes_total: 16500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1700.965
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.2910363674163818
        entropy_coeff: 0.0
        kl: 0.007081172429025173
        model: {}
        policy_loss: -0.052952881902456284
        total_loss: -0.024837158620357513
        vf_explained_var: 0.5540477633476257
        vf_loss: 0.020946048200130463
    load_time_ms: 2.283
    num_steps_sampled: 16500
    num_steps_trained: 16500
    sample_time_ms: 279041.689
    update_time_ms: 5.592
  iterations_since_restore: 33
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.655063291139241
    ram_util_percent: 25.960759493670892
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 742.6737367539729
    mean_inference_ms: 1.8338147426878244
    mean_processing_ms: 1.3612186928227714
  time_since_restore: 12371.091096162796
  time_this_iter_s: 221.81423258781433
  time_total_s: 12371.091096162796
  timestamp: 1637875065
  timesteps_since_restore: 16500
  timesteps_this_iter: 500
  timesteps_total: 16500
  training_iteration: 33
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     33 |          12371.1 | 16500 | 0.508938 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-21-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8943313153549808
  episode_reward_mean: 0.5278155466372946
  episode_reward_min: -0.21608040201005024
  episodes_this_iter: 500
  episodes_total: 17000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1713.077
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.3212411403656006
        entropy_coeff: 0.0
        kl: 0.01271328330039978
        model: {}
        policy_loss: -0.06981565803289413
        total_loss: -0.04381256550550461
        vf_explained_var: 0.549772322177887
        vf_loss: 0.013130886480212212
    load_time_ms: 2.276
    num_steps_sampled: 17000
    num_steps_trained: 17000
    sample_time_ms: 267992.698
    update_time_ms: 5.655
  iterations_since_restore: 34
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.783832335329341
    ram_util_percent: 25.92604790419162
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 734.395496298738
    mean_inference_ms: 1.8262802295899097
    mean_processing_ms: 1.3546298990585641
  time_since_restore: 12605.013746023178
  time_this_iter_s: 233.92264986038208
  time_total_s: 12605.013746023178
  timestamp: 1637875299
  timesteps_since_restore: 17000
  timesteps_this_iter: 500
  timesteps_total: 17000
  training_iteration: 34
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     34 |            12605 | 17000 | 0.527816 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-25-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8884335154826958
  episode_reward_mean: 0.5085718979659875
  episode_reward_min: -0.9950199203187251
  episodes_this_iter: 500
  episodes_total: 17500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1699.258
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.2808758020401
        entropy_coeff: 0.0
        kl: 0.0057724774815142155
        model: {}
        policy_loss: -0.052522748708724976
        total_loss: -0.02488292194902897
        vf_explained_var: 0.5148349404335022
        vf_loss: 0.02179519459605217
    load_time_ms: 2.249
    num_steps_sampled: 17500
    num_steps_trained: 17500
    sample_time_ms: 256908.003
    update_time_ms: 5.712
  iterations_since_restore: 35
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.851803278688525
    ram_util_percent: 25.926557377049182
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 725.4442603416045
    mean_inference_ms: 1.819150855586049
    mean_processing_ms: 1.348069446930565
  time_since_restore: 12818.717039585114
  time_this_iter_s: 213.70329356193542
  time_total_s: 12818.717039585114
  timestamp: 1637875512
  timesteps_since_restore: 17500
  timesteps_this_iter: 500
  timesteps_total: 17500
  training_iteration: 35
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     35 |          12818.7 | 17500 | 0.508572 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-28-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5109160134864479
  episode_reward_min: -0.30526315789473685
  episodes_this_iter: 500
  episodes_total: 18000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1695.649
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.2138173580169678
        entropy_coeff: 0.0
        kl: 0.009929569438099861
        model: {}
        policy_loss: -0.05485949665307999
        total_loss: -0.030240725725889206
        vf_explained_var: 0.5547321438789368
        vf_loss: 0.01456507295370102
    load_time_ms: 2.266
    num_steps_sampled: 18000
    num_steps_trained: 18000
    sample_time_ms: 247020.405
    update_time_ms: 5.701
  iterations_since_restore: 36
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.794295302013422
    ram_util_percent: 25.946979865771816
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 716.7089906349942
    mean_inference_ms: 1.8120582325843555
    mean_processing_ms: 1.3417299108620213
  time_since_restore: 13027.396846532822
  time_this_iter_s: 208.67980694770813
  time_total_s: 13027.396846532822
  timestamp: 1637875721
  timesteps_since_restore: 18000
  timesteps_this_iter: 500
  timesteps_total: 18000
  training_iteration: 36
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     36 |          13027.4 | 18000 | 0.510916 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-32-13
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8564668769716088
  episode_reward_mean: 0.4878211924717539
  episode_reward_min: -1.4029850746268657
  episodes_this_iter: 500
  episodes_total: 18500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1718.812
    learner:
      default_policy:
        cur_kl_coeff: 1.0125000476837158
        cur_lr: 4.999999873689376e-05
        entropy: 1.2108227014541626
        entropy_coeff: 0.0
        kl: 0.0048284525983035564
        model: {}
        policy_loss: -0.05153019353747368
        total_loss: -0.0184358861297369
        vf_explained_var: 0.5320224761962891
        vf_loss: 0.028205499053001404
    load_time_ms: 2.29
    num_steps_sampled: 18500
    num_steps_trained: 18500
    sample_time_ms: 238014.104
    update_time_ms: 5.694
  iterations_since_restore: 37
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.774834437086092
    ram_util_percent: 25.946026490066227
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 708.5933106685679
    mean_inference_ms: 1.8049293540953353
    mean_processing_ms: 1.3362688023646734
  time_since_restore: 13238.871192455292
  time_this_iter_s: 211.4743459224701
  time_total_s: 13238.871192455292
  timestamp: 1637875933
  timesteps_since_restore: 18500
  timesteps_this_iter: 500
  timesteps_total: 18500
  training_iteration: 37
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     37 |          13238.9 | 18500 | 0.487821 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-35-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8736111111111111
  episode_reward_mean: 0.4878177488673285
  episode_reward_min: -1.4594594594594594
  episodes_this_iter: 500
  episodes_total: 19000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1723.163
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.1444076299667358
        entropy_coeff: 0.0
        kl: 0.008809560909867287
        model: {}
        policy_loss: -0.046664685010910034
        total_loss: -0.02305976115167141
        vf_explained_var: 0.6085229516029358
        vf_loss: 0.01914508081972599
    load_time_ms: 2.315
    num_steps_sampled: 19000
    num_steps_trained: 19000
    sample_time_ms: 227946.054
    update_time_ms: 5.842
  iterations_since_restore: 38
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.702158273381293
    ram_util_percent: 25.92841726618705
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 700.0501651988773
    mean_inference_ms: 1.798056908691753
    mean_processing_ms: 1.3303672895325618
  time_since_restore: 13433.992183685303
  time_this_iter_s: 195.120991230011
  time_total_s: 13433.992183685303
  timestamp: 1637876128
  timesteps_since_restore: 19000
  timesteps_this_iter: 500
  timesteps_total: 19000
  training_iteration: 38
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     38 |            13434 | 19000 | 0.487818 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-38-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.5041979525366073
  episode_reward_min: -1.2026143790849673
  episodes_this_iter: 500
  episodes_total: 19500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1734.467
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.086524248123169
        entropy_coeff: 0.0
        kl: 0.007818067446351051
        model: {}
        policy_loss: -0.053515199571847916
        total_loss: -0.02983938530087471
        vf_explained_var: 0.5795888304710388
        vf_loss: 0.01971791870892048
    load_time_ms: 2.307
    num_steps_sampled: 19500
    num_steps_trained: 19500
    sample_time_ms: 218960.417
    update_time_ms: 5.826
  iterations_since_restore: 39
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.786446886446885
    ram_util_percent: 25.94029304029304
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 691.7493489331316
    mean_inference_ms: 1.791128213146052
    mean_processing_ms: 1.3246497376308297
  time_since_restore: 13625.164440393448
  time_this_iter_s: 191.17225670814514
  time_total_s: 13625.164440393448
  timestamp: 1637876319
  timesteps_since_restore: 19500
  timesteps_this_iter: 500
  timesteps_total: 19500
  training_iteration: 39
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     39 |          13625.2 | 19500 | 0.504198 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-42-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8790544255085212
  episode_reward_mean: 0.4890216988097
  episode_reward_min: -1.2010695187165776
  episodes_this_iter: 500
  episodes_total: 20000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1707.346
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.9954544305801392
        entropy_coeff: 0.0
        kl: 0.007909620180726051
        model: {}
        policy_loss: -0.04827312380075455
        total_loss: -0.02549186535179615
        vf_explained_var: 0.5311760902404785
        vf_loss: 0.01877700537443161
    load_time_ms: 2.327
    num_steps_sampled: 20000
    num_steps_trained: 20000
    sample_time_ms: 213279.759
    update_time_ms: 5.876
  iterations_since_restore: 40
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.921283783783784
    ram_util_percent: 25.926013513513514
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 684.6672401005765
    mean_inference_ms: 1.7869681109488529
    mean_processing_ms: 1.3214359700182106
  time_since_restore: 13832.515139341354
  time_this_iter_s: 207.3506989479065
  time_total_s: 13832.515139341354
  timestamp: 1637876526
  timesteps_since_restore: 20000
  timesteps_this_iter: 500
  timesteps_total: 20000
  training_iteration: 40
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     40 |          13832.5 | 20000 | 0.489022 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-45-11
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8707386363636364
  episode_reward_mean: 0.49169436326351706
  episode_reward_min: -1.3554006968641115
  episodes_this_iter: 500
  episodes_total: 20500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1716.791
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.0639604330062866
        entropy_coeff: 0.0
        kl: 0.006683626677840948
        model: {}
        policy_loss: -0.040401481091976166
        total_loss: -0.00723838759586215
        vf_explained_var: 0.5072389245033264
        vf_loss: 0.02977951057255268
    load_time_ms: 2.359
    num_steps_sampled: 20500
    num_steps_trained: 20500
    sample_time_ms: 207479.053
    update_time_ms: 5.792
  iterations_since_restore: 41
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.855893536121675
    ram_util_percent: 25.950570342205324
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 676.8125971958851
    mean_inference_ms: 1.7801337890825966
    mean_processing_ms: 1.3158012265653405
  time_since_restore: 14016.923325777054
  time_this_iter_s: 184.40818643569946
  time_total_s: 14016.923325777054
  timestamp: 1637876711
  timesteps_since_restore: 20500
  timesteps_this_iter: 500
  timesteps_total: 20500
  training_iteration: 41
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     41 |          14016.9 | 20500 | 0.491694 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-48-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.49913584249425774
  episode_reward_min: -0.3333333333333333
  episodes_this_iter: 500
  episodes_total: 21000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1726.506
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.0325032472610474
        entropy_coeff: 0.0
        kl: 0.009701798669993877
        model: {}
        policy_loss: -0.05770701915025711
        total_loss: -0.03905459865927696
        vf_explained_var: 0.6135780215263367
        vf_loss: 0.013740885071456432
    load_time_ms: 2.372
    num_steps_sampled: 21000
    num_steps_trained: 21000
    sample_time_ms: 203470.384
    update_time_ms: 5.697
  iterations_since_restore: 42
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.699239543726234
    ram_util_percent: 26.072243346007603
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 669.3285641389359
    mean_inference_ms: 1.7737297039759465
    mean_processing_ms: 1.310263876176824
  time_since_restore: 14201.41599202156
  time_this_iter_s: 184.49266624450684
  time_total_s: 14201.41599202156
  timestamp: 1637876896
  timesteps_since_restore: 21000
  timesteps_this_iter: 500
  timesteps_total: 21000
  training_iteration: 42
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     42 |          14201.4 | 21000 | 0.499136 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-51-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.4922807955837724
  episode_reward_min: -1.0732984293193717
  episodes_this_iter: 500
  episodes_total: 21500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1714.573
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 1.048964262008667
        entropy_coeff: 0.0
        kl: 0.007922287099063396
        model: {}
        policy_loss: -0.04324698820710182
        total_loss: -0.024837398901581764
        vf_explained_var: 0.5972439050674438
        vf_loss: 0.014398938044905663
    load_time_ms: 2.367
    num_steps_sampled: 21500
    num_steps_trained: 21500
    sample_time_ms: 198206.242
    update_time_ms: 5.665
  iterations_since_restore: 43
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.831404958677686
    ram_util_percent: 25.938842975206608
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 661.4847236231624
    mean_inference_ms: 1.7668489777572236
    mean_processing_ms: 1.3042792880941527
  time_since_restore: 14370.469014406204
  time_this_iter_s: 169.05302238464355
  time_total_s: 14370.469014406204
  timestamp: 1637877065
  timesteps_since_restore: 21500
  timesteps_this_iter: 500
  timesteps_total: 21500
  training_iteration: 43
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     43 |          14370.5 | 21500 | 0.492281 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-53-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8613013698630136
  episode_reward_mean: 0.5025315042367944
  episode_reward_min: -1.037525354969574
  episodes_this_iter: 500
  episodes_total: 22000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1706.222
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.9995244741439819
        entropy_coeff: 0.0
        kl: 0.008563687093555927
        model: {}
        policy_loss: -0.04030891880393028
        total_loss: -0.02151370979845524
        vf_explained_var: 0.585015058517456
        vf_loss: 0.014459840022027493
    load_time_ms: 2.364
    num_steps_sampled: 22000
    num_steps_trained: 22000
    sample_time_ms: 190795.047
    update_time_ms: 5.62
  iterations_since_restore: 44
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.846491228070175
    ram_util_percent: 25.953947368421048
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 653.569655398673
    mean_inference_ms: 1.7598444296822682
    mean_processing_ms: 1.2982321416219307
  time_since_restore: 14530.195520401001
  time_this_iter_s: 159.72650599479675
  time_total_s: 14530.195520401001
  timestamp: 1637877224
  timesteps_since_restore: 22000
  timesteps_this_iter: 500
  timesteps_total: 22000
  training_iteration: 44
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     44 |          14530.2 | 22000 | 0.502532 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-56-35
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8739495798319328
  episode_reward_mean: 0.5012070520067532
  episode_reward_min: -1.135399673735726
  episodes_this_iter: 500
  episodes_total: 22500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1703.874
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.9993281364440918
        entropy_coeff: 0.0
        kl: 0.00767513969913125
        model: {}
        policy_loss: -0.05715099349617958
        total_loss: -0.03276855871081352
        vf_explained_var: 0.5173457264900208
        vf_loss: 0.020496904850006104
    load_time_ms: 2.383
    num_steps_sampled: 22500
    num_steps_trained: 22500
    sample_time_ms: 186515.45
    update_time_ms: 5.554
  iterations_since_restore: 45
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.72909836065574
    ram_util_percent: 25.94918032786885
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 646.5055671280096
    mean_inference_ms: 1.7534600624025813
    mean_processing_ms: 1.292809640707999
  time_since_restore: 14701.078870534897
  time_this_iter_s: 170.88335013389587
  time_total_s: 14701.078870534897
  timestamp: 1637877395
  timesteps_since_restore: 22500
  timesteps_this_iter: 500
  timesteps_total: 22500
  training_iteration: 45
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     45 |          14701.1 | 22500 | 0.501207 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_15-59-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8731735827001753
  episode_reward_mean: 0.5145704725485599
  episode_reward_min: -0.4660633484162896
  episodes_this_iter: 500
  episodes_total: 23000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1714.409
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.9073609709739685
        entropy_coeff: 0.0
        kl: 0.00954493135213852
        model: {}
        policy_loss: -0.051721587777137756
        total_loss: -0.03461164981126785
        vf_explained_var: 0.6172006726264954
        vf_loss: 0.012277795933187008
    load_time_ms: 2.383
    num_steps_sampled: 23000
    num_steps_trained: 23000
    sample_time_ms: 180943.016
    update_time_ms: 5.519
  iterations_since_restore: 46
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.78715596330275
    ram_util_percent: 25.949082568807338
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 638.9667887381071
    mean_inference_ms: 1.7466979733519306
    mean_processing_ms: 1.2875152232309959
  time_since_restore: 14854.139404058456
  time_this_iter_s: 153.06053352355957
  time_total_s: 14854.139404058456
  timestamp: 1637877549
  timesteps_since_restore: 23000
  timesteps_this_iter: 500
  timesteps_total: 23000
  training_iteration: 46
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     46 |          14854.1 | 23000 |  0.51457 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-01-48
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.5130713820563416
  episode_reward_min: -0.3159722222222222
  episodes_this_iter: 500
  episodes_total: 23500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1692.84
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.8855128288269043
        entropy_coeff: 0.0
        kl: 0.006053087767213583
        model: {}
        policy_loss: -0.03255334869027138
        total_loss: -0.015150181949138641
        vf_explained_var: 0.5410938858985901
        vf_loss: 0.014338795095682144
    load_time_ms: 2.389
    num_steps_sampled: 23500
    num_steps_trained: 23500
    sample_time_ms: 175745.556
    update_time_ms: 5.538
  iterations_since_restore: 47
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.749779735682818
    ram_util_percent: 25.995594713656388
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 632.0238171737299
    mean_inference_ms: 1.7408333779963978
    mean_processing_ms: 1.2824891054966587
  time_since_restore: 15013.423820257187
  time_this_iter_s: 159.28441619873047
  time_total_s: 15013.423820257187
  timestamp: 1637877708
  timesteps_since_restore: 23500
  timesteps_this_iter: 500
  timesteps_total: 23500
  training_iteration: 47
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     47 |          15013.4 | 23500 | 0.513071 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-04-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.883385579937304
  episode_reward_mean: 0.5114360275901945
  episode_reward_min: -1.3522012578616351
  episodes_this_iter: 500
  episodes_total: 24000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1687.376
    learner:
      default_policy:
        cur_kl_coeff: 0.5062500238418579
        cur_lr: 4.999999873689376e-05
        entropy: 0.8355241417884827
        entropy_coeff: 0.0
        kl: 0.004527742974460125
        model: {}
        policy_loss: -0.042000602930784225
        total_loss: -0.013519049622118473
        vf_explained_var: 0.5125667452812195
        vf_loss: 0.02618938684463501
    load_time_ms: 2.356
    num_steps_sampled: 24000
    num_steps_trained: 24000
    sample_time_ms: 171428.911
    update_time_ms: 5.617
  iterations_since_restore: 48
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.894009216589861
    ram_util_percent: 25.94884792626728
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 625.0606871988322
    mean_inference_ms: 1.734762548193386
    mean_processing_ms: 1.2773748169511137
  time_since_restore: 15165.326125860214
  time_this_iter_s: 151.90230560302734
  time_total_s: 15165.326125860214
  timestamp: 1637877860
  timesteps_since_restore: 24000
  timesteps_this_iter: 500
  timesteps_total: 24000
  training_iteration: 48
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     48 |          15165.3 | 24000 | 0.511436 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-06-58
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9674665096422789
  episode_reward_mean: 0.5258859351197875
  episode_reward_min: -0.22157434402332363
  episodes_this_iter: 500
  episodes_total: 24500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1702.233
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.871674120426178
        entropy_coeff: 0.0
        kl: 0.009860241785645485
        model: {}
        policy_loss: -0.044721972197294235
        total_loss: -0.02849491313099861
        vf_explained_var: 0.5464507937431335
        vf_loss: 0.013731180690228939
    load_time_ms: 2.372
    num_steps_sampled: 24500
    num_steps_trained: 24500
    sample_time_ms: 168119.068
    update_time_ms: 5.716
  iterations_since_restore: 49
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.832743362831858
    ram_util_percent: 25.974778761061945
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 618.6357651100924
    mean_inference_ms: 1.729144402355239
    mean_processing_ms: 1.272849757147538
  time_since_restore: 15323.548275232315
  time_this_iter_s: 158.22214937210083
  time_total_s: 15323.548275232315
  timestamp: 1637878018
  timesteps_since_restore: 24500
  timesteps_this_iter: 500
  timesteps_total: 24500
  training_iteration: 49
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     49 |          15323.5 | 24500 | 0.525886 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-09-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9009356081452944
  episode_reward_mean: 0.5293129754211043
  episode_reward_min: 0.03981264637002342
  episodes_this_iter: 500
  episodes_total: 25000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1718.395
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.9258931875228882
        entropy_coeff: 0.0
        kl: 0.010728662833571434
        model: {}
        policy_loss: -0.04927097260951996
        total_loss: -0.03501896560192108
        vf_explained_var: 0.5581662654876709
        vf_loss: 0.011536312289536
    load_time_ms: 2.371
    num_steps_sampled: 25000
    num_steps_trained: 25000
    sample_time_ms: 162090.185
    update_time_ms: 5.751
  iterations_since_restore: 50
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.796190476190478
    ram_util_percent: 25.963809523809523
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 612.0290757179222
    mean_inference_ms: 1.7230019970496346
    mean_processing_ms: 1.2676144432036442
  time_since_restore: 15470.771896123886
  time_this_iter_s: 147.22362089157104
  time_total_s: 15470.771896123886
  timestamp: 1637878166
  timesteps_since_restore: 25000
  timesteps_this_iter: 500
  timesteps_total: 25000
  training_iteration: 50
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     50 |          15470.8 | 25000 | 0.529313 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-11-45
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5274441456207045
  episode_reward_min: -0.8354898336414048
  episodes_this_iter: 500
  episodes_total: 25500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1723.599
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.8471462726593018
        entropy_coeff: 0.0
        kl: 0.008912368677556515
        model: {}
        policy_loss: -0.04307302460074425
        total_loss: -0.02711794525384903
        vf_explained_var: 0.6181330680847168
        vf_loss: 0.013699140399694443
    load_time_ms: 2.343
    num_steps_sampled: 25500
    num_steps_trained: 25500
    sample_time_ms: 157625.889
    update_time_ms: 5.757
  iterations_since_restore: 51
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.942
    ram_util_percent: 25.945999999999998
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 605.3917426033807
    mean_inference_ms: 1.7166813375117667
    mean_processing_ms: 1.262669058239865
  time_since_restore: 15610.58875966072
  time_this_iter_s: 139.81686353683472
  time_total_s: 15610.58875966072
  timestamp: 1637878305
  timesteps_since_restore: 25500
  timesteps_this_iter: 500
  timesteps_total: 25500
  training_iteration: 51
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     51 |          15610.6 | 25500 | 0.527444 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-14-13
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610271903323263
  episode_reward_mean: 0.49898256487896614
  episode_reward_min: -2.8783783783783785
  episodes_this_iter: 500
  episodes_total: 26000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1718.687
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.8785185813903809
        entropy_coeff: 0.0
        kl: 0.010544445365667343
        model: {}
        policy_loss: -0.03863818198442459
        total_loss: -0.0016663095448166132
        vf_explained_var: 0.48224371671676636
        vf_loss: 0.034302808344364166
    load_time_ms: 2.324
    num_steps_sampled: 26000
    num_steps_trained: 26000
    sample_time_ms: 153887.238
    update_time_ms: 5.832
  iterations_since_restore: 52
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.243333333333332
    ram_util_percent: 25.972380952380952
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 599.2855121023788
    mean_inference_ms: 1.711163574546802
    mean_processing_ms: 1.2578567190035679
  time_since_restore: 15757.645699262619
  time_this_iter_s: 147.0569396018982
  time_total_s: 15757.645699262619
  timestamp: 1637878453
  timesteps_since_restore: 26000
  timesteps_this_iter: 500
  timesteps_total: 26000
  training_iteration: 52
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     52 |          15757.6 | 26000 | 0.498983 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-16-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.855917667238422
  episode_reward_mean: 0.5026916173587168
  episode_reward_min: -0.33678756476683935
  episodes_this_iter: 500
  episodes_total: 26500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1731.102
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.8548174500465393
        entropy_coeff: 0.0
        kl: 0.011192714795470238
        model: {}
        policy_loss: -0.05243204906582832
        total_loss: -0.037010692059993744
        vf_explained_var: 0.590749204158783
        vf_loss: 0.012588203884661198
    load_time_ms: 2.338
    num_steps_sampled: 26500
    num_steps_trained: 26500
    sample_time_ms: 151062.806
    update_time_ms: 5.863
  iterations_since_restore: 53
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.985572139303482
    ram_util_percent: 25.993034825870645
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 593.1798247345293
    mean_inference_ms: 1.705352398437049
    mean_processing_ms: 1.2530390755023009
  time_since_restore: 15898.578664541245
  time_this_iter_s: 140.9329652786255
  time_total_s: 15898.578664541245
  timestamp: 1637878594
  timesteps_since_restore: 26500
  timesteps_this_iter: 500
  timesteps_total: 26500
  training_iteration: 53
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     53 |          15898.6 | 26500 | 0.502692 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-18-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8736111111111111
  episode_reward_mean: 0.49505010278212513
  episode_reward_min: -1.6283422459893049
  episodes_this_iter: 500
  episodes_total: 27000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1736.08
    learner:
      default_policy:
        cur_kl_coeff: 0.25312501192092896
        cur_lr: 4.999999873689376e-05
        entropy: 0.851654589176178
        entropy_coeff: 0.0
        kl: 0.004582619294524193
        model: {}
        policy_loss: -0.03530745580792427
        total_loss: -0.014395194128155708
        vf_explained_var: 0.6166706681251526
        vf_loss: 0.019752278923988342
    load_time_ms: 2.342
    num_steps_sampled: 27000
    num_steps_trained: 27000
    sample_time_ms: 148701.162
    update_time_ms: 5.809
  iterations_since_restore: 54
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.037628865979382
    ram_util_percent: 25.947422680412373
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 587.1232070727181
    mean_inference_ms: 1.6992536192801058
    mean_processing_ms: 1.2480766789735962
  time_since_restore: 16034.737120866776
  time_this_iter_s: 136.158456325531
  time_total_s: 16034.737120866776
  timestamp: 1637878730
  timesteps_since_restore: 27000
  timesteps_this_iter: 500
  timesteps_total: 27000
  training_iteration: 54
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     54 |          16034.7 | 27000 |  0.49505 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-21-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.5206284026361959
  episode_reward_min: -0.06060606060606061
  episodes_this_iter: 500
  episodes_total: 27500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1725.953
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.7654917240142822
        entropy_coeff: 0.0
        kl: 0.008029264397919178
        model: {}
        policy_loss: -0.03651886805891991
        total_loss: -0.02275901287794113
        vf_explained_var: 0.5339695811271667
        vf_loss: 0.012743650935590267
    load_time_ms: 2.349
    num_steps_sampled: 27500
    num_steps_trained: 27500
    sample_time_ms: 145064.09
    update_time_ms: 5.808
  iterations_since_restore: 55
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.859895833333335
    ram_util_percent: 25.959374999999998
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 581.2321245173991
    mean_inference_ms: 1.6933968750235249
    mean_processing_ms: 1.2432862219344587
  time_since_restore: 16169.148663043976
  time_this_iter_s: 134.41154217720032
  time_total_s: 16169.148663043976
  timestamp: 1637878864
  timesteps_since_restore: 27500
  timesteps_this_iter: 500
  timesteps_total: 27500
  training_iteration: 55
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     55 |          16169.1 | 27500 | 0.520628 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-23-00
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8790544255085212
  episode_reward_mean: 0.5071004679834127
  episode_reward_min: -0.532258064516129
  episodes_this_iter: 500
  episodes_total: 28000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1713.796
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.7927207946777344
        entropy_coeff: 0.0
        kl: 0.00908278301358223
        model: {}
        policy_loss: -0.036798544228076935
        total_loss: -0.019676176831126213
        vf_explained_var: 0.5282618999481201
        vf_loss: 0.01597282662987709
    load_time_ms: 2.348
    num_steps_sampled: 28000
    num_steps_trained: 28000
    sample_time_ms: 141331.211
    update_time_ms: 5.858
  iterations_since_restore: 56
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.012121212121212
    ram_util_percent: 25.953333333333333
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 574.8744259893518
    mean_inference_ms: 1.687687314632497
    mean_processing_ms: 1.2386202714276406
  time_since_restore: 16284.76001214981
  time_this_iter_s: 115.61134910583496
  time_total_s: 16284.76001214981
  timestamp: 1637878980
  timesteps_since_restore: 28000
  timesteps_this_iter: 500
  timesteps_total: 28000
  training_iteration: 56
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     56 |          16284.8 | 28000 |   0.5071 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-25-00
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8707386363636364
  episode_reward_mean: 0.4912195546679774
  episode_reward_min: -0.8426966292134831
  episodes_this_iter: 500
  episodes_total: 28500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1715.792
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.7964727878570557
        entropy_coeff: 0.0
        kl: 0.00837480928748846
        model: {}
        policy_loss: -0.043223608285188675
        total_loss: -0.02355809696018696
        vf_explained_var: 0.5140405893325806
        vf_loss: 0.018605582416057587
    load_time_ms: 2.334
    num_steps_sampled: 28500
    num_steps_trained: 28500
    sample_time_ms: 137382.928
    update_time_ms: 5.841
  iterations_since_restore: 57
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.034502923976605
    ram_util_percent: 25.991812865497078
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 568.8926329558691
    mean_inference_ms: 1.6817366975235746
    mean_processing_ms: 1.233593990357649
  time_since_restore: 16404.581123828888
  time_this_iter_s: 119.82111167907715
  time_total_s: 16404.581123828888
  timestamp: 1637879100
  timesteps_since_restore: 28500
  timesteps_this_iter: 500
  timesteps_total: 28500
  training_iteration: 57
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     57 |          16404.6 | 28500 |  0.49122 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-27-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.4848449339788818
  episode_reward_min: -1.0020325203252032
  episodes_this_iter: 500
  episodes_total: 29000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1730.67
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.8116675615310669
        entropy_coeff: 0.0
        kl: 0.011777161620557308
        model: {}
        policy_loss: -0.04551667720079422
        total_loss: -0.02772454544901848
        vf_explained_var: 0.6055834293365479
        vf_loss: 0.01630159094929695
    load_time_ms: 2.36
    num_steps_sampled: 29000
    num_steps_trained: 29000
    sample_time_ms: 134767.649
    update_time_ms: 5.749
  iterations_since_restore: 58
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.939444444444444
    ram_util_percent: 25.95666666666667
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 563.3189654104472
    mean_inference_ms: 1.6764534131801807
    mean_processing_ms: 1.2292457545183022
  time_since_restore: 16530.47681951523
  time_this_iter_s: 125.89569568634033
  time_total_s: 16530.47681951523
  timestamp: 1637879226
  timesteps_since_restore: 29000
  timesteps_this_iter: 500
  timesteps_total: 29000
  training_iteration: 58
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     58 |          16530.5 | 29000 | 0.484845 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-29-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8684627575277337
  episode_reward_mean: 0.5119312806083038
  episode_reward_min: -0.23958333333333334
  episodes_this_iter: 500
  episodes_total: 29500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1731.635
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.7802839875221252
        entropy_coeff: 0.0
        kl: 0.011572623625397682
        model: {}
        policy_loss: -0.04132303223013878
        total_loss: -0.02950914390385151
        vf_explained_var: 0.6127585768699646
        vf_loss: 0.010349225252866745
    load_time_ms: 2.386
    num_steps_sampled: 29500
    num_steps_trained: 29500
    sample_time_ms: 131318.453
    update_time_ms: 5.717
  iterations_since_restore: 59
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.133898305084745
    ram_util_percent: 25.931638418079093
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 557.8632890149732
    mean_inference_ms: 1.6711187590575172
    mean_processing_ms: 1.2250005267465771
  time_since_restore: 16654.216254472733
  time_this_iter_s: 123.73943495750427
  time_total_s: 16654.216254472733
  timestamp: 1637879350
  timesteps_since_restore: 29500
  timesteps_this_iter: 500
  timesteps_total: 29500
  training_iteration: 59
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     59 |          16654.2 | 29500 | 0.511931 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-31-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8613013698630136
  episode_reward_mean: 0.5059234339859224
  episode_reward_min: -0.03745318352059925
  episodes_this_iter: 500
  episodes_total: 30000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1728.828
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.6983131170272827
        entropy_coeff: 0.0
        kl: 0.010833058506250381
        model: {}
        policy_loss: -0.039044175297021866
        total_loss: -0.02673191949725151
        vf_explained_var: 0.598210871219635
        vf_loss: 0.01094119530171156
    load_time_ms: 2.365
    num_steps_sampled: 30000
    num_steps_trained: 30000
    sample_time_ms: 128611.126
    update_time_ms: 5.746
  iterations_since_restore: 60
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.118713450292399
    ram_util_percent: 25.985380116959064
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 552.4702498660174
    mean_inference_ms: 1.6656802148088798
    mean_processing_ms: 1.2206868177127657
  time_since_restore: 16774.338851451874
  time_this_iter_s: 120.12259697914124
  time_total_s: 16774.338851451874
  timestamp: 1637879470
  timesteps_since_restore: 30000
  timesteps_this_iter: 500
  timesteps_total: 30000
  training_iteration: 60
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     60 |          16774.3 | 30000 | 0.505923 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-33-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8739495798319328
  episode_reward_mean: 0.5119221383537215
  episode_reward_min: -0.2773722627737226
  episodes_this_iter: 500
  episodes_total: 30500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1719.452
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.7201974391937256
        entropy_coeff: 0.0
        kl: 0.008667736314237118
        model: {}
        policy_loss: -0.04564464092254639
        total_loss: -0.03188355267047882
        vf_explained_var: 0.5428488254547119
        vf_loss: 0.012664072215557098
    load_time_ms: 2.377
    num_steps_sampled: 30500
    num_steps_trained: 30500
    sample_time_ms: 125929.035
    update_time_ms: 5.813
  iterations_since_restore: 61
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.97950310559006
    ram_util_percent: 25.940372670807452
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 547.0202049659217
    mean_inference_ms: 1.66004414066112
    mean_processing_ms: 1.216522572740235
  time_since_restore: 16887.241543769836
  time_this_iter_s: 112.90269231796265
  time_total_s: 16887.241543769836
  timestamp: 1637879583
  timesteps_since_restore: 30500
  timesteps_this_iter: 500
  timesteps_total: 30500
  training_iteration: 61
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     61 |          16887.2 | 30500 | 0.511922 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-34-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8731735827001753
  episode_reward_mean: 0.5249975968728517
  episode_reward_min: 0.08639308855291576
  episodes_this_iter: 500
  episodes_total: 31000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1712.529
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.6335449814796448
        entropy_coeff: 0.0
        kl: 0.00896821916103363
        model: {}
        policy_loss: -0.03233861178159714
        total_loss: -0.019362473860383034
        vf_explained_var: 0.5718784928321838
        vf_loss: 0.011841099709272385
    load_time_ms: 2.395
    num_steps_sampled: 31000
    num_steps_trained: 31000
    sample_time_ms: 120100.688
    update_time_ms: 5.79
  iterations_since_restore: 62
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.91968503937008
    ram_util_percent: 25.970078740157483
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 540.9635756808764
    mean_inference_ms: 1.6544001482597512
    mean_processing_ms: 1.2118960498959814
  time_since_restore: 16975.94643831253
  time_this_iter_s: 88.70489454269409
  time_total_s: 16975.94643831253
  timestamp: 1637879672
  timesteps_since_restore: 31000
  timesteps_this_iter: 500
  timesteps_total: 31000
  training_iteration: 62
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     62 |          16975.9 | 31000 | 0.524998 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-36-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.517546565892971
  episode_reward_min: -0.3159722222222222
  episodes_this_iter: 500
  episodes_total: 31500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1714.957
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.617029070854187
        entropy_coeff: 0.0
        kl: 0.011331469751894474
        model: {}
        policy_loss: -0.04191069304943085
        total_loss: -0.026676328852772713
        vf_explained_var: 0.5583300590515137
        vf_loss: 0.013800221495330334
    load_time_ms: 2.402
    num_steps_sampled: 31500
    num_steps_trained: 31500
    sample_time_ms: 116392.41
    update_time_ms: 5.752
  iterations_since_restore: 63
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.010135135135135
    ram_util_percent: 25.993918918918922
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 535.5776920647386
    mean_inference_ms: 1.6491170542712648
    mean_processing_ms: 1.2078099105324898
  time_since_restore: 17079.821451187134
  time_this_iter_s: 103.87501287460327
  time_total_s: 17079.821451187134
  timestamp: 1637879776
  timesteps_since_restore: 31500
  timesteps_this_iter: 500
  timesteps_total: 31500
  training_iteration: 63
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     63 |          17079.8 | 31500 | 0.517547 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-37-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9674665096422789
  episode_reward_mean: 0.5295940344438097
  episode_reward_min: -0.20243902439024392
  episodes_this_iter: 500
  episodes_total: 32000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1713.565
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.6121293902397156
        entropy_coeff: 0.0
        kl: 0.008999106474220753
        model: {}
        policy_loss: -0.03765758499503136
        total_loss: -0.023708073422312737
        vf_explained_var: 0.5917861461639404
        vf_loss: 0.012810559011995792
    load_time_ms: 2.396
    num_steps_sampled: 32000
    num_steps_trained: 32000
    sample_time_ms: 112078.567
    update_time_ms: 5.818
  iterations_since_restore: 64
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.257142857142858
    ram_util_percent: 25.999248120300756
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 530.0216545466649
    mean_inference_ms: 1.6435393430021368
    mean_processing_ms: 1.2034888953098093
  time_since_restore: 17172.82868552208
  time_this_iter_s: 93.00723433494568
  time_total_s: 17172.82868552208
  timestamp: 1637879869
  timesteps_since_restore: 32000
  timesteps_this_iter: 500
  timesteps_total: 32000
  training_iteration: 64
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     64 |          17172.8 | 32000 | 0.529594 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-39-30
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8918238993710692
  episode_reward_mean: 0.5227243658020109
  episode_reward_min: -0.12962962962962962
  episodes_this_iter: 500
  episodes_total: 32500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1731.237
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.6200348138809204
        entropy_coeff: 0.0
        kl: 0.007389280945062637
        model: {}
        policy_loss: -0.03157254308462143
        total_loss: -0.017500970512628555
        vf_explained_var: 0.5447681546211243
        vf_loss: 0.013136361725628376
    load_time_ms: 2.402
    num_steps_sampled: 32500
    num_steps_trained: 32500
    sample_time_ms: 108763.489
    update_time_ms: 5.855
  iterations_since_restore: 65
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.121379310344828
    ram_util_percent: 25.950344827586207
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 524.8978850196053
    mean_inference_ms: 1.6381341506325606
    mean_processing_ms: 1.1989451280715178
  time_since_restore: 17274.266758203506
  time_this_iter_s: 101.438072681427
  time_total_s: 17274.266758203506
  timestamp: 1637879970
  timesteps_since_restore: 32500
  timesteps_this_iter: 500
  timesteps_total: 32500
  training_iteration: 65
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     65 |          17274.3 | 32500 | 0.522724 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-41-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8965327462850853
  episode_reward_mean: 0.5235857506024308
  episode_reward_min: 0.0967741935483871
  episodes_this_iter: 500
  episodes_total: 33000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1729.382
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.6578834652900696
        entropy_coeff: 0.0
        kl: 0.00983352679759264
        model: {}
        policy_loss: -0.026371411979198456
        total_loss: -0.015703611075878143
        vf_explained_var: 0.617616593837738
        vf_loss: 0.00942324474453926
    load_time_ms: 2.399
    num_steps_sampled: 33000
    num_steps_trained: 33000
    sample_time_ms: 107782.951
    update_time_ms: 5.874
  iterations_since_restore: 66
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.085430463576156
    ram_util_percent: 25.952980132450335
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 520.0616963498286
    mean_inference_ms: 1.6331108211513754
    mean_processing_ms: 1.1948291209498225
  time_since_restore: 17380.054062843323
  time_this_iter_s: 105.78730463981628
  time_total_s: 17380.054062843323
  timestamp: 1637880076
  timesteps_since_restore: 33000
  timesteps_this_iter: 500
  timesteps_total: 33000
  training_iteration: 66
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     66 |          17380.1 | 33000 | 0.523586 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-43-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5344594243094783
  episode_reward_min: -0.5148063781321185
  episodes_this_iter: 500
  episodes_total: 33500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1743.766
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.589625895023346
        entropy_coeff: 0.0
        kl: 0.006903337314724922
        model: {}
        policy_loss: -0.03506746143102646
        total_loss: -0.020964108407497406
        vf_explained_var: 0.5590826272964478
        vf_loss: 0.013229652307927608
    load_time_ms: 2.367
    num_steps_sampled: 33500
    num_steps_trained: 33500
    sample_time_ms: 106585.442
    update_time_ms: 5.917
  iterations_since_restore: 67
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.135714285714286
    ram_util_percent: 25.988311688311693
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 515.4342348904885
    mean_inference_ms: 1.62829183784194
    mean_processing_ms: 1.1908958778143364
  time_since_restore: 17488.043975830078
  time_this_iter_s: 107.98991298675537
  time_total_s: 17488.043975830078
  timestamp: 1637880184
  timesteps_since_restore: 33500
  timesteps_this_iter: 500
  timesteps_total: 33500
  training_iteration: 67
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     67 |            17488 | 33500 | 0.534459 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-44-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610271903323263
  episode_reward_mean: 0.49865491621803754
  episode_reward_min: -0.1598639455782313
  episodes_this_iter: 500
  episodes_total: 34000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1741.927
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.6414077877998352
        entropy_coeff: 0.0
        kl: 0.00931569840759039
        model: {}
        policy_loss: -0.03271792456507683
        total_loss: -0.020737236365675926
        vf_explained_var: 0.6305601000785828
        vf_loss: 0.010801670141518116
    load_time_ms: 2.377
    num_steps_sampled: 34000
    num_steps_trained: 34000
    sample_time_ms: 105265.946
    update_time_ms: 5.963
  iterations_since_restore: 68
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.991925465838507
    ram_util_percent: 25.99006211180124
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 511.0794862457341
    mean_inference_ms: 1.6237766629601045
    mean_processing_ms: 1.1873702708982248
  time_since_restore: 17600.726871967316
  time_this_iter_s: 112.68289613723755
  time_total_s: 17600.726871967316
  timestamp: 1637880297
  timesteps_since_restore: 34000
  timesteps_this_iter: 500
  timesteps_total: 34000
  training_iteration: 68
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     68 |          17600.7 | 34000 | 0.498655 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-46-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8596214511041009
  episode_reward_mean: 0.5102216413308468
  episode_reward_min: -0.29844961240310075
  episodes_this_iter: 500
  episodes_total: 34500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1743.889
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.60252445936203
        entropy_coeff: 0.0
        kl: 0.007655944675207138
        model: {}
        policy_loss: -0.03533697873353958
        total_loss: -0.024533389136195183
        vf_explained_var: 0.6554052233695984
        vf_loss: 0.009834634140133858
    load_time_ms: 2.36
    num_steps_sampled: 34500
    num_steps_trained: 34500
    sample_time_ms: 101198.885
    update_time_ms: 6.035
  iterations_since_restore: 69
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.373109243697476
    ram_util_percent: 25.95546218487395
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 505.99492180503273
    mean_inference_ms: 1.6189170351567734
    mean_processing_ms: 1.183337140596762
  time_since_restore: 17683.81677007675
  time_this_iter_s: 83.08989810943604
  time_total_s: 17683.81677007675
  timestamp: 1637880380
  timesteps_since_restore: 34500
  timesteps_this_iter: 500
  timesteps_total: 34500
  training_iteration: 69
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     69 |          17683.8 | 34500 | 0.510222 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-47-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8736111111111111
  episode_reward_mean: 0.5134843570835226
  episode_reward_min: -0.22380952380952382
  episodes_this_iter: 500
  episodes_total: 35000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1743.501
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.5465528964996338
        entropy_coeff: 0.0
        kl: 0.006454157177358866
        model: {}
        policy_loss: -0.030870985239744186
        total_loss: -0.01940813846886158
        vf_explained_var: 0.6398636102676392
        vf_loss: 0.010645999573171139
    load_time_ms: 2.363
    num_steps_sampled: 35000
    num_steps_trained: 35000
    sample_time_ms: 97712.673
    update_time_ms: 6.065
  iterations_since_restore: 70
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.468032786885246
    ram_util_percent: 25.980327868852456
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 501.11945976288274
    mean_inference_ms: 1.6138734744210301
    mean_processing_ms: 1.1792003091773062
  time_since_restore: 17769.073127746582
  time_this_iter_s: 85.25635766983032
  time_total_s: 17769.073127746582
  timestamp: 1637880466
  timesteps_since_restore: 35000
  timesteps_this_iter: 500
  timesteps_total: 35000
  training_iteration: 70
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     70 |          17769.1 | 35000 | 0.513484 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-49-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8790544255085212
  episode_reward_mean: 0.5036954635748473
  episode_reward_min: -0.4429530201342282
  episodes_this_iter: 500
  episodes_total: 35500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1754.362
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.5031349658966064
        entropy_coeff: 0.0
        kl: 0.008256534114480019
        model: {}
        policy_loss: -0.03150130435824394
        total_loss: -0.017304277047514915
        vf_explained_var: 0.5470929145812988
        vf_loss: 0.013152053579688072
    load_time_ms: 2.351
    num_steps_sampled: 35500
    num_steps_trained: 35500
    sample_time_ms: 94718.481
    update_time_ms: 6.032
  iterations_since_restore: 71
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.071186440677966
    ram_util_percent: 25.943220338983053
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 496.31910743701553
    mean_inference_ms: 1.6086728118654068
    mean_processing_ms: 1.1751028266524848
  time_since_restore: 17852.142445087433
  time_this_iter_s: 83.06931734085083
  time_total_s: 17852.142445087433
  timestamp: 1637880549
  timesteps_since_restore: 35500
  timesteps_this_iter: 500
  timesteps_total: 35500
  training_iteration: 71
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     71 |          17852.1 | 35500 | 0.503695 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-50-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8702064896755162
  episode_reward_mean: 0.5021882072440746
  episode_reward_min: -1.2046035805626598
  episodes_this_iter: 500
  episodes_total: 36000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1754.417
    learner:
      default_policy:
        cur_kl_coeff: 0.12656250596046448
        cur_lr: 4.999999873689376e-05
        entropy: 0.494188129901886
        entropy_coeff: 0.0
        kl: 0.004001512657850981
        model: {}
        policy_loss: -0.0324888713657856
        total_loss: -0.00478767417371273
        vf_explained_var: 0.4769633114337921
        vf_loss: 0.02719474956393242
    load_time_ms: 2.371
    num_steps_sampled: 36000
    num_steps_trained: 36000
    sample_time_ms: 93140.232
    update_time_ms: 6.031
  iterations_since_restore: 72
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.623809523809523
    ram_util_percent: 25.944761904761904
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 491.3711963350624
    mean_inference_ms: 1.603619846574883
    mean_processing_ms: 1.170923781326746
  time_since_restore: 17925.06632208824
  time_this_iter_s: 72.92387700080872
  time_total_s: 17925.06632208824
  timestamp: 1637880622
  timesteps_since_restore: 36000
  timesteps_this_iter: 500
  timesteps_total: 36000
  training_iteration: 72
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     72 |          17925.1 | 36000 | 0.502188 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-51-48
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8707386363636364
  episode_reward_mean: 0.5037265305760604
  episode_reward_min: -1.0317700453857792
  episodes_this_iter: 500
  episodes_total: 36500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1752.257
    learner:
      default_policy:
        cur_kl_coeff: 0.06328125298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.5190394520759583
        entropy_coeff: 0.0
        kl: 0.006077307276427746
        model: {}
        policy_loss: -0.025222258642315865
        total_loss: -0.010275588370859623
        vf_explained_var: 0.5944352149963379
        vf_loss: 0.014562094584107399
    load_time_ms: 2.396
    num_steps_sampled: 36500
    num_steps_trained: 36500
    sample_time_ms: 91384.663
    update_time_ms: 6.009
  iterations_since_restore: 73
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.291056910569107
    ram_util_percent: 26.104065040650404
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 486.9217360654253
    mean_inference_ms: 1.5997077232484787
    mean_processing_ms: 1.1676859095999226
  time_since_restore: 18011.363714694977
  time_this_iter_s: 86.29739260673523
  time_total_s: 18011.363714694977
  timestamp: 1637880708
  timesteps_since_restore: 36500
  timesteps_this_iter: 500
  timesteps_total: 36500
  training_iteration: 73
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     73 |          18011.4 | 36500 | 0.503727 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-52-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8684627575277337
  episode_reward_mean: 0.4925378851594628
  episode_reward_min: 0.08045977011494253
  episodes_this_iter: 500
  episodes_total: 37000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1718.491
    learner:
      default_policy:
        cur_kl_coeff: 0.06328125298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.5300650596618652
        entropy_coeff: 0.0
        kl: 0.015832796692848206
        model: {}
        policy_loss: -0.032106634229421616
        total_loss: -0.020823821425437927
        vf_explained_var: 0.6457162499427795
        vf_loss: 0.010280908085405827
    load_time_ms: 2.397
    num_steps_sampled: 37000
    num_steps_trained: 37000
    sample_time_ms: 88790.228
    update_time_ms: 6.049
  iterations_since_restore: 74
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.155789473684207
    ram_util_percent: 25.938947368421054
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 482.07433652672904
    mean_inference_ms: 1.5948445844455672
    mean_processing_ms: 1.1637300282715943
  time_since_restore: 18078.08852481842
  time_this_iter_s: 66.7248101234436
  time_total_s: 18078.08852481842
  timestamp: 1637880775
  timesteps_since_restore: 37000
  timesteps_this_iter: 500
  timesteps_total: 37000
  training_iteration: 74
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     74 |          18078.1 | 37000 | 0.492538 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-54-13
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8613013698630136
  episode_reward_mean: 0.5153286974071327
  episode_reward_min: -0.9207436399217221
  episodes_this_iter: 500
  episodes_total: 37500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1708.669
    learner:
      default_policy:
        cur_kl_coeff: 0.06328125298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.5228519439697266
        entropy_coeff: 0.0
        kl: 0.006045816466212273
        model: {}
        policy_loss: -0.02863711677491665
        total_loss: -0.014964137226343155
        vf_explained_var: 0.6121624112129211
        vf_loss: 0.013290400616824627
    load_time_ms: 2.404
    num_steps_sampled: 37500
    num_steps_trained: 37500
    sample_time_ms: 86469.16
    update_time_ms: 5.946
  iterations_since_restore: 75
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.395535714285714
    ram_util_percent: 25.960714285714282
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 477.6546476567631
    mean_inference_ms: 1.5906151801833301
    mean_processing_ms: 1.1600336485940779
  time_since_restore: 18156.21662902832
  time_this_iter_s: 78.1281042098999
  time_total_s: 18156.21662902832
  timestamp: 1637880853
  timesteps_since_restore: 37500
  timesteps_this_iter: 500
  timesteps_total: 37500
  training_iteration: 75
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     75 |          18156.2 | 37500 | 0.515329 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-55-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8578680203045685
  episode_reward_mean: 0.5045601418079966
  episode_reward_min: -0.3557312252964427
  episodes_this_iter: 500
  episodes_total: 38000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1709.292
    learner:
      default_policy:
        cur_kl_coeff: 0.06328125298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.5078444480895996
        entropy_coeff: 0.0
        kl: 0.008401349186897278
        model: {}
        policy_loss: -0.03388087451457977
        total_loss: -0.020686686038970947
        vf_explained_var: 0.6000564098358154
        vf_loss: 0.012662535533308983
    load_time_ms: 2.395
    num_steps_sampled: 38000
    num_steps_trained: 38000
    sample_time_ms: 83162.1
    update_time_ms: 5.91
  iterations_since_restore: 76
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.309615384615386
    ram_util_percent: 25.97211538461538
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 473.20781014837127
    mean_inference_ms: 1.5858955086665678
    mean_processing_ms: 1.1564167840634956
  time_since_restore: 18228.938621759415
  time_this_iter_s: 72.72199273109436
  time_total_s: 18228.938621759415
  timestamp: 1637880926
  timesteps_since_restore: 38000
  timesteps_this_iter: 500
  timesteps_total: 38000
  training_iteration: 76
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     76 |          18228.9 | 38000 |  0.50456 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-56-42
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8739495798319328
  episode_reward_mean: 0.512011083277975
  episode_reward_min: -0.3695652173913043
  episodes_this_iter: 500
  episodes_total: 38500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1690.104
    learner:
      default_policy:
        cur_kl_coeff: 0.06328125298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.5030360221862793
        entropy_coeff: 0.0
        kl: 0.007233076263219118
        model: {}
        policy_loss: -0.036204300820827484
        total_loss: -0.024438895285129547
        vf_explained_var: 0.6029421091079712
        vf_loss: 0.011307687498629093
    load_time_ms: 2.42
    num_steps_sampled: 38500
    num_steps_trained: 38500
    sample_time_ms: 79947.442
    update_time_ms: 5.941
  iterations_since_restore: 77
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.141666666666667
    ram_util_percent: 25.96944444444445
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 468.95580054450323
    mean_inference_ms: 1.5818098638494964
    mean_processing_ms: 1.1530372062994816
  time_since_restore: 18304.590634822845
  time_this_iter_s: 75.65201306343079
  time_total_s: 18304.590634822845
  timestamp: 1637881002
  timesteps_since_restore: 38500
  timesteps_this_iter: 500
  timesteps_total: 38500
  training_iteration: 77
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     77 |          18304.6 | 38500 | 0.512011 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-57-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.5193343397794273
  episode_reward_min: -0.8867924528301887
  episodes_this_iter: 500
  episodes_total: 39000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1691.627
    learner:
      default_policy:
        cur_kl_coeff: 0.06328125298023224
        cur_lr: 4.999999873689376e-05
        entropy: 0.4609546363353729
        entropy_coeff: 0.0
        kl: 0.004735200200229883
        model: {}
        policy_loss: -0.02954796329140663
        total_loss: -0.012968529015779495
        vf_explained_var: 0.54886394739151
        vf_loss: 0.016279788687825203
    load_time_ms: 2.403
    num_steps_sampled: 39000
    num_steps_trained: 39000
    sample_time_ms: 75021.465
    update_time_ms: 5.891
  iterations_since_restore: 78
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.102197802197802
    ram_util_percent: 25.960439560439568
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 464.4941902965132
    mean_inference_ms: 1.5774298006441505
    mean_processing_ms: 1.1496040528317157
  time_since_restore: 18368.029128074646
  time_this_iter_s: 63.43849325180054
  time_total_s: 18368.029128074646
  timestamp: 1637881066
  timesteps_since_restore: 39000
  timesteps_this_iter: 500
  timesteps_total: 39000
  training_iteration: 78
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     78 |            18368 | 39000 | 0.519334 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-58-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.883385579937304
  episode_reward_mean: 0.5217182999018489
  episode_reward_min: -0.40804597701149425
  episodes_this_iter: 500
  episodes_total: 39500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1700.144
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.44164958596229553
        entropy_coeff: 0.0
        kl: 0.014257924631237984
        model: {}
        policy_loss: -0.0369669571518898
        total_loss: -0.02422209270298481
        vf_explained_var: 0.6108899116516113
        vf_loss: 0.012293729931116104
    load_time_ms: 2.415
    num_steps_sampled: 39500
    num_steps_trained: 39500
    sample_time_ms: 72709.788
    update_time_ms: 5.807
  iterations_since_restore: 79
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.557647058823525
    ram_util_percent: 26.0364705882353
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 460.0583281910197
    mean_inference_ms: 1.5733225859073727
    mean_processing_ms: 1.146372775573259
  time_since_restore: 18428.087034463882
  time_this_iter_s: 60.05790638923645
  time_total_s: 18428.087034463882
  timestamp: 1637881126
  timesteps_since_restore: 39500
  timesteps_this_iter: 500
  timesteps_total: 39500
  training_iteration: 79
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     79 |          18428.1 | 39500 | 0.521718 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_16-59-36
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9674665096422789
  episode_reward_mean: 0.5348510668037232
  episode_reward_min: 0.12406015037593984
  episodes_this_iter: 500
  episodes_total: 40000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1685.058
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4588344991207123
        entropy_coeff: 0.0
        kl: 0.014801141805946827
        model: {}
        policy_loss: -0.027633998543024063
        total_loss: -0.014962718822062016
        vf_explained_var: 0.5631940960884094
        vf_loss: 0.012202959507703781
    load_time_ms: 2.448
    num_steps_sampled: 40000
    num_steps_trained: 40000
    sample_time_ms: 69216.076
    update_time_ms: 5.823
  iterations_since_restore: 80
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.700000000000001
    ram_util_percent: 26.01805555555556
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 455.49453391107573
    mean_inference_ms: 1.568682339605023
    mean_processing_ms: 1.142596749078542
  time_since_restore: 18478.256751537323
  time_this_iter_s: 50.16971707344055
  time_total_s: 18478.256751537323
  timestamp: 1637881176
  timesteps_since_restore: 40000
  timesteps_this_iter: 500
  timesteps_total: 40000
  training_iteration: 80
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     80 |          18478.3 | 40000 | 0.534851 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-00-45
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8965327462850853
  episode_reward_mean: 0.5254299875062638
  episode_reward_min: 0.04950495049504951
  episodes_this_iter: 500
  episodes_total: 40500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1690.06
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.5083765983581543
        entropy_coeff: 0.0
        kl: 0.011687193065881729
        model: {}
        policy_loss: -0.03022914007306099
        total_loss: -0.018346047028899193
        vf_explained_var: 0.574727475643158
        vf_loss: 0.011513291858136654
    load_time_ms: 2.438
    num_steps_sampled: 40500
    num_steps_trained: 40500
    sample_time_ms: 67830.039
    update_time_ms: 5.774
  iterations_since_restore: 81
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.360606060606061
    ram_util_percent: 25.95050505050505
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 451.50747995830346
    mean_inference_ms: 1.5648792491766002
    mean_processing_ms: 1.1396140999971909
  time_since_restore: 18547.515605449677
  time_this_iter_s: 69.25885391235352
  time_total_s: 18547.515605449677
  timestamp: 1637881245
  timesteps_since_restore: 40500
  timesteps_this_iter: 500
  timesteps_total: 40500
  training_iteration: 81
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     81 |          18547.5 | 40500 |  0.52543 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-01-40
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5358128155845907
  episode_reward_min: 0.13247863247863248
  episodes_this_iter: 500
  episodes_total: 41000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1672.888
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4491032361984253
        entropy_coeff: 0.0
        kl: 0.009794650599360466
        model: {}
        policy_loss: -0.027863841503858566
        total_loss: -0.01698944717645645
        vf_explained_var: 0.5836117267608643
        vf_loss: 0.010564492084085941
    load_time_ms: 2.492
    num_steps_sampled: 41000
    num_steps_trained: 41000
    sample_time_ms: 65990.325
    update_time_ms: 5.777
  iterations_since_restore: 82
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.949999999999996
    ram_util_percent: 25.980769230769237
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 447.26110946806176
    mean_inference_ms: 1.5607154478965972
    mean_processing_ms: 1.1362470896318888
  time_since_restore: 18601.869707345963
  time_this_iter_s: 54.35410189628601
  time_total_s: 18601.869707345963
  timestamp: 1637881300
  timesteps_since_restore: 41000
  timesteps_this_iter: 500
  timesteps_total: 41000
  training_iteration: 82
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     82 |          18601.9 | 41000 | 0.535813 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-02-45
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610271903323263
  episode_reward_mean: 0.5135041104322572
  episode_reward_min: -0.02168021680216802
  episodes_this_iter: 500
  episodes_total: 41500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1673.796
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4827137291431427
        entropy_coeff: 0.0
        kl: 0.010240849107503891
        model: {}
        policy_loss: -0.03354360908269882
        total_loss: -0.022105371579527855
        vf_explained_var: 0.613656759262085
        vf_loss: 0.011114218272268772
    load_time_ms: 2.492
    num_steps_sampled: 41500
    num_steps_trained: 41500
    sample_time_ms: 63811.998
    update_time_ms: 5.826
  iterations_since_restore: 83
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.250000000000005
    ram_util_percent: 25.995652173913047
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 443.35555755093327
    mean_inference_ms: 1.556975511593323
    mean_processing_ms: 1.1334221971049079
  time_since_restore: 18666.39355969429
  time_this_iter_s: 64.52385234832764
  time_total_s: 18666.39355969429
  timestamp: 1637881365
  timesteps_since_restore: 41500
  timesteps_this_iter: 500
  timesteps_total: 41500
  training_iteration: 83
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     83 |          18666.4 | 41500 | 0.513504 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-03-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8536155202821869
  episode_reward_mean: 0.5064242874280318
  episode_reward_min: -0.3137254901960784
  episodes_this_iter: 500
  episodes_total: 42000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1697.832
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.44548073410987854
        entropy_coeff: 0.0
        kl: 0.00962064228951931
        model: {}
        policy_loss: -0.02846888080239296
        total_loss: -0.015863211825489998
        vf_explained_var: 0.6097739934921265
        vf_loss: 0.01230126153677702
    load_time_ms: 2.492
    num_steps_sampled: 42000
    num_steps_trained: 42000
    sample_time_ms: 61841.844
    update_time_ms: 5.83
  iterations_since_restore: 84
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.091176470588236
    ram_util_percent: 25.955882352941185
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 439.1356217447074
    mean_inference_ms: 1.5527535181937195
    mean_processing_ms: 1.130018514444855
  time_since_restore: 18713.65777373314
  time_this_iter_s: 47.26421403884888
  time_total_s: 18713.65777373314
  timestamp: 1637881412
  timesteps_since_restore: 42000
  timesteps_this_iter: 500
  timesteps_total: 42000
  training_iteration: 84
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     84 |          18713.7 | 42000 | 0.506424 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-04-23
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8736111111111111
  episode_reward_mean: 0.5072016225714494
  episode_reward_min: -0.26693227091633465
  episodes_this_iter: 500
  episodes_total: 42500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1699.918
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.46764931082725525
        entropy_coeff: 0.0
        kl: 0.009914061054587364
        model: {}
        policy_loss: -0.027228202670812607
        total_loss: -0.017427649348974228
        vf_explained_var: 0.6587782502174377
        vf_loss: 0.009486866183578968
    load_time_ms: 2.461
    num_steps_sampled: 42500
    num_steps_trained: 42500
    sample_time_ms: 59096.94
    update_time_ms: 5.888
  iterations_since_restore: 85
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.306944444444447
    ram_util_percent: 25.955555555555556
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 435.09596990267255
    mean_inference_ms: 1.54890300206545
    mean_processing_ms: 1.127014720903554
  time_since_restore: 18764.35823225975
  time_this_iter_s: 50.70045852661133
  time_total_s: 18764.35823225975
  timestamp: 1637881463
  timesteps_since_restore: 42500
  timesteps_this_iter: 500
  timesteps_total: 42500
  training_iteration: 85
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     85 |          18764.4 | 42500 | 0.507202 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-05-14
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.5138676085705755
  episode_reward_min: 0.026119402985074626
  episodes_this_iter: 500
  episodes_total: 43000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1679.628
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.420754998922348
        entropy_coeff: 0.0
        kl: 0.009338384494185448
        model: {}
        policy_loss: -0.025534426793456078
        total_loss: -0.014281580224633217
        vf_explained_var: 0.6115452647209167
        vf_loss: 0.010957382619380951
    load_time_ms: 2.469
    num_steps_sampled: 43000
    num_steps_trained: 43000
    sample_time_ms: 56989.324
    update_time_ms: 5.891
  iterations_since_restore: 86
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.622972972972972
    ram_util_percent: 25.981081081081086
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 431.171900177969
    mean_inference_ms: 1.5447534951178774
    mean_processing_ms: 1.1237390856224894
  time_since_restore: 18815.801193714142
  time_this_iter_s: 51.44296145439148
  time_total_s: 18815.801193714142
  timestamp: 1637881514
  timesteps_since_restore: 43000
  timesteps_this_iter: 500
  timesteps_total: 43000
  training_iteration: 86
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     86 |          18815.8 | 43000 | 0.513868 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-06-07
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8790544255085212
  episode_reward_mean: 0.5144544733001419
  episode_reward_min: -0.3106060606060606
  episodes_this_iter: 500
  episodes_total: 43500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1696.796
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.39510485529899597
        entropy_coeff: 0.0
        kl: 0.009666990488767624
        model: {}
        policy_loss: -0.031025325879454613
        total_loss: -0.01788400113582611
        vf_explained_var: 0.5713004469871521
        vf_loss: 0.012835451401770115
    load_time_ms: 2.483
    num_steps_sampled: 43500
    num_steps_trained: 43500
    sample_time_ms: 54697.591
    update_time_ms: 5.856
  iterations_since_restore: 87
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.58
    ram_util_percent: 25.972000000000005
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 427.3663803159867
    mean_inference_ms: 1.5408154210919134
    mean_processing_ms: 1.1205665435092984
  time_since_restore: 18868.707062482834
  time_this_iter_s: 52.90586876869202
  time_total_s: 18868.707062482834
  timestamp: 1637881567
  timesteps_since_restore: 43500
  timesteps_this_iter: 500
  timesteps_total: 43500
  training_iteration: 87
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     87 |          18868.7 | 43500 | 0.514454 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-06-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8707386363636364
  episode_reward_mean: 0.4912323016743676
  episode_reward_min: -1.7411764705882353
  episodes_this_iter: 500
  episodes_total: 44000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1698.444
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.43068405985832214
        entropy_coeff: 0.0
        kl: 0.007931693457067013
        model: {}
        policy_loss: -0.031214594841003418
        total_loss: -0.005155820865184069
        vf_explained_var: 0.5137763619422913
        vf_loss: 0.025807814672589302
    load_time_ms: 2.477
    num_steps_sampled: 44000
    num_steps_trained: 44000
    sample_time_ms: 52320.051
    update_time_ms: 5.929
  iterations_since_restore: 88
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.249122807017544
    ram_util_percent: 26.066666666666666
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 423.34482168675015
    mean_inference_ms: 1.5368873034143213
    mean_processing_ms: 1.1176718481264152
  time_since_restore: 18908.38704752922
  time_this_iter_s: 39.67998504638672
  time_total_s: 18908.38704752922
  timestamp: 1637881607
  timesteps_since_restore: 44000
  timesteps_this_iter: 500
  timesteps_total: 44000
  training_iteration: 88
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     88 |          18908.4 | 44000 | 0.491232 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-07-40
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.5071317856427768
  episode_reward_min: -0.23622047244094488
  episodes_this_iter: 500
  episodes_total: 44500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1659.068
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4505192041397095
        entropy_coeff: 0.0
        kl: 0.0132371187210083
        model: {}
        policy_loss: -0.031239910051226616
        total_loss: -0.02042137086391449
        vf_explained_var: 0.6374053359031677
        vf_loss: 0.01039971224963665
    load_time_ms: 2.449
    num_steps_sampled: 44500
    num_steps_trained: 44500
    sample_time_ms: 51593.578
    update_time_ms: 6.009
  iterations_since_restore: 89
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.770666666666665
    ram_util_percent: 26.12933333333334
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 419.7074464914685
    mean_inference_ms: 1.5331789155035447
    mean_processing_ms: 1.1147275479658894
  time_since_restore: 18960.786472558975
  time_this_iter_s: 52.39942502975464
  time_total_s: 18960.786472558975
  timestamp: 1637881660
  timesteps_since_restore: 44500
  timesteps_this_iter: 500
  timesteps_total: 44500
  training_iteration: 89
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     89 |          18960.8 | 44500 | 0.507132 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-08-25
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8684627575277337
  episode_reward_mean: 0.49670148375207995
  episode_reward_min: -0.23786407766990292
  episodes_this_iter: 500
  episodes_total: 45000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1676.234
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.44737422466278076
        entropy_coeff: 0.0
        kl: 0.007318103685975075
        model: {}
        policy_loss: -0.02835979498922825
        total_loss: -0.017419027164578438
        vf_explained_var: 0.6384481191635132
        vf_loss: 0.010709228925406933
    load_time_ms: 2.414
    num_steps_sampled: 45000
    num_steps_trained: 45000
    sample_time_ms: 51121.323
    update_time_ms: 5.948
  iterations_since_restore: 90
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.587692307692308
    ram_util_percent: 26.013846153846156
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 415.993617276653
    mean_inference_ms: 1.529796073543811
    mean_processing_ms: 1.111919743593914
  time_since_restore: 19006.403985261917
  time_this_iter_s: 45.617512702941895
  time_total_s: 19006.403985261917
  timestamp: 1637881705
  timesteps_since_restore: 45000
  timesteps_this_iter: 500
  timesteps_total: 45000
  training_iteration: 90
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     90 |          19006.4 | 45000 | 0.496701 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-09-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8613013698630136
  episode_reward_mean: 0.5130286001487644
  episode_reward_min: -0.06578947368421052
  episodes_this_iter: 500
  episodes_total: 45500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1653.231
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.43413668870925903
        entropy_coeff: 0.0
        kl: 0.01425055880099535
        model: {}
        policy_loss: -0.025605224072933197
        total_loss: -0.01489769946783781
        vf_explained_var: 0.6081709861755371
        vf_loss: 0.0102566322311759
    load_time_ms: 2.417
    num_steps_sampled: 45500
    num_steps_trained: 45500
    sample_time_ms: 48630.717
    update_time_ms: 5.929
  iterations_since_restore: 91
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.170312500000001
    ram_util_percent: 25.9625
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 412.332876617129
    mean_inference_ms: 1.5260492486510024
    mean_processing_ms: 1.1089968289918384
  time_since_restore: 19050.52601671219
  time_this_iter_s: 44.122031450271606
  time_total_s: 19050.52601671219
  timestamp: 1637881750
  timesteps_since_restore: 45500
  timesteps_this_iter: 500
  timesteps_total: 45500
  training_iteration: 91
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     91 |          19050.5 | 45500 | 0.513029 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-10-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8739495798319328
  episode_reward_mean: 0.5127808852351898
  episode_reward_min: 0.10222222222222223
  episodes_this_iter: 500
  episodes_total: 46000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1665.115
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4675995707511902
        entropy_coeff: 0.0
        kl: 0.009953070431947708
        model: {}
        policy_loss: -0.03678865730762482
        total_loss: -0.025433965027332306
        vf_explained_var: 0.5682416558265686
        vf_loss: 0.011039767414331436
    load_time_ms: 2.357
    num_steps_sampled: 46000
    num_steps_trained: 46000
    sample_time_ms: 49245.899
    update_time_ms: 5.857
  iterations_since_restore: 92
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 13.872093023255815
    ram_util_percent: 25.962790697674425
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 409.10734968810897
    mean_inference_ms: 1.5229021387798254
    mean_processing_ms: 1.106440783847905
  time_since_restore: 19111.14961051941
  time_this_iter_s: 60.62359380722046
  time_total_s: 19111.14961051941
  timestamp: 1637881810
  timesteps_since_restore: 46000
  timesteps_this_iter: 500
  timesteps_total: 46000
  training_iteration: 92
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     92 |          19111.1 | 46000 | 0.512781 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-10-55
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8731735827001753
  episode_reward_mean: 0.5227446160882567
  episode_reward_min: -0.3018867924528302
  episodes_this_iter: 500
  episodes_total: 46500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1664.741
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.42705875635147095
        entropy_coeff: 0.0
        kl: 0.0062251584604382515
        model: {}
        policy_loss: -0.022056614980101585
        total_loss: -0.011426731012761593
        vf_explained_var: 0.6362770795822144
        vf_loss: 0.010432916693389416
    load_time_ms: 2.325
    num_steps_sampled: 46500
    num_steps_trained: 46500
    sample_time_ms: 47272.249
    update_time_ms: 5.83
  iterations_since_restore: 93
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.478125
    ram_util_percent: 25.993750000000002
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 405.60857050060105
    mean_inference_ms: 1.5195169483922386
    mean_processing_ms: 1.1037206427261055
  time_since_restore: 19155.932563066483
  time_this_iter_s: 44.782952547073364
  time_total_s: 19155.932563066483
  timestamp: 1637881855
  timesteps_since_restore: 46500
  timesteps_this_iter: 500
  timesteps_total: 46500
  training_iteration: 93
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     93 |          19155.9 | 46500 | 0.522745 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-11-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.5160106768056797
  episode_reward_min: -0.3159722222222222
  episodes_this_iter: 500
  episodes_total: 47000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1669.343
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4354915916919708
        entropy_coeff: 0.0
        kl: 0.010514378547668457
        model: {}
        policy_loss: -0.03522869944572449
        total_loss: -0.02241765707731247
        vf_explained_var: 0.5514461398124695
        vf_loss: 0.01247835997492075
    load_time_ms: 2.33
    num_steps_sampled: 47000
    num_steps_trained: 47000
    sample_time_ms: 48275.314
    update_time_ms: 5.85
  iterations_since_restore: 94
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.50121951219512
    ram_util_percent: 25.975609756097565
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 402.4520773768021
    mean_inference_ms: 1.516300988566107
    mean_processing_ms: 1.101266784629011
  time_since_restore: 19213.273871660233
  time_this_iter_s: 57.34130859375
  time_total_s: 19213.273871660233
  timestamp: 1637881913
  timesteps_since_restore: 47000
  timesteps_this_iter: 500
  timesteps_total: 47000
  training_iteration: 94
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     94 |          19213.3 | 47000 | 0.516011 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-12-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9674665096422789
  episode_reward_mean: 0.5374485684274638
  episode_reward_min: -0.16842105263157894
  episodes_this_iter: 500
  episodes_total: 47500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1678.174
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.40471935272216797
        entropy_coeff: 0.0
        kl: 0.009828019887208939
        model: {}
        policy_loss: -0.028181415051221848
        total_loss: -0.016121257096529007
        vf_explained_var: 0.6076594591140747
        vf_loss: 0.011749198660254478
    load_time_ms: 2.323
    num_steps_sampled: 47500
    num_steps_trained: 47500
    sample_time_ms: 46991.452
    update_time_ms: 5.891
  iterations_since_restore: 95
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.00909090909091
    ram_util_percent: 25.98545454545455
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 398.95431647709574
    mean_inference_ms: 1.5128497005685981
    mean_processing_ms: 1.0984906678259898
  time_since_restore: 19251.224202156067
  time_this_iter_s: 37.95033049583435
  time_total_s: 19251.224202156067
  timestamp: 1637881951
  timesteps_since_restore: 47500
  timesteps_this_iter: 500
  timesteps_total: 47500
  training_iteration: 95
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     95 |          19251.2 | 47500 | 0.537449 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-13-21
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8918238993710692
  episode_reward_mean: 0.5219668573183207
  episode_reward_min: -0.2916666666666667
  episodes_this_iter: 500
  episodes_total: 48000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1700.186
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4414045214653015
        entropy_coeff: 0.0
        kl: 0.007052259985357523
        model: {}
        policy_loss: -0.029503028839826584
        total_loss: -0.015913061797618866
        vf_explained_var: 0.5475064516067505
        vf_loss: 0.01336682215332985
    load_time_ms: 2.341
    num_steps_sampled: 48000
    num_steps_trained: 48000
    sample_time_ms: 46806.776
    update_time_ms: 5.852
  iterations_since_restore: 96
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.557746478873238
    ram_util_percent: 25.98591549295775
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 395.7761988058996
    mean_inference_ms: 1.5099757745989595
    mean_processing_ms: 1.0961395276466739
  time_since_restore: 19301.040778398514
  time_this_iter_s: 49.8165762424469
  time_total_s: 19301.040778398514
  timestamp: 1637882001
  timesteps_since_restore: 48000
  timesteps_this_iter: 500
  timesteps_total: 48000
  training_iteration: 96
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     96 |            19301 | 48000 | 0.521967 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-14-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8965327462850853
  episode_reward_mean: 0.5334871285751313
  episode_reward_min: 0.13247863247863248
  episodes_this_iter: 500
  episodes_total: 48500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1703.742
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4548855721950531
        entropy_coeff: 0.0
        kl: 0.009734762832522392
        model: {}
        policy_loss: -0.02971915900707245
        total_loss: -0.01958160661160946
        vf_explained_var: 0.6293753981590271
        vf_loss: 0.00982954166829586
    load_time_ms: 2.354
    num_steps_sampled: 48500
    num_steps_trained: 48500
    sample_time_ms: 46259.868
    update_time_ms: 5.838
  iterations_since_restore: 97
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.644117647058822
    ram_util_percent: 26.08235294117647
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 392.61482127221433
    mean_inference_ms: 1.5069107446878758
    mean_processing_ms: 1.09378088798939
  time_since_restore: 19348.51353907585
  time_this_iter_s: 47.47276067733765
  time_total_s: 19348.51353907585
  timestamp: 1637882049
  timesteps_since_restore: 48500
  timesteps_this_iter: 500
  timesteps_total: 48500
  training_iteration: 97
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     97 |          19348.5 | 48500 | 0.533487 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-14-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5303111087067361
  episode_reward_min: -0.20496894409937888
  episodes_this_iter: 500
  episodes_total: 49000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1689.237
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.42440977692604065
        entropy_coeff: 0.0
        kl: 0.009875290095806122
        model: {}
        policy_loss: -0.02709825336933136
        total_loss: -0.015290533192455769
        vf_explained_var: 0.6019859910011292
        vf_loss: 0.011495258659124374
    load_time_ms: 2.368
    num_steps_sampled: 49000
    num_steps_trained: 49000
    sample_time_ms: 46355.492
    update_time_ms: 5.736
  iterations_since_restore: 98
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.594827586206899
    ram_util_percent: 26.067241379310346
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 389.3779881698583
    mean_inference_ms: 1.5037421832189073
    mean_processing_ms: 1.091140272305894
  time_since_restore: 19389.00297665596
  time_this_iter_s: 40.48943758010864
  time_total_s: 19389.00297665596
  timestamp: 1637882089
  timesteps_since_restore: 49000
  timesteps_this_iter: 500
  timesteps_total: 49000
  training_iteration: 98
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     98 |            19389 | 49000 | 0.530311 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-15-37
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610271903323263
  episode_reward_mean: 0.5147490328340282
  episode_reward_min: -0.1598639455782313
  episodes_this_iter: 500
  episodes_total: 49500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1715.795
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4246218204498291
        entropy_coeff: 0.0
        kl: 0.01735921949148178
        model: {}
        policy_loss: -0.03218553215265274
        total_loss: -0.019595365971326828
        vf_explained_var: 0.5776624083518982
        vf_loss: 0.012040904723107815
    load_time_ms: 2.413
    num_steps_sampled: 49500
    num_steps_trained: 49500
    sample_time_ms: 45856.968
    update_time_ms: 5.715
  iterations_since_restore: 99
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.48970588235294
    ram_util_percent: 26.052941176470586
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 386.350642348566
    mean_inference_ms: 1.500573510538556
    mean_processing_ms: 1.0887232431919707
  time_since_restore: 19436.68293428421
  time_this_iter_s: 47.67995762825012
  time_total_s: 19436.68293428421
  timestamp: 1637882137
  timesteps_since_restore: 49500
  timesteps_this_iter: 500
  timesteps_total: 49500
  training_iteration: 99
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |     99 |          19436.7 | 49500 | 0.514749 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-16-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8596214511041009
  episode_reward_mean: 0.5018266369076216
  episode_reward_min: -0.3160621761658031
  episodes_this_iter: 500
  episodes_total: 50000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1722.04
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.44111618399620056
        entropy_coeff: 0.0
        kl: 0.009266827255487442
        model: {}
        policy_loss: -0.026140103116631508
        total_loss: -0.01480182446539402
        vf_explained_var: 0.6361644864082336
        vf_loss: 0.011045069433748722
    load_time_ms: 2.437
    num_steps_sampled: 50000
    num_steps_trained: 50000
    sample_time_ms: 46360.206
    update_time_ms: 5.662
  iterations_since_restore: 100
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.86849315068493
    ram_util_percent: 26.00958904109589
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 383.442670282718
    mean_inference_ms: 1.4976134183599898
    mean_processing_ms: 1.086401282800455
  time_since_restore: 19487.395344257355
  time_this_iter_s: 50.71240997314453
  time_total_s: 19487.395344257355
  timestamp: 1637882188
  timesteps_since_restore: 50000
  timesteps_this_iter: 500
  timesteps_total: 50000
  training_iteration: 100
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    100 |          19487.4 | 50000 | 0.501827 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-17-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8736111111111111
  episode_reward_mean: 0.5053787202172708
  episode_reward_min: -0.3202846975088968
  episodes_this_iter: 500
  episodes_total: 50500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1731.763
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.42152178287506104
        entropy_coeff: 0.0
        kl: 0.006358887534588575
        model: {}
        policy_loss: -0.02829173393547535
        total_loss: -0.017330823466181755
        vf_explained_var: 0.6501679420471191
        vf_loss: 0.010759708471596241
    load_time_ms: 2.44
    num_steps_sampled: 50500
    num_steps_trained: 50500
    sample_time_ms: 46767.21
    update_time_ms: 5.672
  iterations_since_restore: 101
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.40289855072464
    ram_util_percent: 26.030434782608694
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 380.5470592194139
    mean_inference_ms: 1.4946596407328043
    mean_processing_ms: 1.0840712399797243
  time_since_restore: 19535.684475660324
  time_this_iter_s: 48.28913140296936
  time_total_s: 19535.684475660324
  timestamp: 1637882236
  timesteps_since_restore: 50500
  timesteps_this_iter: 500
  timesteps_total: 50500
  training_iteration: 101
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    101 |          19535.7 | 50500 | 0.505379 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-18-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.5194641802566319
  episode_reward_min: -0.24615384615384617
  episodes_this_iter: 500
  episodes_total: 51000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1747.78
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3964238464832306
        entropy_coeff: 0.0
        kl: 0.009605553932487965
        model: {}
        policy_loss: -0.025355078279972076
        total_loss: -0.013711316511034966
        vf_explained_var: 0.5925391912460327
        vf_loss: 0.01133984699845314
    load_time_ms: 2.427
    num_steps_sampled: 51000
    num_steps_trained: 51000
    sample_time_ms: 45982.117
    update_time_ms: 5.806
  iterations_since_restore: 102
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.203999999999999
    ram_util_percent: 26.030666666666665
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 377.79580584479487
    mean_inference_ms: 1.4919097258860883
    mean_processing_ms: 1.0819183569585942
  time_since_restore: 19588.619342803955
  time_this_iter_s: 52.93486714363098
  time_total_s: 19588.619342803955
  timestamp: 1637882289
  timesteps_since_restore: 51000
  timesteps_this_iter: 500
  timesteps_total: 51000
  training_iteration: 102
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    102 |          19588.6 | 51000 | 0.519464 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-18-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8790544255085212
  episode_reward_mean: 0.5148161312561836
  episode_reward_min: -0.4220665499124343
  episodes_this_iter: 500
  episodes_total: 51500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1746.61
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3900902271270752
        entropy_coeff: 0.0
        kl: 0.005752767901867628
        model: {}
        policy_loss: -0.023300014436244965
        total_loss: -0.006592538207769394
        vf_explained_var: 0.5035356283187866
        vf_loss: 0.016525449231266975
    load_time_ms: 2.501
    num_steps_sampled: 51500
    num_steps_trained: 51500
    sample_time_ms: 45564.784
    update_time_ms: 5.772
  iterations_since_restore: 103
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.061016949152544
    ram_util_percent: 26.015254237288136
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 374.8601475668585
    mean_inference_ms: 1.4889411413702687
    mean_processing_ms: 1.0794649836887484
  time_since_restore: 19629.217465162277
  time_this_iter_s: 40.598122358322144
  time_total_s: 19629.217465162277
  timestamp: 1637882330
  timesteps_since_restore: 51500
  timesteps_this_iter: 500
  timesteps_total: 51500
  training_iteration: 103
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    103 |          19629.2 | 51500 | 0.514816 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-19-30
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8707386363636364
  episode_reward_mean: 0.49615055193693725
  episode_reward_min: -0.9716417910447761
  episodes_this_iter: 500
  episodes_total: 52000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1736.858
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.408598393201828
        entropy_coeff: 0.0
        kl: 0.011029663495719433
        model: {}
        policy_loss: -0.02992420271039009
        total_loss: -0.01536027155816555
        vf_explained_var: 0.6142740845680237
        vf_loss: 0.014214935712516308
    load_time_ms: 2.486
    num_steps_sampled: 52000
    num_steps_trained: 52000
    sample_time_ms: 43832.878
    update_time_ms: 5.67
  iterations_since_restore: 104
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.007017543859648
    ram_util_percent: 26.217543859649126
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 371.9698414546073
    mean_inference_ms: 1.486343791036844
    mean_processing_ms: 1.0774387208061198
  time_since_restore: 19669.140609502792
  time_this_iter_s: 39.92314434051514
  time_total_s: 19669.140609502792
  timestamp: 1637882370
  timesteps_since_restore: 52000
  timesteps_this_iter: 500
  timesteps_total: 52000
  training_iteration: 104
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    104 |          19669.1 | 52000 | 0.496151 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-20-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.49260311721249017
  episode_reward_min: -0.23116883116883116
  episodes_this_iter: 500
  episodes_total: 52500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1741.393
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.40578365325927734
        entropy_coeff: 0.0
        kl: 0.00955766811966896
        model: {}
        policy_loss: -0.030570628121495247
        total_loss: -0.018211226910352707
        vf_explained_var: 0.6280102133750916
        vf_loss: 0.012056989595293999
    load_time_ms: 2.512
    num_steps_sampled: 52500
    num_steps_trained: 52500
    sample_time_ms: 43782.406
    update_time_ms: 5.668
  iterations_since_restore: 105
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.745283018867925
    ram_util_percent: 26.01132075471698
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 369.0858847418163
    mean_inference_ms: 1.4834932816741344
    mean_processing_ms: 1.0751591112765306
  time_since_restore: 19706.6317756176
  time_this_iter_s: 37.49116611480713
  time_total_s: 19706.6317756176
  timestamp: 1637882408
  timesteps_since_restore: 52500
  timesteps_this_iter: 500
  timesteps_total: 52500
  training_iteration: 105
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    105 |          19706.6 | 52500 | 0.492603 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-20-47
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8648648648648649
  episode_reward_mean: 0.5124756120670939
  episode_reward_min: -1.069802731411229
  episodes_this_iter: 500
  episodes_total: 53000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1743.605
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.40467408299446106
        entropy_coeff: 0.0
        kl: 0.009197392500936985
        model: {}
        policy_loss: -0.035236213356256485
        total_loss: -0.02143390104174614
        vf_explained_var: 0.6180716753005981
        vf_loss: 0.013511295430362225
    load_time_ms: 2.482
    num_steps_sampled: 53000
    num_steps_trained: 53000
    sample_time_ms: 42707.388
    update_time_ms: 5.722
  iterations_since_restore: 106
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.224999999999998
    ram_util_percent: 26.01607142857143
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 366.2878445068783
    mean_inference_ms: 1.480472251826018
    mean_processing_ms: 1.0726979758541049
  time_since_restore: 19745.72008085251
  time_this_iter_s: 39.08830523490906
  time_total_s: 19745.72008085251
  timestamp: 1637882447
  timesteps_since_restore: 53000
  timesteps_this_iter: 500
  timesteps_total: 53000
  training_iteration: 106
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    106 |          19745.7 | 53000 | 0.512476 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-21-17
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8541147132169576
  episode_reward_mean: 0.5087498616163659
  episode_reward_min: -0.15702479338842976
  episodes_this_iter: 500
  episodes_total: 53500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1748.591
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.40102988481521606
        entropy_coeff: 0.0
        kl: 0.009270310401916504
        model: {}
        policy_loss: -0.03613060340285301
        total_loss: -0.02490820363163948
        vf_explained_var: 0.6056194305419922
        vf_loss: 0.010929080657660961
    load_time_ms: 2.5
    num_steps_sampled: 53500
    num_steps_trained: 53500
    sample_time_ms: 40910.081
    update_time_ms: 5.663
  iterations_since_restore: 107
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.986046511627906
    ram_util_percent: 26.0
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 363.362744849133
    mean_inference_ms: 1.4773824879330846
    mean_processing_ms: 1.0702767547443715
  time_since_restore: 19775.26979470253
  time_this_iter_s: 29.549713850021362
  time_total_s: 19775.26979470253
  timestamp: 1637882477
  timesteps_since_restore: 53500
  timesteps_this_iter: 500
  timesteps_total: 53500
  training_iteration: 107
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    107 |          19775.3 | 53500 |  0.50875 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-22-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8739495798319328
  episode_reward_mean: 0.5081183480293777
  episode_reward_min: -1.1618497109826589
  episodes_this_iter: 500
  episodes_total: 54000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1749.164
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4422377645969391
        entropy_coeff: 0.0
        kl: 0.007412173319607973
        model: {}
        policy_loss: -0.02775854803621769
        total_loss: -0.012315957807004452
        vf_explained_var: 0.5915729403495789
        vf_loss: 0.01520806085318327
    load_time_ms: 2.488
    num_steps_sampled: 54000
    num_steps_trained: 54000
    sample_time_ms: 41920.868
    update_time_ms: 5.814
  iterations_since_restore: 108
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.198611111111111
    ram_util_percent: 26.0375
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 360.88317472518247
    mean_inference_ms: 1.4750330150706894
    mean_processing_ms: 1.0683041555246038
  time_since_restore: 19825.875062465668
  time_this_iter_s: 50.60526776313782
  time_total_s: 19825.875062465668
  timestamp: 1637882528
  timesteps_since_restore: 54000
  timesteps_this_iter: 500
  timesteps_total: 54000
  training_iteration: 108
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    108 |          19825.9 | 54000 | 0.508118 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-22-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.5225491567925515
  episode_reward_min: -1.316546762589928
  episodes_this_iter: 500
  episodes_total: 54500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1743.097
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.38774773478507996
        entropy_coeff: 0.0
        kl: 0.00899716466665268
        model: {}
        policy_loss: -0.028690576553344727
        total_loss: -0.01237985398620367
        vf_explained_var: 0.5895107984542847
        vf_loss: 0.01602604240179062
    load_time_ms: 2.442
    num_steps_sampled: 54500
    num_steps_trained: 54500
    sample_time_ms: 41369.899
    update_time_ms: 5.816
  iterations_since_restore: 109
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.88688524590164
    ram_util_percent: 26.014754098360655
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 358.29396111464587
    mean_inference_ms: 1.4724734769987644
    mean_processing_ms: 1.0661640831471426
  time_since_restore: 19867.983513593674
  time_this_iter_s: 42.10845112800598
  time_total_s: 19867.983513593674
  timestamp: 1637882570
  timesteps_since_restore: 54500
  timesteps_this_iter: 500
  timesteps_total: 54500
  training_iteration: 109
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    109 |            19868 | 54500 | 0.522549 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-23-21
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.883385579937304
  episode_reward_mean: 0.5236663833820742
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 55000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1743.539
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3741734027862549
        entropy_coeff: 0.0
        kl: 0.006337790284305811
        model: {}
        policy_loss: -0.018895257264375687
        total_loss: -0.00694690179079771
        vf_explained_var: 0.589487612247467
        vf_loss: 0.011747821234166622
    load_time_ms: 2.434
    num_steps_sampled: 55000
    num_steps_trained: 55000
    sample_time_ms: 39367.761
    update_time_ms: 5.895
  iterations_since_restore: 110
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.845454545454544
    ram_util_percent: 26.202272727272728
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 355.5419047622972
    mean_inference_ms: 1.4697078514033233
    mean_processing_ms: 1.0641642551925303
  time_since_restore: 19898.68032670021
  time_this_iter_s: 30.696813106536865
  time_total_s: 19898.68032670021
  timestamp: 1637882601
  timesteps_since_restore: 55000
  timesteps_this_iter: 500
  timesteps_total: 55000
  training_iteration: 110
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    110 |          19898.7 | 55000 | 0.523666 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-23-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9674665096422789
  episode_reward_mean: 0.5275918239553362
  episode_reward_min: -0.793010752688172
  episodes_this_iter: 500
  episodes_total: 55500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1736.26
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.38110408186912537
        entropy_coeff: 0.0
        kl: 0.00790548324584961
        model: {}
        policy_loss: -0.030936097726225853
        total_loss: -0.01566147617995739
        vf_explained_var: 0.5356524586677551
        vf_loss: 0.015024490654468536
    load_time_ms: 2.427
    num_steps_sampled: 55500
    num_steps_trained: 55500
    sample_time_ms: 37627.703
    update_time_ms: 5.999
  iterations_since_restore: 111
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.113636363636367
    ram_util_percent: 26.061363636363634
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 352.8456380179512
    mean_inference_ms: 1.4670285011690565
    mean_processing_ms: 1.0619119911292132
  time_since_restore: 19929.496876478195
  time_this_iter_s: 30.81654977798462
  time_total_s: 19929.496876478195
  timestamp: 1637882632
  timesteps_since_restore: 55500
  timesteps_this_iter: 500
  timesteps_total: 55500
  training_iteration: 111
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    111 |          19929.5 | 55500 | 0.527592 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-24-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8965327462850853
  episode_reward_mean: 0.5335366263503428
  episode_reward_min: 0.11572052401746726
  episodes_this_iter: 500
  episodes_total: 56000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1719.141
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.37400496006011963
        entropy_coeff: 0.0
        kl: 0.012833887711167336
        model: {}
        policy_loss: -0.027333572506904602
        total_loss: -0.014669003896415234
        vf_explained_var: 0.5735836029052734
        vf_loss: 0.012258490547537804
    load_time_ms: 2.479
    num_steps_sampled: 56000
    num_steps_trained: 56000
    sample_time_ms: 35217.862
    update_time_ms: 5.922
  iterations_since_restore: 112
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.88780487804878
    ram_util_percent: 26.036585365853657
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 350.1579462763467
    mean_inference_ms: 1.4643843894630575
    mean_processing_ms: 1.0597327869216584
  time_since_restore: 19958.161081552505
  time_this_iter_s: 28.664205074310303
  time_total_s: 19958.161081552505
  timestamp: 1637882660
  timesteps_since_restore: 56000
  timesteps_this_iter: 500
  timesteps_total: 56000
  training_iteration: 112
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    112 |          19958.2 | 56000 | 0.533537 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-24-51
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8884335154826958
  episode_reward_mean: 0.5271849265664316
  episode_reward_min: 0.13247863247863248
  episodes_this_iter: 500
  episodes_total: 56500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1709.914
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4181897044181824
        entropy_coeff: 0.0
        kl: 0.007231572642922401
        model: {}
        policy_loss: -0.019277406856417656
        total_loss: -0.00926224235445261
        vf_explained_var: 0.6076273918151855
        vf_loss: 0.009786352515220642
    load_time_ms: 2.393
    num_steps_sampled: 56500
    num_steps_trained: 56500
    sample_time_ms: 34238.311
    update_time_ms: 5.905
  iterations_since_restore: 113
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.863636363636363
    ram_util_percent: 26.14545454545454
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 347.5515082507798
    mean_inference_ms: 1.463856967735564
    mean_processing_ms: 1.05754355346563
  time_since_restore: 19988.870678424835
  time_this_iter_s: 30.709596872329712
  time_total_s: 19988.870678424835
  timestamp: 1637882691
  timesteps_since_restore: 56500
  timesteps_this_iter: 500
  timesteps_total: 56500
  training_iteration: 113
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    113 |          19988.9 | 56500 | 0.527185 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-25-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.526389666524444
  episode_reward_min: 0.1016949152542373
  episodes_this_iter: 500
  episodes_total: 57000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1714.941
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.4319210946559906
        entropy_coeff: 0.0
        kl: 0.009013096801936626
        model: {}
        policy_loss: -0.022479115054011345
        total_loss: -0.011630506254732609
        vf_explained_var: 0.6101281046867371
        vf_loss: 0.010563417337834835
    load_time_ms: 2.38
    num_steps_sampled: 57000
    num_steps_trained: 57000
    sample_time_ms: 34156.68
    update_time_ms: 5.986
  iterations_since_restore: 114
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.171428571428573
    ram_util_percent: 26.132142857142856
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 345.14075707863105
    mean_inference_ms: 1.4613045803051397
    mean_processing_ms: 1.0555028367470436
  time_since_restore: 20028.028833389282
  time_this_iter_s: 39.15815496444702
  time_total_s: 20028.028833389282
  timestamp: 1637882731
  timesteps_since_restore: 57000
  timesteps_this_iter: 500
  timesteps_total: 57000
  training_iteration: 114
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    114 |            20028 | 57000 |  0.52639 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-25-58
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610271903323263
  episode_reward_mean: 0.5073103035825969
  episode_reward_min: -0.1598639455782313
  episodes_this_iter: 500
  episodes_total: 57500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1714.412
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.38632574677467346
        entropy_coeff: 0.0
        kl: 0.0076811532489955425
        model: {}
        policy_loss: -0.0253785140812397
        total_loss: -0.014876801520586014
        vf_explained_var: 0.6423975229263306
        vf_loss: 0.010258687660098076
    load_time_ms: 2.375
    num_steps_sampled: 57500
    num_steps_trained: 57500
    sample_time_ms: 33150.308
    update_time_ms: 5.971
  iterations_since_restore: 115
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.953846153846152
    ram_util_percent: 26.230769230769234
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 342.56631780592454
    mean_inference_ms: 1.4586870269077479
    mean_processing_ms: 1.0534429655487882
  time_since_restore: 20055.451273918152
  time_this_iter_s: 27.42244052886963
  time_total_s: 20055.451273918152
  timestamp: 1637882758
  timesteps_since_restore: 57500
  timesteps_this_iter: 500
  timesteps_total: 57500
  training_iteration: 115
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    115 |          20055.5 | 57500 |  0.50731 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-26-29
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8736111111111111
  episode_reward_mean: 0.5102462267724962
  episode_reward_min: 0.07829977628635347
  episodes_this_iter: 500
  episodes_total: 58000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1717.434
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3892546594142914
        entropy_coeff: 0.0
        kl: 0.010084334760904312
        model: {}
        policy_loss: -0.024400906637310982
        total_loss: -0.015012451447546482
        vf_explained_var: 0.6799089908599854
        vf_loss: 0.009069382213056087
    load_time_ms: 2.372
    num_steps_sampled: 58000
    num_steps_trained: 58000
    sample_time_ms: 32342.636
    update_time_ms: 5.892
  iterations_since_restore: 116
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.106666666666666
    ram_util_percent: 26.1111111111111
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 340.0984642367982
    mean_inference_ms: 1.456333779850507
    mean_processing_ms: 1.0515918497550005
  time_since_restore: 20086.492463111877
  time_this_iter_s: 31.041189193725586
  time_total_s: 20086.492463111877
  timestamp: 1637882789
  timesteps_since_restore: 58000
  timesteps_this_iter: 500
  timesteps_total: 58000
  training_iteration: 116
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    116 |          20086.5 | 58000 | 0.510246 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-26-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.5144934077050624
  episode_reward_min: -0.9777448071216617
  episodes_this_iter: 500
  episodes_total: 58500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1711.071
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.35600167512893677
        entropy_coeff: 0.0
        kl: 0.005697197746485472
        model: {}
        policy_loss: -0.023405328392982483
        total_loss: -0.005463617853820324
        vf_explained_var: 0.5716561675071716
        vf_loss: 0.01776144467294216
    load_time_ms: 2.328
    num_steps_sampled: 58500
    num_steps_trained: 58500
    sample_time_ms: 31695.655
    update_time_ms: 6.021
  iterations_since_restore: 117
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.83030303030303
    ram_util_percent: 26.112121212121213
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 337.53710362758835
    mean_inference_ms: 1.4534242984439627
    mean_processing_ms: 1.049412142298991
  time_since_restore: 20109.50910973549
  time_this_iter_s: 23.01664662361145
  time_total_s: 20109.50910973549
  timestamp: 1637882813
  timesteps_since_restore: 58500
  timesteps_this_iter: 500
  timesteps_total: 58500
  training_iteration: 117
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    117 |          20109.5 | 58500 | 0.514493 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-27-24
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8790544255085212
  episode_reward_mean: 0.5083405397442848
  episode_reward_min: 0.1337386018237082
  episodes_this_iter: 500
  episodes_total: 59000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1720.975
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3405890166759491
        entropy_coeff: 0.0
        kl: 0.005506584420800209
        model: {}
        policy_loss: -0.02045954391360283
        total_loss: -0.009255004115402699
        vf_explained_var: 0.570297360420227
        vf_loss: 0.01103031262755394
    load_time_ms: 2.305
    num_steps_sampled: 59000
    num_steps_trained: 59000
    sample_time_ms: 29757.009
    update_time_ms: 5.912
  iterations_since_restore: 118
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.117777777777777
    ram_util_percent: 26.14444444444444
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 335.15881936438325
    mean_inference_ms: 1.4509825146328994
    mean_processing_ms: 1.0475008102318457
  time_since_restore: 20140.825266122818
  time_this_iter_s: 31.3161563873291
  time_total_s: 20140.825266122818
  timestamp: 1637882844
  timesteps_since_restore: 59000
  timesteps_this_iter: 500
  timesteps_total: 59000
  training_iteration: 118
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    118 |          20140.8 | 59000 | 0.508341 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-27-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8702064896755162
  episode_reward_mean: 0.511288183053042
  episode_reward_min: -0.924198250728863
  episodes_this_iter: 500
  episodes_total: 59500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1733.324
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3632189929485321
        entropy_coeff: 0.0
        kl: 0.011728656478226185
        model: {}
        policy_loss: -0.02232169359922409
        total_loss: -0.0036787856370210648
        vf_explained_var: 0.5368139743804932
        vf_loss: 0.01827179826796055
    load_time_ms: 2.331
    num_steps_sampled: 59500
    num_steps_trained: 59500
    sample_time_ms: 28725.073
    update_time_ms: 5.904
  iterations_since_restore: 119
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.047826086956523
    ram_util_percent: 26.126086956521725
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 332.83045053846683
    mean_inference_ms: 1.4485919662480458
    mean_processing_ms: 1.0455039242283983
  time_since_restore: 20172.73808002472
  time_this_iter_s: 31.912813901901245
  time_total_s: 20172.73808002472
  timestamp: 1637882876
  timesteps_since_restore: 59500
  timesteps_this_iter: 500
  timesteps_total: 59500
  training_iteration: 119
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    119 |          20172.7 | 59500 | 0.511288 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-28-19
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8707386363636364
  episode_reward_mean: 0.5083344178502657
  episode_reward_min: -0.2962962962962963
  episodes_this_iter: 500
  episodes_total: 60000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1715.217
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.34566551446914673
        entropy_coeff: 0.0
        kl: 0.007942002266645432
        model: {}
        policy_loss: -0.020197266712784767
        total_loss: -0.00902375765144825
        vf_explained_var: 0.6249716281890869
        vf_loss: 0.010922214016318321
    load_time_ms: 2.316
    num_steps_sampled: 60000
    num_steps_trained: 60000
    sample_time_ms: 27907.013
    update_time_ms: 5.88
  iterations_since_restore: 120
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.878125
    ram_util_percent: 26.115625
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 330.38435233668275
    mean_inference_ms: 1.4460094292834071
    mean_processing_ms: 1.0433367646870393
  time_since_restore: 20195.07137155533
  time_this_iter_s: 22.33329153060913
  time_total_s: 20195.07137155533
  timestamp: 1637882899
  timesteps_since_restore: 60000
  timesteps_this_iter: 500
  timesteps_total: 60000
  training_iteration: 120
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    120 |          20195.1 | 60000 | 0.508334 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-28-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.4940089228626094
  episode_reward_min: 0.08287292817679558
  episodes_this_iter: 500
  episodes_total: 60500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1734.346
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.349202960729599
        entropy_coeff: 0.0
        kl: 0.010767132975161076
        model: {}
        policy_loss: -0.02913055010139942
        total_loss: -0.018926281481981277
        vf_explained_var: 0.6423219442367554
        vf_loss: 0.009863579645752907
    load_time_ms: 2.336
    num_steps_sampled: 60500
    num_steps_trained: 60500
    sample_time_ms: 27876.341
    update_time_ms: 5.741
  iterations_since_restore: 121
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.111363636363642
    ram_util_percent: 26.10454545454545
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 328.11361283610165
    mean_inference_ms: 1.4437229597352363
    mean_processing_ms: 1.0415651595654958
  time_since_restore: 20225.77237343788
  time_this_iter_s: 30.7010018825531
  time_total_s: 20225.77237343788
  timestamp: 1637882929
  timesteps_since_restore: 60500
  timesteps_this_iter: 500
  timesteps_total: 60500
  training_iteration: 121
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    121 |          20225.8 | 60500 | 0.494009 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-29-11
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8613013698630136
  episode_reward_mean: 0.516917332985905
  episode_reward_min: 0.09944134078212291
  episodes_this_iter: 500
  episodes_total: 61000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1745.339
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3051499128341675
        entropy_coeff: 0.0
        kl: 0.007491830736398697
        model: {}
        policy_loss: -0.01474435068666935
        total_loss: -0.004565776791423559
        vf_explained_var: 0.5946747064590454
        vf_loss: 0.00994153693318367
    load_time_ms: 2.264
    num_steps_sampled: 61000
    num_steps_trained: 61000
    sample_time_ms: 27179.18
    update_time_ms: 5.783
  iterations_since_restore: 122
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.425806451612905
    ram_util_percent: 26.11290322580646
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 325.73505168340165
    mean_inference_ms: 1.4412471152581525
    mean_processing_ms: 1.0395706119100545
  time_since_restore: 20247.575208425522
  time_this_iter_s: 21.80283498764038
  time_total_s: 20247.575208425522
  timestamp: 1637882951
  timesteps_since_restore: 61000
  timesteps_this_iter: 500
  timesteps_total: 61000
  training_iteration: 122
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    122 |          20247.6 | 61000 | 0.516917 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-29-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8739495798319328
  episode_reward_mean: 0.5133595659161986
  episode_reward_min: 0.10222222222222223
  episodes_this_iter: 500
  episodes_total: 61500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1738.979
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.293084055185318
        entropy_coeff: 0.0
        kl: 0.0068711815401911736
        model: {}
        policy_loss: -0.01699323020875454
        total_loss: -0.006298470310866833
        vf_explained_var: 0.6262171268463135
        vf_loss: 0.010477342642843723
    load_time_ms: 2.257
    num_steps_sampled: 61500
    num_steps_trained: 61500
    sample_time_ms: 27370.112
    update_time_ms: 5.866
  iterations_since_restore: 123
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 14.77872340425532
    ram_util_percent: 26.119148936170202
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 323.5719099201572
    mean_inference_ms: 1.4390942565840559
    mean_processing_ms: 1.0377949473237655
  time_since_restore: 20280.130934238434
  time_this_iter_s: 32.55572581291199
  time_total_s: 20280.130934238434
  timestamp: 1637882984
  timesteps_since_restore: 61500
  timesteps_this_iter: 500
  timesteps_total: 61500
  training_iteration: 123
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    123 |          20280.1 | 61500 |  0.51336 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-30-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8731735827001753
  episode_reward_mean: 0.5156160730642577
  episode_reward_min: 0.13157894736842105
  episodes_this_iter: 500
  episodes_total: 62000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1741.992
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.2926901876926422
        entropy_coeff: 0.0
        kl: 0.008434124290943146
        model: {}
        policy_loss: -0.02079196646809578
        total_loss: -0.011180397123098373
        vf_explained_var: 0.6431958675384521
        vf_loss: 0.009344705380499363
    load_time_ms: 2.282
    num_steps_sampled: 62000
    num_steps_trained: 62000
    sample_time_ms: 25801.367
    update_time_ms: 5.832
  iterations_since_restore: 124
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.433333333333334
    ram_util_percent: 26.115151515151517
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 321.2964304035586
    mean_inference_ms: 1.4367054201737885
    mean_processing_ms: 1.035856232735648
  time_since_restore: 20303.63226556778
  time_this_iter_s: 23.501331329345703
  time_total_s: 20303.63226556778
  timestamp: 1637883008
  timesteps_since_restore: 62000
  timesteps_this_iter: 500
  timesteps_total: 62000
  training_iteration: 124
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    124 |          20303.6 | 62000 | 0.515616 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-30-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.5203552831524477
  episode_reward_min: -0.08674698795180723
  episodes_this_iter: 500
  episodes_total: 62500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1735.512
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.27838587760925293
        entropy_coeff: 0.0
        kl: 0.010519376955926418
        model: {}
        policy_loss: -0.014226801693439484
        total_loss: -0.0018134635174646974
        vf_explained_var: 0.5764548182487488
        vf_loss: 0.01208049338310957
    load_time_ms: 2.27
    num_steps_sampled: 62500
    num_steps_trained: 62500
    sample_time_ms: 24877.877
    update_time_ms: 5.818
  iterations_since_restore: 125
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.2
    ram_util_percent: 26.100000000000005
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 318.97134798888874
    mean_inference_ms: 1.434286698019277
    mean_processing_ms: 1.0339861875442418
  time_since_restore: 20321.754392385483
  time_this_iter_s: 18.122126817703247
  time_total_s: 20321.754392385483
  timestamp: 1637883026
  timesteps_since_restore: 62500
  timesteps_this_iter: 500
  timesteps_total: 62500
  training_iteration: 125
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    125 |          20321.8 | 62500 | 0.520355 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-30-54
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.883385579937304
  episode_reward_mean: 0.5268221331176376
  episode_reward_min: -0.34854771784232363
  episodes_this_iter: 500
  episodes_total: 63000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1729.944
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.2949407994747162
        entropy_coeff: 0.0
        kl: 0.014306237921118736
        model: {}
        policy_loss: -0.03943514823913574
        total_loss: -0.027464408427476883
        vf_explained_var: 0.5872127413749695
        vf_loss: 0.011518082581460476
    load_time_ms: 2.266
    num_steps_sampled: 63000
    num_steps_trained: 63000
    sample_time_ms: 24535.591
    update_time_ms: 5.901
  iterations_since_restore: 126
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.357499999999998
    ram_util_percent: 26.110000000000003
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 316.83278238581664
    mean_inference_ms: 1.4320314824566958
    mean_processing_ms: 1.0322292059826945
  time_since_restore: 20349.317671775818
  time_this_iter_s: 27.563279390335083
  time_total_s: 20349.317671775818
  timestamp: 1637883054
  timesteps_since_restore: 63000
  timesteps_this_iter: 500
  timesteps_total: 63000
  training_iteration: 126
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    126 |          20349.3 | 63000 | 0.526822 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-31-09
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9674665096422789
  episode_reward_mean: 0.532735879257222
  episode_reward_min: 0.140625
  episodes_this_iter: 500
  episodes_total: 63500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1719.475
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.27963343262672424
        entropy_coeff: 0.0
        kl: 0.005546548403799534
        model: {}
        policy_loss: -0.017919281497597694
        total_loss: -0.004849646706134081
        vf_explained_var: 0.5338854789733887
        vf_loss: 0.012894142419099808
    load_time_ms: 2.25
    num_steps_sampled: 63500
    num_steps_trained: 63500
    sample_time_ms: 23701.996
    update_time_ms: 5.886
  iterations_since_restore: 127
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.447619047619046
    ram_util_percent: 26.12380952380953
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 314.52502432182035
    mean_inference_ms: 1.4296239707318286
    mean_processing_ms: 1.0303101185406232
  time_since_restore: 20363.89284300804
  time_this_iter_s: 14.57517123222351
  time_total_s: 20363.89284300804
  timestamp: 1637883069
  timesteps_since_restore: 63500
  timesteps_this_iter: 500
  timesteps_total: 63500
  training_iteration: 127
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    127 |          20363.9 | 63500 | 0.532736 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-31-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8965327462850853
  episode_reward_mean: 0.5331374016821327
  episode_reward_min: 0.11572052401746726
  episodes_this_iter: 500
  episodes_total: 64000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1709.882
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.28491175174713135
        entropy_coeff: 0.0
        kl: 0.006827506236732006
        model: {}
        policy_loss: -0.023636313155293465
        total_loss: -0.01319785974919796
        vf_explained_var: 0.6160540580749512
        vf_loss: 0.010222434997558594
    load_time_ms: 2.247
    num_steps_sampled: 64000
    num_steps_trained: 64000
    sample_time_ms: 23149.588
    update_time_ms: 5.934
  iterations_since_restore: 128
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.848648648648648
    ram_util_percent: 26.124324324324327
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 312.4262848279768
    mean_inference_ms: 1.4274255146959942
    mean_processing_ms: 1.0285502334968801
  time_since_restore: 20389.588916540146
  time_this_iter_s: 25.696073532104492
  time_total_s: 20389.588916540146
  timestamp: 1637883094
  timesteps_since_restore: 64000
  timesteps_this_iter: 500
  timesteps_total: 64000
  training_iteration: 128
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    128 |          20389.6 | 64000 | 0.533137 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-32-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5376655531895318
  episode_reward_min: 0.13247863247863248
  episodes_this_iter: 500
  episodes_total: 64500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1708.78
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.3036653995513916
        entropy_coeff: 0.0
        kl: 0.008134115487337112
        model: {}
        policy_loss: -0.014468211680650711
        total_loss: -0.0036613219417631626
        vf_explained_var: 0.6246639490127563
        vf_loss: 0.010549507103860378
    load_time_ms: 2.23
    num_steps_sampled: 64500
    num_steps_trained: 64500
    sample_time_ms: 22823.076
    update_time_ms: 5.938
  iterations_since_restore: 129
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.429268292682927
    ram_util_percent: 26.1170731707317
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 310.4039641292027
    mean_inference_ms: 1.4253091805480351
    mean_processing_ms: 1.0269976972958847
  time_since_restore: 20418.225474119186
  time_this_iter_s: 28.636557579040527
  time_total_s: 20418.225474119186
  timestamp: 1637883123
  timesteps_since_restore: 64500
  timesteps_this_iter: 500
  timesteps_total: 64500
  training_iteration: 129
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    129 |          20418.2 | 64500 | 0.537666 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-32-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610271903323263
  episode_reward_mean: 0.5100915186517515
  episode_reward_min: 0.1016949152542373
  episodes_this_iter: 500
  episodes_total: 65000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1724.596
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.2729063928127289
        entropy_coeff: 0.0
        kl: 0.010634678415954113
        model: {}
        policy_loss: -0.025206496939063072
        total_loss: -0.014287753961980343
        vf_explained_var: 0.5959672331809998
        vf_loss: 0.01058226078748703
    load_time_ms: 2.223
    num_steps_sampled: 65000
    num_steps_trained: 65000
    sample_time_ms: 22798.341
    update_time_ms: 5.907
  iterations_since_restore: 130
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.653125000000001
    ram_util_percent: 26.1375
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 308.31467727703614
    mean_inference_ms: 1.4230760397781739
    mean_processing_ms: 1.0252212924598996
  time_since_restore: 20440.469106197357
  time_this_iter_s: 22.243632078170776
  time_total_s: 20440.469106197357
  timestamp: 1637883146
  timesteps_since_restore: 65000
  timesteps_this_iter: 500
  timesteps_total: 65000
  training_iteration: 130
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    130 |          20440.5 | 65000 | 0.510092 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-32-46
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.855917667238422
  episode_reward_mean: 0.5110846932874901
  episode_reward_min: -0.1598639455782313
  episodes_this_iter: 500
  episodes_total: 65500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1725.666
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.2804122865200043
        entropy_coeff: 0.0
        kl: 0.00527413422241807
        model: {}
        policy_loss: -0.015166890807449818
        total_loss: -0.004634777083992958
        vf_explained_var: 0.6298438906669617
        vf_loss: 0.010365238413214684
    load_time_ms: 2.19
    num_steps_sampled: 65500
    num_steps_trained: 65500
    sample_time_ms: 21793.156
    update_time_ms: 6.015
  iterations_since_restore: 131
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.37666666666667
    ram_util_percent: 26.13666666666667
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 306.23290589055176
    mean_inference_ms: 1.420871281201245
    mean_processing_ms: 1.0234313608771952
  time_since_restore: 20461.12987613678
  time_this_iter_s: 20.660769939422607
  time_total_s: 20461.12987613678
  timestamp: 1637883166
  timesteps_since_restore: 65500
  timesteps_this_iter: 500
  timesteps_total: 65500
  training_iteration: 131
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    131 |          20461.1 | 65500 | 0.511085 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-33-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8736111111111111
  episode_reward_mean: 0.5097607968891854
  episode_reward_min: 0.0777479892761394
  episodes_this_iter: 500
  episodes_total: 66000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1719.827
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.28899556398391724
        entropy_coeff: 0.0
        kl: 0.005695588421076536
        model: {}
        policy_loss: -0.020539453253149986
        total_loss: -0.011338385753333569
        vf_explained_var: 0.6992440819740295
        vf_loss: 0.009020856581628323
    load_time_ms: 2.178
    num_steps_sampled: 66000
    num_steps_trained: 66000
    sample_time_ms: 21999.251
    update_time_ms: 6.037
  iterations_since_restore: 132
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.367647058823529
    ram_util_percent: 26.114705882352943
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 304.2314770933307
    mean_inference_ms: 1.4187308420251874
    mean_processing_ms: 1.0218117750441833
  time_since_restore: 20484.934792995453
  time_this_iter_s: 23.804916858673096
  time_total_s: 20484.934792995453
  timestamp: 1637883190
  timesteps_since_restore: 66000
  timesteps_this_iter: 500
  timesteps_total: 66000
  training_iteration: 132
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    132 |          20484.9 | 66000 | 0.509761 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-33-29
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8499184339314845
  episode_reward_mean: 0.5197561646081365
  episode_reward_min: 0.033582089552238806
  episodes_this_iter: 500
  episodes_total: 66500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1718.587
    learner:
      default_policy:
        cur_kl_coeff: 0.03164062649011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.2420872300863266
        entropy_coeff: 0.0
        kl: 0.0048525333404541016
        model: {}
        policy_loss: -0.010840297676622868
        total_loss: 0.00013069369015283883
        vf_explained_var: 0.5726099610328674
        vf_loss: 0.010817460715770721
    load_time_ms: 2.185
    num_steps_sampled: 66500
    num_steps_trained: 66500
    sample_time_ms: 20609.037
    update_time_ms: 5.98
  iterations_since_restore: 133
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.74074074074074
    ram_util_percent: 26.11481481481482
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 302.18408706161284
    mean_inference_ms: 1.4166257945783634
    mean_processing_ms: 1.020153411945772
  time_since_restore: 20503.57537651062
  time_this_iter_s: 18.640583515167236
  time_total_s: 20503.57537651062
  timestamp: 1637883209
  timesteps_since_restore: 66500
  timesteps_this_iter: 500
  timesteps_total: 66500
  training_iteration: 133
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    133 |          20503.6 | 66500 | 0.519756 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-33-52
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8790544255085212
  episode_reward_mean: 0.5111321477295645
  episode_reward_min: -0.17647058823529413
  episodes_this_iter: 500
  episodes_total: 67000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1716.281
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2622634768486023
        entropy_coeff: 0.0
        kl: 0.005349463317543268
        model: {}
        policy_loss: -0.023171622306108475
        total_loss: -0.010145395994186401
        vf_explained_var: 0.5690581202507019
        vf_loss: 0.012941589578986168
    load_time_ms: 2.171
    num_steps_sampled: 67000
    num_steps_trained: 67000
    sample_time_ms: 20517.152
    update_time_ms: 6.048
  iterations_since_restore: 134
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.284374999999999
    ram_util_percent: 26.140625
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 300.2243968821685
    mean_inference_ms: 1.414496813853661
    mean_processing_ms: 1.0184840201207077
  time_since_restore: 20526.13505268097
  time_this_iter_s: 22.55967617034912
  time_total_s: 20526.13505268097
  timestamp: 1637883232
  timesteps_since_restore: 67000
  timesteps_this_iter: 500
  timesteps_total: 67000
  training_iteration: 134
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    134 |          20526.1 | 67000 | 0.511132 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-34-19
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8707386363636364
  episode_reward_mean: 0.5010922878676317
  episode_reward_min: -1.1004709576138147
  episodes_this_iter: 500
  episodes_total: 67500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1728.869
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2812651991844177
        entropy_coeff: 0.0
        kl: 0.01002553477883339
        model: {}
        policy_loss: -0.02580389566719532
        total_loss: -0.006325990427285433
        vf_explained_var: 0.5581552982330322
        vf_loss: 0.019319290295243263
    load_time_ms: 2.189
    num_steps_sampled: 67500
    num_steps_trained: 67500
    sample_time_ms: 21387.947
    update_time_ms: 6.029
  iterations_since_restore: 135
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.771794871794876
    ram_util_percent: 26.110256410256415
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 298.3564512794741
    mean_inference_ms: 1.4125450217521283
    mean_processing_ms: 1.0168614704480596
  time_since_restore: 20553.092302799225
  time_this_iter_s: 26.957250118255615
  time_total_s: 20553.092302799225
  timestamp: 1637883259
  timesteps_since_restore: 67500
  timesteps_this_iter: 500
  timesteps_total: 67500
  training_iteration: 135
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    135 |          20553.1 | 67500 | 0.501092 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-34-43
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.5034984324989978
  episode_reward_min: -0.2490272373540856
  episodes_this_iter: 500
  episodes_total: 68000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1735.226
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2759532630443573
        entropy_coeff: 0.0
        kl: 0.012719310820102692
        model: {}
        policy_loss: -0.028019947931170464
        total_loss: -0.01668582111597061
        vf_explained_var: 0.6311742663383484
        vf_loss: 0.011132905259728432
    load_time_ms: 2.193
    num_steps_sampled: 68000
    num_steps_trained: 68000
    sample_time_ms: 20997.261
    update_time_ms: 6.077
  iterations_since_restore: 136
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.88529411764706
    ram_util_percent: 26.114705882352943
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 296.46946871954367
    mean_inference_ms: 1.4105443034045346
    mean_processing_ms: 1.015264155841891
  time_since_restore: 20576.812812566757
  time_this_iter_s: 23.72050976753235
  time_total_s: 20576.812812566757
  timestamp: 1637883283
  timesteps_since_restore: 68000
  timesteps_this_iter: 500
  timesteps_total: 68000
  training_iteration: 136
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    136 |          20576.8 | 68000 | 0.503498 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-35-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.5033435414601151
  episode_reward_min: -0.2675324675324675
  episodes_this_iter: 500
  episodes_total: 68500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1735.005
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.3086526095867157
        entropy_coeff: 0.0
        kl: 0.00798854511231184
        model: {}
        policy_loss: -0.024861108511686325
        total_loss: -0.013607734814286232
        vf_explained_var: 0.6361755728721619
        vf_loss: 0.011126990430057049
    load_time_ms: 2.182
    num_steps_sampled: 68500
    num_steps_trained: 68500
    sample_time_ms: 21565.854
    update_time_ms: 6.08
  iterations_since_restore: 137
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.910344827586206
    ram_util_percent: 26.134482758620695
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 294.561592196498
    mean_inference_ms: 1.4085991396764563
    mean_processing_ms: 1.013642765219526
  time_since_restore: 20597.07238841057
  time_this_iter_s: 20.259575843811035
  time_total_s: 20597.07238841057
  timestamp: 1637883304
  timesteps_since_restore: 68500
  timesteps_this_iter: 500
  timesteps_total: 68500
  training_iteration: 137
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    137 |          20597.1 | 68500 | 0.503344 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-35-24
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8613013698630136
  episode_reward_mean: 0.5099031306676104
  episode_reward_min: -0.19298245614035087
  episodes_this_iter: 500
  episodes_total: 69000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1751.092
    learner:
      default_policy:
        cur_kl_coeff: 0.01582031324505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.24050432443618774
        entropy_coeff: 0.0
        kl: 0.004400487989187241
        model: {}
        policy_loss: -0.012804665602743626
        total_loss: -0.0016814380651339889
        vf_explained_var: 0.5935664772987366
        vf_loss: 0.01105362456291914
    load_time_ms: 2.189
    num_steps_sampled: 69000
    num_steps_trained: 69000
    sample_time_ms: 21033.335
    update_time_ms: 6.039
  iterations_since_restore: 138
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.236666666666668
    ram_util_percent: 26.150000000000002
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 292.6827277883727
    mean_inference_ms: 1.406566569536358
    mean_processing_ms: 1.012021725672666
  time_since_restore: 20617.604766607285
  time_this_iter_s: 20.53237819671631
  time_total_s: 20617.604766607285
  timestamp: 1637883324
  timesteps_since_restore: 69000
  timesteps_this_iter: 500
  timesteps_total: 69000
  training_iteration: 138
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    138 |          20617.6 | 69000 | 0.509903 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-35-48
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8739495798319328
  episode_reward_mean: 0.5115033271536525
  episode_reward_min: -0.9554234769687965
  episodes_this_iter: 500
  episodes_total: 69500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1745.354
    learner:
      default_policy:
        cur_kl_coeff: 0.00791015662252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.2597546875476837
        entropy_coeff: 0.0
        kl: 0.006231950595974922
        model: {}
        policy_loss: -0.02289406768977642
        total_loss: -0.008300869725644588
        vf_explained_var: 0.561796247959137
        vf_loss: 0.014543900266289711
    load_time_ms: 2.18
    num_steps_sampled: 69500
    num_steps_trained: 69500
    sample_time_ms: 20511.834
    update_time_ms: 6.013
  iterations_since_restore: 139
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.415151515151514
    ram_util_percent: 26.136363636363637
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 290.8728996339756
    mean_inference_ms: 1.4048031176720228
    mean_processing_ms: 1.01067192412008
  time_since_restore: 20640.96857023239
  time_this_iter_s: 23.36380362510681
  time_total_s: 20640.96857023239
  timestamp: 1637883348
  timesteps_since_restore: 69500
  timesteps_this_iter: 500
  timesteps_total: 69500
  training_iteration: 139
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    139 |            20641 | 69500 | 0.511503 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-36-16
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8731735827001753
  episode_reward_mean: 0.5275697212129321
  episode_reward_min: 0.08639308855291576
  episodes_this_iter: 500
  episodes_total: 70000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1740.116
    learner:
      default_policy:
        cur_kl_coeff: 0.00791015662252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.257381409406662
        entropy_coeff: 0.0
        kl: 0.010238582268357277
        model: {}
        policy_loss: -0.01838522218167782
        total_loss: -0.007300593890249729
        vf_explained_var: 0.6108334064483643
        vf_loss: 0.011003640480339527
    load_time_ms: 2.167
    num_steps_sampled: 70000
    num_steps_trained: 70000
    sample_time_ms: 21070.322
    update_time_ms: 6.01
  iterations_since_restore: 140
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.502499999999998
    ram_util_percent: 26.147499999999997
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 289.15197800807294
    mean_inference_ms: 1.4029694711124399
    mean_processing_ms: 1.0092103721921752
  time_since_restore: 20668.745181798935
  time_this_iter_s: 27.77661156654358
  time_total_s: 20668.745181798935
  timestamp: 1637883376
  timesteps_since_restore: 70000
  timesteps_this_iter: 500
  timesteps_total: 70000
  training_iteration: 140
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    140 |          20668.7 | 70000 |  0.52757 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-36-40
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.51792158872598
  episode_reward_min: -0.15421686746987953
  episodes_this_iter: 500
  episodes_total: 70500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1711.104
    learner:
      default_policy:
        cur_kl_coeff: 0.00791015662252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.2308843731880188
        entropy_coeff: 0.0
        kl: 0.004308366682380438
        model: {}
        policy_loss: -0.016564272344112396
        total_loss: -0.0045820618979632854
        vf_explained_var: 0.5719301104545593
        vf_loss: 0.01194813009351492
    load_time_ms: 2.178
    num_steps_sampled: 70500
    num_steps_trained: 70500
    sample_time_ms: 21444.443
    update_time_ms: 5.926
  iterations_since_restore: 141
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.082857142857144
    ram_util_percent: 26.14571428571429
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 287.4065851705638
    mean_inference_ms: 1.4012297563229157
    mean_processing_ms: 1.0077436670908901
  time_since_restore: 20692.855830430984
  time_this_iter_s: 24.11064863204956
  time_total_s: 20692.855830430984
  timestamp: 1637883400
  timesteps_since_restore: 70500
  timesteps_this_iter: 500
  timesteps_total: 70500
  training_iteration: 141
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.2/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    141 |          20692.9 | 70500 | 0.517922 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-37-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9674665096422789
  episode_reward_mean: 0.5293866771096405
  episode_reward_min: -0.17902813299232737
  episodes_this_iter: 500
  episodes_total: 71000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1717.338
    learner:
      default_policy:
        cur_kl_coeff: 0.003955078311264515
        cur_lr: 4.999999873689376e-05
        entropy: 0.23534470796585083
        entropy_coeff: 0.0
        kl: 0.01590888202190399
        model: {}
        policy_loss: -0.03732209652662277
        total_loss: -0.025495121255517006
        vf_explained_var: 0.5809120535850525
        vf_loss: 0.011764065362513065
    load_time_ms: 2.181
    num_steps_sampled: 71000
    num_steps_trained: 71000
    sample_time_ms: 21443.74
    update_time_ms: 5.789
  iterations_since_restore: 142
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.93529411764706
    ram_util_percent: 26.13823529411765
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 285.67854151709173
    mean_inference_ms: 1.3993949907329475
    mean_processing_ms: 1.0063376027569546
  time_since_restore: 20716.714730501175
  time_this_iter_s: 23.85890007019043
  time_total_s: 20716.714730501175
  timestamp: 1637883424
  timesteps_since_restore: 71000
  timesteps_this_iter: 500
  timesteps_total: 71000
  training_iteration: 142
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    142 |          20716.7 | 71000 | 0.529387 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-37-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8918238993710692
  episode_reward_mean: 0.5315034135309513
  episode_reward_min: -0.12962962962962962
  episodes_this_iter: 500
  episodes_total: 71500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1718.296
    learner:
      default_policy:
        cur_kl_coeff: 0.003955078311264515
        cur_lr: 4.999999873689376e-05
        entropy: 0.223871648311615
        entropy_coeff: 0.0
        kl: 0.01007007248699665
        model: {}
        policy_loss: -0.021223390474915504
        total_loss: -0.008838533423841
        vf_explained_var: 0.5518593788146973
        vf_loss: 0.0123450281098485
    load_time_ms: 2.181
    num_steps_sampled: 71500
    num_steps_trained: 71500
    sample_time_ms: 21774.592
    update_time_ms: 5.822
  iterations_since_restore: 143
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.946875000000002
    ram_util_percent: 26.13125
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 283.95043582033026
    mean_inference_ms: 1.3974727336327462
    mean_processing_ms: 1.004896307856541
  time_since_restore: 20738.674030542374
  time_this_iter_s: 21.95930004119873
  time_total_s: 20738.674030542374
  timestamp: 1637883446
  timesteps_since_restore: 71500
  timesteps_this_iter: 500
  timesteps_total: 71500
  training_iteration: 143
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    143 |          20738.7 | 71500 | 0.531503 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-37-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8965327462850853
  episode_reward_mean: 0.5331235396388786
  episode_reward_min: 0.13247863247863248
  episodes_this_iter: 500
  episodes_total: 72000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1705.027
    learner:
      default_policy:
        cur_kl_coeff: 0.003955078311264515
        cur_lr: 4.999999873689376e-05
        entropy: 0.2599864900112152
        entropy_coeff: 0.0
        kl: 0.008002502843737602
        model: {}
        policy_loss: -0.01818493753671646
        total_loss: -0.008555363863706589
        vf_explained_var: 0.6248571872711182
        vf_loss: 0.009597924537956715
    load_time_ms: 2.178
    num_steps_sampled: 72000
    num_steps_trained: 72000
    sample_time_ms: 21308.67
    update_time_ms: 5.788
  iterations_since_restore: 144
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.572000000000001
    ram_util_percent: 26.172000000000004
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 282.1889855583812
    mean_inference_ms: 1.3955284613019645
    mean_processing_ms: 1.0033502401380883
  time_since_restore: 20756.44046521187
  time_this_iter_s: 17.76643466949463
  time_total_s: 20756.44046521187
  timestamp: 1637883464
  timesteps_since_restore: 72000
  timesteps_this_iter: 500
  timesteps_total: 72000
  training_iteration: 144
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    144 |          20756.4 | 72000 | 0.533124 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-38-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5326804769840193
  episode_reward_min: 0.13859275053304904
  episodes_this_iter: 500
  episodes_total: 72500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1701.792
    learner:
      default_policy:
        cur_kl_coeff: 0.003955078311264515
        cur_lr: 4.999999873689376e-05
        entropy: 0.25439292192459106
        entropy_coeff: 0.0
        kl: 0.012752389535307884
        model: {}
        policy_loss: -0.016866810619831085
        total_loss: -0.0064026671461761
        vf_explained_var: 0.6071599125862122
        vf_loss: 0.010413707233965397
    load_time_ms: 2.18
    num_steps_sampled: 72500
    num_steps_trained: 72500
    sample_time_ms: 20828.503
    update_time_ms: 5.828
  iterations_since_restore: 145
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.415625
    ram_util_percent: 26.128125000000004
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 280.5078710711063
    mean_inference_ms: 1.3938716351694076
    mean_processing_ms: 1.0020386010054483
  time_since_restore: 20778.562758922577
  time_this_iter_s: 22.122293710708618
  time_total_s: 20778.562758922577
  timestamp: 1637883486
  timesteps_since_restore: 72500
  timesteps_this_iter: 500
  timesteps_total: 72500
  training_iteration: 145
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    145 |          20778.6 | 72500 |  0.53268 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-38-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610271903323263
  episode_reward_mean: 0.5117191836776005
  episode_reward_min: -0.02040816326530612
  episodes_this_iter: 500
  episodes_total: 73000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1694.944
    learner:
      default_policy:
        cur_kl_coeff: 0.003955078311264515
        cur_lr: 4.999999873689376e-05
        entropy: 0.2572503089904785
        entropy_coeff: 0.0
        kl: 0.007998825050890446
        model: {}
        policy_loss: -0.019684256985783577
        total_loss: -0.008476466871798038
        vf_explained_var: 0.5919234752655029
        vf_loss: 0.011176154948771
    load_time_ms: 2.199
    num_steps_sampled: 73000
    num_steps_trained: 73000
    sample_time_ms: 20624.116
    update_time_ms: 5.759
  iterations_since_restore: 146
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.654838709677417
    ram_util_percent: 26.158064516129038
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 278.84418680149207
    mean_inference_ms: 1.3922258781453691
    mean_processing_ms: 1.0007357355996391
  time_since_restore: 20800.170612812042
  time_this_iter_s: 21.607853889465332
  time_total_s: 20800.170612812042
  timestamp: 1637883508
  timesteps_since_restore: 73000
  timesteps_this_iter: 500
  timesteps_total: 73000
  training_iteration: 146
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    146 |          20800.2 | 73000 | 0.511719 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-38-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8596214511041009
  episode_reward_mean: 0.5090819355680277
  episode_reward_min: -0.2736842105263158
  episodes_this_iter: 500
  episodes_total: 73500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1704.102
    learner:
      default_policy:
        cur_kl_coeff: 0.003955078311264515
        cur_lr: 4.999999873689376e-05
        entropy: 0.24020451307296753
        entropy_coeff: 0.0
        kl: 0.013145601376891136
        model: {}
        policy_loss: -0.017360582947731018
        total_loss: -0.007098448928445578
        vf_explained_var: 0.6402688026428223
        vf_loss: 0.010210160166025162
    load_time_ms: 2.22
    num_steps_sampled: 73500
    num_steps_trained: 73500
    sample_time_ms: 20649.242
    update_time_ms: 5.653
  iterations_since_restore: 147
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.133333333333333
    ram_util_percent: 26.170000000000005
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 277.189492008329
    mean_inference_ms: 1.3903743469709118
    mean_processing_ms: 0.9993943364809545
  time_since_restore: 20820.77196621895
  time_this_iter_s: 20.601353406906128
  time_total_s: 20820.77196621895
  timestamp: 1637883529
  timesteps_since_restore: 73500
  timesteps_this_iter: 500
  timesteps_total: 73500
  training_iteration: 147
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    147 |          20820.8 | 73500 | 0.509082 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-39-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8736111111111111
  episode_reward_mean: 0.5138450301009839
  episode_reward_min: 0.0703883495145631
  episodes_this_iter: 500
  episodes_total: 74000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1706.039
    learner:
      default_policy:
        cur_kl_coeff: 0.003955078311264515
        cur_lr: 4.999999873689376e-05
        entropy: 0.22329223155975342
        entropy_coeff: 0.0
        kl: 0.004537017550319433
        model: {}
        policy_loss: -0.011232810094952583
        total_loss: -0.0014119511470198631
        vf_explained_var: 0.6608377695083618
        vf_loss: 0.0098029226064682
    load_time_ms: 2.206
    num_steps_sampled: 74000
    num_steps_trained: 74000
    sample_time_ms: 20317.229
    update_time_ms: 5.711
  iterations_since_restore: 148
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.276
    ram_util_percent: 26.140000000000004
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 275.51019305955793
    mean_inference_ms: 1.3885695448347164
    mean_processing_ms: 0.9979149214043924
  time_since_restore: 20838.003421783447
  time_this_iter_s: 17.2314555644989
  time_total_s: 20838.003421783447
  timestamp: 1637883546
  timesteps_since_restore: 74000
  timesteps_this_iter: 500
  timesteps_total: 74000
  training_iteration: 148
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    148 |            20838 | 74000 | 0.513845 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-39-26
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8790544255085212
  episode_reward_mean: 0.51661320644374
  episode_reward_min: 0.014112903225806451
  episodes_this_iter: 500
  episodes_total: 74500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1715.091
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.21464687585830688
        entropy_coeff: 0.0
        kl: 0.010385185480117798
        model: {}
        policy_loss: -0.014125742949545383
        total_loss: -0.0026553955394774675
        vf_explained_var: 0.5689063668251038
        vf_loss: 0.01144980639219284
    load_time_ms: 2.203
    num_steps_sampled: 74500
    num_steps_trained: 74500
    sample_time_ms: 19854.09
    update_time_ms: 5.751
  iterations_since_restore: 149
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.81851851851852
    ram_util_percent: 26.140740740740743
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 273.87519472933536
    mean_inference_ms: 1.386895211558587
    mean_processing_ms: 0.9966366044726254
  time_since_restore: 20856.828330039978
  time_this_iter_s: 18.82490825653076
  time_total_s: 20856.828330039978
  timestamp: 1637883566
  timesteps_since_restore: 74500
  timesteps_this_iter: 500
  timesteps_total: 74500
  training_iteration: 149
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    149 |          20856.8 | 74500 | 0.516613 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-39-36
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8702064896755162
  episode_reward_mean: 0.5108106248756287
  episode_reward_min: -0.22085889570552147
  episodes_this_iter: 500
  episodes_total: 75000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1722.889
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.22041797637939453
        entropy_coeff: 0.0
        kl: 0.011540716513991356
        model: {}
        policy_loss: -0.013975189067423344
        total_loss: 0.0008947247406467795
        vf_explained_var: 0.5383831262588501
        vf_loss: 0.01484709046781063
    load_time_ms: 2.205
    num_steps_sampled: 75000
    num_steps_trained: 75000
    sample_time_ms: 18142.239
    update_time_ms: 5.83
  iterations_since_restore: 150
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.45
    ram_util_percent: 26.15625
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 272.15472082572245
    mean_inference_ms: 1.3850030291120372
    mean_processing_ms: 0.9950908638204241
  time_since_restore: 20867.56591153145
  time_this_iter_s: 10.737581491470337
  time_total_s: 20867.56591153145
  timestamp: 1637883576
  timesteps_since_restore: 75000
  timesteps_this_iter: 500
  timesteps_total: 75000
  training_iteration: 150
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    150 |          20867.6 | 75000 | 0.510811 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-39-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8707386363636364
  episode_reward_mean: 0.5052497395179701
  episode_reward_min: -0.2755102040816326
  episodes_this_iter: 500
  episodes_total: 75500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1740.534
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.2088608592748642
        entropy_coeff: 0.0
        kl: 0.00688495859503746
        model: {}
        policy_loss: -0.018782222643494606
        total_loss: -0.007536536548286676
        vf_explained_var: 0.5973652601242065
        vf_loss: 0.011232078075408936
    load_time_ms: 2.212
    num_steps_sampled: 75500
    num_steps_trained: 75500
    sample_time_ms: 17312.491
    update_time_ms: 5.82
  iterations_since_restore: 151
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.817391304347824
    ram_util_percent: 26.160869565217393
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 270.52766698472306
    mean_inference_ms: 1.38341183236172
    mean_processing_ms: 0.9938073053108751
  time_since_restore: 20883.554849624634
  time_this_iter_s: 15.988938093185425
  time_total_s: 20883.554849624634
  timestamp: 1637883593
  timesteps_since_restore: 75500
  timesteps_this_iter: 500
  timesteps_total: 75500
  training_iteration: 151
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    151 |          20883.6 | 75500 |  0.50525 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-40-06
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.49516927649144205
  episode_reward_min: -0.3756906077348066
  episodes_this_iter: 500
  episodes_total: 76000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1736.865
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.253979355096817
        entropy_coeff: 0.0
        kl: 0.010681862942874432
        model: {}
        policy_loss: -0.02248198911547661
        total_loss: -0.010169118642807007
        vf_explained_var: 0.6361235976219177
        vf_loss: 0.012291745282709599
    load_time_ms: 2.201
    num_steps_sampled: 76000
    num_steps_trained: 76000
    sample_time_ms: 16214.926
    update_time_ms: 5.909
  iterations_since_restore: 152
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.677777777777777
    ram_util_percent: 26.155555555555555
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 268.8802784191079
    mean_inference_ms: 1.3816526216233485
    mean_processing_ms: 0.9924613090426094
  time_since_restore: 20896.402189731598
  time_this_iter_s: 12.847340106964111
  time_total_s: 20896.402189731598
  timestamp: 1637883606
  timesteps_since_restore: 76000
  timesteps_this_iter: 500
  timesteps_total: 76000
  training_iteration: 152
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    152 |          20896.4 | 76000 | 0.495169 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-40-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8632352941176471
  episode_reward_mean: 0.5168469340552879
  episode_reward_min: 0.10964912280701754
  episodes_this_iter: 500
  episodes_total: 76500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1745.094
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.2188369184732437
        entropy_coeff: 0.0
        kl: 0.006767128128558397
        model: {}
        policy_loss: -0.014548956416547298
        total_loss: -0.005447498522698879
        vf_explained_var: 0.6299472451210022
        vf_loss: 0.00908808782696724
    load_time_ms: 2.216
    num_steps_sampled: 76500
    num_steps_trained: 76500
    sample_time_ms: 15605.524
    update_time_ms: 5.862
  iterations_since_restore: 153
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.08695652173913
    ram_util_percent: 26.147826086956524
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 267.2953206765646
    mean_inference_ms: 1.3799696996712805
    mean_processing_ms: 0.9911658054841029
  time_since_restore: 20912.348917245865
  time_this_iter_s: 15.946727514266968
  time_total_s: 20912.348917245865
  timestamp: 1637883622
  timesteps_since_restore: 76500
  timesteps_this_iter: 500
  timesteps_total: 76500
  training_iteration: 153
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    153 |          20912.3 | 76500 | 0.516847 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-40-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8463375796178344
  episode_reward_mean: 0.5101014614484602
  episode_reward_min: 0.09944134078212291
  episodes_this_iter: 500
  episodes_total: 77000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1764.613
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.21774902939796448
        entropy_coeff: 0.0
        kl: 0.010432137176394463
        model: {}
        policy_loss: -0.01818637177348137
        total_loss: -0.007967062294483185
        vf_explained_var: 0.6049156188964844
        vf_loss: 0.010198681615293026
    load_time_ms: 2.207
    num_steps_sampled: 77000
    num_steps_trained: 77000
    sample_time_ms: 15525.438
    update_time_ms: 5.846
  iterations_since_restore: 154
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.332
    ram_util_percent: 26.156
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 265.74583335724174
    mean_inference_ms: 1.3783722564391696
    mean_processing_ms: 0.9898704590189741
  time_since_restore: 20929.510010004044
  time_this_iter_s: 17.16109275817871
  time_total_s: 20929.510010004044
  timestamp: 1637883639
  timesteps_since_restore: 77000
  timesteps_this_iter: 500
  timesteps_total: 77000
  training_iteration: 154
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    154 |          20929.5 | 77000 | 0.510101 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-40-59
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8739495798319328
  episode_reward_mean: 0.5127622558761131
  episode_reward_min: -0.271356783919598
  episodes_this_iter: 500
  episodes_total: 77500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1767.683
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.22715772688388824
        entropy_coeff: 0.0
        kl: 0.009761568158864975
        model: {}
        policy_loss: -0.021606383845210075
        total_loss: -0.010672071017324924
        vf_explained_var: 0.587638258934021
        vf_loss: 0.010914999060332775
    load_time_ms: 2.192
    num_steps_sampled: 77500
    num_steps_trained: 77500
    sample_time_ms: 15256.518
    update_time_ms: 5.885
  iterations_since_restore: 155
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.08214285714286
    ram_util_percent: 26.11785714285715
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 264.244665759737
    mean_inference_ms: 1.3769452977113728
    mean_processing_ms: 0.9886602778842123
  time_since_restore: 20948.974107027054
  time_this_iter_s: 19.464097023010254
  time_total_s: 20948.974107027054
  timestamp: 1637883659
  timesteps_since_restore: 77500
  timesteps_this_iter: 500
  timesteps_total: 77500
  training_iteration: 155
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    155 |            20949 | 77500 | 0.512762 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-41-11
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.5226418228833765
  episode_reward_min: -0.888646288209607
  episodes_this_iter: 500
  episodes_total: 78000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1774.372
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.19704684615135193
        entropy_coeff: 0.0
        kl: 0.007850759662687778
        model: {}
        policy_loss: -0.019633566960692406
        total_loss: -0.004043967463076115
        vf_explained_var: 0.5667018294334412
        vf_loss: 0.015574071556329727
    load_time_ms: 2.176
    num_steps_sampled: 78000
    num_steps_trained: 78000
    sample_time_ms: 14286.841
    update_time_ms: 5.852
  iterations_since_restore: 156
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.516666666666666
    ram_util_percent: 26.150000000000002
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 262.6679892558379
    mean_inference_ms: 1.3753137023517323
    mean_processing_ms: 0.9873637838123152
  time_since_restore: 20960.95212507248
  time_this_iter_s: 11.978018045425415
  time_total_s: 20960.95212507248
  timestamp: 1637883671
  timesteps_since_restore: 78000
  timesteps_this_iter: 500
  timesteps_total: 78000
  training_iteration: 156
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    156 |            20961 | 78000 | 0.522642 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-41-19
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.883385579937304
  episode_reward_mean: 0.524105493865104
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 78500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1772.684
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.19477355480194092
        entropy_coeff: 0.0
        kl: 0.0054208217188715935
        model: {}
        policy_loss: -0.010892484337091446
        total_loss: 8.660554726702685e-07
        vf_explained_var: 0.603047251701355
        vf_loss: 0.01088261604309082
    load_time_ms: 2.176
    num_steps_sampled: 78500
    num_steps_trained: 78500
    sample_time_ms: 13055.027
    update_time_ms: 5.929
  iterations_since_restore: 157
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.325000000000003
    ram_util_percent: 26.175
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 261.0651721477635
    mean_inference_ms: 1.373664796526263
    mean_processing_ms: 0.9859102692349371
  time_since_restore: 20969.219111919403
  time_this_iter_s: 8.266986846923828
  time_total_s: 20969.219111919403
  timestamp: 1637883679
  timesteps_since_restore: 78500
  timesteps_this_iter: 500
  timesteps_total: 78500
  training_iteration: 157
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    157 |          20969.2 | 78500 | 0.524105 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-41-30
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9674665096422789
  episode_reward_mean: 0.5300355560636576
  episode_reward_min: 0.06177606177606178
  episodes_this_iter: 500
  episodes_total: 79000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1760.912
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.21501193940639496
        entropy_coeff: 0.0
        kl: 0.007489404641091824
        model: {}
        policy_loss: -0.014417891390621662
        total_loss: -0.002277264604344964
        vf_explained_var: 0.5651267170906067
        vf_loss: 0.012125811539590359
    load_time_ms: 2.205
    num_steps_sampled: 79000
    num_steps_trained: 79000
    sample_time_ms: 12412.463
    update_time_ms: 5.867
  iterations_since_restore: 158
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.19333333333333
    ram_util_percent: 26.14666666666667
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 259.5129266204527
    mean_inference_ms: 1.3720096858974846
    mean_processing_ms: 0.9846468095294979
  time_since_restore: 20979.907586574554
  time_this_iter_s: 10.688474655151367
  time_total_s: 20979.907586574554
  timestamp: 1637883690
  timesteps_since_restore: 79000
  timesteps_this_iter: 500
  timesteps_total: 79000
  training_iteration: 158
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    158 |          20979.9 | 79000 | 0.530036 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-41-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8965327462850853
  episode_reward_mean: 0.5349976150611382
  episode_reward_min: -0.9755501222493888
  episodes_this_iter: 500
  episodes_total: 79500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1748.008
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.18645203113555908
        entropy_coeff: 0.0
        kl: 0.0073759364895522594
        model: {}
        policy_loss: -0.018049385398626328
        total_loss: -0.0029203426092863083
        vf_explained_var: 0.5679346919059753
        vf_loss: 0.015114450827240944
    load_time_ms: 2.203
    num_steps_sampled: 79500
    num_steps_trained: 79500
    sample_time_ms: 11875.145
    update_time_ms: 5.842
  iterations_since_restore: 159
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.652631578947368
    ram_util_percent: 26.178947368421053
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 258.0139512477499
    mean_inference_ms: 1.3705153844396754
    mean_processing_ms: 0.9834190082001844
  time_since_restore: 20993.229341983795
  time_this_iter_s: 13.321755409240723
  time_total_s: 20993.229341983795
  timestamp: 1637883704
  timesteps_since_restore: 79500
  timesteps_this_iter: 500
  timesteps_total: 79500
  training_iteration: 159
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    159 |          20993.2 | 79500 | 0.534998 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-41-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8884335154826958
  episode_reward_mean: 0.5309187174973498
  episode_reward_min: 0.1388888888888889
  episodes_this_iter: 500
  episodes_total: 80000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1727.447
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.1928841918706894
        entropy_coeff: 0.0
        kl: 0.0065373522229492664
        model: {}
        policy_loss: -0.01262186374515295
        total_loss: -0.0025197030045092106
        vf_explained_var: 0.6044715642929077
        vf_loss: 0.010089237242937088
    load_time_ms: 2.22
    num_steps_sampled: 80000
    num_steps_trained: 80000
    sample_time_ms: 12133.288
    update_time_ms: 5.85
  iterations_since_restore: 160
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.726315789473684
    ram_util_percent: 26.189473684210526
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 256.5321435040365
    mean_inference_ms: 1.368953431228243
    mean_processing_ms: 0.9821647778223267
  time_since_restore: 21006.341963529587
  time_this_iter_s: 13.112621545791626
  time_total_s: 21006.341963529587
  timestamp: 1637883717
  timesteps_since_restore: 80000
  timesteps_this_iter: 500
  timesteps_total: 80000
  training_iteration: 160
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    160 |          21006.3 | 80000 | 0.530919 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-42-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.523027535919543
  episode_reward_min: 0.06285714285714286
  episodes_this_iter: 500
  episodes_total: 80500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1724.232
    learner:
      default_policy:
        cur_kl_coeff: 0.0019775391556322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.19044937193393707
        entropy_coeff: 0.0
        kl: 0.0032187735196202993
        model: {}
        policy_loss: -0.012361825443804264
        total_loss: -0.0015531214885413647
        vf_explained_var: 0.5870175361633301
        vf_loss: 0.010802347213029861
    load_time_ms: 2.206
    num_steps_sampled: 80500
    num_steps_trained: 80500
    sample_time_ms: 11565.59
    update_time_ms: 5.837
  iterations_since_restore: 161
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.88
    ram_util_percent: 26.160000000000004
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 255.03294019319645
    mean_inference_ms: 1.3674229734798473
    mean_processing_ms: 0.9809635130983351
  time_since_restore: 21016.62194299698
  time_this_iter_s: 10.279979467391968
  time_total_s: 21016.62194299698
  timestamp: 1637883728
  timesteps_since_restore: 80500
  timesteps_this_iter: 500
  timesteps_total: 80500
  training_iteration: 161
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    161 |          21016.6 | 80500 | 0.523028 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-42-19
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8564668769716088
  episode_reward_mean: 0.5131037250648243
  episode_reward_min: -0.1598639455782313
  episodes_this_iter: 500
  episodes_total: 81000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1728.671
    learner:
      default_policy:
        cur_kl_coeff: 0.0009887695778161287
        cur_lr: 4.999999873689376e-05
        entropy: 0.18172559142112732
        entropy_coeff: 0.0
        kl: 0.00886986032128334
        model: {}
        policy_loss: -0.013881981372833252
        total_loss: -0.0037598521448671818
        vf_explained_var: 0.6381681561470032
        vf_loss: 0.010113359428942204
    load_time_ms: 2.205
    num_steps_sampled: 81000
    num_steps_trained: 81000
    sample_time_ms: 11394.783
    update_time_ms: 5.893
  iterations_since_restore: 162
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.076470588235296
    ram_util_percent: 26.158823529411766
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 253.56156377650723
    mean_inference_ms: 1.3660829015220297
    mean_processing_ms: 0.9798047201166717
  time_since_restore: 21027.805884599686
  time_this_iter_s: 11.18394160270691
  time_total_s: 21027.805884599686
  timestamp: 1637883739
  timesteps_since_restore: 81000
  timesteps_this_iter: 500
  timesteps_total: 81000
  training_iteration: 162
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    162 |          21027.8 | 81000 | 0.513104 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-42-35
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8736111111111111
  episode_reward_mean: 0.5060475348016282
  episode_reward_min: 0.0777479892761394
  episodes_this_iter: 500
  episodes_total: 81500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1727.99
    learner:
      default_policy:
        cur_kl_coeff: 0.0009887695778161287
        cur_lr: 4.999999873689376e-05
        entropy: 0.20608678460121155
        entropy_coeff: 0.0
        kl: 0.008774782530963421
        model: {}
        policy_loss: -0.015506710857152939
        total_loss: -0.006539167370647192
        vf_explained_var: 0.6535423398017883
        vf_loss: 0.008958869613707066
    load_time_ms: 2.185
    num_steps_sampled: 81500
    num_steps_trained: 81500
    sample_time_ms: 11343.49
    update_time_ms: 5.925
  iterations_since_restore: 163
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.881818181818183
    ram_util_percent: 26.172727272727272
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 252.16144667735298
    mean_inference_ms: 1.3646925009533948
    mean_processing_ms: 0.9786547421663094
  time_since_restore: 21043.23329806328
  time_this_iter_s: 15.42741346359253
  time_total_s: 21043.23329806328
  timestamp: 1637883755
  timesteps_since_restore: 81500
  timesteps_this_iter: 500
  timesteps_total: 81500
  training_iteration: 163
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    163 |          21043.2 | 81500 | 0.506048 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-42-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8721109399075501
  episode_reward_mean: 0.5205639201737542
  episode_reward_min: -0.0990990990990991
  episodes_this_iter: 500
  episodes_total: 82000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1708.571
    learner:
      default_policy:
        cur_kl_coeff: 0.0009887695778161287
        cur_lr: 4.999999873689376e-05
        entropy: 0.16269345581531525
        entropy_coeff: 0.0
        kl: 0.01632430963218212
        model: {}
        policy_loss: -0.023683881387114525
        total_loss: -0.01252063363790512
        vf_explained_var: 0.6049458980560303
        vf_loss: 0.01114711444824934
    load_time_ms: 2.182
    num_steps_sampled: 82000
    num_steps_trained: 82000
    sample_time_ms: 10524.252
    update_time_ms: 5.978
  iterations_since_restore: 164
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.307692307692307
    ram_util_percent: 26.199999999999996
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 250.69900836056743
    mean_inference_ms: 1.3631365897909864
    mean_processing_ms: 0.9774953449277319
  time_since_restore: 21052.007796049118
  time_this_iter_s: 8.774497985839844
  time_total_s: 21052.007796049118
  timestamp: 1637883764
  timesteps_since_restore: 82000
  timesteps_this_iter: 500
  timesteps_total: 82000
  training_iteration: 164
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    164 |            21052 | 82000 | 0.520564 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-42-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8790544255085212
  episode_reward_mean: 0.5112027361985749
  episode_reward_min: -0.20759493670886076
  episodes_this_iter: 500
  episodes_total: 82500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1689.691
    learner:
      default_policy:
        cur_kl_coeff: 0.0009887695778161287
        cur_lr: 4.999999873689376e-05
        entropy: 0.16035106778144836
        entropy_coeff: 0.0
        kl: 0.006407027132809162
        model: {}
        policy_loss: -0.01263371016830206
        total_loss: -0.0008673656266182661
        vf_explained_var: 0.5695558190345764
        vf_loss: 0.01176000852137804
    load_time_ms: 2.162
    num_steps_sampled: 82500
    num_steps_trained: 82500
    sample_time_ms: 9473.095
    update_time_ms: 5.932
  iterations_since_restore: 165
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.284615384615385
    ram_util_percent: 26.161538461538466
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 249.25314438137727
    mean_inference_ms: 1.3615554787098547
    mean_processing_ms: 0.976293726046359
  time_since_restore: 21060.77007675171
  time_this_iter_s: 8.762280702590942
  time_total_s: 21060.77007675171
  timestamp: 1637883773
  timesteps_since_restore: 82500
  timesteps_this_iter: 500
  timesteps_total: 82500
  training_iteration: 165
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    165 |          21060.8 | 82500 | 0.511203 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-43-04
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8707386363636364
  episode_reward_mean: 0.5079469319250772
  episode_reward_min: -0.25483870967741934
  episodes_this_iter: 500
  episodes_total: 83000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1669.608
    learner:
      default_policy:
        cur_kl_coeff: 0.0009887695778161287
        cur_lr: 4.999999873689376e-05
        entropy: 0.17720071971416473
        entropy_coeff: 0.0
        kl: 0.005823978688567877
        model: {}
        policy_loss: -0.0086861252784729
        total_loss: 0.005928804166615009
        vf_explained_var: 0.5737830400466919
        vf_loss: 0.01460917666554451
    load_time_ms: 2.189
    num_steps_sampled: 83000
    num_steps_trained: 83000
    sample_time_ms: 9406.964
    update_time_ms: 5.983
  iterations_since_restore: 166
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.99375
    ram_util_percent: 26.2
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 247.85394216221206
    mean_inference_ms: 1.3600108413842442
    mean_processing_ms: 0.9750960969078692
  time_since_restore: 21071.886085271835
  time_this_iter_s: 11.116008520126343
  time_total_s: 21071.886085271835
  timestamp: 1637883784
  timesteps_since_restore: 83000
  timesteps_this_iter: 500
  timesteps_total: 83000
  training_iteration: 166
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    166 |          21071.9 | 83000 | 0.507947 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-43-19
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.5053463422995688
  episode_reward_min: -1.0317700453857792
  episodes_this_iter: 500
  episodes_total: 83500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1680.198
    learner:
      default_policy:
        cur_kl_coeff: 0.0009887695778161287
        cur_lr: 4.999999873689376e-05
        entropy: 0.1936762034893036
        entropy_coeff: 0.0
        kl: 0.005055772140622139
        model: {}
        policy_loss: -0.016882143914699554
        total_loss: -0.002029126277193427
        vf_explained_var: 0.596777081489563
        vf_loss: 0.014848018996417522
    load_time_ms: 2.18
    num_steps_sampled: 83500
    num_steps_trained: 83500
    sample_time_ms: 10054.47
    update_time_ms: 5.944
  iterations_since_restore: 167
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.6
    ram_util_percent: 26.20952380952381
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 246.51299631825034
    mean_inference_ms: 1.3586307556745878
    mean_processing_ms: 0.9740357358955817
  time_since_restore: 21086.734429359436
  time_this_iter_s: 14.848344087600708
  time_total_s: 21086.734429359436
  timestamp: 1637883799
  timesteps_since_restore: 83500
  timesteps_this_iter: 500
  timesteps_total: 83500
  training_iteration: 167
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    167 |          21086.7 | 83500 | 0.505346 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-43-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.50174055521922
  episode_reward_min: 0.08287292817679558
  episodes_this_iter: 500
  episodes_total: 84000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1677.255
    learner:
      default_policy:
        cur_kl_coeff: 0.0009887695778161287
        cur_lr: 4.999999873689376e-05
        entropy: 0.19422011077404022
        entropy_coeff: 0.0
        kl: 0.008646958507597446
        model: {}
        policy_loss: -0.017600033432245255
        total_loss: -0.008393765427172184
        vf_explained_var: 0.6294744610786438
        vf_loss: 0.009197725914418697
    load_time_ms: 2.15
    num_steps_sampled: 84000
    num_steps_trained: 84000
    sample_time_ms: 10191.477
    update_time_ms: 5.915
  iterations_since_restore: 168
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.583333333333332
    ram_util_percent: 26.216666666666665
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 245.15604561856028
    mean_inference_ms: 1.3572195779950706
    mean_processing_ms: 0.9728778812272528
  time_since_restore: 21098.76209616661
  time_this_iter_s: 12.027666807174683
  time_total_s: 21098.76209616661
  timestamp: 1637883811
  timesteps_since_restore: 84000
  timesteps_this_iter: 500
  timesteps_total: 84000
  training_iteration: 168
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    168 |          21098.8 | 84000 | 0.501741 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-43-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8613013698630136
  episode_reward_mean: 0.5088464846178674
  episode_reward_min: -1.4037037037037037
  episodes_this_iter: 500
  episodes_total: 84500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1665.115
    learner:
      default_policy:
        cur_kl_coeff: 0.0009887695778161287
        cur_lr: 4.999999873689376e-05
        entropy: 0.18229077756404877
        entropy_coeff: 0.0
        kl: 0.006876557599753141
        model: {}
        policy_loss: -0.018070705235004425
        total_loss: -0.003537242766469717
        vf_explained_var: 0.6031957864761353
        vf_loss: 0.014526661485433578
    load_time_ms: 2.169
    num_steps_sampled: 84500
    num_steps_trained: 84500
    sample_time_ms: 10095.926
    update_time_ms: 5.892
  iterations_since_restore: 169
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 15.8
    ram_util_percent: 26.223529411764705
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 243.81958545181865
    mean_inference_ms: 1.3557655670432909
    mean_processing_ms: 0.9717541620368256
  time_since_restore: 21111.005690813065
  time_this_iter_s: 12.243594646453857
  time_total_s: 21111.005690813065
  timestamp: 1637883824
  timesteps_since_restore: 84500
  timesteps_this_iter: 500
  timesteps_total: 84500
  training_iteration: 169
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    169 |            21111 | 84500 | 0.508846 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-43-56
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8739495798319328
  episode_reward_mean: 0.512834349780792
  episode_reward_min: 0.06653992395437262
  episodes_this_iter: 500
  episodes_total: 85000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1683.742
    learner:
      default_policy:
        cur_kl_coeff: 0.0009887695778161287
        cur_lr: 4.999999873689376e-05
        entropy: 0.17429399490356445
        entropy_coeff: 0.0
        kl: 0.00842929258942604
        model: {}
        policy_loss: -0.0096836993470788
        total_loss: 0.000926725275348872
        vf_explained_var: 0.6061035990715027
        vf_loss: 0.01060209609568119
    load_time_ms: 2.168
    num_steps_sampled: 85000
    num_steps_trained: 85000
    sample_time_ms: 9940.326
    update_time_ms: 5.872
  iterations_since_restore: 170
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.147058823529413
    ram_util_percent: 26.211764705882352
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 242.49014663025358
    mean_inference_ms: 1.3543982147950289
    mean_processing_ms: 0.9706402241197066
  time_since_restore: 21122.748735427856
  time_this_iter_s: 11.74304461479187
  time_total_s: 21122.748735427856
  timestamp: 1637883836
  timesteps_since_restore: 85000
  timesteps_this_iter: 500
  timesteps_total: 85000
  training_iteration: 170
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    170 |          21122.7 | 85000 | 0.512834 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-44-08
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8731735827001753
  episode_reward_mean: 0.5243349720306592
  episode_reward_min: 0.13157894736842105
  episodes_this_iter: 500
  episodes_total: 85500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1701.108
    learner:
      default_policy:
        cur_kl_coeff: 0.0009887695778161287
        cur_lr: 4.999999873689376e-05
        entropy: 0.18616363406181335
        entropy_coeff: 0.0
        kl: 0.007070052437484264
        model: {}
        policy_loss: -0.016088927164673805
        total_loss: -0.006774487905204296
        vf_explained_var: 0.6444154977798462
        vf_loss: 0.009307454340159893
    load_time_ms: 2.162
    num_steps_sampled: 85500
    num_steps_trained: 85500
    sample_time_ms: 10143.376
    update_time_ms: 5.949
  iterations_since_restore: 171
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.668421052631583
    ram_util_percent: 26.215789473684207
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 241.18456912067765
    mean_inference_ms: 1.3529575868923942
    mean_processing_ms: 0.9695477720503264
  time_since_restore: 21135.233295679092
  time_this_iter_s: 12.484560251235962
  time_total_s: 21135.233295679092
  timestamp: 1637883848
  timesteps_since_restore: 85500
  timesteps_this_iter: 500
  timesteps_total: 85500
  training_iteration: 171
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    171 |          21135.2 | 85500 | 0.524335 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-44-18
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.5178421059631034
  episode_reward_min: -0.0752212389380531
  episodes_this_iter: 500
  episodes_total: 86000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1706.257
    learner:
      default_policy:
        cur_kl_coeff: 0.0009887695778161287
        cur_lr: 4.999999873689376e-05
        entropy: 0.15793611109256744
        entropy_coeff: 0.0
        kl: 0.004644338041543961
        model: {}
        policy_loss: -0.011439140886068344
        total_loss: 0.0014751041308045387
        vf_explained_var: 0.5329228043556213
        vf_loss: 0.01290965173393488
    load_time_ms: 2.189
    num_steps_sampled: 86000
    num_steps_trained: 86000
    sample_time_ms: 9938.521
    update_time_ms: 5.864
  iterations_since_restore: 172
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.861538461538466
    ram_util_percent: 26.2076923076923
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 239.85596992011946
    mean_inference_ms: 1.351437218415097
    mean_processing_ms: 0.9683631558488746
  time_since_restore: 21144.41956782341
  time_this_iter_s: 9.186272144317627
  time_total_s: 21144.41956782341
  timestamp: 1637883858
  timesteps_since_restore: 86000
  timesteps_this_iter: 500
  timesteps_total: 86000
  training_iteration: 172
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    172 |          21144.4 | 86000 | 0.517842 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-44-28
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.883385579937304
  episode_reward_mean: 0.5277903676157334
  episode_reward_min: -0.22660098522167488
  episodes_this_iter: 500
  episodes_total: 86500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1716.406
    learner:
      default_policy:
        cur_kl_coeff: 0.0004943847889080644
        cur_lr: 4.999999873689376e-05
        entropy: 0.18164096772670746
        entropy_coeff: 0.0
        kl: 0.010581706650555134
        model: {}
        policy_loss: -0.018252763897180557
        total_loss: -0.007582496386021376
        vf_explained_var: 0.6063966155052185
        vf_loss: 0.010665042325854301
    load_time_ms: 2.185
    num_steps_sampled: 86500
    num_steps_trained: 86500
    sample_time_ms: 9414.594
    update_time_ms: 5.846
  iterations_since_restore: 173
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.413333333333334
    ram_util_percent: 26.213333333333328
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 238.55560513389221
    mean_inference_ms: 1.3501056611783926
    mean_processing_ms: 0.9673140580689344
  time_since_restore: 21154.709199666977
  time_this_iter_s: 10.289631843566895
  time_total_s: 21154.709199666977
  timestamp: 1637883868
  timesteps_since_restore: 86500
  timesteps_this_iter: 500
  timesteps_total: 86500
  training_iteration: 173
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    173 |          21154.7 | 86500 |  0.52779 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-44-39
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9674665096422789
  episode_reward_mean: 0.5338655181259125
  episode_reward_min: 0.11572052401746726
  episodes_this_iter: 500
  episodes_total: 87000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1735.509
    learner:
      default_policy:
        cur_kl_coeff: 0.0004943847889080644
        cur_lr: 4.999999873689376e-05
        entropy: 0.17797742784023285
        entropy_coeff: 0.0
        kl: 0.007928898558020592
        model: {}
        policy_loss: -0.011775152757763863
        total_loss: 0.0008157666306942701
        vf_explained_var: 0.5574209094047546
        vf_loss: 0.012586998753249645
    load_time_ms: 2.209
    num_steps_sampled: 87000
    num_steps_trained: 87000
    sample_time_ms: 9602.572
    update_time_ms: 5.889
  iterations_since_restore: 174
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.825
    ram_util_percent: 26.2
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 237.27692960713105
    mean_inference_ms: 1.3487415696501444
    mean_processing_ms: 0.9663330135827112
  time_since_restore: 21165.555033683777
  time_this_iter_s: 10.845834016799927
  time_total_s: 21165.555033683777
  timestamp: 1637883879
  timesteps_since_restore: 87000
  timesteps_this_iter: 500
  timesteps_total: 87000
  training_iteration: 174
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    174 |          21165.6 | 87000 | 0.533866 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-44-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8965327462850853
  episode_reward_mean: 0.5361579354872095
  episode_reward_min: 0.14225941422594143
  episodes_this_iter: 500
  episodes_total: 87500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1755.263
    learner:
      default_policy:
        cur_kl_coeff: 0.0004943847889080644
        cur_lr: 4.999999873689376e-05
        entropy: 0.21264350414276123
        entropy_coeff: 0.0
        kl: 0.005952622275799513
        model: {}
        policy_loss: -0.017481651157140732
        total_loss: -0.007232756819576025
        vf_explained_var: 0.571739137172699
        vf_loss: 0.010245952755212784
    load_time_ms: 2.224
    num_steps_sampled: 87500
    num_steps_trained: 87500
    sample_time_ms: 9789.359
    update_time_ms: 5.875
  iterations_since_restore: 175
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.893333333333334
    ram_util_percent: 26.219999999999995
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 236.0117992994204
    mean_inference_ms: 1.3473128344955145
    mean_processing_ms: 0.9651995785837086
  time_since_restore: 21176.38354420662
  time_this_iter_s: 10.828510522842407
  time_total_s: 21176.38354420662
  timestamp: 1637883890
  timesteps_since_restore: 87500
  timesteps_this_iter: 500
  timesteps_total: 87500
  training_iteration: 175
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    175 |          21176.4 | 87500 | 0.536158 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-45-02
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.5314373499681705
  episode_reward_min: -0.26903553299492383
  episodes_this_iter: 500
  episodes_total: 88000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1772.164
    learner:
      default_policy:
        cur_kl_coeff: 0.0004943847889080644
        cur_lr: 4.999999873689376e-05
        entropy: 0.20102132856845856
        entropy_coeff: 0.0
        kl: 0.00833301991224289
        model: {}
        policy_loss: -0.01729312166571617
        total_loss: -0.005958340130746365
        vf_explained_var: 0.614955723285675
        vf_loss: 0.011330661363899708
    load_time_ms: 2.212
    num_steps_sampled: 88000
    num_steps_trained: 88000
    sample_time_ms: 9766.235
    update_time_ms: 5.852
  iterations_since_restore: 176
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.362499999999997
    ram_util_percent: 26.206249999999997
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 234.76471049795285
    mean_inference_ms: 1.3459344228339913
    mean_processing_ms: 0.9641448505450292
  time_since_restore: 21187.437236070633
  time_this_iter_s: 11.053691864013672
  time_total_s: 21187.437236070633
  timestamp: 1637883902
  timesteps_since_restore: 88000
  timesteps_this_iter: 500
  timesteps_total: 88000
  training_iteration: 176
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    176 |          21187.4 | 88000 | 0.531437 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-45-12
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610271903323263
  episode_reward_mean: 0.5168827822673402
  episode_reward_min: 0.1016949152542373
  episodes_this_iter: 500
  episodes_total: 88500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1756.857
    learner:
      default_policy:
        cur_kl_coeff: 0.0004943847889080644
        cur_lr: 4.999999873689376e-05
        entropy: 0.18930883705615997
        entropy_coeff: 0.0
        kl: 0.009387172758579254
        model: {}
        policy_loss: -0.01354304701089859
        total_loss: -0.0026171673089265823
        vf_explained_var: 0.5967082381248474
        vf_loss: 0.010921245440840721
    load_time_ms: 2.201
    num_steps_sampled: 88500
    num_steps_trained: 88500
    sample_time_ms: 9346.802
    update_time_ms: 5.859
  iterations_since_restore: 177
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.40625
    ram_util_percent: 26.224999999999998
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 233.52616783794068
    mean_inference_ms: 1.344661182150935
    mean_processing_ms: 0.9632313370433908
  time_since_restore: 21197.937047719955
  time_this_iter_s: 10.49981164932251
  time_total_s: 21197.937047719955
  timestamp: 1637883912
  timesteps_since_restore: 88500
  timesteps_this_iter: 500
  timesteps_total: 88500
  training_iteration: 177
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    177 |          21197.9 | 88500 | 0.516883 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-45-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8596214511041009
  episode_reward_mean: 0.5106901775240684
  episode_reward_min: 0.0777479892761394
  episodes_this_iter: 500
  episodes_total: 89000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1759.227
    learner:
      default_policy:
        cur_kl_coeff: 0.0004943847889080644
        cur_lr: 4.999999873689376e-05
        entropy: 0.20692190527915955
        entropy_coeff: 0.0
        kl: 0.009208424016833305
        model: {}
        policy_loss: -0.01591549627482891
        total_loss: -0.0063760788179934025
        vf_explained_var: 0.6461769342422485
        vf_loss: 0.009534869343042374
    load_time_ms: 2.247
    num_steps_sampled: 89000
    num_steps_trained: 89000
    sample_time_ms: 8925.162
    update_time_ms: 5.96
  iterations_since_restore: 178
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.62727272727273
    ram_util_percent: 26.2
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 232.27088709972992
    mean_inference_ms: 1.343484688385946
    mean_processing_ms: 0.9622909322462554
  time_since_restore: 21205.773686647415
  time_this_iter_s: 7.836638927459717
  time_total_s: 21205.773686647415
  timestamp: 1637883920
  timesteps_since_restore: 89000
  timesteps_this_iter: 500
  timesteps_total: 89000
  training_iteration: 178
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    178 |          21205.8 | 89000 |  0.51069 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-45-34
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8736111111111111
  episode_reward_mean: 0.5066125988251697
  episode_reward_min: 0.09060402684563758
  episodes_this_iter: 500
  episodes_total: 89500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1756.541
    learner:
      default_policy:
        cur_kl_coeff: 0.0004943847889080644
        cur_lr: 4.999999873689376e-05
        entropy: 0.19422367215156555
        entropy_coeff: 0.0
        kl: 0.01450676191598177
        model: {}
        policy_loss: -0.02101149410009384
        total_loss: -0.011764352209866047
        vf_explained_var: 0.6768541932106018
        vf_loss: 0.009239965118467808
    load_time_ms: 2.233
    num_steps_sampled: 89500
    num_steps_trained: 89500
    sample_time_ms: 9077.392
    update_time_ms: 5.942
  iterations_since_restore: 179
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.419999999999998
    ram_util_percent: 26.214999999999996
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 231.09802403432278
    mean_inference_ms: 1.3422003495725305
    mean_processing_ms: 0.9613238018071394
  time_since_restore: 21219.51286792755
  time_this_iter_s: 13.739181280136108
  time_total_s: 21219.51286792755
  timestamp: 1637883934
  timesteps_since_restore: 89500
  timesteps_this_iter: 500
  timesteps_total: 89500
  training_iteration: 179
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    179 |          21219.5 | 89500 | 0.506613 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-45-42
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8722222222222222
  episode_reward_mean: 0.5259636358268165
  episode_reward_min: 0.033582089552238806
  episodes_this_iter: 500
  episodes_total: 90000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1755.993
    learner:
      default_policy:
        cur_kl_coeff: 0.0004943847889080644
        cur_lr: 4.999999873689376e-05
        entropy: 0.17110523581504822
        entropy_coeff: 0.0
        kl: 0.005782558117061853
        model: {}
        policy_loss: -0.010767975822091103
        total_loss: 0.00035710097290575504
        vf_explained_var: 0.5691719651222229
        vf_loss: 0.011122209019958973
    load_time_ms: 2.235
    num_steps_sampled: 90000
    num_steps_trained: 90000
    sample_time_ms: 8693.037
    update_time_ms: 5.899
  iterations_since_restore: 180
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.39166666666667
    ram_util_percent: 26.20833333333333
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 229.87056401563717
    mean_inference_ms: 1.340858297964407
    mean_processing_ms: 0.9603127748602951
  time_since_restore: 21227.406500339508
  time_this_iter_s: 7.893632411956787
  time_total_s: 21227.406500339508
  timestamp: 1637883942
  timesteps_since_restore: 90000
  timesteps_this_iter: 500
  timesteps_total: 90000
  training_iteration: 180
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    180 |          21227.4 | 90000 | 0.525964 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-45-50
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8790544255085212
  episode_reward_mean: 0.512768664429947
  episode_reward_min: -0.08163265306122448
  episodes_this_iter: 500
  episodes_total: 90500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1734.873
    learner:
      default_policy:
        cur_kl_coeff: 0.0004943847889080644
        cur_lr: 4.999999873689376e-05
        entropy: 0.19889989495277405
        entropy_coeff: 0.0
        kl: 0.008304484188556671
        model: {}
        policy_loss: -0.012811793945729733
        total_loss: 0.00022065520170144737
        vf_explained_var: 0.5594589114189148
        vf_loss: 0.013028348796069622
    load_time_ms: 2.249
    num_steps_sampled: 90500
    num_steps_trained: 90500
    sample_time_ms: 8203.58
    update_time_ms: 5.916
  iterations_since_restore: 181
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.954545454545453
    ram_util_percent: 26.209090909090904
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 228.65285050785863
    mean_inference_ms: 1.33953144958107
    mean_processing_ms: 0.9593191471517778
  time_since_restore: 21234.785578250885
  time_this_iter_s: 7.379077911376953
  time_total_s: 21234.785578250885
  timestamp: 1637883950
  timesteps_since_restore: 90500
  timesteps_this_iter: 500
  timesteps_total: 90500
  training_iteration: 181
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    181 |          21234.8 | 90500 | 0.512769 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-46-03
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8707386363636364
  episode_reward_mean: 0.504463095656354
  episode_reward_min: -0.22085889570552147
  episodes_this_iter: 500
  episodes_total: 91000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1723.397
    learner:
      default_policy:
        cur_kl_coeff: 0.0004943847889080644
        cur_lr: 4.999999873689376e-05
        entropy: 0.18230277299880981
        entropy_coeff: 0.0
        kl: 0.004436420276761055
        model: {}
        policy_loss: -0.010015364736318588
        total_loss: 0.003815992968156934
        vf_explained_var: 0.5528930425643921
        vf_loss: 0.013829167000949383
    load_time_ms: 2.257
    num_steps_sampled: 91000
    num_steps_trained: 91000
    sample_time_ms: 8618.79
    update_time_ms: 5.986
  iterations_since_restore: 182
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.926315789473684
    ram_util_percent: 26.23157894736842
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 227.51142191345355
    mean_inference_ms: 1.338336288564157
    mean_processing_ms: 0.9583661617053066
  time_since_restore: 21248.01018500328
  time_this_iter_s: 13.22460675239563
  time_total_s: 21248.01018500328
  timestamp: 1637883963
  timesteps_since_restore: 91000
  timesteps_this_iter: 500
  timesteps_total: 91000
  training_iteration: 182
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    182 |            21248 | 91000 | 0.504463 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-46-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8689458689458689
  episode_reward_mean: 0.49394480185617706
  episode_reward_min: 0.10401891252955082
  episodes_this_iter: 500
  episodes_total: 91500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1717.971
    learner:
      default_policy:
        cur_kl_coeff: 0.0002471923944540322
        cur_lr: 4.999999873689376e-05
        entropy: 0.21904657781124115
        entropy_coeff: 0.0
        kl: 0.005912414751946926
        model: {}
        policy_loss: -0.010934501886367798
        total_loss: -0.001551458379253745
        vf_explained_var: 0.6771026849746704
        vf_loss: 0.009381591342389584
    load_time_ms: 2.26
    num_steps_sampled: 91500
    num_steps_trained: 91500
    sample_time_ms: 8226.919
    update_time_ms: 6.012
  iterations_since_restore: 183
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.333333333333332
    ram_util_percent: 26.2
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 226.3070491739659
    mean_inference_ms: 1.3370015822054016
    mean_processing_ms: 0.9573005634329166
  time_since_restore: 21254.327026605606
  time_this_iter_s: 6.3168416023254395
  time_total_s: 21254.327026605606
  timestamp: 1637883970
  timesteps_since_restore: 91500
  timesteps_this_iter: 500
  timesteps_total: 91500
  training_iteration: 183
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    183 |          21254.3 | 91500 | 0.493945 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-46-23
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8692551505546752
  episode_reward_mean: 0.5164666117110241
  episode_reward_min: 0.08287292817679558
  episodes_this_iter: 500
  episodes_total: 92000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1723.347
    learner:
      default_policy:
        cur_kl_coeff: 0.0002471923944540322
        cur_lr: 4.999999873689376e-05
        entropy: 0.24109947681427002
        entropy_coeff: 0.0
        kl: 0.014756772667169571
        model: {}
        policy_loss: -0.014644283801317215
        total_loss: -0.005468262825161219
        vf_explained_var: 0.6494269371032715
        vf_loss: 0.009172379039227962
    load_time_ms: 2.238
    num_steps_sampled: 92000
    num_steps_trained: 92000
    sample_time_ms: 8380.229
    update_time_ms: 5.965
  iterations_since_restore: 184
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.2
    ram_util_percent: 26.22222222222222
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 225.181118511464
    mean_inference_ms: 1.3358467766837485
    mean_processing_ms: 0.9563408333732182
  time_since_restore: 21266.75955939293
  time_this_iter_s: 12.432532787322998
  time_total_s: 21266.75955939293
  timestamp: 1637883983
  timesteps_since_restore: 92000
  timesteps_this_iter: 500
  timesteps_total: 92000
  training_iteration: 184
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    184 |          21266.8 | 92000 | 0.516467 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-46-33
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8613013698630136
  episode_reward_mean: 0.5103643178397775
  episode_reward_min: 0.09555555555555556
  episodes_this_iter: 500
  episodes_total: 92500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1695.599
    learner:
      default_policy:
        cur_kl_coeff: 0.0002471923944540322
        cur_lr: 4.999999873689376e-05
        entropy: 0.1853248029947281
        entropy_coeff: 0.0
        kl: 0.004992560483515263
        model: {}
        policy_loss: -0.010565931908786297
        total_loss: -0.000388732849387452
        vf_explained_var: 0.6063358783721924
        vf_loss: 0.010175964795053005
    load_time_ms: 2.22
    num_steps_sampled: 92500
    num_steps_trained: 92500
    sample_time_ms: 8323.608
    update_time_ms: 5.935
  iterations_since_restore: 185
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.69333333333333
    ram_util_percent: 26.199999999999996
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 224.04357557589253
    mean_inference_ms: 1.3346184014106455
    mean_processing_ms: 0.9553280419627329
  time_since_restore: 21276.743180513382
  time_this_iter_s: 9.98362112045288
  time_total_s: 21276.743180513382
  timestamp: 1637883993
  timesteps_since_restore: 92500
  timesteps_this_iter: 500
  timesteps_total: 92500
  training_iteration: 185
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    185 |          21276.7 | 92500 | 0.510364 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-46-41
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8739495798319328
  episode_reward_mean: 0.5150219728876249
  episode_reward_min: 0.11764705882352941
  episodes_this_iter: 500
  episodes_total: 93000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1692.19
    learner:
      default_policy:
        cur_kl_coeff: 0.0001235961972270161
        cur_lr: 4.999999873689376e-05
        entropy: 0.22177278995513916
        entropy_coeff: 0.0
        kl: 0.010923203080892563
        model: {}
        policy_loss: -0.01645093411207199
        total_loss: -0.005245694890618324
        vf_explained_var: 0.5773146152496338
        vf_loss: 0.011203899048268795
    load_time_ms: 2.199
    num_steps_sampled: 93000
    num_steps_trained: 93000
    sample_time_ms: 7994.631
    update_time_ms: 5.937
  iterations_since_restore: 186
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.663636363636364
    ram_util_percent: 26.236363636363635
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 222.89252785964385
    mean_inference_ms: 1.333396402302958
    mean_processing_ms: 0.9543344236991979
  time_since_restore: 21284.47284245491
  time_this_iter_s: 7.72966194152832
  time_total_s: 21284.47284245491
  timestamp: 1637884001
  timesteps_since_restore: 93000
  timesteps_this_iter: 500
  timesteps_total: 93000
  training_iteration: 186
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    186 |          21284.5 | 93000 | 0.515022 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-46-49
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8865336658354115
  episode_reward_mean: 0.527335383907501
  episode_reward_min: 0.08639308855291576
  episodes_this_iter: 500
  episodes_total: 93500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1683.005
    learner:
      default_policy:
        cur_kl_coeff: 0.0001235961972270161
        cur_lr: 4.999999873689376e-05
        entropy: 0.1970801204442978
        entropy_coeff: 0.0
        kl: 0.006276683881878853
        model: {}
        policy_loss: -0.012083316221833229
        total_loss: -0.0007191729382611811
        vf_explained_var: 0.6041973233222961
        vf_loss: 0.011363374069333076
    load_time_ms: 2.198
    num_steps_sampled: 93500
    num_steps_trained: 93500
    sample_time_ms: 7749.569
    update_time_ms: 5.938
  iterations_since_restore: 187
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.641666666666666
    ram_util_percent: 26.224999999999998
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 221.7576578363855
    mean_inference_ms: 1.3322398348444457
    mean_processing_ms: 0.9533836859917064
  time_since_restore: 21292.430864334106
  time_this_iter_s: 7.958021879196167
  time_total_s: 21292.430864334106
  timestamp: 1637884009
  timesteps_since_restore: 93500
  timesteps_this_iter: 500
  timesteps_total: 93500
  training_iteration: 187
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    187 |          21292.4 | 93500 | 0.527335 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s18_512_i1_out.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-46-57
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.883385579937304
  episode_reward_mean: 0.5212410677922116
  episode_reward_min: 0.0
  episodes_this_iter: 500
  episodes_total: 94000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1684.246
    learner:
      default_policy:
        cur_kl_coeff: 0.0001235961972270161
        cur_lr: 4.999999873689376e-05
        entropy: 0.17620427906513214
        entropy_coeff: 0.0
        kl: 0.006276790983974934
        model: {}
        policy_loss: -0.015583766624331474
        total_loss: -0.004335194826126099
        vf_explained_var: 0.5830997824668884
        vf_loss: 0.011247791349887848
    load_time_ms: 2.158
    num_steps_sampled: 94000
    num_steps_trained: 94000
    sample_time_ms: 7772.659
    update_time_ms: 5.899
  iterations_since_restore: 188
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.88181818181818
    ram_util_percent: 26.254545454545454
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 220.63449594023672
    mean_inference_ms: 1.3310424601861393
    mean_processing_ms: 0.9524066532342097
  time_since_restore: 21300.509704351425
  time_this_iter_s: 8.078840017318726
  time_total_s: 21300.509704351425
  timestamp: 1637884017
  timesteps_since_restore: 94000
  timesteps_this_iter: 500
  timesteps_total: 94000
  training_iteration: 188
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    188 |          21300.5 | 94000 | 0.521241 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-47-05
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.9674665096422789
  episode_reward_mean: 0.5340546322355353
  episode_reward_min: 0.13537117903930132
  episodes_this_iter: 500
  episodes_total: 94500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1707.361
    learner:
      default_policy:
        cur_kl_coeff: 0.0001235961972270161
        cur_lr: 4.999999873689376e-05
        entropy: 0.17463693022727966
        entropy_coeff: 0.0
        kl: 0.0055755446664988995
        model: {}
        policy_loss: -0.010060097090899944
        total_loss: 0.001470498158596456
        vf_explained_var: 0.5997730493545532
        vf_loss: 0.011529910378158092
    load_time_ms: 2.14
    num_steps_sampled: 94500
    num_steps_trained: 94500
    sample_time_ms: 7146.611
    update_time_ms: 5.932
  iterations_since_restore: 189
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.474999999999998
    ram_util_percent: 26.23333333333333
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 219.51914309945687
    mean_inference_ms: 1.329863745440057
    mean_processing_ms: 0.9514760976619759
  time_since_restore: 21308.219445943832
  time_this_iter_s: 7.709741592407227
  time_total_s: 21308.219445943832
  timestamp: 1637884025
  timesteps_since_restore: 94500
  timesteps_this_iter: 500
  timesteps_total: 94500
  training_iteration: 189
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    189 |          21308.2 | 94500 | 0.534055 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-47-13
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8918238993710692
  episode_reward_mean: 0.5274567247737733
  episode_reward_min: 0.11572052401746726
  episodes_this_iter: 500
  episodes_total: 95000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1699.653
    learner:
      default_policy:
        cur_kl_coeff: 0.0001235961972270161
        cur_lr: 4.999999873689376e-05
        entropy: 0.1907891482114792
        entropy_coeff: 0.0
        kl: 0.004879091866314411
        model: {}
        policy_loss: -0.00847975816577673
        total_loss: 0.003281388198956847
        vf_explained_var: 0.5695379376411438
        vf_loss: 0.011760546825826168
    load_time_ms: 2.136
    num_steps_sampled: 95000
    num_steps_trained: 95000
    sample_time_ms: 7129.337
    update_time_ms: 5.941
  iterations_since_restore: 190
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.236363636363635
    ram_util_percent: 26.218181818181815
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 218.41541135528587
    mean_inference_ms: 1.3286887522131567
    mean_processing_ms: 0.9505414890992766
  time_since_restore: 21315.863429307938
  time_this_iter_s: 7.643983364105225
  time_total_s: 21315.863429307938
  timestamp: 1637884033
  timesteps_since_restore: 95000
  timesteps_this_iter: 500
  timesteps_total: 95000
  training_iteration: 190
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    190 |          21315.9 | 95000 | 0.527457 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-47-22
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8965327462850853
  episode_reward_mean: 0.524489835249846
  episode_reward_min: 0.13247863247863248
  episodes_this_iter: 500
  episodes_total: 95500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1711.593
    learner:
      default_policy:
        cur_kl_coeff: 6.179809861350805e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.21115373075008392
        entropy_coeff: 0.0
        kl: 0.005504862871021032
        model: {}
        policy_loss: -0.008492243476212025
        total_loss: 0.0006407654145732522
        vf_explained_var: 0.6463416218757629
        vf_loss: 0.009132678620517254
    load_time_ms: 2.136
    num_steps_sampled: 95500
    num_steps_trained: 95500
    sample_time_ms: 7271.732
    update_time_ms: 5.959
  iterations_since_restore: 191
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.153846153846153
    ram_util_percent: 26.238461538461536
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 217.33617775852215
    mean_inference_ms: 1.3275969631503315
    mean_processing_ms: 0.949668624141681
  time_since_restore: 21324.786087036133
  time_this_iter_s: 8.92265772819519
  time_total_s: 21324.786087036133
  timestamp: 1637884042
  timesteps_since_restore: 95500
  timesteps_this_iter: 500
  timesteps_total: 95500
  training_iteration: 191
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    191 |          21324.8 | 95500 |  0.52449 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-47-32
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8958068614993647
  episode_reward_mean: 0.540520617339846
  episode_reward_min: 0.1016949152542373
  episodes_this_iter: 500
  episodes_total: 96000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1713.684
    learner:
      default_policy:
        cur_kl_coeff: 6.179809861350805e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.2088770866394043
        entropy_coeff: 0.0
        kl: 0.005369756370782852
        model: {}
        policy_loss: -0.014478984288871288
        total_loss: -0.003456889884546399
        vf_explained_var: 0.5735574960708618
        vf_loss: 0.011021760292351246
    load_time_ms: 2.118
    num_steps_sampled: 96000
    num_steps_trained: 96000
    sample_time_ms: 6869.13
    update_time_ms: 5.939
  iterations_since_restore: 192
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.96153846153846
    ram_util_percent: 26.246153846153845
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 216.27131338756578
    mean_inference_ms: 1.3264744439793967
    mean_processing_ms: 0.9487714781463
  time_since_restore: 21334.00611639023
  time_this_iter_s: 9.220029354095459
  time_total_s: 21334.00611639023
  timestamp: 1637884052
  timesteps_since_restore: 96000
  timesteps_this_iter: 500
  timesteps_total: 96000
  training_iteration: 192
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    192 |            21334 | 96000 | 0.540521 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-47-44
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8610271903323263
  episode_reward_mean: 0.5026623260267172
  episode_reward_min: -0.1598639455782313
  episodes_this_iter: 500
  episodes_total: 96500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1724.845
    learner:
      default_policy:
        cur_kl_coeff: 6.179809861350805e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.23083245754241943
        entropy_coeff: 0.0
        kl: 0.00753202848136425
        model: {}
        policy_loss: -0.015009356662631035
        total_loss: -0.004504699259996414
        vf_explained_var: 0.6294931769371033
        vf_loss: 0.010504189878702164
    load_time_ms: 2.118
    num_steps_sampled: 96500
    num_steps_trained: 96500
    sample_time_ms: 7488.757
    update_time_ms: 5.973
  iterations_since_restore: 193
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.657894736842106
    ram_util_percent: 26.273684210526316
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 215.2514048466946
    mean_inference_ms: 1.325532533501325
    mean_processing_ms: 0.9479051481198666
  time_since_restore: 21346.6319770813
  time_this_iter_s: 12.625860691070557
  time_total_s: 21346.6319770813
  timestamp: 1637884064
  timesteps_since_restore: 96500
  timesteps_this_iter: 500
  timesteps_total: 96500
  training_iteration: 193
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    193 |          21346.6 | 96500 | 0.502662 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-47-53
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8596214511041009
  episode_reward_mean: 0.5147501657221075
  episode_reward_min: 0.0777479892761394
  episodes_this_iter: 500
  episodes_total: 97000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1689.217
    learner:
      default_policy:
        cur_kl_coeff: 6.179809861350805e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.21868768334388733
        entropy_coeff: 0.0
        kl: 0.006341790780425072
        model: {}
        policy_loss: -0.016359597444534302
        total_loss: -0.006938507780432701
        vf_explained_var: 0.6730045080184937
        vf_loss: 0.009420700371265411
    load_time_ms: 2.111
    num_steps_sampled: 97000
    num_steps_trained: 97000
    sample_time_ms: 7122.948
    update_time_ms: 5.89
  iterations_since_restore: 194
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.3
    ram_util_percent: 26.216666666666665
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 214.20279985688333
    mean_inference_ms: 1.3244942750349835
    mean_processing_ms: 0.9470640893456909
  time_since_restore: 21355.049762010574
  time_this_iter_s: 8.417784929275513
  time_total_s: 21355.049762010574
  timestamp: 1637884073
  timesteps_since_restore: 97000
  timesteps_this_iter: 500
  timesteps_total: 97000
  training_iteration: 194
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    194 |            21355 | 97000 |  0.51475 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-48-02
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8736111111111111
  episode_reward_mean: 0.5196519980900364
  episode_reward_min: 0.0703883495145631
  episodes_this_iter: 500
  episodes_total: 97500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1716.939
    learner:
      default_policy:
        cur_kl_coeff: 6.179809861350805e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.19201883673667908
        entropy_coeff: 0.0
        kl: 0.009820118546485901
        model: {}
        policy_loss: -0.01734917238354683
        total_loss: -0.007620833348482847
        vf_explained_var: 0.6553380489349365
        vf_loss: 0.009727731347084045
    load_time_ms: 2.127
    num_steps_sampled: 97500
    num_steps_trained: 97500
    sample_time_ms: 6957.753
    update_time_ms: 5.94
  iterations_since_restore: 195
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.323076923076925
    ram_util_percent: 26.21538461538461
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 213.16293368670773
    mean_inference_ms: 1.3234007548183548
    mean_processing_ms: 0.9461831910061401
  time_since_restore: 21363.660312891006
  time_this_iter_s: 8.610550880432129
  time_total_s: 21363.660312891006
  timestamp: 1637884082
  timesteps_since_restore: 97500
  timesteps_this_iter: 500
  timesteps_total: 97500
  training_iteration: 195
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    195 |          21363.7 | 97500 | 0.519652 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-48-10
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8790544255085212
  episode_reward_mean: 0.5051182248653867
  episode_reward_min: 0.014112903225806451
  episodes_this_iter: 500
  episodes_total: 98000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1718.518
    learner:
      default_policy:
        cur_kl_coeff: 6.179809861350805e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.19005709886550903
        entropy_coeff: 0.0
        kl: 0.005820472724735737
        model: {}
        policy_loss: -0.008467002771794796
        total_loss: 0.0034284505527466536
        vf_explained_var: 0.5552378296852112
        vf_loss: 0.011895102448761463
    load_time_ms: 2.133
    num_steps_sampled: 98000
    num_steps_trained: 98000
    sample_time_ms: 6942.809
    update_time_ms: 5.945
  iterations_since_restore: 196
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.89090909090909
    ram_util_percent: 26.2
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 212.12460615419832
    mean_inference_ms: 1.3223103523945314
    mean_processing_ms: 0.945280335890775
  time_since_restore: 21371.256420612335
  time_this_iter_s: 7.596107721328735
  time_total_s: 21371.256420612335
  timestamp: 1637884090
  timesteps_since_restore: 98000
  timesteps_this_iter: 500
  timesteps_total: 98000
  training_iteration: 196
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    196 |          21371.3 | 98000 | 0.505118 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-48-20
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8702064896755162
  episode_reward_mean: 0.5107452679544177
  episode_reward_min: -0.7912087912087912
  episodes_this_iter: 500
  episodes_total: 98500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1744.335
    learner:
      default_policy:
        cur_kl_coeff: 6.179809861350805e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.17971087992191315
        entropy_coeff: 0.0
        kl: 0.00649453466758132
        model: {}
        policy_loss: -0.015358302742242813
        total_loss: 0.002124061109498143
        vf_explained_var: 0.5522515773773193
        vf_loss: 0.017481960356235504
    load_time_ms: 2.238
    num_steps_sampled: 98500
    num_steps_trained: 98500
    sample_time_ms: 7164.15
    update_time_ms: 5.975
  iterations_since_restore: 197
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.526666666666664
    ram_util_percent: 26.20666666666666
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 211.12446867946807
    mean_inference_ms: 1.321257654770337
    mean_processing_ms: 0.9444260398508532
  time_since_restore: 21381.687247037888
  time_this_iter_s: 10.430826425552368
  time_total_s: 21381.687247037888
  timestamp: 1637884100
  timesteps_since_restore: 98500
  timesteps_this_iter: 500
  timesteps_total: 98500
  training_iteration: 197
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    197 |          21381.7 | 98500 | 0.510745 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


[2m[36m(pid=22800)[0m Program ./new_garbage_22800/s15_512_256_sub_2.c does not compile in two seconds. Consider removing it or increasing the timeout parameter in utility.py.
Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-48-31
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8707386363636364
  episode_reward_mean: 0.507676357620938
  episode_reward_min: -0.10344827586206896
  episodes_this_iter: 500
  episodes_total: 99000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1735.272
    learner:
      default_policy:
        cur_kl_coeff: 6.179809861350805e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.18161092698574066
        entropy_coeff: 0.0
        kl: 0.007208296097815037
        model: {}
        policy_loss: -0.017490489408373833
        total_loss: -0.006919861305505037
        vf_explained_var: 0.640811562538147
        vf_loss: 0.010570193640887737
    load_time_ms: 2.261
    num_steps_sampled: 99000
    num_steps_trained: 99000
    sample_time_ms: 7389.772
    update_time_ms: 6.022
  iterations_since_restore: 198
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.546666666666667
    ram_util_percent: 26.199999999999996
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 210.13427658746502
    mean_inference_ms: 1.3202878256313533
    mean_processing_ms: 0.9436669108219852
  time_since_restore: 21391.932841300964
  time_this_iter_s: 10.245594263076782
  time_total_s: 21391.932841300964
  timestamp: 1637884111
  timesteps_since_restore: 99000
  timesteps_this_iter: 500
  timesteps_total: 99000
  training_iteration: 198
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    198 |          21391.9 | 99000 | 0.507676 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-48-42
  done: false
  episode_len_mean: 1.0
  episode_reward_max: 0.8684627575277337
  episode_reward_mean: 0.49456180714390513
  episode_reward_min: 0.10497237569060773
  episodes_this_iter: 500
  episodes_total: 99500
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1732.15
    learner:
      default_policy:
        cur_kl_coeff: 6.179809861350805e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.2224724143743515
        entropy_coeff: 0.0
        kl: 0.00917560514062643
        model: {}
        policy_loss: -0.017115723341703415
        total_loss: -0.007229497656226158
        vf_explained_var: 0.6340556740760803
        vf_loss: 0.00988565944135189
    load_time_ms: 2.301
    num_steps_sampled: 99500
    num_steps_trained: 99500
    sample_time_ms: 7719.949
    update_time_ms: 6.035
  iterations_since_restore: 199
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.625
    ram_util_percent: 26.206249999999997
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 209.16079018717696
    mean_inference_ms: 1.3192527297825036
    mean_processing_ms: 0.9428792533629532
  time_since_restore: 21402.913895845413
  time_this_iter_s: 10.981054544448853
  time_total_s: 21402.913895845413
  timestamp: 1637884122
  timesteps_since_restore: 99500
  timesteps_this_iter: 500
  timesteps_total: 99500
  training_iteration: 199
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+-------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |    ts |   reward |
|-------------------+----------+---------------------+--------+------------------+-------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    199 |          21402.9 | 99500 | 0.494562 |
+-------------------+----------+---------------------+--------+------------------+-------+----------+


Result for PPO_autovec_00000:
  custom_metrics: {}
  date: 2021-11-25_17-48-52
  done: true
  episode_len_mean: 1.0
  episode_reward_max: 0.8613013698630136
  episode_reward_mean: 0.5194585153153296
  episode_reward_min: 0.10964912280701754
  episodes_this_iter: 500
  episodes_total: 100000
  experiment_id: c4bf29a2b43f4c30a24da93afcd8c323
  experiment_tag: '0'
  hostname: DESKTOP-D8CG7UF
  info:
    grad_time_ms: 1725.881
    learner:
      default_policy:
        cur_kl_coeff: 6.179809861350805e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.20497122406959534
        entropy_coeff: 0.0
        kl: 0.010376065038144588
        model: {}
        policy_loss: -0.013338551856577396
        total_loss: -0.003699598368257284
        vf_explained_var: 0.6073034405708313
        vf_loss: 0.009638311341404915
    load_time_ms: 2.289
    num_steps_sampled: 100000
    num_steps_trained: 100000
    sample_time_ms: 7902.112
    update_time_ms: 5.996
  iterations_since_restore: 200
  node_ip: 172.28.226.60
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.557142857142857
    ram_util_percent: 26.221428571428568
  pid: 22795
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 208.1822331438703
    mean_inference_ms: 1.318182485441991
    mean_processing_ms: 0.9420493883096751
  time_since_restore: 21412.31558728218
  time_this_iter_s: 9.401691436767578
  time_total_s: 21412.31558728218
  timestamp: 1637884132
  timesteps_since_restore: 100000
  timesteps_this_iter: 500
  timesteps_total: 100000
  training_iteration: 200
  trial_id: '00000'
  
== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 RUNNING)
+-------------------+----------+---------------------+--------+------------------+--------+----------+
| Trial name        | status   | loc                 |   iter |   total time (s) |     ts |   reward |
|-------------------+----------+---------------------+--------+------------------+--------+----------|
| PPO_autovec_00000 | RUNNING  | 172.28.226.60:22795 |    200 |          21412.3 | 100000 | 0.519459 |
+-------------------+----------+---------------------+--------+------------------+--------+----------+


== Status ==
Memory usage on this node: 3.3/12.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/6.35 GiB heap, 0.0/2.2 GiB objects
Result logdir: /home/bdmanley/ray_results/neurovectorizer_train
Number of trials: 1 (1 TERMINATED)
+-------------------+------------+-------+--------+------------------+--------+----------+
| Trial name        | status     | loc   |   iter |   total time (s) |     ts |   reward |
|-------------------+------------+-------+--------+------------------+--------+----------|
| PPO_autovec_00000 | TERMINATED |       |    200 |          21412.3 | 100000 | 0.519459 |
+-------------------+------------+-------+--------+------------------+--------+----------+


